---
title: 13차시 2 :StatQuest(Neural Network 2)
layout: single
classes: wide
categories:
  - Neural Network
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 18. 신경망에서의 어텐션(Attention) 메커니즘
- 출처:[Attention for Neural Networks](https://www.youtube.com/watch?v=PSs6nxngL6k&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=19)

어텐션은 **긴 문장 처리 시 발생하는 문제점을 해결하고, 트랜스포머(Transformers)와 같은 최신 대규모 언어 모델(Large Language Models, LLM)의 기초를 이해하는 데 필수적인 개념**입니다. 

### **18.1 어텐션이 해결하는 문제점**
*   **기존 인코더-디코더 모델의 한계**: 기본적인 인코더-디코더 모델에서는 LSTM(Long Short-Term Memory)을 사용하더라도, 입력 문장 전체를 단일 **'맥락 벡터(context vector)'**로 압축합니다.
*   **정보 손실 문제**: "Let's go"와 같은 짧은 문장에는 문제가 없지만, "Don't eat the delicious looking and smelling pizza"처럼 길고 복잡한 문장의 경우, 문장 초반의 중요한 단어("Don't")가 잊혀져 의미가 완전히 반대가 되는 심각한 문제가 발생할 수 있습니다. 이는 많은 양의 정보를 단일 경로로 전달하기 때문에 발생하는 현상입니다.

### **18.2 어텐션의 핵심 아이디어**
*   **직접적인 접근 경로 추가**: 어텐션의 주요 아이디어는 **인코더에서 디코더로 새로운 경로들을 추가하여, 디코더의 각 단계가 모든 개별 입력 값에 직접 접근할 수 있도록** 하는 것입니다.
*   이는 마치 LSTM이 RNN의 장기 기억 문제를 해결하기 위해 별도의 경로를 제공하는 것과 유사하게, 더 많은 데이터를 처리할 때 인코더-디코더 모델의 장기 기억 문제를 해결합니다.

### **18.3 어텐션 작동 방식 (간략화)**
어텐션은 디코더가 다음 단어를 예측할 때, 입력 문장의 어떤 부분에 '주의(attention)'를 기울여야 할지 결정하는 과정입니다.

*   **유사도 점수 계산**:
    *   먼저, 인코더의 각 LSTM 출력(입력 단어들의 인코딩)과 디코더의 현재 LSTM 출력(지금까지 생성된 단어의 인코딩) 간의 **유사도(similarity)**를 계산합니다.
    *   이 유사도는 주로 **내적(Dot Product)**을 통해 계산되며, 이는 두 수열이 얼마나 유사한지를 빠르고 쉽게 파악할 수 있는 방법입니다 (양수가 클수록 유사하고, 음수가 클수록 반대됨).
*   **소프트맥스 함수 적용**:
    *   계산된 유사도 점수들은 **소프트맥스(Softmax) 함수**를 통과합니다.
    *   소프트맥스는 점수들을 0에서 1 사이의 값으로 변환하며, 이 값들의 합은 1이 됩니다. 이 값들을 **각 인코딩된 입력 단어를 얼마만큼의 비율로 사용해야 하는지에 대한 '가중치'**로 생각할 수 있습니다 (예: 첫 번째 단어 40%, 두 번째 단어 60%).
*   **어텐션 값 생성**:
    *   각 인코딩된 입력 단어(예: "let's", "go")에 해당 가중치를 곱하여 스케일을 조정한 후, 이 스케일된 값들을 모두 더합니다.
    *   이렇게 합산된 값이 바로 **'어텐션 값(Attention Values)'**이 됩니다. 이 값은 현재 디코딩 단계에서 입력 문장의 어떤 부분이 가장 중요한지를 종합적으로 반영합니다.
*   **다음 단어 예측**:
    *   최종적으로, 이 어텐션 값과 디코더의 현재 상태를 완전 연결(fully connected) 레이어에 입력하고, 다시 소프트맥스 함수를 거쳐 다음 출력 단어(예: "vamos")를 예측합니다.

### **18.4 결론 및 중요성**
어텐션이 추가된 인코더-디코더 모델에서 인코더는 거의 동일하게 작동하지만, **디코더의 각 단계는 이제 개별 입력 단어들의 인코딩에 직접 접근할 수 있게 됩니다**. 유사도 점수와 소프트맥스 함수를 통해 각 입력 단어의 인코딩이 다음 출력 단어를 예측하는 데 얼마나 기여해야 할지 결정하는 것입니다.

이러한 어텐션 메커니즘은 **트랜스포머 아키텍처를 이해하는 데 중요한 디딤돌**이며, ChatGPT와 같은 대규모 언어 모델의 기반을 형성합니다. 심지어 어텐션 모델에서는 기존 LSTM이 필요 없어질 수도 있습니다.

## 19. 트랜스포머 신경망
- 출처:[Transformer Neural Networks, ChatGPT's foundation](https://www.youtube.com/watch?v=zxQyTK8quyY&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=20)

Transformer(트랜스포머) 신경망은 ChatGPT의 기반이 되는 기술로, 텍스트 번역과 같은 작업에서 뛰어난 성능을 보이는 인공신경망의 한 종류입니다.

트랜스포머는 크게 **인코더(Encoder)**와 **디코더(Decoder)** 두 부분으로 나뉘며, 영어를 스페인어로 번역하는 과정을 통해 그 원리를 이해할 수 있습니다.

### **19.1 입력 인코딩 (인코더)**

인코더는 입력 문장('Let's go'와 같은 영어 문장)을 숫자로 변환하고, 단어의 순서와 단어 간의 관계를 파악하는 역할을 합니다.

*   **단어 임베딩 (Word Embedding)**
    *   신경망은 숫자만 입력값으로 받기 때문에, 먼저 입력 단어를 숫자로 변환해야 합니다.
    *   **단어 임베딩**은 어휘 목록에 있는 각 단어, 단어 조각 및 기호(예: 문장의 끝을 나타내는 'EOS')를 고유한 입력값으로 사용하고, 비교적 간단한 신경망을 통해 단어를 숫자로 변환합니다.
    *   이때 사용되는 가중치(weights)는 **역전파(backpropagation)**라는 과정을 통해 최적화됩니다. 단어 임베딩 네트워크는 입력 문장의 길이에 상관없이 각 단어나 기호에 대해 동일하게 재사용되어 유연성을 제공합니다.
    *   예를 들어, 'Let's'라는 단어는 1.87과 0.09와 같은 숫자로 표현될 수 있습니다.

*   **위치 인코딩 (Positional Encoding)**
    *   "Squatch eats Pizza"와 "Pizza eats Squatch"는 같은 단어를 사용하지만 의미가 완전히 다릅니다. 따라서 단어의 순서를 파악하는 것이 매우 중요합니다.
    *   **위치 인코딩**은 각 단어의 임베딩 값에 단어 순서에 해당하는 숫자를 추가하여 단어의 위치 정보를 유지하는 기법입니다.
    *   이 숫자는 교대하는 사인(sine) 및 코사인(cosine) 파형 시퀀스에서 파생됩니다. 각 단어는 고유한 위치 값 시퀀스를 가지게 됩니다.

*   **셀프 어텐션 (Self-Attention)**
    *   **셀프 어텐션**은 문장 내의 모든 단어와 각 단어 간의 유사성을 계산하여 단어 간의 관계를 추적하는 메커니즘입니다. 예를 들어, "The pizza came out of the oven and **it** tasted good"이라는 문장에서 'it'이 'pizza'를 가리키는지 'oven'을 가리키는지 파악하는 데 도움을 줍니다.
    *   각 단어에 대해 **쿼리(Query)**, **키(Key)**, **값(Value)**이라는 세 가지 값을 생성합니다.
    *   **쿼리**와 **키** 사이의 **내적(dot product)**을 계산하여 유사성을 측정합니다.
    *   이 유사성 점수는 **소프트맥스(softmax)** 함수를 통해 0에서 1 사이의 값으로 변환되며, 각 단어의 인코딩에 얼마나 많은 비중을 두어야 할지를 결정하는 데 사용됩니다.
    *   **병렬 컴퓨팅(parallel computing)**을 통해 모든 단어의 쿼리, 키, 값을 동시에 계산할 수 있어 처리 속도가 빠릅니다.
    *   복잡한 문장 관계를 파악하기 위해 여러 개의 셀프 어텐션 셀을 쌓을 수 있으며, 이를 **멀티 헤드 어텐션(Multi-head Attention)**이라고 부릅니다.

*   **잔차 연결 (Residual Connections)**
    *   **잔차 연결**은 위치 인코딩된 값을 셀프 어텐션 값에 더하는 것으로, 복잡한 신경망을 더 쉽게 훈련할 수 있도록 돕습니다. 이를 통해 셀프 어텐션 계층은 단어 간의 관계 설정에만 집중하고, 단어 임베딩 및 위치 인코딩 정보 보존 부담을 줄일 수 있습니다.

인코더는 이러한 과정을 통해 입력 단어를 숫자로 인코딩하고, 단어의 위치 및 단어 간의 관계를 파악합니다.

### **19.2 출력 디코딩 (디코더)**

디코더는 인코딩된 입력값을 받아 번역된 출력 문장('vamos'와 같은 스페인어 문장)을 생성합니다.

*   **시작 토큰(EOS/SOS)**: 디코딩 과정은 일반적으로 'EOS'(End Of Sequence) 또는 'SOS'(Start Of Sequence)와 같은 특별한 토큰의 임베딩 값으로 시작됩니다.
*   **단어 임베딩 및 위치 인코딩**: 인코더와 유사하게, 출력 어휘에 대한 단어 임베딩 및 위치 인코딩이 적용됩니다.
*   **디코더 셀프 어텐션**: 출력 문장 내의 단어들 간의 관계를 추적하기 위해 자체적인 셀프 어텐션 계층을 사용합니다. 이때 사용되는 가중치는 인코더의 셀프 어텐션 가중치와 다릅니다.
*   **인코더-디코더 어텐션 (Encoder-Decoder Attention)**
    *   이것은 디코더가 입력 문장의 중요한 단어들을 추적하도록 돕는 핵심 메커니즘입니다.
    *   디코더의 쿼리 값과 인코더의 키 및 값 간의 유사성을 계산하여 입력 문장에서 어떤 단어에 집중해야 하는지를 결정합니다. 이를 통해 번역 과정에서 중요한 정보가 손실되는 것을 방지합니다. 예를 들어 "Don't eat the delicious pizza"에서 'Don't'라는 부정적인 의미가 번역에 반영되도록 돕습니다.
    *   이때 사용되는 가중치 세트는 셀프 어텐션에 사용되는 것과 다릅니다.
*   **잔차 연결**: 인코더와 마찬가지로 디코더에서도 잔차 연결을 사용하여 훈련을 용이하게 합니다.
*   **완전 연결 계층 및 소프트맥스 (Fully Connected Layer & Softmax)**
    *   디코더의 최종 단계에서 두 개의 값이 완전 연결 계층을 통과합니다. 이 계층은 출력 어휘의 각 토큰에 대한 하나의 출력을 가지며, 가중치와 편향을 포함하는 간단한 신경망입니다.
    *   이후 최종 **소프트맥스** 함수를 통해 다음 번역될 단어(예: 'vamos')를 선택합니다.
*   **반복적인 디코딩**: 디코더는 'EOS' 토큰을 출력할 때까지 번역된 단어를 다시 입력으로 사용하여 다음 단어를 예측하는 과정을 반복합니다.

### **19.3 트랜스포머의 주요 특징 요약**

트랜스포머는 다음 네 가지 핵심 기능을 통해 효율적인 텍스트 처리 및 번역을 가능하게 합니다:

*   **단어 임베딩**: 단어를 숫자로 인코딩합니다.
*   **위치 인코딩**: 단어의 위치(순서)를 인코딩합니다.
*   **셀프 어텐션**: 입력 및 출력 문장 내에서 단어 간의 관계를 인코딩합니다.
*   **인코더-디코더 어텐션**: 입력 및 출력 문장 간의 관계를 추적하여 중요한 단어가 번역에서 누락되지 않도록 합니다.
*   **잔차 연결**: 각 하위 단위가 문제의 한 부분에만 집중할 수 있도록 하여 복잡한 신경망 훈련을 용이하게 합니다.

이러한 특징들 덕분에 트랜스포머는 단어를 숫자로 변환하고, 단어의 위치와 관계를 파악하며, **병렬 처리**를 통해 빠르고 효율적으로 훈련될 수 있습니다.

### **19.4 추가적인 고려 사항**

*   **정규화(Normalization)**: 더 큰 어휘와 긴 문장을 다룰 때는 각 단계 후에 값을 정규화하는 것이 성능 향상에 도움이 됩니다.
*   **어텐션 값 스케일링**: 내적을 임베딩 값 수의 제곱근으로 나누어 어텐션 값을 스케일링하면 길고 복잡한 구문을 인코딩하고 디코딩하는 데 도움이 됩니다.
*   **추가 신경망**: 트랜스포머에 추가적인 은닉 계층(hidden layers)이 있는 신경망을 더하여 복잡한 데이터에 더 잘 적합시킬 수 있습니다.

## 20. 디코더-온리 트랜스포머(Decoder-Only Transformer)
- 출처:[Decoder-Only Transformers, ChatGPTs specific Transformer](https://www.youtube.com/watch?v=bQ5BoolX9Ag&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=21)

이 트랜스포머는 **ChatGPT에 사용된 특정 유형의 트랜스포머**입니다.

### **20.1 워드 임베딩 (Word Embedding)**
*   트랜스포머는 뉴럴 네트워크의 일종으로, 입력값으로 숫자를 사용합니다. 따라서 "What is StatQuest?"와 같은 문장의 단어들을 숫자로 변환하는 과정이 필요합니다.
*   **워드 임베딩**은 단어를 숫자로 변환하는 일반적인 방법입니다. 각 단어와 기호(예: 문장 끝을 나타내는 EOS 심볼)를 **토큰(token)**이라고 부르며, 이 토큰들은 워드 임베딩 네트워크를 통해 숫자로 변환됩니다.
*   예를 들어, "What"이라는 단어는 네트워크를 거쳐 두 개의 숫자(-2.38, 0.10)로 표현됩니다. 이 네트워크는 **가중치(weights)**라는 숫자를 사용하며, 이 가중치들은 **역전파(backpropagation)**라는 과정을 통해 최적화됩니다. 이는 트랜스포머를 훈련(training)시켜 단어를 정확하게 예측하도록 할 때 이루어집니다.
*   각 단어에 대해 동일한 워드 임베딩 네트워크를 재사용하므로, 트랜스포머는 다양한 길이의 프롬프트를 처리할 수 있습니다.

### **20.2 위치 인코딩 (Positional Encoding)**
*   단어의 순서는 문장의 의미에 매우 중요합니다. 예를 들어, "Squatch eats pizza"와 "Pizza eats Squatch"는 단어는 같지만 의미가 다릅니다.
*   **위치 인코딩**은 트랜스포머가 단어 순서를 추적하는 기술입니다. 이는 사인(sine) 및 코사인(cosine) 파동 함수를 사용하여 각 단어 임베딩에 대한 고유한 위치 값을 생성합니다. 이 위치 값은 워드 임베딩 값에 더해져서 단어의 순서 정보를 포함하게 됩니다.

### **20.3 마스크드 셀프 어텐션 (Masked Self-Attention)**
*   디코더-온리 트랜스포머는 **마스크드 셀프 어텐션**이라는 메커니즘을 사용하여 단어들 간의 관계를 파악합니다. 이는 예를 들어 문장 내의 "it"이 "pizza"를 지칭하는지 "oven"을 지칭하는지 올바르게 연결하는 데 도움을 줍니다.
*   마스크드 셀프 어텐션은 **각 단어가 자기 자신 및 그 이전에 오는 모든 단어들과 얼마나 유사한지 계산**하여 작동합니다. 이후 이 유사도 점수를 사용하여 각 단어가 디코더-온리 트랜스포머에 의해 어떻게 인코딩되는지에 영향을 미칩니다.
*   세 가지 주요 구성 요소가 있습니다:
    *   **쿼리(Query) 숫자**: 현재 단어에 대한 정보를 나타냅니다.
    *   **키(Key) 숫자**: 현재 단어와 비교할 다른 단어들에 대한 정보를 나타냅니다.
    *   **값(Value) 숫자**: 현재 단어의 인코딩에 사용할 실제 정보를 나타냅니다.
*   유사도는 **닷 프로덕트(dot product)**를 통해 계산되며, 이 점수들은 **소프트맥스 함수(softmax function)**를 거쳐 0에서 1 사이의 값으로 변환되어 각 이전 단어의 "값"을 얼마나 사용할지 결정하는 퍼센티지 역할을 합니다.
*   "마스크드(masked)"라는 이름은 이 기능이 현재 단어 *이후에 오는* 단어들에는 접근하지 않고 오직 자기 자신과 *이전에 오는* 단어들만 본다는 것을 의미합니다. 이러한 특징 때문에 **자기회귀(auto-regressive)** 방식이라고도 불립니다.
*   트랜스포머는 복잡한 문장에서 단어 관계를 더 잘 파악하기 위해 여러 개의 **마스크드 셀프 어텐션 셀(masked self-attention cells)**을 쌓아서 사용하기도 합니다. 각 셀은 고유한 가중치 세트를 가집니다.

### **20.4 잔차 연결 (Residual Connections)**
*   복잡한 뉴럴 네트워크를 더 쉽게 훈련할 수 있도록 하는 장치입니다. 마스크드 셀프 어텐션 값에 위치 인코딩된 값을 다시 더하는 방식으로, 어텐션 계층이 단어 임베딩 및 위치 인코딩 정보를 보존하면서 입력 단어 간의 관계를 설정할 수 있게 합니다.

### **20.5 출력 생성 (Generating Output)**
*   디코더-온리 트랜스포머는 프롬프트 인코딩에 사용한 것과 **정확히 동일한 구성 요소**를 사용하여 다음 단어를 예측하고 응답을 생성합니다.
*   인코딩이 완료되면, 일반적으로 **EOS(End of Sentence/Sequence)** 토큰(또는 SOS 토큰)으로 출력을 생성하기 시작합니다.
*   생성 과정은 다음과 같습니다:
    1.  현재 토큰(예: EOS)을 워드 임베딩 및 위치 인코딩을 통해 숫자로 변환합니다.
    2.  이전 단어들과의 관계를 파악하기 위해 마스크드 셀프 어텐션을 적용합니다. 출력 생성 시에는 **프롬프트의 중요한 단어들을 추적하기 위해 프롬프트 자체도 포함**하여 마스크드 셀프 어텐션을 계산합니다.
    3.  잔차 연결을 추가합니다.
    4.  이 인코딩된 값을 **완전 연결 계층(fully connected layer)**과 **소프트맥스 함수**를 통해 다음 단어를 예측합니다.
    5.  예측된 단어(예: "awesome")가 다시 입력이 되어 이 과정을 반복합니다. 이 과정은 **EOS 토큰이 생성될 때까지** 계속됩니다.

### **20.6 일반 트랜스포머와의 주요 차이점**
*   **디코더-온리 트랜스포머**:
    *   **단일 유닛**으로 입력 인코딩과 출력 생성을 모두 수행합니다.
    *   **마스크드 셀프 어텐션만 사용**하며, 이를 입력과 출력 **모두에 항상 적용**합니다.
*   **일반(Normal) 트랜스포머 (인코더-디코더)**:
    *   입력 인코딩을 위한 **인코더(encoder)**와 출력 생성을 위한 **디코더(decoder)**라는 **두 개의 분리된 유닛**을 사용합니다.
    *   인코더에서는 입력의 모든 단어를 고려하는 **셀프 어텐션(self-attention)**을 사용합니다.
    *   디코더에서는 인코더의 키(key)와 값(value)을 사용하여 입력의 중요한 단어를 추적하는 **인코더-디코더 어텐션(encoder-decoder attention)**을 사용합니다.
    *   훈련 시에만 디코더에서 마스크드 셀프 어텐션을 사용하여 출력 토큰들을 예측합니다.

디코더-온리 트랜스포머의 각 부분은 재사용 가능하며, 프롬프트의 길이가 달라도 처리할 수 있고, 여러 컴퓨팅 코어가 있을 경우 인코딩이 병렬로 빠르게 이루어질 수 있다는 장점이 있습니다.

## 21. 인코더 전용 트랜스포머(Encoder-Only Transformers): BERT와 그 외 모델
- 출처:[Encoder-Only Transformers (like BERT) for RAG](https://www.youtube.com/watch?v=GDN649X_acE&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=22)

### **21.1 트랜스포머의 탄생과 진화**
*   **시작**: 2017년에 처음 등장한 트랜스포머는 '인코더(Encoder)'와 '디코더(Decoder)'라는 두 부분으로 구성되었습니다. 이는 영어 텍스트를 스페인어와 같은 다른 언어로 번역하는 '시퀀스 투 시퀀스(seq2seq)' 또는 '인코더-디코더 모델'에 기반했습니다.
*   **분리 독립**: 얼마 지나지 않아 인코더와 디코더가 각각 독립적으로도 유용하다는 사실이 밝혀졌습니다.
    *   **디코더 전용 트랜스포머**: 텍스트 생성(번역 포함)에 특화되었으며, **ChatGPT**와 같은 모델의 기반이 됩니다.
    *   **인코더 전용 트랜스포머**: **BERT** 및 다른 여러 모델의 기반이 되며, **사물 클러스터링 및 분류**에 탁월한 능력을 보여줍니다. 디코더 전용 모델만큼 주목받지는 못했지만, 강력한 기능을 가지고 있습니다.

### **21.2 인코더 전용 트랜스포머의 세 가지 핵심 구성 요소**
인코더 전용 트랜스포머는 세 가지 기본적인 구성 요소를 통해 입력 텍스트를 처리합니다.

*   **① 단어 임베딩 (Word Embedding)**
    *   **목적**: 단어, 단어 조각, 기호(총칭하여 '토큰')를 숫자로 변환하는 과정입니다. 신경망은 숫자만 처리하기 때문에 이 과정이 필수적입니다.
    *   **핵심 아이디어**: 단순히 각 단어에 무작위 숫자를 할당하는 대신, **유사한 의미와 용도로 사용되는 단어에는 유사한 숫자를 할당**하여 신경망의 학습 효율을 높입니다. 또한, 같은 단어라도 문맥에 따라 다른 의미를 가질 수 있으므로, **각 단어를 하나 이상의 숫자(임베딩)로 표현**하여 다양한 문맥에 쉽게 적응할 수 있도록 합니다.
    *   **생성 방법**: 비교적 간단한 신경망을 훈련시켜 입력 단어 다음에 올 단어를 예측하도록 함으로써 최적의 단어 임베딩을 학습합니다.

*   **② 위치 인코딩 (Positional Encoding)**
    *   **목적**: 단어의 **순서를 추적**하는 데 도움을 줍니다.
    *   **중요성**: "Squatch eats pizza"와 "Pizza eats Squatch"는 같은 단어를 사용하지만 단어 순서에 따라 의미가 완전히 달라지므로, 단어 순서를 파악하는 것이 매우 중요합니다.

*   **③ 자기 주의 (Self-Attention)**
    *   **목적**: 문장 내 단어들 간의 **관계**를 파악하는 데 도움을 줍니다.
    *   **작동 방식**: 문장 내에서 각 단어가 다른 모든 단어(자기 자신 포함)와 얼마나 유사한지 계산합니다. 예를 들어, "The pizza came out of the oven and it tasted good"이라는 문장에서 'it'이 'pizza'를 가리키는지 'oven'을 가리키는지 올바르게 연결하는 데 자기 주의가 사용됩니다. 인코더 전용 트랜스포머는 '자기 주의(Self-Attention)'만을 사용합니다.

### **21.3 문맥 인식 임베딩 (Context-Aware Embeddings)**
위 세 가지 구성 요소(단어 임베딩, 위치 인코딩, 자기 주의)를 결합하면 각 토큰에 대한 새로운 종류의 임베딩이 생성됩니다. 이를 **문맥 인식 임베딩(Context-Aware Embedding)** 또는 **문맥화 임베딩(Contextualized Embedding)**이라고 부릅니다. 이 임베딩은 각 단어의 위치 정보뿐만 아니라 단어들 간의 관계 정보까지 포함합니다.

### **21.4 인코더 전용 트랜스포머의 주요 활용 분야**

문맥 인식 임베딩은 다양한 멋진 작업을 수행하는 데 사용될 수 있습니다:

*   **유사한 문장/문서 클러스터링**: 문맥 인식 임베딩은 유사한 문장이나 문서들을 함께 묶는 데 활용됩니다.
*   **검색 증강 생성 (Retrieval Augmented Generation, RAG)**:
    *   **원리**: 문서를 텍스트 블록으로 나누고, 인코더 전용 트랜스포머를 사용하여 각 블록에 대한 문맥 인식 임베딩을 생성합니다.
    *   **활용**: 사용자가 "피자는 무엇인가요?"와 같은 질문(프롬프트)을 하면, RAG는 이 질문에 대한 임베딩을 생성하고, 문서 블록 중 질문과 가장 유사한 텍스트 덩어리를 찾아 AI 답변 생성에 활용합니다.
*   **분류 (Classification)**: 문맥 인식 임베딩은 일반 신경망이나 로지스틱 회귀 모델의 입력값으로 사용되어 텍스트의 감정(긍정적/부정적) 분류와 같은 다양한 분류 작업을 수행할 수 있습니다. 예를 들어, 링크드인에서 피자에 대한 긍정적 또는 부정적 의견을 분류하는 데 활용될 수 있습니다.

ChatGPT와 같은 디코더 전용 트랜스포머가 많은 주목을 받지만, 인코더 전용 트랜스포머는 문맥 인식 임베딩을 생성하여 클러스터링, RAG, 분류 등 **매우 다양한 설정에서 유용한 기능**을 제공하며, 그 강력함은 결코 간과할 수 없습니다.

## 22. 신경망과 함께하는 강화 학습: 필수 개념
- 출처:[Reinforcement Learning with Neural Networks](https://www.youtube.com/watch?v=9hbQieQh7-o&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=23)

신경망을 훈련시킬 때 **미리 알려진 정답(이상적인 출력값)이 없을 경우** 어떻게 모델을 학습시킬 수 있는지에 대한 핵심적인 방법을 설명합니다. 특히 **정책 경사법(Policy Gradients)**이라는 강화 학습 알고리즘을 사용하여 신경망을 최적화하는 과정을 다룹니다.

### **22.1 문제 상황: 왜 강화 학습이 필요한가?**

프렌치프라이를 먹기 위해 두 가게(Squatch's Fry Shack 또는 Norm's Fry Hut) 중 하나를 선택해야 하는 상황을 가정합니다. 우리가 얼마나 배고픈지(입력값)에 따라 어느 가게가 더 좋을지 결정해야 하지만, 각 가게에서 얼마나 많은 프라이를 받을지는 **미리 알 수 없습니다**.

일반적인 신경망 훈련은 입력값과 그에 대한 **이상적인 출력값(정답)**이 있는 훈련 데이터셋을 사용합니다. 이러한 데이터가 있다면 **역전파(Backpropagation)**를 사용하여 신경망의 가중치나 편향을 조정할 수 있습니다. 하지만 우리 예시처럼 이상적인 출력값을 미리 알 수 없을 때는 역전파를 사용할 수 없으며, 이때 **강화 학습**이 필요합니다.

### **22.2 정책 경사법의 핵심 아이디어: '추측'과 '보상'**

정책 경사법은 미리 정답을 알 수 없을 때, **일단 '추측'을 하고 그 추측의 결과를 바탕으로 학습하는 방식**입니다.

**학습 과정 (프렌치프라이 예시):**

1.  **신경망을 통한 선택**:
    *   우리의 **배고픔 수준(예: 0.0은 배고프지 않음)**을 신경망에 입력합니다.
    *   신경망은 Norm's에 갈 확률(P_norm)과 Squatch's에 갈 확률(P_squatch)을 출력합니다.
    *   이 확률을 바탕으로 **무작위로** 한 가게를 선택합니다 (예: 0.2가 Squatch's 영역에 속해 Squatch's를 선택).

2.  **이상적인 값 '추측'**:
    *   우리가 선택한 가게(예: Squatch's)에 가는 것이 **이상적인 선택이었다고 '추측'**합니다.
    *   이 추측에 따라 이상적인 P_squatch는 1.0, P_norm은 0.0이 됩니다.

3.  **초기 미분값 계산**:
    *   이 '추측'된 이상적인 값과 신경망의 실제 출력값 간의 **차이**를 바탕으로, 최적화하려는 편향(bias)에 대한 **미분값(derivative)**을 계산합니다. 이 미분값은 편향을 어떤 방향으로 얼마나 조정해야 할지 알려주는 초기 지표입니다.

4.  **'보상(Reward)' 부여**:
    *   이제 실제로 선택한 가게(Squatch's)에서 프렌치프라이를 주문합니다.
    *   받은 프라이의 양(예: 배고프지 않은데 적은 양을 받음)과 우리의 배고픔 수준을 고려하여, **우리의 '추측'이 옳았는지(보상 1.0)** 또는 **틀렸는지(보상 -1.0)**를 판단하고 **보상 값을 할당**합니다.
    *   보상 값은 반드시 1.0과 -1.0일 필요는 없으며, 추측의 '옳고 그름'과 '정도'에 따라 양수 또는 음수의 다양한 값을 가질 수 있습니다 (예: 2.0 또는 -2.0).

5.  **미분값 조정**:
    *   계산된 초기 미분값에 **보상 값**을 곱하여 **'업데이트된 미분값(updated derivative)'**을 얻습니다.
    *   이 단계가 매우 중요합니다. 만약 초기 '추측'이 틀렸다면 (즉, 보상이 음수라면), 음수 보상을 곱함으로써 미분값의 **방향이 반전되어** 편향을 올바른 방향으로 조정하도록 합니다.

6.  **경사 하강법(Gradient Descent)으로 최적화**:
    *   업데이트된 미분값을 **경사 하강법**에 적용하여 신경망의 편향을 조정합니다. (예: `새로운 편향 = 이전 편향 - 학습률 * 업데이트된 미분값`).
    *   이를 통해 신경망은 더 나은 결정을 내리도록 학습됩니다.

7.  **반복 학습**:
    *   이 과정을 다양한 배고픔 수준(입력값)에 대해 **반복적으로 수행**합니다.
    *   충분히 반복하면 편향 값은 특정 값 주위에 **수렴하게 되고**, 모델 훈련이 완료됩니다.

### **22.3 학습 결과**

훈련이 완료되면:

*   **배고프지 않을 때(입력 0.0)**는 항상 Squatch's에 갈 확률이 1이 되어, 적은 양의 프라이를 주는 Squatch's를 선택하게 됩니다.
*   **매우 배고플 때(입력 1.0)**는 항상 Norm's에 갈 확률이 1이 되어, 많은 양의 프라이를 주는 Norm's를 선택하게 됩니다.


강화 학습은 **미리 정해진 정답이나 목표 값이 없을 때 신경망을 최적화할 수 있도록 해주는 강력한 방법**입니다. '추측'을 통해 행동하고, 그 행동의 결과에 따라 '보상'을 받아 신경망의 매개변수를 조정함으로써 스스로 올바른 '정책'을 학습해 나갑니다.

## 23. 신경망을 활용한 강화 학습: 정책 경사법의 수학적 세부 사항
- 출처:[Reinforcement Learning with Neural Networks: Mathematical Details](https://www.youtube.com/watch?v=DVGmsnxB2UQ&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=24)

프라이를 먹기 위해 두 가게(Squatch's Fry Shack과 Norm's Fry Hut) 중 한 곳을 선택하는 시나리오를 통해 신경망 훈련 과정을 설명합니다. 중요한 점은 어떤 가게가 더 좋은 프라이를 줄지 미리 알 수 없기 때문에, 일반적인 역전파(Backpropagation) 대신 강화 학습을 사용한다는 것입니다. 목표는 신경망의 **편향(Bias) 값**을 최적화하는 것입니다.

### **23.1 초기 예측 및 행동 선택**
*   **입력값:** 배고픔 정도(예: 0.0은 배고프지 않음)를 신경망에 입력합니다.
*   **확률 계산:** 신경망은 시그모이드(Sigmoid) 활성화 함수를 통해 각 가게(예: P_Norm, P_Squatch)를 선택할 확률을 출력합니다.
*   **행동 선택:** 0과 1 사이의 난수를 생성하여 계산된 확률에 따라 방문할 가게를 무작위로 결정합니다.

### **23.2 "올바른 추측" 가정 및 차이 정량화 (크로스 엔트로피)**
*   **가정:** 선택된 가게(예: Squatch's)로 가는 것이 "올바른 행동"이었다고 가정합니다. 이상적인 경우, 해당 가게의 선택 확률은 1.0이 되어야 합니다.
*   **크로스 엔트로피 사용:** 신경망이 출력한 실제 확률(예: P_Squatch = 0.5)과 이상적인 확률(1.0) 사이의 차이를 **크로스 엔트로피(Cross Entropy)**를 사용하여 정량화합니다.
*   **수식:** Squatch's 방문에 대한 크로스 엔트로피(C_Squatch)는 일반적으로 `-log(P_Squatch)`로 정의되지만, 신경망의 출력이 P_Norm이므로 `-log(1 - P_Norm)`으로 재작성될 수 있습니다.

### **23.3 편향(Bias)에 대한 크로스 엔트로피 미분**
*   **목표:** 편향 값을 최적화하기 위해 크로스 엔트로피(C_Squatch)를 편향(Bias)에 대해 미분합니다.
*   **연쇄 법칙(Chain Rule):** 이 미분은 연쇄 법칙을 사용하여 `(dC_Squatch / dP_Norm) * (dP_Norm / dX) * (dX / dBias)` 순으로 각 부분을 계산하여 이루어집니다.
    *   `dC_Squatch / dP_Norm`: 크로스 엔트로피를 신경망 출력에 대해 미분합니다.
    *   `dP_Norm / dX`: 시그모이드 활성화 함수의 미분 값입니다.
    *   `dX / dBias`: 입력값(hunger), 가중치(weight), 편향(bias)으로 구성된 X를 편향에 대해 미분합니다.
*   **결과:** 이 과정을 통해 현재 편향 값에서 접선의 기울기를 나타내는 최종 미분 값(예: P_Norm=0.5일 때 0.5)을 얻습니다. 이 값은 편향을 어떤 방향으로 업데이트할지에 대한 초기 정보를 제공합니다.

### **23.4 강화 학습: 보상(Reward)을 통한 미분 값 조정**
*   **추측의 불확실성:** 앞서 계산된 미분 값은 "올바른 추측"이라는 가정 하에 나온 것이므로, 실제 결과에 따라 수정이 필요할 수 있습니다.
*   **보상 결정:** 실제로 프라이를 주문한 후 얻은 결과(예: 작은 프라이, 큰 프라이)를 기반으로 **보상(Reward)**을 결정합니다.
    *   **올바른 추측:** 예상과 일치하는 좋은 결과(예: 배고프지 않은데 작은 프라이) → 보상 `1.0`.
    *   **잘못된 추측:** 예상과 다른 좋지 않은 결과(예: 배고프지 않은데 큰 프라이) → 보상 `-1.0`.
*   **업데이트된 미분 값:** 계산된 미분 값에 이 보상 값을 **곱하여 "업데이트된 미분 값"**을 생성합니다.
    *   만약 초기 추측이 **틀렸다면** (보상 -1.0), 음수 보상을 곱함으로써 미분 값의 **방향을 반전시켜 오류를 수정**합니다. 이것이 정책 경사법에서 강화 학습이 핵심적으로 작용하는 부분입니다.

### **23.5 경사 하강법(Gradient Descent)으로 편향 업데이트**
*   **단계 크기 계산:** 업데이트된 미분 값과 학습률(Learning Rate, 예: 1.0)을 사용하여 경사 하강법으로 **단계 크기(Step Size)**를 계산합니다 (`단계 크기 = 학습률 * 업데이트된 미분 값`).
*   **편향 업데이트:** 새로운 편향 값은 `(이전 편향 값 - 단계 크기)`로 계산됩니다. 이 새로운 편향 값으로 신경망을 업데이트하고, 이는 다음 예측에 반영됩니다.

### **23.6 반복 훈련 및 모델 수렴**
*   위의 과정을 다양한 입력값(배고픔 정도 0~1)에 대해 반복적으로 수행합니다.
*   훈련이 진행됨에 따라, 신경망은 특정 배고픔 수준에서 어떤 가게가 최적의 선택인지를 학습하고, 해당 행동의 확률을 높이도록 편향 값을 조정합니다.
*   충분한 훈련 후에는 편향 값이 특정 값(예: -10 근처)으로 수렴하며, 이는 모델 훈련이 완료되었음을 의미합니다.
*   **참고:** 보상 함수는 실제 시나리오에서 훨씬 더 복잡하게 설계될 수 있지만, 그 목적은 항상 추측에 기반한 미분 값을 업데이트하고 필요시 수정하는 것입니다.

이러한 과정을 통해 신경망은 불확실한 환경에서 시행착오를 거쳐 학습하고, 보상을 통해 자신의 결정을 수정하며 최적의 행동 정책을 찾아가는 강화 학습의 원리를 이해할 수 있습니다.

## 24. 사람의 피드백을 활용한 강화 학습(RLHF)
- 출처:[Reinforcement Learning with Human Feedback (RLHF)](https://www.youtube.com/watch?v=qPN_XZcJf_s&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=25)

ChatGPT나 DeepSeek과 같은 대규모 언어 모델(LLM)을 처음부터 구축하고 훈련하는 과정을 통해 RLHF의 개념을 설명합니다. 

### 24.1 **LLM 훈련의 세 가지 주요 단계**

**1. 사전 훈련 (Pre-training)**
*   **목표:** 모델이 다음에 올 토큰(단어 또는 단어의 일부)을 예측하도록 훈련합니다.
*   **과정:**
    *   훈련되지 않은 디코더 전용 트랜스포머 모델은 모든 가중치와 편향이 무작위 값으로 초기화됩니다.
    *   이 모델에 "Stat Quest는 무엇인가요?"와 같은 질문을 하면 "블라블라블라"와 같은 무작위 응답을 생성합니다.
    *   모델은 위키피디아와 같은 방대한 텍스트 코퍼스를 사용하여 다음 토큰을 예측하도록 훈련됩니다. 예를 들어, "A는 일본인"이라는 토큰을 사용하여 "소녀"를 예측하도록 훈련합니다.
    *   이 과정은 일반적인 **역전파(backpropagation)**를 사용하며, 이 단계를 **사전 훈련(pre-training)**이라고 부릅니다.
*   **결과:** 사전 훈련된 모델은 주어진 텍스트 조각에서 다음 토큰을 예측하는 데는 꽤 능숙해지지만, 실제 사용자가 기대하는 "정중하고 유용한" 응답을 생성하지는 못합니다. 이는 모델이 사용자가 원하는 방식과 **정렬되지 않은(unaligned)** 상태임을 의미합니다.

**2. 지도 미세 조정 (Supervised Fine-tuning, SFT)**
*   **목표:** 사전 훈련된 모델을 사용자가 실제로 원하는 방식(정중하고 유용한 응답)과 **정렬하기 시작**합니다.
*   **과정:**
    *   SFT는 **사람이 만든 프롬프트(prompt)와 응답(response) 쌍**으로 구성된 데이터셋을 사용합니다. 예를 들어, "AI를 배우기 좋은 유튜브 채널은 무엇인가요?"라는 프롬프트에 대해 "Stat Quest는 AI를 배우기 좋은 채널입니다."라는 응답을 사람이 직접 작성합니다.
    *   모델은 이 쌍을 사용하여 해당 프롬프트에 대해 특정 응답을 생성하도록 일반적인 **역전파(backpropagation)**를 사용하여 훈련됩니다.
*   **한계:**
    *   프롬프트와 응답을 만드는 데 시간과 비용이 많이 들기 때문에 SFT 데이터셋은 사전 훈련 데이터셋에 비해 **상대적으로 작습니다**.
    *   이로 인해 모델은 SFT 데이터셋에 **과적합(overfit)**될 수 있습니다. 즉, 훈련된 특정 프롬프트에는 적절하게 응답하지만, **새로운 프롬프트에는 잘 일반화되지 않습니다**.

**3. 사람의 피드백을 활용한 강화 학습 (Reinforcement Learning with Human Feedback, RLHF)**
*   **목표:** SFT의 과적합 문제를 해결하고, 모델이 **처음 훈련되지 않은 새로운 프롬프트에도 적절하게 응답**하도록 훈련합니다. 이를 위해 훨씬 더 큰 데이터셋을 만들면서도 사람의 선호도를 얻는 데 필요한 비용을 최소화합니다.
*   **과정:**
    *   **3.1. 다양한 응답 생성:** 특정 프롬프트(예: "AI를 배우기 좋은 유튜브 채널은 무엇인가요?")에 대해 모델은 소프트맥스(softmax) 함수의 출력을 확률로 사용하여 **다양한 응답**을 생성할 수 있습니다. 가장 높은 확률을 가진 토큰이 더 자주 선택되지만, 다른 토큰도 선택될 가능성이 있어 "Stat Quest는 훌륭한 채널이다", "Stat Quest는 멋진 채널이다"와 같은 다른 응답이 나올 수 있습니다.
    *   **3.2. 사람의 선호도 수집 (Human Feedback):** 생성된 여러 응답 중 **두 개씩 짝지어 사람들에게 어떤 응답을 선호하는지 묻습니다**. 사람들이 직접 응답을 작성하는 것보다 선호도를 나열하는 것이 훨씬 빠르고 효율적이며, 이것이 바로 RLHF의 "사람 피드백" 부분입니다.
    *   **3.3. 보상 모델(Reward Model) 훈련:**
        *   SFT를 거친 모델을 복사한 다음, 임베딩(unembedding) 레이어를 제거하고 단일 출력을 갖도록 수정하여 **보상 모델**을 만듭니다.
        *   이 보상 모델은 앞에서 수집한 **사람의 선호도 데이터**를 사용하여 훈련됩니다. 목표는 선호되는 응답에는 **양의 보상(positive reward)**을, 선호되지 않는 응답에는 **음의 보상(negative reward)**을 생성하도록 하는 것입니다.
        *   이 훈련은 OpenAI의 손실 함수(loss function)와 같은 것을 사용하여 모델이 스스로 적절한 보상 값을 찾도록 합니다. 이 손실 함수는 선호되는 응답의 보상(Reward better)과 선호되지 않는 응답의 보상(Reward worse)의 차이를 시그모이드(sigmoid) 및 로그(log) 함수에 넣어 계산하며, 경사 하강법(gradient descent)으로 최적화하기 위해 -1을 곱하여 곡선을 뒤집습니다.
    *   **3.4. 보상 모델을 이용한 원래 LLM 훈련:**
        *   보상 모델 훈련이 완료되면, 이 모델을 사용하여 SFT만 거친 **원래 LLM을 훈련**합니다.
        *   이때 SFT 데이터셋에 없었던 **새로운 프롬프트**를 사용합니다.
        *   원래 LLM이 프롬프트에 대한 응답을 생성하면, **보상 모델이 해당 응답에 대한 보상을 계산**합니다. 응답이 유용하지 않으면 음의 보상을, 유용하고 정중하면 양의 보상을 받습니다.
        *   이 보상 값을 사용하여 강화 학습을 통해 원래 LLM을 훈련함으로써, 모델은 **새로운 프롬프트에 대해서도 정중하고 유용한 응답을 생성**하도록 학습됩니다. 이 과정은 과적합을 피하는 데 도움이 됩니다.

### 24.2 **최종 결과**
*   RLHF를 통해 훈련이 완료된 최종 모델은 언어적으로 훈련되었을 뿐만 아니라, **사람들이 실제로 사용하기 원하는 방식과 정렬**됩니다.
*   따라서 모델에 "Stat Quest는 무엇인가요?"라고 물으면 "블라블라블라" 대신 "Josh Starmer의 Stat Quest는 통계, 머신러닝, AI를 배우기 좋은 멋진 유튜브 채널입니다."와 같은 정중하고 유용한 응답을 생성하게 됩니다.

## 25. 신경망을 위한 텐서(Tensors for Neural Networks)
- 출처:[Tensors for Neural Networks](https://www.youtube.com/watch?v=L35fFDpwIM4&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=26)

신경망(Neural Networks) 맥락에서 사용되는 **텐서(Tensors)**에 대해 명확하게 설명합니다. 특히, 수학 및 물리 커뮤니티에서 정의하는 방식이 아닌, **머신러닝 커뮤니티에서 텐서가 어떻게 사용되는지에 초점**을 맞춥니다.

### **25.. 텐서가 필요한 이유: 신경망의 수학적 복잡성**
신경망은 간단한 모델이라도 많은 수학적 계산을 필요로 합니다. 예를 들어,
*   하나의 입력과 하나의 출력을 가진 간단한 신경망도 훈련 데이터에 맞춰 곡선을 학습시키기 위해 많은 수학이 필요하며,
*   여러 입력과 출력을 가진 신경망은 더 많은 계산을 하고,
*   6x6 픽셀 이미지와 같이 상대적으로 작은 흑백 이미지를 다루는 합성곱 신경망(Convolutional Neural Network)조차도 상당한 양의 수학적 연산을 수행해야 합니다.
하지만 실제 상황에서는 훨씬 더 복잡한 신경망이 사용됩니다. 예를 들어, 256x256 크기의 컬러 이미지(빨강, 초록, 파랑 세 가지 채널로 구성)의 경우 **단 하나의 이미지에 대해서만 196,608개의 픽셀에 대한 수학적 연산**이 필요합니다. 게다가 수많은 이미지를 학습시키고, 비디오 같은 시퀀스 데이터를 처리할 경우 그 수학적 연산의 양은 기하급수적으로 증가합니다.

**이 모든 복잡한 수학적 연산을 효율적으로 처리하기 위해 고안된 것이 바로 텐서입니다**.

### **25.2 머신러닝 관점에서 텐서란?**
신경망을 개발하는 사람의 관점에서 텐서는 다음과 같은 방식으로 활용됩니다:
*   **데이터 저장:** 입력 데이터(예: 이미지의 세 가지 컬러 채널)를 저장하는 방식입니다. 입력은 단일 값처럼 매우 간단할 수도 있습니다.
*   **가중치 및 편향 저장:** 신경망을 구성하는 가중치(weights)와 편향(biases) 값도 텐서로 저장됩니다.

텐서는 기존의 데이터 구조에 **새로운 용어를 붙인 것**처럼 보일 수 있습니다:
*   **0차원 텐서 (Zero-dimensional tensor):** 단일 값(스칼라, scalar).
*   **1차원 텐서 (One-dimensional tensor):** 두 개의 입력 값과 같이 여러 값을 저장하는 배열(array).
*   **2차원 텐서 (Two-dimensional tensor):** 단일 이미지와 같은 행렬(matrix).
*   **n차원 텐서 (N-dimensional tensor):** 비디오와 같은 다차원 행렬 또는 다차원 배열(nd array).

신경망을 만드는 사람의 입장에서는 텐서가 기존에 있던 용어를 그저 바꾼 것 같아 **"지루하게" 느껴질 수도 있습니다**.

### **25.3 텐서의 핵심 가치: "정말 중요한 점"**
하지만 텐서가 단순한 이름 변경을 넘어 중요한 이유는 다음과 같습니다:
*   **하드웨어 가속(Hardware Acceleration):** 텐서는 일반적인 스칼라, 배열, 행렬과 달리 **하드웨어 가속을 활용하도록 설계**되었습니다. 이를 통해 데이터에 대한 모든 수학적 연산을 **상대적으로 빠르게** 수행할 수 있습니다. 주로 **GPU(Graphics Processing Units)**와 같은 특수 칩으로 속도를 높이지만, **TPU(Tensor Processing Units)**와 같이 텐서에 특화된 칩도 있습니다.
*   **자동 미분(Automatic Differentiation)을 통한 역전파(Backpropagation) 처리:** 신경망 훈련의 중요한 부분 중 하나는 최적의 가중치와 편향을 추정하기 위해 **역전파(Backpropagation)**를 사용하는 것입니다. 역전파는 많은 미분 계산과 체인 룰(chain rule)을 수반하는데, 텐서는 **자동 미분 기능으로 이 역전파 과정을 자동으로 처리**해줍니다. 이 덕분에 개발자는 복잡한 미분 계산에 신경 쓰지 않고도 복잡한 신경망을 만들 수 있습니다.

**요약하자면, 신경망을 위한 텐서는 데이터를 담고(입력 데이터, 가중치, 편향), 하드웨어 가속을 통해 신경망이 필요한 모든 수학 연산을 빠르게 수행하며, 자동 미분으로 역전파를 처리합니다**.

## 26. 신경망을 위한 필수 행렬 대수학
- 출처:[Essential Matrix Algebra for Neural Networks](https://www.youtube.com/watch?v=ZTt9gsGcdDo&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=27)

### **26.1 신경망과 행렬 대수학의 필요성**
아무리 정교한 신경망 모델(예: 트랜스포머)이라도 상대적으로 간단한 다이어그램으로 설명할 수 있지만, PyTorch 같은 도구를 사용하여 신경망을 코딩하거나 관련 문서를 읽거나 최신 연구 논문을 이해하려면 **행렬 방정식에 대한 이해가 필수적**입니다. 행렬 방정식은 신경망을 매우 **간결하게(compact way) 설명**하는 방법을 제공하기 때문입니다.

### **26.2 선형 변환(Linear Transformation)의 이해**
행렬 대수학의 핵심 중 하나는 **선형 변환(Linear Transformation)**을 다루는 데 특히 유용하다는 것입니다.
*   **선형 변환**이란 입력 값의 **일정한 변화(constant change)가 출력 값의 일정한 변화로 이어지는(constant change in the output)** 변환을 의미합니다. 마치 직선의 기울기처럼 변화의 양이 항상 일정한 것이죠.
*   반대로 **비선형 변환(Nonlinear Transformation)**은 입력 값의 일정한 변화가 출력 값의 다른 변화량으로 이어지는 변환입니다. 곡선의 기울기가 변하는 것과 유사합니다.
*   신경망에서는 이러한 선형 변환이 중요한 역할을 합니다.

### **26.3 행렬(Matrices)의 기본 개념**
행렬은 데이터를 구조화하여 표현하는 방법입니다.
*   **행렬 표기법:** 입력 데이터(예: x, y 좌표)는 **행렬(matrix)** 형태로 표현될 수 있습니다.
*   **행렬의 종류:**
    *   **행렬(Row Matrix) 또는 행 벡터(Row Vector):** 한 개의 행과 여러 개의 열로 구성된 행렬 (예: 1x2 행렬). 이를 **1차원 행렬(one-dimensional matrix)**이라고도 합니다.
    *   **2x2 행렬:** 두 개의 행과 두 개의 열로 구성된 행렬. 이를 **2차원 행렬(two-dimensional matrix)**이라고도 합니다.
*   **전치(Transpose):** 행렬의 행을 열로, 열을 행으로 바꾸는 것을 **전치(transposing)**라고 하며, **'t'**라는 윗첨자로 표기합니다. 이는 행렬의 차원을 변경할 수 있습니다 (예: 1x2 행렬이 2x1 행렬로 변경).

### **26.4 행렬 곱셈(Matrix Multiplication)의 중요성**
행렬 곱셈은 신경망의 핵심 연산입니다.
*   **계산 방식:** 행렬 곱셈은 **"행 by 열(row by column)"** 방식으로 이루어집니다. 첫 번째 행렬의 행과 두 번째 행렬의 열에 있는 숫자들을 각각 곱한 다음 모두 더하는 방식입니다.
*   **주요 이유 (핵심): 여러 변환의 결합**
    *   행렬 곱셈이 복잡해 보이지만, **여러 개의 선형 변환을 하나의 단일 변환으로 통합(combine a sequence of transformations into a single transformation)할 수 있게 해주는 핵심 기능**을 제공합니다. 이는 중간 단계를 거치지 않고 원래 지점에서 최종 지점으로 직접 이동할 수 있게 합니다.
*   **곱셈 순서의 중요성:** 행렬 곱셈은 교환법칙이 성립하지 않으며, **순서를 바꾸면 결과가 달라지거나 아예 계산이 불가능할 수 있습니다**. 첫 번째 행렬의 열 개수와 두 번째 행렬의 행 개수가 일치해야 곱셈이 가능합니다.

### **26.5 신경망에 행렬 대수학 적용하기**
신경망은 기본적으로 일련의 선형 변환과 비선형 활성화 함수(activation function)의 조합으로 볼 수 있습니다.
*   **입력, 가중치, 편향:** 신경망은 입력 값(예: 꽃잎/꽃받침 너비)을 **가중치(weights)**라는 계수를 포함하는 행렬과 곱하고, **편향(bias) 값**을 더합니다. 이 가중치와 편향 값들은 **역전파(backpropagation)**라는 과정을 통해 학습됩니다.
*   **활성화 함수:** 이 선형 변환의 결과에 ReLU(Rectified Linear Unit)와 같은 **활성화 함수**를 적용하여 비선형성을 추가합니다.
*   **최종 예측:** 이러한 과정을 여러 번 반복하여 최종적으로 원하는 출력(예: 붓꽃의 종)을 예측합니다.
*   **PyTorch의 `nn.Linear` 클래스:** PyTorch의 `nn.Linear` 클래스는 신경망의 한 부분을 담당하며, **입력 값에 가중치를 곱하고 편향을 더하는 선형 변환**을 수행합니다. 이 클래스의 이름도 선형 변환을 수행하기 때문에 붙여진 것입니다.

### **26.6 행렬과 텐서 (Matrix vs. Tensor)**
비록 행렬과 텐서 사이에 기술적인 차이가 있지만, **개념적으로 많은 유사점**을 가집니다. 에러 메시지 등을 통해 1차원 행렬(하나의 행 또는 열) 대신 최소 2차원 이상의 행렬을 기대하는 경우를 볼 수 있습니다.

### **26.7 최신 신경망의 예시: 어텐션(Attention)**
ChatGPT 같은 트랜스포머(Transformers) 아키텍처에서 사용되는 **어텐션(Attention)** 메커니즘도 행렬 대수학을 기반으로 합니다. 여기서는 'Q', 'K', 'V' 세 가지 행렬을 사용하며, 행렬 곱셈, 전치, 나눗셈, 소프트맥스(SoftMax) 함수 등을 통해 복잡한 계산을 수행합니다. 이러한 복잡한 메커니즘도 행렬 대수학을 통해 간결하게 표현하고 계산할 수 있습니다.

결론적으로, 신경망을 이해하고 개발하기 위해서는 **행렬을 사용하여 데이터를 표현하고, 행렬 곱셈을 통해 여러 변환을 효율적으로 결합하며, 이러한 연산들이 신경망의 동작 원리를 어떻게 구성하는지 파악하는 것이 매우 중요합니다.**

## 27. 트랜스포머 신경망의 행렬 수학
- 출처:[The matrix math behind transformer neural networks](https://www.youtube.com/watch?v=KphmOJnLAdI&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=28)


### 27.1 트랜스포머 행렬 표기의 중요성
*   행렬 표기를 이해하면 **트랜스포머와 일반적인 신경망을 코딩하는 것이 훨씬 쉬워진다**고 강조합니다.
*   특히, 이 영상에서는 **인코더-디코더 트랜스포머**를 다루는데, 이는 모든 유형의 트랜스포머에 필요한 모든 것을 포함하고 있기 때문입니다.
*   예시로 "Let's go"를 스페인어 "Vamos"로 번역하는 과정을 통해 행렬 연산을 설명합니다.

### 27.2 인코더(Encoder)의 수학적 처리 과정

1.  **단어 임베딩(Word Embeddings) 생성**:
    *   입력 문구 "SOS let's go"를 구성하는 각 토큰(SOS: Start Of Sequence)에 대해 **단어 임베딩 값**을 결정합니다.
    *   각 입력 토큰은 워드 임베딩 네트워크를 통해 처리되며, 이는 입력 값 행렬에 **가중치(weights)**를 포함하는 행렬을 곱하는 **행렬 곱셈**으로 표현됩니다. 이 과정을 통해 각 토큰의 단어 임베딩이 생성됩니다.

2.  **위치 인코딩(Positional Encoding) 추가**:
    *   단어 임베딩에 **위치 인코딩**을 더합니다. 이는 토큰의 순서 정보를 유지하기 위함입니다.
    *   위치 인코딩 값은 사인(sine) 및 코사인(cosine) 곡선에서 파생된 **y-축 좌표**이며, 실제로는 미리 계산되어 저장된 값을 사용합니다.
    *   이 과정을 통해 **단어 임베딩과 위치 인코딩이 합쳐진 인코딩된 값**을 얻습니다.

3.  **셀프 어텐션(Self-Attention) 계산**:
    *   인코딩된 값을 사용하여 **쿼리(Query, Q), 키(Key, K), 값(Value, V)**을 계산합니다.
    *   예를 들어, 쿼리 값은 인코딩된 토큰 값에 **쿼리 가중치(Query Weights)** 행렬을 곱하여 얻습니다. 키와 값도 같은 방식으로 계산됩니다.
    *   **Q 행렬과 K 행렬의 전치(transpose)를 곱합니다 (Q * K^T)**. 이는 각 토큰의 쿼리와 키 간의 **내적(Dot Product)**을 계산하여 **비정규화된 유사도(unscaled similarity)**를 얻는 과정입니다. 내적은 두 요소 간의 유사도를 측정하는 데 사용됩니다.
    *   계산된 비정규화된 유사도를 **d_k(키 행렬의 차원)의 제곱근**으로 나누어 **스케일링**합니다. 이는 성능을 향상시키는 것으로 알려져 있습니다.
    *   스케일링된 유사도 행렬의 각 행에 **소프트맥스(SoftMax) 함수**를 적용합니다. 소프트맥스 결과는 각 행의 합이 1이 되도록 하여, 각 토큰 간의 **관계 요약**을 백분율로 나타냅니다. 예를 들어, SOS 토큰이 자신과 1% 유사하고 'lets'와 99% 유사하다는 식입니다.
    *   이 **백분율 행렬에 V 행렬을 곱하여** 최종 **셀프 어텐션 점수**를 계산합니다.

4.  **잔차 연결(Residual Connections) 추가**:
    *   계산된 셀프 어텐션 점수에 위치 인코딩 직후의 원래 값을 다시 더해 **잔차 연결**을 만듭니다. 이 결과가 인코더의 최종 출력입니다.

### 27.3 디코더(Decoder)의 수학적 처리 과정 (훈련 중)

1.  **디코더 초기화 및 교사 강요(Teacher Forcing)**:
    *   훈련 시 목표는 "let's go"를 스페인어 "Vamos"와 "EOS" (End Of Sequence)로 번역하는 것입니다.
    *   디코더는 **SOS 토큰**으로 초기화되며, 첫 번째 디코더 유닛은 "Vamos"를 출력해야 합니다.
    *   훈련 중에는 두 번째 디코더가 **알려진 출력 값("Vamos")**으로 초기화되는데, 이를 **교사 강요**라고 하며 훈련 속도를 높이는 데 사용됩니다.
    *   디코더는 SOS 및 Vamos 토큰을 입력으로 받아 임베딩 값을 추출합니다.

2.  **단어 임베딩 및 위치 인코딩 (디코더)**:
    *   인코더와 마찬가지로 디코더 입력 토큰(SOS, Vamos)에 대해 단어 임베딩을 생성하고 위치 인코딩을 추가합니다.

3.  **마스킹된 셀프 어텐션(Masked Self-Attention) 계산**:
    *   디코더 전용 가중치를 사용하여 Q, K, V 행렬을 계산하고, 비정규화된 내적 유사도를 계산합니다.
    *   **마스킹(Masking)** 개념이 도입됩니다. 훈련 중이라도 특정 토큰이 **미래의 토큰을 "엿보는" 것을 방지**하기 위해 마스크 행렬을 사용하여 계산에 포함되지 않아야 하는 값에 **음의 무한대**를 추가합니다.
    *   이렇게 마스킹된 유사도 행렬에 소프트맥스 함수를 적용하면, SOS 토큰은 자신과 100% 유사하고 미래 토큰과는 0% 유사하게 됩니다.
    *   마지막으로, 마스킹된 백분율에 V 행렬을 곱하여 **마스킹된 셀프 어텐션 점수**를 얻습니다.

4.  **잔차 연결 추가 (디코더)**:
    *   계산된 마스킹된 셀프 어텐션 점수에 원래의 단어 및 위치 인코딩을 더합니다.

5.  **인코더-디코더 어텐션(Encoder-Decoder Attention) 계산**:
    *   인코더-디코더 어텐션은 일반적인 셀프 어텐션과 유사하지만, **Q 행렬은 디코더의 값으로 생성**되고, **K와 V 행렬은 인코더의 출력 행렬로 생성**됩니다.
    *   이후 인코더에서와 동일한 방식으로 어텐션 점수를 계산합니다.

6.  **잔차 연결 및 완전 연결 계층(Fully Connected Layer)**:
    *   다시 잔차 연결을 추가합니다.
    *   이 값들을 **완전 연결 계층**을 통과시킵니다. 이 계층은 각 토큰에 대해 계산된 두 개의 입력 값을 받아, 출력 단어장 내의 각 토큰에 해당하는 5개의 출력 값을 생성합니다.
    *   행렬 곱셈을 통해 이 계산이 동시에 이루어집니다.
    *   **편향(bias) 항**을 더하여 완전 연결 계층의 출력을 얻습니다.

7.  **소프트맥스 함수를 통한 최종 출력**:
    *   완전 연결 계층의 출력에 소프트맥스 함수를 적용합니다.
    *   이 결과 행렬은 각 디코더 사본의 출력을 포함하며, 가장 높은 값을 가진 토큰이 트랜스포머가 생성하는 최종 출력 토큰이 됩니다 (예: "Vamos" 다음 "EOS").

이 과정을 통해 트랜스포머 신경망이 행렬 연산을 활용하여 입력 문장을 번역하는 방식과, 특히 인코더-디코더 구조 내에서 셀프 어텐션이 어떻게 작동하는지 상세히 이해할 수 있습니다.

## 28. PyTorch 소개
- 출처:[The StatQuest Introduction to PyTorch](https://www.youtube.com/watch?v=FHdlXe1bSe4&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=29)

### **28.1 신경망의 목표 설정 및 준비물**
이 튜토리얼에서는 특정 약물 용량이 바이러스에 얼마나 효과적인지 예측하는 간단한 데이터셋을 사용합니다. 낮은 용량과 높은 용량은 효과가 없었지만, 중간 용량은 효과가 있었던 데이터를 모델링합니다. 이를 구현하기 위해 다음 Python 모듈을 설치하고 임포트합니다:
*   **`torch` (PyTorch)**: 텐서를 생성하고 모든 수치 값을 저장하며, 가속화된 연산 및 자동 미분 기능을 활용합니다.
*   **`torch.nn`**: 신경망의 가중치(weights)와 편향(biases) 텐서를 신경망의 일부로 만듭니다.
*   **`torch.nn.functional`**: ReLU와 같은 활성화 함수를 제공합니다.
*   **`torch.optim.sgd` (SGD)**: 확률적 경사 하강법(Stochastic Gradient Descent)으로 신경망을 데이터에 맞추기 위한 옵티마이저입니다.
*   **`matplotlib` 및 `seaborn`**: 멋진 그래프를 그리는 데 사용됩니다.

### **28.2 PyTorch로 신경망 구축하기 (basic_nnn 클래스)**
신경망을 구축하기 위해 `basic_nnn`이라는 새로운 Python 클래스를 생성하며, 이 클래스는 PyTorch의 `nn.Module` 클래스를 상속받습니다.
*   **`__init__` 메서드**:
    *   `nn.Module`의 초기화 메서드를 호출합니다.
    *   신경망의 가중치와 편향을 초기화합니다. 각 가중치와 편향은 **신경망 파라미터(Neural Network Parameter)**로 생성됩니다. 이를 파라미터로 만들면 나중에 최적화할 수 있습니다.
    *   `requires_grad=False`로 설정하여 특정 가중치(예: W00)는 최적화할 필요가 없음을 PyTorch에 알립니다.
*   **`forward` 메서드**:
    *   입력 값(약물 용량)이 신경망을 통과하여 출력 값(예측된 효과)을 계산하는 방법을 정의합니다.
    *   입력 값에 가중치를 곱하고 편향을 더한 후 `f.relu` (ReLU 활성화 함수)를 적용합니다.
    *   여러 개의 ReLU 활성화 함수를 사용하여 입력 값을 처리하고, 그 결과를 합산하여 최종 편향을 더한 후 다시 ReLU를 적용하여 최종 출력 값을 반환합니다.
    *   이 메서드는 주어진 입력 값에 대해 신경망을 통한 **순방향 전달(forward pass)**을 수행하여 출력 값을 계산합니다.

### **28.3 신경망 작동 확인**
구축한 신경망이 의도한 대로 작동하는지 확인하기 위해:
*   `torch.linspace` 함수를 사용하여 0에서 1 사이의 다양한 약물 용량(입력)을 담은 텐서를 생성합니다.
*   `basic_nnn` 클래스로부터 신경망 인스턴스(`model`)를 생성하고, 이 입력 텐서를 모델에 전달합니다. 모델에 입력 텐서를 전달하면 자동으로 `forward` 메서드가 호출됩니다.
*   `matplotlib`과 `seaborn`을 사용하여 입력 용량과 모델의 예측 효과를 그래프로 그립니다. 이 그래프는 신경망이 학습 데이터에 맞는 굽은 형태를 생성하는지 시각적으로 보여줍니다.

### **28.4 신경망 최적화 (훈련)**
만약 신경망의 편향 중 하나가 최적의 값이 아니라고 가정하고, PyTorch를 사용해 **백프로파게이션(Backpropagation)**으로 이를 최적화합니다.
*   **`basic_nnn_train` 클래스**: 최적화할 신경망을 만들기 위해 `basic_nnn`을 복사하고, 최적화할 편향(`final_bias`)의 초기 값을 0.0으로 설정하며, **`requires_grad=True`**로 설정하여 PyTorch에 이 파라미터를 최적화해야 함을 알립니다.
*   **훈련 데이터 생성**: 입력 용량(0, 0.5, 1)과 관찰된 출력 값(0, 1, 0)을 담은 텐서(`inputs`와 `labels`)를 생성합니다.
*   **옵티마이저 객체 생성**: `torch.optim.SGD`를 사용하여 옵티마이저 객체를 생성하고, `model.parameters()`를 인자로 전달하여 `requires_grad=True`로 설정된 모든 파라미터를 최적화하도록 합니다. 학습률(learning rate)도 설정합니다.
*   **경사 하강법(Gradient Descent) 훈련 루프**:
    *   **에포크(Epoch)**: 모든 훈련 데이터를 한 번 처리하는 과정을 에포크라고 합니다. 이 루프는 100번의 에포크 동안 반복됩니다.
    *   **손실(Loss) 계산**: 각 에포크 내에서 훈련 데이터의 각 포인트에 대해 다음을 수행합니다:
        *   모델의 예측 출력 값을 얻습니다.
        *   예측 값과 알려진 참 값 간의 차이(잔차)를 기반으로 손실 함수(예: 제곱 잔차)를 사용하여 **손실**을 계산합니다. 손실은 모델이 데이터에 얼마나 잘 맞는지 측정합니다.
    *   **`loss.backward()`**: 손실 함수를 최적화하려는 파라미터(예: `b_sub_final`)에 대해 미분 값을 계산합니다. 이 메서드는 각 훈련 데이터 포인트에 대한 미분 값을 누적합니다.
    *   **`optimizer.step()`**: `loss.backward()`를 통해 계산되고 누적된 미분 값을 사용하여 옵티마이저가 `b_sub_final`의 값을 개선하기 위한 작은 단계를 수행합니다.
    *   **`optimizer.zero_grad()`**: 다음 반복에서 새로운 미분 값이 이전 미분 값에 누적되는 것을 방지하기 위해 현재 저장된 미분 값을 0으로 초기화합니다.

### **28.5 최적화된 모델 확인**
훈련 루프가 완료되면 `final_bias`의 최적화된 최종 값을 확인하고, 이 값으로 업데이트된 모델의 출력 값을 다시 그래프로 그려 초기 데이터에 얼마나 잘 맞는지 시각적으로 검증합니다. 이 과정을 통해 신경망이 예상대로 작동하며 훈련 데이터에 잘 맞는다는 것을 확인할 수 있습니다.

## 29. PyTorch와 Lightning을 활용하여 신경망을 코딩
- 출처:[Introduction to Coding Neural Networks with PyTorch and Lightning](https://www.youtube.com/watch?v=khMzi6xPbuM&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=30)

### **29.1 기본 PyTorch 신경망 코딩의 복습 및 한계점**
이전 장에서 간단한 데이터셋에 맞춰 간단한 신경망을 코딩했습니다. 이때 가중치(weights)와 편향(biases) 및 데이터를 신경망에 통과시키는 코드를 포함하는 클래스를 만들었고, 신경망을 역전파(backpropagation)로 최적화하는 코드는 클래스와는 완전히 분리해서 작성했습니다.

하지만 PyTorch만 사용할 경우 몇 가지 어려움이 있었습니다:
*   **학습률(learning rate) 설정의 어려움**: 경사 하강법(gradient descent)을 위한 좋은 학습률을 찾는 것이 항상 쉽지 않았습니다.
*   **코드의 가독성 및 작성의 복잡성**: 신경망 훈련 코드가 읽고 쓰기 어려웠습니다.
*   **GPU/TPU 사용 시 코드 변경의 필요성**: 학습 가속화를 위해 GPU나 TPU를 사용하려면 코드를 상당히 변경해야 했습니다. 예를 들어, 단일 CPU에서 작동하는 코드를 여러 GPU 시스템으로 옮기려면 많은 수정이 필요했습니다.

### **29.2 Lightning의 도입 및 장점**
**PyTorch에 Lightning을 결합하면 이러한 문제들을 해결하고 더 쉽게 코드를 작성하며 기능을 향상시킬 수 있습니다**.

**2.1. PyTorch와 Lightning의 결합**
*   **필요한 모듈 임포트**: `torch`로 텐서(tensors)를 생성하고, `torch.nn`으로 가중치 및 편향 텐서를 신경망의 일부로 만들며, `torch.nn.functional`로 활성화 함수를 사용합니다. `SGD`를 임포트하여 확률적 경사 하강법(Stochastic Gradient Descent)을 사용하고, **Lightning을 `L`로 임포트하여 훈련을 더 쉽게 코딩합니다**.
*   **데이터 처리 간소화**: `torch.utils.data`에서 `TensorDataset`과 `DataLoader`를 임포트하여 더 큰 데이터셋으로 작업할 때 편리함을 제공합니다.
    *   **`DataLoader`의 유용성**: 많은 데이터를 다룰 때 `DataLoader`는 데이터를 배치(batches)로 쉽게 접근하게 하고, 각 에포크(epoch)마다 데이터를 섞는 것을 쉽게 하며, 디버깅을 위해 데이터의 일부만 빠르게 훈련시키는 것을 가능하게 합니다.
*   **`LightningModule` 상속**: 신경망 클래스를 생성할 때, 기존 PyTorch에서 `nn.module`을 상속하던 것과 달리 **`LightningModule`을 상속합니다**.
*   **코드 통합**: PyTorch만 사용할 때는 가중치와 편향을 추적하는 클래스와 데이터를 신경망에 통과시키는 `forward` 함수를 만든 다음, `b_final`을 최적화하는 코드를 별도로 작성했습니다. 그러나 **Lightning을 추가하면 신경망과 관련된 모든 코드를 같은 장소에 통합합니다**. 즉, `init` 메서드(가중치, 편향, 학습률), `forward` 메서드(데이터 통과), `configure_optimizers` 메서드(최적화 방법 설정), `training_step` 메서드(손실 계산)를 모두 클래스 내에 정의합니다.

**2.2. Lightning을 이용한 신경망 훈련의 간소화**
*   **자동 학습률 찾기**:
    *   이전에는 학습률을 직접 찾아야 했지만, Lightning에서는 `Lightning Trainer`를 생성한 후 `tuner.lr_find()`를 호출하여 **최적화된 학습률을 자동으로 찾을 수 있습니다**.
    *   `lr_find` 함수는 최소 및 최대 학습률 사이에서 여러 후보 학습률을 생성하고 테스트하여 가장 적절한 값을 제안합니다. 이렇게 찾아진 학습률은 모델에 설정될 수 있습니다.
*   **간소화된 훈련 루프**:
    *   PyTorch만 사용할 때는 옵티마이저 객체를 생성하고, `for` 루프를 통해 에포크별로 예측 값 계산, 손실 계산, `loss.backward()`를 통한 미분 계산, `optimizer.step()`을 통한 최적화, `optimizer.zero_grad()`를 통한 그래디언트 초기화 등 많은 코드를 작성해야 했습니다.
    *   Lightning을 사용하면, 복잡한 훈련 루프 코드를 작성하는 대신 **`training_step` 함수 내에서 손실(loss)을 계산하는 코드만 작성하면 됩니다**.
    *   `trainer.fit(model, dataloader)` 함수를 호출하면, Lightning 트레이너가 `configure_optimizers`를 통해 옵티마이저를 설정하고, `training_step`을 호출하여 손실을 계산하며, 개발자가 직접 코딩하지 않아도 `optimizer.zero_grad()`, `loss.backward()`, `optimizer.step()`과 같은 일련의 과정을 자동으로 처리하여 파라미터를 최적화합니다.
*   **GPU/TPU 가속화의 용이성**:
    *   CPU는 신경망 훈련에 느릴 수 있으며, GPU는 훨씬 많은 코어를 가지고 있어 훈련 속도를 10배 또는 100배 빠르게 할 수 있습니다. PyTorch만 사용할 때는 텐서를 수동으로 GPU로 이동시키고 관리하는 것이 복잡했습니다.
    *   Lightning을 사용하면, 트레이너 객체를 생성할 때 `accelerator`를 `"auto"`로 설정하고 `devices`를 `"auto"`로 설정함으로써 **Lightning이 사용 가능한 GPU를 자동으로 감지하고 활용하게 할 수 있습니다**.
    *   이로 인해 코드를 수정하지 않고도 단일 CPU 노트북에서 테스트한 코드를 여러 GPU가 있는 고급 컴퓨팅 환경으로 쉽게 옮길 수 있습니다.

### **29.3 요약**
Lightning은 PyTorch와 함께 사용될 때 신경망 코딩의 **복잡성을 줄이고, 훈련 과정을 자동화하며, 하드웨어 가속기(GPU/TPU) 활용을 극적으로 단순화**하여 AI 입문자와 전문가 모두에게 강력하고 효율적인 도구를 제공합니다. 동영상에 사용된 모든 코드는 무료로 다운로드할 수 있습니다.

## 30. PyTorch + Lightning을 이용한 Long Short-Term Memory (LSTM)
- 출처:[Long Short-Term Memory with PyTorch + Lightning](https://www.youtube.com/watch?v=RHGiXPuo_pI&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=31)

LSTM의 개념을 직접 코드로 구현하는 과정과 PyTorch의 내장 `nn.LSTM` 함수를 활용하는 두 가지 방법을 소개하며, Lightning 라이브러리가 훈련 과정을 얼마나 쉽게 만드는지 보여줍니다.

### **30.1 LSTM의 핵심 개념 및 동작 원리 (이론)**
LSTM은 **순차 데이터(sequential data)에서 과거의 중요한 정보를 기억하여 미래를 예측**하는 데 사용됩니다. 영상에서는 두 회사의 주가 데이터를 예시로 들며 이를 설명합니다.
*   **예시**: A 회사와 B 회사의 주가 데이터가 주어졌을 때, LSTM은 1일차 데이터를 기억하여 5일차 주가를 정확하게 예측하는 것을 목표로 합니다.
*   **LSTM 단위의 작동 방식**: 이론적으로 LSTM 단위가 어떻게 작동하는지 설명한 후, 이를 PyTorch와 Lightning으로 코딩합니다.

### **30.2 LSTM 직접 코딩하기 (Coding from Scratch)**

영상의 주요 부분은 LSTM 단위를 처음부터 직접 코딩하는 과정을 상세히 설명하는 것입니다.
*   **필수 라이브러리 임포트**:
    *   `torch`: 텐서(tensor) 생성 및 수치 값 저장.
    *   `torch.nn`: 가중치(weight)와 편향(bias) 텐서를 신경망의 일부로 만듦.
    *   `torch.nn.functional`: 활성화 함수(activation function) 사용.
    *   `Adam`: 최적화 함수(optimizer)로, SGD보다 빠르게 최적 값을 찾음.
    *   `lightning as L`: 훈련 코드를 더 쉽게 만듦.
    *   `torch.utils.data.TensorDataset` 및 `DataLoader`: 데이터 로딩 및 배치 처리에 유용.
*   **`LstmByHand` 클래스 정의**:
    *   **`lightning.LightningModule` 상속**: 훈련을 용이하게 하기 위해 `lightning.LightningModule`을 상속받아 클래스를 정의합니다.
    *   **`init` 메서드**:
        *   **가중치 및 편향 초기화**: 모든 가중치와 편향 텐서를 생성하고 초기화합니다.
        *   **초기화 방식**: 가중치는 평균이 0, 표준편차가 1인 **정규 분포(normal distribution)에서 무작위로 생성된 값**으로 초기화하고, 편향은 0으로 초기화합니다.
        *   **`requires_grad=True`**: 이 값들을 최적화할 것이므로 `requires_grad`를 `True`로 설정합니다.
    *   **`lstm_unit` 메서드**:
        *   **LSTM 수학 연산**: LSTM 단위 내의 모든 수학 연산을 수행하는 메서드입니다.
        *   **3단계 과정**:
            1.  **기억할 장기 기억(long-term memory)의 비율 결정**: 시그모이드(sigmoid) 활성화 함수를 사용하여 현재 장기 기억에서 얼마를 기억할지 결정합니다.
            2.  **새로운 잠재적 장기 기억 생성 및 기억할 비율 결정**: 새로운 잠재적 장기 기억을 만들고, 그중 얼마를 기억할지 시그모이드 함수를 통해 결정합니다. 이 잠재적 장기 기억은 tanh 활성화 함수를 거쳐 생성됩니다.
            3.  **새로운 단기 기억(short-term memory) 생성 및 출력 비율 결정**: 업데이트된 장기 기억의 tanh 값에 기반하여 새로운 단기 기억을 만들고, 그중 얼마를 출력할지 시그모이드 함수를 통해 결정합니다.
        *   업데이트된 장기 기억과 단기 기억을 반환합니다.
    *   **`forward` 메서드**:
        *   **Unrolled LSTM을 통한 순방향 전달**: 입력 시퀀스(예: 4일간의 주가)를 `lstm_unit`에 반복적으로 전달하여 순방향 전달을 수행합니다.
        *   초기 장기/단기 기억은 0으로 설정하고, 각 날짜의 값을 처리하면서 업데이트된 기억을 다음 단계에 전달합니다.
        *   최종 단기 기억을 출력으로 반환합니다.
    *   **`configure_optimizers` 메서드**: `Adam` 옵티마이저를 설정합니다.
    *   **`training_step` 메서드**:
        *   **손실(Loss) 계산**: 예측과 실제 값 사이의 손실(여기서는 제곱 잔차의 합)을 계산합니다.
        *   **훈련 진행 상황 로깅**: Lightning의 `log` 메서드를 사용하여 훈련 손실과 각 회사의 예측 값을 기록합니다. 이 로그는 나중에 TensorBoard에서 시각화하는 데 사용됩니다.

### **30.3 훈련 및 평가 (Training and Evaluation)**

*   **초기 예측**: 무작위 가중치로 초기 모델을 만들었을 때의 예측값을 확인합니다. 대개는 실제 값과 매우 다릅니다.
*   **훈련 데이터 준비**: 입력 데이터(4일간의 주가)와 레이블(예측 목표 값, A 회사 0, B 회사 1)을 `TensorDataset`과 `DataLoader`로 묶습니다. `DataLoader`는 배치(batch) 처리, 데이터 셔플(shuffle), 빠른 디버깅 훈련에 유용합니다.
*   **Lightning `Trainer` 사용**: `lightning.Trainer` 객체를 생성하고 `fit` 메서드를 호출하여 모델을 훈련합니다.
*   **TensorBoard를 통한 훈련 모니터링**:
    *   **로그 파일 분석**: `training_step`에서 기록한 손실과 예측 값을 `lightning_logs` 디렉토리에 저장합니다.
    *   **시각화**: 터미널에서 `tensorboard --logdir=lightning_logs` 명령어를 실행하여 웹 브라우저에서 훈련 진행 상황을 그래프로 시각화합니다.
    *   **훈련 중단 시점 결정**: 손실 곡선이 평평해졌는지, 예측값이 목표에 충분히 가까워졌는지 등을 통해 훈련을 더 진행할지 결정합니다.
*   **체크포인트 (Checkpoints) 및 추가 훈련**: Lightning은 훈련 중간에 체크포인트를 저장하므로, 필요시 **이전 훈련 지점부터 추가 에포크(epoch)를 진행**할 수 있습니다.

### **30.4 PyTorch 내장 `nn.LSTM` 함수 사용 (Simplified Implementation)**

LSTM을 직접 코딩하는 방법을 배운 후, PyTorch의 내장 `nn.LSTM` 함수를 사용하면 훨씬 쉽게 구현할 수 있음을 보여줍니다.
*   **`LightningLstm` 클래스 정의**:
    *   **`init` 메서드**: `nn.LSTM` 함수를 호출하여 LSTM 레이어를 생성합니다.
        *   `input_size`: 입력 특징(feature)의 수 (예: 주가는 1개 특징).
        *   `hidden_size`: 출력 값의 수 (예: 예측값 1개 또는 다른 신경망 입력에 연결될 경우 그에 맞는 수).
    *   **`forward` 메서드**:
        *   입력 데이터를 PyTorch `View` 함수를 사용하여 **전치(transpose)**하고, 이를 `nn.LSTM`에 전달합니다.
        *   `nn.LSTM`의 출력(lstm_out) 중 **마지막 LSTM 단위의 단기 기억 값(-1 인덱스)**을 예측값으로 추출하여 반환합니다.
    *   **`configure_optimizers` 메서드**: `Adam` 옵티마이저를 설정합니다. 내장 함수를 사용할 때는 학습률(learning rate)을 더 크게(예: 0.1) 설정하여 더 빠르게 수렴하는 것을 보여줍니다.
    *   **`training_step` 메서드**: 직접 코딩할 때와 동일하게 손실을 계산하고 로그를 기록합니다.
*   **`nn.LSTM`을 이용한 훈련**: 내장 함수를 사용하면 **훨씬 적은 에포크(예: 5000 에포크 -> 300 에포크)**만으로도 좋은 예측 성능에 도달할 수 있음을 보여줍니다.
*   **TensorBoard 비교**: 직접 코딩한 모델과 `nn.LSTM`을 사용한 모델의 훈련 로그를 TensorBoard에서 비교하여, 내장 함수의 효율성을 시각적으로 확인합니다.

PyTorch와 Lightning을 활용하여 LSTM을 직접 구현하는 심층적인 이해를 제공하고, 나아가 PyTorch의 내장 기능을 활용하여 효율적으로 모델을 구축하고 훈련하는 실용적인 방법을 안내합니다.특히, Lightning 라이브러리가 훈련, 로깅, 체크포인트 관리 등 복잡한 과정을 얼마나 간소화하는지 명확하게 보여주는 것이 특징입니다.

## 31. PyTorch + Lightning을 이용한 단어 임베딩
- 출처:[Word Embedding in PyTorch + Lightning](https://www.youtube.com/watch?v=Qf06XDYXCXI&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=32)

PyTorch와 Lightning을 사용하여 **단어 임베딩(Word Embedding)** 네트워크를 구축하고 훈련하는 방법을 단계별로 설명합니다. 단어 임베딩은 텍스트 데이터를 처리하는 데 필수적인 기술이며, AI 및 자연어 처리(NLP) 분야에 입문하는 분들에게 매우 유용합니다.

### **31.1 단어 임베딩이란?**
단어 임베딩은 단어를 숫자의 형태로 변환하는 것입니다. 이 숫자를 **임베딩 값(embedding values)**이라고 부르며, 이를 그래프에 플로팅했을 때 "Troll 2"와 "Jim Kata"처럼 **유사한 맥락에서 사용되는 단어들이 서로 가깝게 나타나도록** 합니다. 이를 통해 컴퓨터가 단어의 의미론적 유사성을 이해할 수 있게 됩니다.

### **31.2 사용 도구 및 라이브러리**
*   **PyTorch**: 텐서 생성 및 신경망 구축의 핵심 라이브러리.
*   **PyTorch Lightning (L)**: 코드 작성 과정을 간소화하고, 클라우드에서의 자동 코드 최적화 및 확장을 용이하게 합니다.
*   **torch.nn**: 네트워크에서 사용할 가중치(weights) 및 여러 헬퍼 함수를 생성합니다.
*   **Adam**: 역전파(back propagation)를 통해 신경망을 데이터에 맞게 훈련시키는 데 사용되는 최적화 도구입니다.
*   **torch.utils.data (TensorDataset, DataLoader)**: 많은 데이터를 배치(batch)로 쉽게 접근하고, 각 에포크(Epoch)마다 데이터를 섞으며, 디버깅을 위해 데이터의 일부만 사용하는 것을 용이하게 합니다.
*   **pandas, matplotlib, Seaborn**: 임베딩 값을 시각화하여 그래프를 그리는 데 사용됩니다.

### **31.3 훈련 데이터 준비**
*   **예시 문장**: "Troll 2 is great"와 "Jim Kata is great" 두 문장을 사용합니다.
*   **고유 토큰**: "Troll 2", "is", "great", "Jim Kata".
*   **원-핫 인코딩(One-Hot Encoding)**: 각 고유 토큰을 숫자로 표현하는 방법으로, 특정 토큰에 해당하는 위치만 '1'이고 나머지는 '0'인 벡터를 만듭니다 (예: "Troll 2"를으로 표현).
*   **입력(Inputs) 및 레이블(Labels)**:
    *   **입력**: 특정 단어의 원-핫 인코딩.
    *   **레이블**: 해당 입력 단어 다음에 올 것으로 예상되는 단어의 원-핫 인코딩입니다 (예: "Troll 2"가 입력이면 "is"가 레이블). 기계 학습에서는 이를 알려진 또는 이상적인 출력 값이라고 부릅니다.
*   **TensorDataset & DataLoader**: 준비된 입력과 레이블을 결합하여 `TensorDataset`을 만들고, 이를 통해 `DataLoader`를 생성합니다.

### **31.4 워드 임베딩 네트워크 구축 (기본부터)**
신경망을 만들 때는 항상 새로운 클래스를 정의하는 것부터 시작하며, Lightning의 기능을 활용하기 위해 `lightning.LightningModule`을 상속받습니다.

*   **`__init__` 메서드**:
    *   상위 클래스 `LightningModule`의 초기화 메서드를 호출합니다.
    *   **가중치(weights) 초기화**: `uniform.sample`을 사용하여 -0.5에서 0.5 사이의 균일 분포에서 무작위 값을 선택하여 네트워크의 모든 가중치를 초기화합니다.
    *   **손실 함수(Loss Function)**: `nn.CrossEntropyLoss`를 호출하여 클래스에 손실 함수 접근 권한을 부여합니다. 이 함수는 원하는 출력과 실제 출력 간의 차이를 정량화합니다.
*   **`forward` 메서드**:
    *   입력(원-핫 인코딩)을 네트워크에 통과시켜 활성화 함수를 거치기 전의 합계를 계산합니다.
    *   활성화 함수는 항등 함수(identity function)로, 입력이 곧 출력이 됩니다.
    *   **softmax**: `nn.CrossEntropyLoss`가 softmax 계산을 대신 해주기 때문에 `forward` 메서드에서는 명시적으로 softmax를 계산할 필요가 없습니다.
    *   `torch.stack`을 사용하여 출력 값을 묶어 그래디언트(gradients)가 보존되도록 합니다.
*   **`configure_optimizers` 메서드**:
    *   `Adam` 최적화 도구를 설정하고, 학습률(learning rate)을 0.1로 설정합니다.
*   **`training_step` 메서드**:
    *   훈련 데이터 배치를 입력과 레이블로 분리합니다.
    *   입력을 `forward` 메서드를 통해 네트워크에 전달하여 예측 값을 얻습니다.
    *   예측 값과 이상적인 레이블 값을 `nn.CrossEntropyLoss` 함수에 전달하여 손실(loss)을 계산하고 반환합니다.

### **31.5 임베딩 값 시각화 및 훈련**
*   **훈련 전 시각화**: `pandas` 데이터프레임으로 가중치 값을 정리하고, `matplotlib`과 `seaborn`을 사용하여 산점도(scatter plot)를 그립니다. 훈련 전에는 "Troll 2"와 "Jim Kata" 같은 유사한 맥락의 단어들이 서로 멀리 떨어져 있음을 확인할 수 있습니다.
*   **네트워크 훈련**: `lightning.Trainer`를 생성하고, `trainer.fit` 메서드에 모델과 `DataLoader`를 전달하여 최대 100 에포크 동안 훈련시킵니다.
*   **훈련 후 시각화**: 훈련 후에는 "Troll 2"와 "Jim Kata"의 임베딩 값이 **매우 유사해진 것**을 그래프를 통해 확인할 수 있습니다. 이는 네트워크가 유사한 맥락의 단어들을 가깝게 배치하도록 학습되었음을 의미합니다.
*   **예측 검증**: 훈련된 네트워크에 "Troll 2"를 입력하면, 예상대로 "is"의 원-핫 인코딩을 올바르게 예측하는 것을 확인할 수 있습니다.

### **31.6 PyTorch의 `nn.Linear`를 사용하여 코드 간소화**
*   `nn.Linear`를 사용하면 가중치 생성 및 초기화, 곱셈 및 덧셈 계산 과정을 **훨씬 간결하게** 만들 수 있습니다.
*   `__init__` 메서드에서 `nn.Parameter` 대신 `nn.Linear` 객체를 두 번 호출하여 입력-은닉 계층, 은닉-출력 계층의 가중치를 생성합니다.
*   `forward` 메서드에서는 입력 값을 `nn.Linear` 객체에 전달하는 것만으로 모든 계산이 자동으로 이루어집니다.
*   이 방법을 사용하면 '기본부터' 구현했을 때보다 **코드의 양이 현저히 줄어듭니다**.

### **31.7 사전 훈련된 임베딩(`nn.Embedding`) 사용**
*   실제 응용에서는 직접 임베딩을 훈련하기보다 **사전 훈련된 임베딩(pre-trained word embeddings)**을 로드하여 사용하는 경우가 많습니다. Word2Vec이나 ChatGPT와 같은 Transformer 모델이 생성한 임베딩이 좋은 예시입니다.
*   `nn.Embedding` 객체를 생성하고, `from_pretrained` 메서드를 사용하여 사전 훈련된 가중치를 로드할 수 있습니다. 이때 `transpose`(`.T`)를 사용하여 가중치 행을 열로 변환하는 과정이 필요할 수 있습니다.
*   단어를 인덱스에 매핑하는 딕셔너리를 만들면, 단어 토큰 자체를 사용하여 임베딩 값에 쉽게 접근할 수 있습니다.
*   이렇게 로드된 임베딩 객체는 Transformer와 같은 더 큰 신경망에 연결하여 사용할 수 있습니다.

## 32. 디코더-온리 트랜스포머(decoder-only Transformer)를 PyTorch로 처음부터 코딩
- 출처:[Coding a ChatGPT Like Transformer From Scratch in PyTorch](https://www.youtube.com/watch?v=C9QSpl5nmrY&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=33)

1.  **목표 및 기본 개념**:
    *   **목표**: 주어진 프롬프트("what is stat Quest", "Stat Quest is what")에 대해 "awesome"이라는 응답을 생성하는 트랜스포머를 구축하는 것입니다.
    *   **ChatGPT의 기초**: 이 영상에서 구현하는 디코더-온리 트랜스포머는 ChatGPT와 같은 대규모 언어 모델의 기본적인 구조입니다.
    *   **필수 라이브러리**: PyTorch의 `torch`, `torch.nn`, `torch.nn.functional` 모듈과 최적화를 위한 `Adam`, 데이터 처리를 위한 `TensorDataset`, `DataLoader`, 그리고 코드 작성을 쉽게 하고 자동 최적화를 돕는 `lightning`을 사용합니다.

2.  **데이터 준비**:
    *   **어휘(Vocabulary)**: "what", "is", "stat", "Quest", "awesome", 그리고 문장의 끝을 나타내는 "EOS" 토큰으로 구성됩니다.
    *   **토큰 ID 매핑**: PyTorch의 워드 임베딩 함수는 숫자만 입력으로 받기 때문에, 각 토큰을 고유한 ID 번호로 매핑하여 딕셔너리에 저장합니다.
    *   **입력-출력 시퀀스 생성**: 트랜스포머는 각 입력 토큰이 다음 토큰을 생성하도록 학습됩니다. 예를 들어, 프롬프트 "what is stat Quest"에 대한 응답 "awesome"을 위해, 입력은 "what is stat Quest EOS awesome"이 되고, 그에 대한 레이블(정답)은 "is stat Quest EOS awesome EOS"이 됩니다. 이렇게 준비된 입력과 레이블은 `TensorDataset`과 `DataLoader`를 사용하여 훈련 데이터셋으로 변환됩니다.

3.  **트랜스포머의 핵심 구성 요소**:

    *   **워드 임베딩 (Word Embedding)**:
        *   단어(토큰)를 숫자로 표현된 고차원 벡터로 변환하는 과정입니다.
        *   이 벡터들은 단어의 의미적 유사성을 나타내며, `nn.Embedding` 모듈을 사용하여 자동으로 처리됩니다.

    *   **위치 인코딩 (Positional Encoding)**:
        *   트랜스포머는 순환 신경망(RNN)과 달리 시퀀스의 순서 정보를 직접 처리하지 못하므로, **토큰의 상대적 또는 절대적 위치 정보를 임베딩 값에 추가**해야 합니다.
        *   사인(sine) 및 코사인(cosine) 함수를 사용하여 각 토큰의 위치(pos)와 임베딩 차원(i)에 따라 고유한 위치 인코딩 값을 계산합니다.
        *   이 값들은 미리 계산되어 행렬에 저장되며, `PositionEncoding` 클래스에서 `D_model`(임베딩 차원)과 `MaxLen`(최대 시퀀스 길이)을 사용하여 구현됩니다. `forward` 메서드에서 워드 임베딩 값에 위치 인코딩 값을 더해줍니다.

    *   **마스크드 셀프 어텐션 (Masked Self-Attention)**:
        *   **어텐션 메커니즘**은 모델이 시퀀스 내의 다른 토큰들과의 관계를 파악하여 각 토큰의 중요도를 계산하게 합니다.
        *   **쿼리(Q), 키(K), 값(V)**라는 세 가지 벡터를 계산하며, 이들은 `nn.Linear` 모듈을 사용하여 워드 임베딩 값으로부터 생성됩니다.
        *   **스케일링**: Q와 K의 전치 행렬 곱을 계산하여 유사도(`Sims`)를 구한 뒤, `D_model`의 제곱근으로 스케일링합니다.
        *   **마스킹(Masking)**: **디코더-온리 트랜스포머의 핵심**으로, 현재 토큰이 미래의 토큰들을 미리 보지 못하도록 가려줍니다. 이는 `Sims` 행렬에서 미래 토큰에 해당하는 값들을 음의 무한대에 가까운 값(-1e9)으로 대체하여 소프트맥스 함수를 거치면 해당 어텐션 가중치가 0이 되도록 만듭니다.
        *   **소프트맥스**: 스케일링된 유사도에 소프트맥스 함수를 적용하여 각 토큰이 다른 토큰에 미치는 영향의 **백분율(`attention_percents`)**을 결정합니다.
        *   **최종 어텐션 점수**: `attention_percents`와 V 행렬을 곱하여 최종 어텐션 점수를 얻습니다.
        *   이 모든 과정은 `Attention` 클래스 내에서 구현됩니다.

4.  **디코더-온리 트랜스포머 모델 구축 및 훈련**:
    *   **모델 클래스**: `DecoderOnlyTransformer` 클래스는 `lightning.LightningModule`을 상속받아 위의 워드 임베딩, 위치 인코딩, 어텐션 모듈을 통합합니다.
    *   **잔여 연결 (Residual Connections)**: 어텐션 결과에 원래의 입력 값을 더하여 그래디언트 소실 문제를 완화하고 학습을 돕습니다.
    *   **피드포워드 계층 (Fully Connected Layer)**: 어텐션 결과는 완전 연결 계층을 통과하여 최종 출력을 생성합니다.
    *   **손실 함수 (Loss Function)**: `CrossEntropyLoss`를 사용하여 모델의 예측과 실제 레이블 간의 차이를 정량화하며, 이 함수는 소프트맥스 단계를 내부에 포함하고 있습니다.
    *   **옵티마이저 (Optimizer)**: `Adam` 옵티마이저를 사용하여 모델의 가중치를 업데이트합니다.
    *   **훈련 과정**: `lightning.Trainer`를 사용하여 지정된 에포크(epoch) 수만큼 모델을 훈련합니다. 훈련 전에는 모델이 "EOS"와 같은 무의미한 출력을 생성했지만, 훈련 후에는 "awesome EOS"와 같이 원하는 응답을 정확히 생성합니다.

