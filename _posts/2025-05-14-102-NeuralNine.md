---
title: 42차시 2:NeuralNine
layout: single
classes: wide
categories:
  - NeuralNine
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 11. 파이썬 다중 프로세싱

- 출처: [Python Multiprocessing Explained in 7 Minutes](https://www.youtube.com/watch?v=EI1gLCvdX_U&t=3s)

파이썬에서 **다중 프로세싱(Multiprocessing)**은 여러 작업을 동시에 처리하여 프로그램 속도를 확 끌어올리는 기술입니다. 마치 여러 명이 동시에 일해서 작업 시간을 단축하는 것과 비슷하다고 생각하면 됩니다.

### 11.1 다중 스레딩 vs. 다중 프로세싱: 뭐가 다를까?

파이썬에는 **다중 스레딩(Multi-threading)**이라는 개념도 있습니다. 하지만 파이썬은 **GIL(Global Interpreter Lock)**이라는 특성 때문에 다중 스레딩으로는 CPU를 많이 쓰는 작업에서 **진정한 동시 처리(병렬 처리)**가 불가능해요. 마치 한 명의 일꾼이 여러 작업을 번갈아 하는 것과 같아서, 실제로는 동시에 처리되는 게 아닙니다.

반면, **다중 프로세싱**은 여러 개의 독립적인 **프로세스(Process)**를 만들어서 각각의 프로세스가 동시에 작업을 처리하게 합니다. 이는 마치 여러 명의 일꾼이 각자 맡은 일을 동시에 처리하는 것과 같아서, **진정한 동시 처리(병렬 처리)**가 가능하고, 그만큼 작업 속도도 빨라지는 거죠.

### 11.2 다중 프로세싱을 위한 파이썬 도구들

파이썬의 `multiprocessing` 모듈에는 다중 프로세싱을 효율적으로 사용할 수 있도록 도와주는 여러 가지 도구(클래스)들이 있습니다. 몇 가지 주요 도구들을 알아볼까요?

* **`Pool` (풀)**:
    * **언제 쓸까요?** 여러 개의 작업에 똑같은 계산을 동시에 적용할 때 유용해요. 예를 들어, 12,000개의 숫자에 복잡한 계산을 해야 한다면, 이 `Pool`을 사용하면 혼자 계산할 때보다 훨씬 빠르게 끝낼 수 있어요. 마치 여러 명의 전문가가 각자 할당된 숫자에 대해 동시에 계산하는 것과 같아요.
    * **예시**: 12,000개의 숫자에 팩토리얼(factorial) 계산을 할 때, 혼자 하면 9.1초 걸리던 작업을 5개의 `Pool` 프로세스를 사용하면 2.9초 만에 끝낼 수 있어요. 엄청 빠르죠!

* **`Process` (프로세스)**:
    * **언제 쓸까요?** 아주 특정한 한 가지 작업을 별도의 프로세스로 실행하고 싶을 때 사용해요.
    * **예시**: 컴퓨터가 복잡한 계산을 하는 동안에도, 동시에 다른 프로세스가 5초마다 "잘 작동하고 있어요!"라는 메시지를 계속 출력하게 할 수 있어요. 계산과 메시지 출력이 동시에 이루어지는 거죠.

* **`Queue` (큐, 대기열)**:
    * **언제 쓸까요?** 여러 프로세스가 서로 정보를 주고받을 때 사용해요. 특히 정보가 들어간 순서대로 정확하게 처리되어야 할 때 아주 유용합니다.
    * **예시**: 한 프로세스가 물건을 생산해서 큐에 넣어두면, 다른 프로세스들이 큐에 있는 물건들을 하나씩 가져다가 소비해요. 아무리 여러 프로세스가 동시에 가져가도 큐에 들어간 순서대로 정확하게 처리됩니다.

* **`Pipe` (파이프)**:
    * **언제 쓸까요?** 두 개의 프로세스가 직접적으로 대화할 수 있는 통로를 만들 때 사용해요.
    * **예시**: 한 프로세스가 다른 프로세스에게 메시지를 보내면, 다른 프로세스가 그 메시지를 바로 받아서 처리할 수 있어요. 필요하다면 양쪽에서 서로 메시지를 주고받을 수도 있습니다.

* **`Lock` (잠금)**:
    * **언제 쓸까요?** 여러 프로세스가 동시에 한 가지 중요한 데이터(자원)를 건드려서 문제가 생기는 것을 막을 때 사용해요. 마치 화장실 문에 잠금장치가 있어서 한 번에 한 명만 들어갈 수 있게 하는 것과 같아요.
    * **예시**: 네 개의 프로세스가 하나의 공유된 숫자 값을 100,000번씩 늘리려고 할 때, `Lock`을 사용하지 않으면 값이 엉망이 될 수 있어요. 하지만 `Lock`을 사용하면 한 번에 하나의 프로세스만 값을 변경할 수 있도록 보장해서, 우리가 원하는 정확한 최종 값(400,000)을 얻을 수 있습니다.

* **`Semaphore` (세마포어)**:
    * **언제 쓸까요?** `Lock`과 비슷하지만, 동시에 여러 프로세스가 특정 자원에 접근할 수 있도록 허용할 때 사용해요. 하지만 그 허용 개수는 우리가 정할 수 있습니다.
    * **예시**: 6개의 프로세스가 있는데, 동시에 2개의 프로세스만 특정 작업을 하도록 제한하고 싶을 때 `Semaphore`를 사용합니다. 마치 6명의 일꾼이 있지만, 2개의 작업대만 있어서 동시에 2명만 작업할 수 있는 것과 비슷해요.


### 11.3. `Pool` (풀) 예제

`Pool`을 사용하여 여러 숫자의 제곱을 병렬로 계산하는 예제입니다.

```python
import multiprocessing
import os
import time

def calculate_square(number):
    """주어진 숫자의 제곱을 계산합니다."""
    # print(f"Process ID: {os.getpid()} - Calculating square of {number}")
    return number * number

if __name__ == "__main__":
    numbers = range(10)  # 0부터 9까지의 숫자

    print("--- Pool 예제 시작 ---")
    start_time = time.time()

    # 4개의 프로세스 풀을 생성
    with multiprocessing.Pool(processes=4) as pool:
        # map 함수를 사용하여 각 숫자에 calculate_square 함수 적용
        results = pool.map(calculate_square, numbers)

    print(f"결과: {results}")
    end_time = time.time()
    print(f"총 실행 시간: {end_time - start_time:.4f} 초")
    print("--- Pool 예제 종료 ---")

```

**설명:**

  * `calculate_square` 함수는 주어진 숫자의 제곱을 계산합니다.
  * `multiprocessing.Pool(processes=4)`는 4개의 프로세스를 사용하는 풀을 만듭니다.
  * `pool.map(calculate_square, numbers)`는 `numbers` 리스트의 각 항목에 `calculate_square` 함수를 병렬로 적용하고 결과를 수집합니다.


### 11.4 `Process` (프로세스) 예제

두 개의 독립적인 프로세스를 생성하여 각각 다른 작업을 수행하는 예제입니다.

```python
import multiprocessing
import time
import os

def task1():
    """첫 번째 프로세스에서 실행될 작업입니다."""
    print(f"Process ID: {os.getpid()} - Task 1 시작")
    for i in range(3):
        time.sleep(1)
        print(f"Process ID: {os.getpid()} - Task 1 진행 중... ({i+1}/3)")
    print(f"Process ID: {os.getpid()} - Task 1 완료")

def task2():
    """두 번째 프로세스에서 실행될 작업입니다."""
    print(f"Process ID: {os.getpid()} - Task 2 시작")
    for i in range(2):
        time.sleep(1.5)
        print(f"Process ID: {os.getpid()} - Task 2 진행 중... ({i+1}/2)")
    print(f"Process ID: {os.getpid()} - Task 2 완료")

if __name__ == "__main__":
    print("--- Process 예제 시작 ---")
    
    # Process 객체 생성
    p1 = multiprocessing.Process(target=task1)
    p2 = multiprocessing.Process(target=task2)

    # 프로세스 시작
    p1.start()
    p2.start()

    # 모든 프로세스가 완료될 때까지 기다림
    p1.join()
    p2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Process 예제 종료 ---")
```

**설명:**

  * `task1`과 `task2`는 각각 다른 메시지를 출력하며 일정 시간 대기하는 함수입니다.
  * `multiprocessing.Process(target=함수명)`을 사용하여 각 함수를 실행할 새 프로세스를 생성합니다.
  * `p.start()`로 프로세스를 시작합니다.
  * `p.join()`은 해당 프로세스가 끝날 때까지 메인 프로세스가 기다리도록 합니다.


### 11.5 `Queue` (큐, 대기열) 예제

`Queue`를 사용하여 생산자 프로세스와 소비자 프로세스 간에 데이터를 주고받는 예제입니다.

```python
import multiprocessing
import time
import os

def producer(queue):
    """항목을 큐에 추가하는 생산자 함수입니다."""
    print(f"Process ID: {os.getpid()} - 생산자 시작")
    for i in range(5):
        item = f"아이템 {i+1}"
        queue.put(item)
        print(f"Process ID: {os.getpid()} - {item} 생산 및 큐에 추가")
        time.sleep(0.5)
    queue.put(None) # 소비자가 작업을 마쳤음을 알리는 신호
    print(f"Process ID: {os.getpid()} - 생산자 완료")

def consumer(queue, name):
    """큐에서 항목을 가져와 처리하는 소비자 함수입니다."""
    print(f"Process ID: {os.getpid()} - 소비자 {name} 시작")
    while True:
        item = queue.get()
        if item is None:
            # 생산자가 보낸 종료 신호를 받으면 다시 큐에 넣고 종료
            queue.put(None)
            break
        print(f"Process ID: {os.getpid()} - 소비자 {name} - {item} 소비")
        time.sleep(1)
    print(f"Process ID: {os.getpid()} - 소비자 {name} 완료")

if __name__ == "__main__":
    print("--- Queue 예제 시작 ---")
    
    q = multiprocessing.Queue() # 큐 생성

    # 생산자 프로세스 생성
    p_producer = multiprocessing.Process(target=producer, args=(q,))
    # 소비자 프로세스 생성
    p_consumer1 = multiprocessing.Process(target=consumer, args=(q, "A"))
    p_consumer2 = multiprocessing.Process(target=consumer, args=(q, "B"))

    # 프로세스 시작
    p_producer.start()
    p_consumer1.start()
    p_consumer2.start()

    # 모든 프로세스가 완료될 때까지 기다림
    p_producer.join()
    p_consumer1.join()
    p_consumer2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Queue 예제 종료 ---")
```

**설명:**

  * `producer` 함수는 `queue.put()`을 사용하여 큐에 데이터를 넣습니다.
  * `consumer` 함수는 `queue.get()`을 사용하여 큐에서 데이터를 가져옵니다.
  * `queue.put(None)`은 생산자가 더 이상 생산할 것이 없음을 소비자에게 알리는 "종료 신호"로 사용됩니다.


### 11.6 `Pipe` (파이프) 예제

두 프로세스 간에 단방향 및 양방향 통신을 설정하는 예제입니다.

```python
import multiprocessing
import time
import os

def sender(conn, messages):
    """메시지를 파이프를 통해 보내는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Sender 시작")
    for msg in messages:
        conn.send(msg)
        print(f"Process ID: {os.getpid()} - 메시지 보냄: {msg}")
        time.sleep(0.5)
    conn.close() # 통신 종료
    print(f"Process ID: {os.getpid()} - Sender 완료")

def receiver(conn):
    """파이프를 통해 메시지를 받는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Receiver 시작")
    while True:
        try:
            msg = conn.recv()
            print(f"Process ID: {os.getpid()} - 메시지 받음: {msg}")
        except EOFError: # 파이프가 닫히면 발생하는 오류
            break
        time.sleep(0.7)
    print(f"Process ID: {os.getpid()} - Receiver 완료")

if __name__ == "__main__":
    print("--- Pipe 예제 시작 (단방향) ---")
    
    # 단방향 파이프 생성 (부모-자식 연결)
    parent_conn, child_conn = multiprocessing.Pipe(duplex=False) # duplex=False는 단방향을 의미

    messages_to_send = ["안녕", "파이프", "예제", "데이터"]
    
    p_sender = multiprocessing.Process(target=sender, args=(child_conn, messages_to_send))
    p_receiver = multiprocessing.Process(target=receiver, args=(parent_conn,))

    p_sender.start()
    p_receiver.start()

    p_sender.join()
    p_receiver.join()

    print("\n--- Pipe 예제 시작 (양방향) ---")
    
    # 양방향 파이프 생성
    conn1, conn2 = multiprocessing.Pipe(duplex=True) # duplex=True는 양방향을 의미

    def worker1(conn):
        conn.send("Worker1 입니다. 안녕!")
        print(f"Process ID: {os.getpid()} - Worker1 받음: {conn.recv()}")
        conn.close()

    def worker2(conn):
        print(f"Process ID: {os.getpid()} - Worker2 받음: {conn.recv()}")
        conn.send("Worker2 입니다. 잘 가!")
        conn.close()

    p_worker1 = multiprocessing.Process(target=worker1, args=(conn1,))
    p_worker2 = multiprocessing.Process(target=worker2, args=(conn2,))

    p_worker1.start()
    p_worker2.start()

    p_worker1.join()
    p_worker2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Pipe 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Pipe()`를 호출하면 두 개의 연결 객체(`conn1`, `conn2`)가 반환됩니다. 이 두 객체는 파이프의 양쪽 끝을 나타냅니다.
  * `conn.send()`를 사용하여 데이터를 파이프를 통해 보냅니다.
  * `conn.recv()`를 사용하여 파이프에서 데이터를 받습니다.
  * `duplex=True`로 설정하면 양방향 통신이 가능하며, 기본값은 `False`로 단방향입니다.


### 11.7 `Lock` (잠금) 예제

`Lock`을 사용하여 여러 프로세스가 공유 자원(공유 숫자)을 안전하게 수정하는 예제입니다.

```python
import multiprocessing
import time
import os

def increment_shared_counter(counter, lock):
    """공유 카운터 값을 증가시키는 함수입니다."""
    print(f"Process ID: {os.getpid()} - 카운터 증가 시작")
    for _ in range(100000): # 10만 번 증가
        lock.acquire() # 락 획득 (다른 프로세스가 접근 못하게 잠금)
        try:
            counter.value += 1
        finally:
            lock.release() # 락 해제 (다른 프로세스가 접근 가능하게 풀어줌)
    print(f"Process ID: {os.getpid()} - 카운터 증가 완료")

if __name__ == "__main__":
    print("--- Lock 예제 시작 ---")
    
    # 공유할 숫자 변수 생성 (Value 객체는 여러 프로세스에서 공유 가능)
    shared_counter = multiprocessing.Value('i', 0) # 'i'는 정수형을 의미, 초기값 0
    lock = multiprocessing.Lock() # 락 객체 생성

    processes = []
    num_processes = 4

    for _ in range(num_processes):
        p = multiprocessing.Process(target=increment_shared_counter, args=(shared_counter, lock))
        processes.append(p)
        p.start()

    for p in processes:
        p.join()

    print(f"최종 카운터 값: {shared_counter.value}") # 예상 값: 400000
    print("--- Lock 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Value('i', 0)`는 여러 프로세스에서 공유할 수 있는 정수형 변수를 생성합니다.
  * `multiprocessing.Lock()`으로 락 객체를 생성합니다.
  * `lock.acquire()`는 락을 획득하여 다른 프로세스가 해당 코드 블록에 접근하지 못하도록 합니다.
  * `lock.release()`는 락을 해제하여 다른 프로세스가 접근할 수 있도록 합니다. `try...finally` 블록을 사용하여 락이 항상 해제되도록 보장하는 것이 중요합니다.


### 11.8 `Semaphore` (세마포어) 예제

`Semaphore`를 사용하여 동시에 특정 작업에 접근할 수 있는 프로세스의 수를 제한하는 예제입니다.

```python
import multiprocessing
import time
import os

def worker_with_semaphore(semaphore, worker_id):
    """세마포어를 사용하여 작업하는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Worker {worker_id} 대기 중...")
    semaphore.acquire() # 세마포어 획득 (접근 허용 대기)
    try:
        print(f"Process ID: {os.getpid()} - Worker {worker_id} 작업 시작! (동시 실행 가능 수: 2)")
        time.sleep(2) # 작업 수행 시간
        print(f"Process ID: {os.getpid()} - Worker {worker_id} 작업 완료!")
    finally:
        semaphore.release() # 세마포어 해제 (다른 프로세스가 접근 가능하도록)

if __name__ == "__main__":
    print("--- Semaphore 예제 시작 ---")
    
    # 동시에 2개의 프로세스만 접근을 허용하는 세마포어 생성
    semaphore = multiprocessing.Semaphore(2) 

    processes = []
    num_workers = 6 # 총 6개의 워커 프로세스 생성

    for i in range(num_workers):
        p = multiprocessing.Process(target=worker_with_semaphore, args=(semaphore, i + 1))
        processes.append(p)
        p.start()

    for p in processes:
        p.join()

    print("모든 워커 프로세스 완료. 메인 프로세스 종료.")
    print("--- Semaphore 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Semaphore(2)`는 동시에 2개의 프로세스만 `acquire()`를 성공적으로 호출할 수 있도록 제한합니다.
  * `semaphore.acquire()`는 세마포어를 획득하여 허용된 개수 내에서 작업을 시작합니다.
  * `semaphore.release()`는 세마포어를 해제하여 다른 프로세스가 접근할 수 있도록 합니다.


## 12. NumPy, 왜 배우나요? 데이터 과학의 필수 도구
- 출처: [NumPy Full Python Course - Data Science Fundamentals](https://www.youtube.com/watch?v=4c_mwnYdbhQ)


NumPy는 파이썬(Python)에서 **숫자 계산**을 빠르고 효율적으로 할 수 있게 도와주는 특별한 도구예요. 특히 **벡터, 행렬, 배열** 같은 데이터를 다룰 때 강력한 힘을 발휘하죠.

  * **빠르고 효율적이에요**: NumPy는 파이썬으로 만들어졌지만, 실제 핵심 부분은 C언어로 되어 있어서 엄청나게 빠르답니다.
  * **데이터 과학의 기반**: 판다스(Pandas), 사이킷런(scikit-learn), 텐서플로우(TensorFlow) 등 데이터 과학과 머신러닝 분야에서 사용하는 대부분의 중요한 도구들이 바로 이 NumPy를 기반으로 하고 있어요. 그래서 데이터 과학 분야에 관심 있다면 NumPy는 꼭 알아야 하는 필수 지식이죠\!
  * **어마어마하게 많이 쓰여요**: 개발자들이 가장 많이 사용하는 도구 중 하나로 손꼽힐 만큼 널리 사용되고 있어요.

### 12.1 NumPy 설치하고 사용하기

NumPy를 사용하려면 먼저 컴퓨터에 설치해야 해요.

1.  **설치**: 컴퓨터의 '명령 프롬프트'나 '터미널'을 열고 다음 명령어를 입력하세요.
    ```bash
    pip install numpy
    ```
2.  **가져오기 (Import)**: 파이썬 코드에서 NumPy를 사용하려면 항상 맨 위에 다음 코드를 추가해야 해요.
    ```python
    import numpy as np
    ```
    여기서 `as np`는 '앞으로 NumPy를 `np`라는 짧은 이름으로 부를게\!'라는 약속이에요. 이렇게 하면 코드를 더 짧게 쓸 수 있어서 편리하죠.

### 12.2 NumPy 배열 (Arrays)의 기초

NumPy의 가장 중요한 개념은 바로 \*\*배열(Array)\*\*이에요. 파이썬의 '리스트(List)'와 비슷하게 여러 개의 값을 담을 수 있지만, 훨씬 강력하고 효율적이랍니다.

  * **배열 만들기**: 파이썬 리스트를 `np.array()` 안에 넣어서 만들 수 있어요.
    ```python
    my_list = [1, 2, 3]
    my_array = np.array(my_list)
    print(my_array)
    # 결과: [1 2 3] (리스트와 다르게 쉼표가 없어요!)
    ```
  * **빠른 이유**: NumPy 배열은 C언어로 최적화되어 있어서 계산이 훨씬 빨라요.
  * **데이터 타입이 같아야 해요**: 파이썬 리스트는 숫자, 글자 등 다양한 종류의 데이터를 한꺼번에 담을 수 있지만, NumPy 배열은 **모든 요소가 같은 종류의 데이터**여야 해요.
      * 만약 다른 종류의 데이터를 섞어서 넣으면, NumPy가 알아서 가장 넓은 범위의 데이터 타입(예: 숫자와 글자를 섞으면 모두 글자로)으로 바꿔서 저장해요.
      * 너무 복잡한 데이터 타입(예: 딕셔너리)을 섞으면 NumPy의 장점인 속도가 느려질 수 있으니 주의하세요.
  * **데이터 타입 지정**: 배열을 만들 때 `dtype`이라는 옵션을 사용해서 특정 데이터 타입을 명확하게 지정할 수도 있어요.
    ```python
    # 정수형 배열 만들기
    int_array = np.array([1, 2, 3], dtype='int32')
    # 실수형 배열 만들기
    float_array = np.array([1.0, 2.5, 3.0], dtype='float64')
    ```

### 12.3 NumPy 배열의 특징 알아보기 (속성)

만든 배열이 어떤 모습인지 궁금할 때가 있죠? 배열의 여러 정보를 알려주는 속성들이 있어요.

  * **`shape` (모양)**: 배열이 몇 줄, 몇 칸으로 되어 있는지 알려줘요. (예: `(3, 3)`은 3줄 3칸 배열)
  * **`ndim` (차원 수)**: 배열이 몇 차원인지 알려줘요. (예: 1차원, 2차원 등)
  * **`size` (전체 개수)**: 배열 안에 데이터가 총 몇 개 들어있는지 알려줘요.
  * **`dtype` (데이터 타입)**: 배열 안의 데이터가 어떤 종류인지 알려줘요. (예: `int32`, `float64`)

**예시**:

```python
# 2차원 배열 만들기 (3줄 3칸)
my_2d_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

print("배열의 모양:", my_2d_array.shape) # 결과: (3, 3)
print("배열의 차원:", my_2d_array.ndim) # 결과: 2
print("배열의 전체 요소 개수:", my_2d_array.size) # 결과: 9
print("배열 요소의 데이터 타입:", my_2d_array.dtype) # 결과: int32 (정수형)
```

### 12.4 특별한 배열 만들기 (자동 채우기)

특정 값으로 채워진 배열을 쉽게 만들 수 있어요.

  * **`np.full(shape, value)`**: 원하는 모양(`shape`)으로 만들고, 모든 칸을 원하는 값(`value`)으로 채워요.
  * **`np.zeros(shape)`**: 모든 칸을 0으로 채워요.
  * **`np.ones(shape)`**: 모든 칸을 1로 채워요.
  * **`np.empty(shape)`**: 그냥 빈 공간만 확보하고, 값을 채우지 않아요. 그래서 기존 메모리에 있던 알 수 없는 값들이 들어있을 수 있지만, `zeros`나 `ones`보다 빠를 수 있어요.

### 12.5 규칙적인 숫자 배열 만들기

특정 규칙에 따라 숫자가 나열된 배열을 만들 때 유용해요.

  * **`np.arange(start, end, step_size)`**: `start`부터 `end` 직전까지 `step_size` 간격으로 숫자를 만들어요. (예: 0, 2, 4, ...)
  * **`np.linspace(start, end, num_values)`**: `start`와 `end` 사이를 `num_values`개로 똑같이 나눠서 숫자를 만들어요.



### 12.6 특별한 값 (NaN, Inf)

데이터를 다루다 보면 '숫자가 아님'이나 '무한대' 같은 특별한 값이 필요할 때가 있어요.

  * **`np.nan` (Not a Number)**: '숫자가 아님'을 나타내요. 데이터가 비어있거나, 계산 결과가 숫자가 아닐 때 사용해요.
  * **`np.inf` (Infinity)**: '무한대'를 나타내요. 예를 들어, 어떤 수를 0으로 나누면 무한대가 되죠.
  * **확인 함수**: `np.isnan(값)`으로 NaN인지, `np.isinf(값)`으로 Infinity인지 확인할 수 있어요.


### 12.7 NumPy 배열로 수학 계산하기

NumPy의 가장 큰 장점 중 하나는 배열 단위로 편리하게 수학 계산을 할 수 있다는 점이에요.

  * **숫자 하나로 계산 (스칼라 연산)**: 배열에 숫자 하나를 곱하거나 더하면, **배열의 모든 요소**에 똑같이 적용돼요. 일반 파이썬 리스트와는 다르게 작동하죠\!
    ```python
    arr = np.array([1, 2, 3])
    print(arr * 2) # 결과: [2 4 6]
    ```
  * **배열끼리 계산**: 두 개의 NumPy 배열끼리 더하거나 곱하면, **같은 위치에 있는 요소끼리** 계산돼요.
    ```python
    arr1 = np.array([1, 2, 3])
    arr2 = np.array([4, 5, 6])
    print(arr1 + arr2) # 결과: [5 7 9] (1+4, 2+5, 3+6)
    ```
    **중요**: 배열끼리 계산할 때는 배열의 **모양이 같아야** 해요.
  * **다양한 수학 함수**: `np.sqrt()` (제곱근), `np.sin()` (사인), `np.exp()` (지수) 등 다양한 수학 함수를 배열에 바로 적용할 수 있어요. 이 함수들도 각 요소에 대해 계산돼요.


### 12.8 배열의 구조를 바꾸는 방법

데이터 분석을 하다 보면 배열의 모양을 바꾸거나, 특정 값을 추가/삭제해야 할 때가 많아요.

1.값 추가, 삽입, 삭제

  * **`np.append(배열, 값)`**: 배열의 끝에 값을 추가한 **새로운** 배열을 만들어요. (원본 배열은 바뀌지 않아요\!)
  * **`np.insert(배열, 위치, 값)`**: 지정된 `위치`에 값을 삽입한 **새로운** 배열을 만들어요.
  * **`np.delete(배열, 인덱스, axis)`**: 지정된 `인덱스`의 요소를 삭제해요. `axis`를 사용해서 행(가로줄, `axis=0`) 또는 열(세로줄, `axis=1`) 단위로 삭제할 수 있어요.

2.모양 변경 (Reshape)

  * **`배열.reshape(새로운_모양)`**: 배열의 모양을 변경한 **새로운** 배열을 만들어요. 요소의 순서는 그대로 유지돼요.
  * **`배열.resize(새로운_모양)`**: **원본 배열 자체의** 모양을 변경해요. 반환하는 값은 없어요.

3.1차원으로 만들기 (Flattening)

다차원 배열을 한 줄짜리 배열로 만들 때 사용해요.

  * **`배열.flatten()`**: 1차원 **복사본**을 만들어요. 복사본을 바꿔도 원본은 바뀌지 않아요.
  * **`배열.ravel()`**: 1차원 \*\*뷰(View)\*\*를 만들어요. 뷰를 바꾸면 **원본 배열도 같이 바뀌어요**\! (메모리를 공유한다는 뜻)

4.행과 열 바꾸기 (Transposing)

테이블의 가로와 세로를 바꾸는 것처럼, 배열의 행과 열을 서로 바꿀 때 사용해요.

  * **`배열.transpose()`** 또는 **`배열.T`**: 행은 열로, 열은 행으로 바꿔줘요.


### 12.9 배열 합치고 나누기

여러 개의 배열을 하나로 합치거나, 하나의 배열을 여러 개로 나눌 수 있어요.

1.합치기 (Joining)

  * **`np.concatenate((배열1, 배열2), axis)`**: 여러 배열을 `axis` 방향으로 연결해요. `axis=0`은 위아래로(행을 따라), `axis=1`은 좌우로(열을 따라) 붙여요.
  * **`np.vstack((배열1, 배열2))`**: 수직으로(위아래로) 쌓아요. (`concatenate`의 `axis=0`과 비슷)
  * **`np.hstack((배열1, 배열2))`**: 수평으로(좌우로) 쌓아요. (`concatenate`의 `axis=1`과 비슷)

2.나누기 (Splitting)

  * **`np.split(배열, 나눌_개수, axis)`**: 배열을 `나눌_개수`만큼 작은 배열로 나눠요. `axis`에 따라 행 또는 열을 기준으로 나눌 수 있어요.


### 12.10 배열에서 통계값 얻기 (집계 함수)

배열 안에 있는 데이터의 통계값을 쉽게 계산할 수 있어요.

  * **`배열.min()`**: 가장 작은 값
  * **`배열.max()`**: 가장 큰 값
  * **`배열.mean()`**: 평균값
  * **`배열.std()`**: 표준 편차 (데이터가 평균에서 얼마나 떨어져 있는지)
  * **`배열.sum()`**: 모든 값의 합계
  * **`np.median(배열)`**: 중앙값 (데이터를 순서대로 나열했을 때 가운데 있는 값)


### 12.11 무작위 값 만들기 (Randomness)

임의의 숫자를 만들 때 유용해요.

  * **`np.random.randint(low, high, size)`**: `low`부터 `high` 직전까지 범위에서 무작위 정수를 만들어요. `size`로 원하는 배열 모양을 지정할 수 있어요.
  * **`np.random.normal(loc, scale, size)`**: 정규 분포(평균 `loc`, 표준편차 `scale`)에 따라 무작위 값을 만들어요.
  * **`np.random.choice(배열, size)`**: 주어진 `배열`에서 무작위로 요소를 선택해요.


### 12.12 NumPy 배열 저장하고 불러오기

만든 NumPy 배열을 파일로 저장하거나, 파일에 저장된 배열을 다시 불러올 수 있어요.

  * **NumPy 전용 형식 (.npy 파일)**:
      * **저장**: `np.save('파일이름.npy', 배열)`
      * **불러오기**: `np.load('파일이름.npy')`
  * **CSV 파일 (쉼표로 구분된 텍스트 파일)**:
      * **저장**: `np.savetxt('파일이름.csv', 배열, delimiter=',')` (쉼표로 구분해서 저장)
      * **불러오기**: `np.loadtxt('파일이름.csv', delimiter=',')` (쉼표로 구분된 파일 불러오기)

## 13. NumPy, 더 깊이 파고들기: 데이터 과학 전문가가 되기 위한 고급 기술
- 출처: [Advanced NumPy Course - Vectorization, Masking, Broadcasting & More](https://www.youtube.com/watch?v=pQt8yQuPOGo&t=2792s)

NumPy의 기본적인 사용법(배열 만들기, 모양 확인, 간단한 계산)은 이제 익숙하신가요? 이번에는 NumPy를 **더 똑똑하고 효율적으로** 사용하는 방법들을 알아볼 거예요. 이 기술들을 알면 복잡한 데이터도 손쉽게 다루고, 컴퓨터가 계산하는 속도도 훨씬 빨라질 거예요\!

### 13.1 브로드캐스팅 (Broadcasting): 다른 모양의 배열끼리도 척척 계산

  * **쉽게 말하면**: 서로 다른 \*\*모양(shape)\*\*을 가진 두 배열끼리도 NumPy가 알아서 크기를 맞춰줘서 계산할 수 있게 해주는 기능이에요. 마치 작은 배열을 큰 배열에 맞게 **자동으로 늘려서** 연산하는 것과 같아요.
  * **어떻게 작동하나요?**: NumPy는 한 배열의 축(차원)을 따라서 요소를 반복해서 다른 배열의 모양과 호환되도록 만들어줘요.
  * **언제 호환될까요?**: 두 배열의 해당 축 숫자가 같거나, 둘 중 하나가 1인 경우에 호환돼요. 예를 들어, (5, 7, 1, 4) 배열과 (7, 4) 배열은 서로 다른 모양이지만, 브로드캐스팅 규칙에 따라 연산이 가능할 수 있어요.
  * **장점**: 우리가 일일이 배열의 크기를 맞춰줄 필요 없이 NumPy가 자동으로 처리해줘요.
  * **주의**: 호환되지 않는 모양끼리 연산하면 오류가 발생해요\!

### 13.2 고급 인덱싱 (Advanced Indexing): 원하는 데이터만 쏙쏙 뽑아내기

인덱싱은 배열에서 특정 데이터를 선택하는 방법이에요. 기본적인 인덱싱(하나의 요소 선택, 슬라이싱 등) 외에 더 복잡한 방법들이 있어요.

  * **리스트로 인덱싱하기**: 숫자나 슬라이스 대신 **리스트**를 사용해서 여러 개의 행이나 열을 한 번에 선택할 수 있어요.
    ```python
    import numpy as np
    arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    print(arr[[0, 2]]) # 0번째 행과 2번째 행 선택: [[1,2,3], [7,8,9]]
    ```
  * **차원 인덱싱 (`:` 사용)**: 콜론(`:`)을 사용하면 특정 차원의 **모든** 요소를 선택할 수 있어요.
    ```python
    print(arr[:, 1]) # 모든 행에서 두 번째(인덱스 1) 열 선택: [2, 5, 8]
    ```
  * **새로운 축 추가 (`np.newaxis`)**: `np.newaxis`를 사용하면 배열에 **새로운 차원**을 추가할 수 있어요. 특정 인공지능 모델에서는 데이터의 모양이 정해져 있어서 이렇게 차원을 추가해야 할 때가 있어요.
    ```python
    vec = np.array([1, 2, 3])
    print(vec.shape)      # (3,)
    new_vec = vec[np.newaxis, :] # 행 차원 추가
    print(new_vec.shape)  # (1, 3)
    ```
  * **결합 인덱싱**: 행과 열에 동시에 고급 인덱싱을 적용해서 원하는 데이터 덩어리를 정확히 선택할 수 있어요.
  * **불리언 인덱싱 (Boolean Indexing)**: `True`/`False` 값으로 이루어진 **불리언 배열**을 사용해서 특정 조건을 만족하는 요소만 선택하거나 숨길 수 있어요.
    ```python
    data = np.array([10, 20, 5, 30, 15])
    mask = data > 15 # 15보다 큰 값은 True, 아니면 False
    print(data[mask]) # 결과: [20, 30]
    ```

### 13.3 정렬 및 검색 (Sorting and Searching): 데이터를 정리하고 필요한 값 찾기

데이터를 분석하기 전에 특정 순서로 정렬하거나, 원하는 값을 찾아야 할 때가 많아요.

  * **정렬 (Sorting)**
      * **`np.sort(배열)`**: 원본 배열은 그대로 두고, **정렬된 새 배열**을 만들어줘요.
      * **`배열.sort()`**: **원본 배열 자체**를 정렬해서 바꿔버려요.
      * **축(axis)별 정렬**: `axis` 옵션을 사용해서 행(`axis=1`) 또는 열(`axis=0`)을 기준으로 정렬할 수 있어요.
  * **값 검색 및 인덱스 찾기 (Searching)**
      * **`np.argmax(배열)`**: 배열에서 \*\*가장 큰 값의 위치(인덱스)\*\*를 알려줘요. 인공지능에서 가장 확률이 높은 결과를 찾을 때 유용해요.
      * **`np.argmin(배열)`**: 배열에서 **가장 작은 값의 위치**를 알려줘요.
      * **`np.nonzero(배열)`**: 배열에서 **0이 아닌 값들의 위치**를 알려줘요.
      * **`np.where(조건, 값1, 값2)`**: 조건에 따라 `값1` 또는 `값2`를 선택해서 새로운 배열을 만들어줘요. 예를 들어, 특정 숫자보다 작은 값은 0으로 바꾸고 싶을 때 쓸 수 있어요.

### 13.4 반복 (Iteration): 배열의 모든 요소에 쉽게 접근하기

다차원 배열의 모든 요소를 하나씩 살펴보려면 보통 `for` 반복문을 여러 번 중첩해서 써야 해서 복잡하고 느릴 수 있어요.

  * **`np.nditer`**: `np.nditer`는 배열의 차원에 상관없이 모든 요소를 효율적으로 반복할 수 있게 해주는 특별한 도구예요.
  * **반복 중 값 변경**: `op_flags=['readwrite']` 옵션을 `np.nditer`에 추가하면 반복하면서 배열의 요소 값을 직접 변경할 수도 있어요.

### 13.5 마스킹 (Masking): 특정 데이터를 임시로 숨기거나 제외하기

데이터 분석 시, 특정 값(예: 잘못된 데이터, 극단적인 값)을 계산에서 제외하고 싶을 때가 있어요. 이때 마스킹을 사용하면 데이터를 아예 삭제하지 않고도 숨길 수 있어요.

  * **개념**: 마스킹은 데이터를 '제거'하는 대신 '가려버리는' 거예요. 마치 가면을 씌워서 보이지 않게 하는 것과 같죠.
  * **`numpy.ma.MaskedArray`**: `numpy.ma` 모듈을 사용해서 마스킹된 배열을 만들 수 있어요. 어떤 데이터를 가릴지는 0(안 가림)과 1(가림)로 된 `마스크` 리스트로 지정해요.
  * **자동 마스킹 함수**: 특정 조건(예: 특정 값보다 큰 값, 유효하지 않은 값)에 따라 자동으로 마스킹해주는 편리한 함수들도 많아요. 예를 들어, `ma.masked_invalid(배열)`은 NaN(숫자 아님)이나 Infinity(무한대) 같은 유효하지 않은 값을 자동으로 가려줘요.

### 13.6 뷰 (View) vs. 복사 (Copy): 데이터 변경의 함정

NumPy에서 배열을 다룰 때, 원본 데이터를 직접 바꾸는지 아니면 복사본을 만들어서 작업하는지 이해하는 것이 정말 중요해요. 실수로 원본 데이터를 망가뜨릴 수 있거든요\!

  * **뷰 (View)**: 배열의 일부를 선택했는데, 이게 **원본 데이터와 연결된 다른 이름** 같은 거예요. 뷰를 변경하면 **원본 배열의 데이터도 함께 변경**돼요. 주로 **슬라이싱**(`배열[시작:끝]`)을 할 때 뷰가 만들어져요.
  * **복사 (Copy)**: 원본 데이터와는 **완전히 독립적인 새로운 데이터 덩어리**를 만드는 거예요. 복사본을 변경해도 **원본 배열은 전혀 바뀌지 않아요**. **고급 인덱싱**을 사용하거나, `배열.copy()`를 사용하면 복사본이 만들어져요.
  * **확인 방법 (`.base` 속성)**: 배열의 `.base` 속성이 `None`이면 원본이거나 복사본이에요. 만약 `None`이 아니면, 이 배열은 다른 배열의 '뷰'라는 뜻이고, `.base`가 가리키는 것이 원본 배열이에요.

### 13.7 벡터화 (Vectorization): 파이썬 반복문 대신 NumPy의 힘 활용하기

파이썬 `for` 반복문으로 배열의 각 요소를 처리하는 것은 느릴 수 있어요. NumPy는 이런 작업을 훨씬 빠르게 처리하는 `벡터화`라는 강력한 기능을 제공해요.

  * **개념**: NumPy는 내부적으로 C언어로 구현되어 있어서, `for` 반복문 없이 배열 전체에 연산을 한 번에 적용하는 것이 가능해요. 이걸 `벡터화`라고 불러요.
  * **`np.vectorize`**: 만약 직접 만든 파이썬 함수를 NumPy 배열에 적용하고 싶다면, `np.vectorize`를 사용해서 그 함수를 NumPy와 호환되도록 '포장'할 수 있어요. 이렇게 하면 NumPy가 각 요소에 함수를 빠르게 적용해줘요.

### 13.8 행렬 곱셈 연산자 (`@`)

  * `@` 연산자는 NumPy에서 **행렬 곱셈**을 수행하는 편리한 방법이에요. 예전에는 `np.matmul()` 함수를 사용해야 했지만, 이제는 `@` 기호 하나로 더 직관적으로 사용할 수 있어요. 선형대수학에서 많이 쓰이는 중요한 연산이죠\!

### 13.9 사용자 정의 데이터 타입 (Custom Data Types): 메모리를 효율적으로

NumPy는 배열의 요소에 따라 `int64`(정수), `float64`(실수) 등의 데이터 타입을 자동으로 추론해요. 하지만 때로는 우리가 직접 데이터 타입을 지정해서 메모리 사용을 최적화하거나, 원치 않는 타입 변경을 막을 수 있어요.

  * **명시적 지정**: `np.dtype`을 사용해서 `np.int32`(4바이트 정수)처럼 특정 데이터 타입을 명확하게 지정할 수 있어요.
  * **문자열 표기법**: `'U10'` (최대 10자 유니코드 문자열), `'I4'` (4바이트 정수)처럼 간결한 문자열로도 데이터 타입을 지정할 수 있어요.
  * **왜 중요할까요?**: NumPy가 데이터를 자동으로 추론할 때, 실제 필요한 것보다 더 많은 메모리를 할당할 수 있어요. 예를 들어, 짧은 문자열만 있는 배열에 NumPy가 `U100` (100자 문자열)을 할당할 수도 있죠. 이때 `U10`처럼 정확히 지정해주면 **메모리를 훨씬 효율적으로 사용**하고, 연산 속도도 빨라져요.

## 14. Pandas
- 출처: [Pandas Full Python Course - Data Science Fundamentals](https://www.youtube.com/watch?v=EhYC02PD_gc)

### 14.1 Pandas는 왜 중요할까요?

  * **데이터를 쉽게 다룰 수 있어요**: Pandas는 파이썬에서 데이터를 쉽게 넣고 빼고, 정리하고, 분석할 수 있도록 만들어졌어요.
  * **핵심은 '데이터프레임'**: Pandas의 가장 중요한 개념은 \*\*데이터프레임(DataFrame)\*\*이라는 거예요. 이건 마치 엑셀 시트나 데이터베이스의 테이블처럼 **표 형태로 데이터를 저장**하는 구조라고 생각하면 돼요. 대부분의 데이터는 이 데이터프레임 형태로 되어 있거나 쉽게 바꿀 수 있어서, 머신러닝 모델을 만들거나 통계 분석, 시각화 등을 할 때 아주 유용하게 쓰여요.
  * **다양한 기능**: 데이터프레임에서 원하는 데이터를 찾고(쿼리), 걸러내고(필터링), 요약하고(집계), 묶고(그룹화), 정렬하고, 여러 개의 표를 합치는(연결, 병합) 등 데이터와 관련된 거의 모든 작업을 할 수 있어요.

### 14.2 Pandas 시작하기: 설치와 기본 사용법

Pandas를 사용하려면 먼저 컴퓨터에 설치해야 해요.

  * **설치**: 명령 프롬프트나 터미널을 열고 다음 명령어 중 하나를 입력하세요.
    ```bash
    pip install pandas
    # 또는
    pip3 install pandas
    ```
  * **편리한 개발 환경**: 데이터 과학 작업에는 \*\*Jupyter Lab(주피터 랩)\*\*이나 \*\*Jupyter Notebook(주피터 노트북)\*\*을 사용하는 게 좋아요. 코드를 한 줄씩 실행할 수 있어서 데이터를 매번 다시 불러오거나 모델을 재학습할 필요 없이 편하게 작업할 수 있답니다.
  * **불러오기**: 파이썬 코드에서 Pandas를 사용하려면 항상 맨 위에 다음 코드를 추가해야 해요.
    ```python
    import pandas as pd
    ```
    여기서 `as pd`는 '앞으로 Pandas를 `pd`라는 짧은 이름으로 부를게\!'라는 약속이에요. 이렇게 하면 코드를 더 짧게 쓸 수 있어서 편리하죠.

### 14.3 Pandas의 핵심 데이터 구조: Series와 DataFrame

Pandas는 데이터를 \*\*Series(시리즈)\*\*와 \*\*DataFrame(데이터프레임)\*\*이라는 두 가지 형태로 다뤄요.

  * **Series (시리즈)**

      * **데이터프레임의 '한 줄' 또는 '한 칸'**: Series는 데이터프레임의 \*\*단일 컬럼(열)\*\*이라고 생각하면 돼요.
      * **값과 인덱스**: 파이썬의 '딕셔너리(사전)'처럼 값을 가지고 있고, 각 값에 대한 **인덱스(Index)** 또는 \*\*레이블(Label)\*\*을 가지고 있어요. 인덱스는 기본적으로 0부터 시작하는 숫자지만, 'a', 'b', 'c'처럼 우리가 원하는 이름을 붙일 수도 있어요.
      * **인덱스는 중복 가능**: 데이터베이스의 '기본 키'와 다르게 Series의 인덱스는 중복될 수도 있어요.
      * **빠른 접근**: 이 인덱스를 사용하면 데이터에 빠르게 접근할 수 있답니다.

  * **DataFrame (데이터프레임)**

      * **Series들의 모임**: 데이터프레임은 여러 개의 Series(컬럼)가 합쳐져서 만들어진 **표 형태의 구조**예요.
      * **만들기**: 보통 파이썬 딕셔너리를 사용해서 만들어요. 딕셔너리의 '키'가 컬럼 이름이 되고, '값'은 해당 컬럼의 데이터 리스트가 돼요.
      * **인덱스 관리**: 데이터프레임도 기본적으로 0부터 시작하는 행 인덱스를 가지고 있어요. 특정 컬럼을 행의 인덱스로 설정하거나(`df.set_index()`), 인덱스를 다시 일반 컬럼으로 되돌릴 수 있어요(`df.reset_index()`).
          * **주의**: `df = df.set_index('컬럼명')`처럼 변경된 내용을 다시 변수에 할당해야 적용돼요. `inplace=True` 옵션은 가급적 사용하지 않는 것이 좋아요.
      * **데이터 정렬**: 데이터프레임끼리 계산할 때는 인덱스를 기준으로 데이터를 맞춰서 계산해요.


### 14.4 데이터 불러오고 저장하기

Pandas는 다양한 형식의 데이터를 쉽게 불러오고 저장할 수 있게 해줘요.

  * **저장하기 (`to_csv()`, `to_json()` 등)**:
    ```python
    df.to_csv('내_데이터.csv') # 데이터프레임을 CSV 파일로 저장
    ```
    `index=False` 옵션을 추가하면 저장할 때 행 인덱스가 파일에 포함되지 않아서 깔끔해요.
  * **불러오기 (`pd.read_csv()`, `pd.read_json()` 등)**:
    ```python
    my_df = pd.read_csv('내_데이터.csv') # CSV 파일을 데이터프레임으로 불러오기
    ```
    만약 데이터를 저장할 때 행 인덱스도 같이 저장했는데, 불러올 때 인덱스 컬럼이 추가로 생긴다면 `index_col=0` 옵션을 사용해서 첫 번째 컬럼을 인덱스로 지정해주면 돼요.

### 14.5 데이터 훑어보기 (탐색)

데이터를 분석하기 전에 전체적인 모습을 파악하는 것이 중요해요.

  * **미리보기**:
      * `df.head(n)`: 데이터프레임의 **맨 위 `n`개** 행을 보여줘요 (기본값은 5개).
      * `df.tail(n)`: 데이터프레임의 **맨 아래 `n`개** 행을 보여줘요.
      * `df.sample(n)`: 데이터프레임에서 **무작위로 `n`개** 행을 뽑아 보여줘요.
  * **기본 정보 확인**:
      * `df.columns`: 데이터프레임의 **모든 컬럼 이름**을 리스트로 보여줘요.
      * `df.info()`: 각 컬럼의 이름, **비어있지 않은 값의 개수(결측치 확인)**, 데이터 타입 등 데이터프레임의 **간략한 요약 정보**를 한눈에 볼 수 있어요. 다양한 데이터 타입이 섞여 있으면 성능이 느려질 수 있어요.
  * **통계 정보 확인**:
      * `df.describe()`: 숫자형 컬럼에 대한 \*\*요약 통계(평균, 최소/최대값 등)\*\*를 한 번에 보여줘요.
      * `df['컬럼명'].mean()`: 특정 컬럼의 **평균**을 계산해요. `.min()`, `.max()`, `.std()` (표준 편차), `.median()` (중앙값), `.sum()` 등 다양한 통계 함수를 사용할 수 있어요.
  * **데이터 시각화**: Pandas는 Matplotlib이라는 그림 그리는 도구와 연동해서 데이터를 쉽게 그림으로 보여줄 수 있어요.
      * `df['컬럼명'].hist()`: 특정 컬럼의 데이터가 어떻게 분포되어 있는지 **히스토그램**으로 보여줘요.
      * `df.hist()`: 모든 숫자형 컬럼에 대한 히스토그램을 한 번에 그려줘요.
      * `df['컬럼명'].plot()`: 기본적으로 선 그래프를 그려주며, `plot.bar`(막대 그래프), `plot.pie`(파이 그래프) 등으로 변경할 수도 있어요.

### 14.6 데이터 접근 및 조작 (인덱싱)

원하는 데이터만 선택하거나 값을 바꾸는 방법을 알아볼게요.

  * **특정 값/행/열 선택**:
      * `df.loc[]` (레이블 기반): **인덱스 이름**이나 **컬럼 이름**을 사용해서 선택해요.
        ```python
        df.loc['앨리스']        # '앨리스' 인덱스를 가진 행 선택
        df.loc['앨리스', '나이']  # '앨리스' 행의 '나이' 컬럼 값 선택
        ```
      * `df.iloc[]` (정수 위치 기반): \*\*정수 위치(순서)\*\*를 사용해서 선택해요.
        ```python
        df.iloc[0]          # 첫 번째 행 선택
        df.iloc[0, 1]       # 첫 번째 행의 두 번째 컬럼 값 선택
        ```
      * `df.at[]` / `df.iat[]`: 단일 값을 빠르게 선택하거나 변경할 때 `loc`/`iloc`보다 효율적이에요.
  * **데이터 변경**: `df.at['앨리스', '나이'] = 60`처럼 특정 셀이나 행의 값을 바꿀 수 있어요.
  * **새로운 행 추가**: `df.loc['존'] = [90, '선생님']`처럼 새로운 인덱스 이름을 사용해서 새로운 행을 쉽게 추가할 수 있어요.
  * **슬라이싱**: `df.iloc[0:2]`처럼 파이썬의 슬라이싱 문법을 사용해서 여러 행을 한 번에 선택할 수 있어요.
  * **컬럼 단위 연산**: `df['나이'] = df['나이'] * 2`처럼 컬럼 전체에 대해 수학 계산을 할 수 있어요.
  * **`apply()` 함수**: 데이터프레임의 컬럼(Series)이나 행에 **직접 만든 함수**를 적용할 때 사용해요. `axis=1`을 지정하면 행 단위로 함수를 적용할 수 있어요.

### 14.7 데이터 클리닝 (깔끔하게 정리하기)

실제 데이터에는 빠져있거나(결측치), 잘못된 값들이 많아요. 이런 '더러운' 데이터를 깔끔하게 정리하는 것이 데이터 클리닝이에요.

  * **결측치 (Missing Values)**: 데이터가 비어있는 값은 보통 `NaN`(Not a Number, 숫자가 아님)으로 표시돼요.
      * `df.info()`로 비어있지 않은 값의 개수를 확인해서 결측치를 찾을 수 있어요.
  * **결측치 처리**:
      * `df.dropna()`: `NaN` 값이 있는 **모든 행을 삭제**해요.
      * `df.fillna(값)`: `NaN` 값을 특정 값(예: 0, -1)으로 **채워 넣어요**.
      * `df['컬럼명'].fillna(df['컬럼명'].mean())`: 특정 컬럼의 **평균값** 등으로 `NaN` 값을 채우는 똑똑한 방법도 있어요.
      * `df['컬럼명'].notna()`: `NaN`이 아닌 값에 대해 `True`를 반환해서 결측치가 없는 행만 걸러낼 때 사용해요.

### 14.8 데이터 반복 (Iteration): 행과 열을 하나씩 훑어보기

데이터프레임의 각 행이나 열을 반복해서 처리해야 할 때가 있어요.

  * **행 단위 반복**: `for index, row in df.iterrows():` 형태로 사용해서 데이터프레임의 각 행을 하나씩 살펴볼 수 있어요. `row`는 해당 행의 값을 담고 있는 Series 객체예요.
  * **컬럼 단위 반복**: `for col_name, col_series in df.items():` 형태로 사용해서 각 컬럼을 하나씩 살펴볼 수 있어요.

### 14.9 데이터 필터링 및 쿼리 (원하는 데이터만 골라내기)

특정 조건을 만족하는 데이터만 골라낼 때 사용해요.

  * **불리언 인덱싱**: 조건을 만족하면 `True`, 아니면 `False`를 가진 Series를 만들어서, `True`인 행만 선택하는 방식이에요.
    ```python
    df[df['나이'] > 50] # 나이가 50보다 많은 사람만 선택
    ```
  * **조건 결합**: `&` (그리고), `|` (또는), `~` (아닌) 연산자를 사용해서 여러 조건을 함께 적용할 수 있어요.
    ```python
    df[(df['나이'] > 50) & (df['직업'].notna())] # 나이가 50보다 많고 직업이 비어있지 않은 사람 선택
    ```
  * **문자열/날짜 시간 메소드**: 컬럼 이름 뒤에 `.str`이나 `.dt`를 붙여서 문자열이나 날짜/시간 데이터에 대한 특별한 작업을 할 수 있어요.
      * `df['이름'].str.endswith('이')`: 이름이 '이'로 끝나는지 확인
      * `df['생일'].dt.year > 1950`: 생일의 연도가 1950년보다 뒤인지 확인
  * **`isin()` 메소드**: 특정 컬럼의 값이 주어진 리스트 안에 포함되는지 확인할 때 사용해요.
  * **`query()` 메소드**: 조건문을 문자열 형태로 직접 써서 데이터를 필터링할 수 있는 또 다른 방법이에요. 가독성이 좋고, 데이터가 많을 때 성능 이점도 있을 수 있지만, 모든 필터링 문법을 지원하지는 않아요.

### 14.10 데이터 그룹화 (Grouping): 데이터를 묶어서 요약하기

특정 기준(예: 직업, 지역)별로 데이터를 묶어서 각 그룹의 평균, 합계 등을 계산할 때 사용해요.

  * `df.groupby('컬럼명')`: 특정 컬럼의 같은 값을 가진 데이터끼리 묶어요.
  * 묶은 데이터에 `mean()`, `min()`, `max()`, `sum()` 같은 **집계 함수**를 적용하면 각 그룹별 통계치를 쉽게 얻을 수 있어요. 여러 개의 집계 함수를 동시에 적용할 수도 있답니다.

### 14.11 데이터 정렬 (Sorting): 원하는 순서대로 줄 세우기

  * `df.sort_values(by='컬럼명')`: 특정 컬럼의 값을 기준으로 데이터프레임을 정렬해요.
  * `ascending=False` 옵션을 추가하면 내림차순(큰 값부터 작은 값 순서)으로 정렬할 수 있어요.

### 14.12 데이터 병합, 연결, 조인 (표 합치기)

여러 개의 데이터프레임을 하나로 합쳐야 할 때 사용하는 기능이에요.

  * **Concatenating (연결)**: 데이터프레임을 단순히 위아래로(행 기준) 또는 옆으로(열 기준) 쌓아 올리는 거예요.
      * `pd.concat([df1, df2])`: 행을 위아래로 연결 (기본값)
      * `pd.concat([df1, df2], axis=1)`: 열을 옆으로 연결 (두 데이터프레임의 인덱스가 같을 때 유용)
  * **Merging (병합)**: 두 데이터프레임에 **공통된 컬럼**이 있을 때, 그 컬럼의 값을 기준으로 데이터를 합치는 거예요. 마치 엑셀에서 VLOOKUP을 하는 것과 비슷해요.
      * `pd.merge(df1, df2, on='공통컬럼명', how='병합방식')`
      * **`how` 매개변수**: 어떻게 합칠지 결정해요.
          * `'inner'` (기본값): 두 표 모두에 있는 공통된 데이터만 합쳐요.
          * `'outer'`: 두 표의 모든 데이터를 합치고, 없는 부분은 `NaN`으로 채워요.
          * `'left'`: 왼쪽 표의 모든 데이터를 기준으로 합치고, 오른쪽 표에 없는 부분은 `NaN`으로 채워요.
          * `'right'`: 오른쪽 표의 모든 데이터를 기준으로 합치고, 왼쪽 표에 없는 부분은 `NaN`으로 채워요.
  * **Joining (조인)**: `merge`와 비슷하지만, **인덱스를 기준**으로 데이터를 합치는 방법이에요.
