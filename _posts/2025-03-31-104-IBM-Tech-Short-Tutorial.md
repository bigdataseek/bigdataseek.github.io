---
title: 25차시 3:IBM TECH(종합 내용)
layout: single
classes: wide
categories:
  - IBM TECH(종합 내용)
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 21. Bias-Variance Tradeoff
- 출처: [Mastering Bias and Variance in Machine Learning Models](https://www.youtube.com/watch?v=tUs0fFo7ki8)

### **21.1 문제 상황**

* **데이터 전처리 후 머신러닝 모델 학습 시 발생할 수 있는 문제**
    * **과소적합 (Underfitting):**
        * 모델이 너무 단순하여 데이터의 복잡한 패턴을 제대로 학습하지 못하는 현상입니다.
        * 훈련 데이터와 테스트 데이터 모두에서 낮은 성능을 보입니다.
        * 예시: 선형 회귀 모델로 비선형 데이터 패턴을 예측하는 경우
    * **과적합 (Overfitting):**
        * 모델이 훈련 데이터의 노이즈까지 과도하게 학습하여 새로운 데이터에 대한 일반화 능력이 떨어지는 현상입니다.
        * 훈련 데이터에서는 높은 성능을 보이지만, 테스트 데이터에서는 낮은 성능을 보입니다.
        * 예시: 매우 복잡한 결정 트리 모델로 작은 데이터셋을 학습하는 경우

### **21.2 원인 분석: Bias 와 Variance**

* **Bias (편향):**
    * 모델의 예측값이 실제값에서 얼마나 벗어나는지를 나타냅니다.
    * 높은 Bias는 모델의 단순성으로 인해 발생하는 오차입니다.
    * 높은 Bias 모델은 데이터의 숨겨진 패턴을 간과하고, 단순한 가정에 기반하여 예측합니다.
* **Variance (분산):**
    * 훈련 데이터의 작은 변동에 모델의 예측값이 얼마나 민감하게 변하는지를 나타냅니다.
    * 높은 Variance는 모델의 복잡성으로 인해 발생하는 오차입니다.
    * 높은 Variance 모델은 훈련 데이터의 노이즈까지 학습하여, 새로운 데이터에 대한 예측 성능이 불안정

### **21.3 Bias-Variance Tradeoff**

* **이상적인 모델:**
    * 낮은 Bias와 낮은 Variance를 동시에 달성하는 것은 매우 어렵습니다.
    * 모델의 복잡도를 적절히 조절하여 Bias와 Variance 사이의 균형을 찾는 것이 중요합니다.
* **모델 복잡도 증가에 따른 변화:**
    * 모델 복잡도 증가 → Bias 감소, Variance 증가: 모델이 복잡해질수록 훈련 데이터를 더 잘 학습하지만, 노이즈에도 민감해집니다.
    * 총 에러(Total Error) = Bias² + Variance + Noise: 총 에러는 Bias와 Variance의 영향을 받으며, Noise는 데이터 자체의 불가피한 오차입니다.
* **목표:**
    * 총 에러를 최소화하는 최적의 모델 복잡도를 찾는 것이 핵심입니다.
    * 이를 위해 교차 검증(Cross-Validation) 등의 기법을 사용하여 모델의 성능을 평가하고, 하이퍼파라미터를 조정합니다.

### **21.4 해결책 심층 분석**

* **모델 복잡도 조절:**
    * 모델의 복잡도를 줄여 Bias를 낮추고, Variance를 줄여 과적합을 방지합니다.
    * 규제(Regularization) 기법을 사용하여 모델의 복잡도를 제어합니다. (L1, L2 규제)
    * 다양한 모델들을 시도해보고 비교해봅니다.
* **데이터 확보 및 전처리:**
    * 더 많은 훈련 데이터를 확보하여 모델의 일반화 능력을 향상합니다.
    * 데이터 전처리 과정에서 노이즈를 제거하고, 중요한 특성을 추출합니다.
* **앙상블(Ensemble) 기법:**
    * 여러 모델을 결합하여 Bias와 Variance를 동시에 줄입니다.
    * 배깅(Bagging), 부스팅(Boosting) 등의 앙상블 기법을 사용합니다.
* **교차 검증(Cross-Validation):**
    * 모델의 성능을 객관적으로 평가하고, 과적합을 방지합니다.
    * K-fold 교차 검증 등의 기법을 사용하여 모델의 일반화 성능을 측정합니다.
