---
title: 25차시 3:IBM TECH(종합 내용)
layout: single
classes: wide
categories:
  - IBM TECH(종합 내용)
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 21. Bias-Variance Tradeoff
- 출처: [Mastering Bias and Variance in Machine Learning Models](https://www.youtube.com/watch?v=tUs0fFo7ki8)

### **21.1 문제 상황**

* **데이터 전처리 후 머신러닝 모델 학습 시 발생할 수 있는 문제**
    * **과소적합 (Underfitting):**
        * 모델이 너무 단순하여 데이터의 복잡한 패턴을 제대로 학습하지 못하는 현상입니다.
        * 훈련 데이터와 테스트 데이터 모두에서 낮은 성능을 보입니다.
        * 예시: 선형 회귀 모델로 비선형 데이터 패턴을 예측하는 경우
    * **과적합 (Overfitting):**
        * 모델이 훈련 데이터의 노이즈까지 과도하게 학습하여 새로운 데이터에 대한 일반화 능력이 떨어지는 현상입니다.
        * 훈련 데이터에서는 높은 성능을 보이지만, 테스트 데이터에서는 낮은 성능을 보입니다.
        * 예시: 매우 복잡한 결정 트리 모델로 작은 데이터셋을 학습하는 경우

### **21.2 원인 분석: Bias 와 Variance**

* **Bias (편향):**
    * 모델의 예측값이 실제값에서 얼마나 벗어나는지를 나타냅니다.
    * 높은 Bias는 모델의 단순성으로 인해 발생하는 오차입니다.
    * 높은 Bias 모델은 데이터의 숨겨진 패턴을 간과하고, 단순한 가정에 기반하여 예측합니다.
* **Variance (분산):**
    * 훈련 데이터의 작은 변동에 모델의 예측값이 얼마나 민감하게 변하는지를 나타냅니다.
    * 높은 Variance는 모델의 복잡성으로 인해 발생하는 오차입니다.
    * 높은 Variance 모델은 훈련 데이터의 노이즈까지 학습하여, 새로운 데이터에 대한 예측 성능이 불안정

### **21.3 Bias-Variance Tradeoff**

* **이상적인 모델:**
    * 낮은 Bias와 낮은 Variance를 동시에 달성하는 것은 매우 어렵습니다.
    * 모델의 복잡도를 적절히 조절하여 Bias와 Variance 사이의 균형을 찾는 것이 중요합니다.
* **모델 복잡도 증가에 따른 변화:**
    * 모델 복잡도 증가 → Bias 감소, Variance 증가: 모델이 복잡해질수록 훈련 데이터를 더 잘 학습하지만, 노이즈에도 민감해집니다.
    * 총 에러(Total Error) = Bias² + Variance + Noise: 총 에러는 Bias와 Variance의 영향을 받으며, Noise는 데이터 자체의 불가피한 오차입니다.
* **목표:**
    * 총 에러를 최소화하는 최적의 모델 복잡도를 찾는 것이 핵심입니다.
    * 이를 위해 교차 검증(Cross-Validation) 등의 기법을 사용하여 모델의 성능을 평가하고, 하이퍼파라미터를 조정합니다.

### **21.4 해결책 심층 분석**

* **모델 복잡도 조절:**
    * 모델의 복잡도를 줄여 Bias를 낮추고, Variance를 줄여 과적합을 방지합니다.
    * 규제(Regularization) 기법을 사용하여 모델의 복잡도를 제어합니다. (L1, L2 규제)
    * 다양한 모델들을 시도해보고 비교해봅니다.
* **데이터 확보 및 전처리:**
    * 더 많은 훈련 데이터를 확보하여 모델의 일반화 능력을 향상합니다.
    * 데이터 전처리 과정에서 노이즈를 제거하고, 중요한 특성을 추출합니다.
* **앙상블(Ensemble) 기법:**
    * 여러 모델을 결합하여 Bias와 Variance를 동시에 줄입니다.
    * 배깅(Bagging), 부스팅(Boosting) 등의 앙상블 기법을 사용합니다.
* **교차 검증(Cross-Validation):**
    * 모델의 성능을 객관적으로 평가하고, 과적합을 방지합니다.
    * K-fold 교차 검증 등의 기법을 사용하여 모델의 일반화 성능을 측정합니다.


## 22. RAG 모델 평가를 위한 핵심 지표
- 출처: [7 measurements that help minimize model risk for RAG](https://www.youtube.com/watch?v=DRZMjP5Pg5A)

### **22.1 RAG (Retrieval Augmented Generation)란?**

*   벡터 데이터베이스의 최신 정보를 활용하여 질문에 대한 답변을 자연어로 제공하는 생성 AI 방법. 이 방법은 대규모 언어 모델(LLM)에 검색된 외부 데이터를 결합하여, 단순히 학습된 데이터에 의존하지 않고 실시간으로 업데이트된 정보를 반영할 수 있는 것이 특징이다.
*   여러 소스의 정보를 종합하여 하나의 답변으로 제공하는 것이 핵심. 예를 들어, 뉴스 기사, 학술 논문, 웹 데이터 등 다양한 출처에서 추출된 정보를 통합하여 사용자가 요구한 질문에 맞는 일관성 있는 응답을 생성한다.

### **22.2. RAG 모델 평가의 중요성**

*   모델 모니터링을 통해 위험을 최소화하고 안전하게 사용. 이는 모델이 부정확하거나 편향된 정보를 제공하거나, 윤리적 문제를 일으킬 가능성을 줄이기 위해 필수적이며, 특히 실제 응용 환경에서 신뢰성을 확보하는 데 중요한 역할을 한다.

### **22.3 7가지 핵심 평가 지표**

*   **Rouge (Recall and Completeness):** 
    - 모델이 생성한 응답과 사람이 생성한 예상 응답 그룹을 비교하여 응답의 완성도를 측정 (0과 1 사이의 값). 
    - 이 지표는 생성된 텍스트가 참조 답변의 내용을 얼마나 잘 포함하고 있는지를 평가하며, 주로 정보의 재현율에 초점을 둔다.
*   **BLEU (Precision):** 
    - 모델이 생성한 응답과 예상 응답 그룹을 비교하여 단어의 정확도를 측정. 긴 응답에 대한 페널티가 있을 수 있음. 
    - 이 지표는 생성된 텍스트가 참조 텍스트와 얼마나 정확히 일치하는지를 확인하며, 특히 번역이나 요약 작업에서 자주 사용된다.
*   **METEOR (Harmonic Mean of Precision and Recall):** 
    - 정밀도와 재현율의 평균을 제공하여 모델 성능에 대한 균형 잡힌 평가를 제공. 
    - 단어의 동의어, 어간, 의미적 유사성을 고려하기 때문에 BLEU보다 더 유연한 평가가 가능하다.
*   **PII (Personally Identifiable Information):** 
    - 개인 식별 정보 (전화번호, 이메일, 이름 등)가 모델에서 생성되지 않도록 관리. 
    - 이는 개인정보 보호법(GDPR 등)을 준수하고, 사용자의 프라이버시를 지키기 위한 필수적인 요소로, 특히 상업적 활용 시 중요하다.
*   **HAP (Hate, Abuse, Profanity):** 
    - 혐오, 학대, 욕설 콘텐츠가 모델에서 생성되지 않도록 모니터링. 
    - 이는 모델이 사회적 책임을 다하고, 사용자에게 안전하고 적절한 경험을 제공하도록 보장
*   **Context Relevance:** 
    - 모델이 질문과 관련된 답변을 제공하는지 평가.
    - 예: "뉴욕주의 위치와 수도는?" 질문에 "뉴욕은 엠파이어 스테이트이다."라는 답변은 관련성이 낮음. 이 지표는 모델이 문맥을 이해하고 주제에서 벗어나지 않는지를 확인하며, 사용자 경험에 직접적인 영향을 미친다.
*   **Hallucination:** 
    - 모델이 사실과 다르거나 완전히 틀린 정보를 제공하지 않도록 확인.
    - 예: 뉴욕에 대한 질문에 대해 정확하고 관련된 정보를 제공하는지 확인. 이는 모델이 검색된 데이터를 기반으로 하더라도 잘못된 추론이나 허구를 생성하지 않도록 보장하는 데 중점을 둔다.


## 23. 고객 상담 경험 개선을 위한 생성형 AI 활용
- 출처: [5 Generative AI Capabilities for Call Center Dashboards](https://www.youtube.com/watch?v=Vipb458S-co)


### **23.1 문제점**

*   고객 상담 시 실제 상담원 연결이 어렵고, 연결되더라도 상담원이 고객의 이전 상담 내역이나 문제 상황을 제대로 파악하지 못해 불편함 발생  
    - 예를 들어, 고객이 반복적으로 동일한 문제를 설명해야 하거나, 상담원이 맥락을 이해하지 못해 부정확한 답변을 제공하는 경우가 빈번히 발생하며, 이는 고객의 시간 낭비와 불만으로 이어짐.

### **23.2 해결 방안: 생성형 AI 활용**

1.  **LLM(Large Language Model) 활용:**

    *   **요약:** 이전 상담 내용을 LLM을 통해 요약하여 상담원이 빠르게 고객의 상황 파악  
        - 방대한 텍스트 데이터를 몇 문장으로 압축해 상담원이 고객과의 대화 시작 전 핵심 정보만 빠르게 확인 가능.  
    *   **감정 분석:** 이전 상담 내용의 감정(긍정/부정) 분석하여 상담 시 고객 응대 전략 수립  
        - 예: 고객이 이전 상담에서 좌절감을 표현했다면, 상담원이 더 공감적인 태도로 접근하거나 신속한 문제 해결에 집중하도록 유도.  
    *   **의도 분류:** 고객의 상담 목적(제품 문의, 청구 문제 등)을 LLM이 분류하여 상담 효율 증대  
        - 고객 문의의 핵심 의도를 자동으로 파악해 상담원을 적절한 부서나 전문 분야로 연결하거나, 관련 자료를 미리 준비하게 함.

2.  **RAG(Retrieval Augmented Generation) 활용:**

    *   상담원이 질문을 입력하는 대신, AI가 실시간 음성 인식을 통해 상담 내용을 파악하고 관련 정보를 제공  
        - 고객과의 대화 중 실시간으로 음성을 텍스트로 변환하고, 이를 기반으로 즉각적인 답변 자료를 제시해 상담 지연 최소화.  
    *   제품 설명서, FAQ, 이전 문의 티켓 등의 데이터를 벡터 데이터베이스에 저장하여 LLM이 필요한 정보를 신속하게 검색 및 제공  
        - 방대한 데이터 속에서 키워드 기반이 아닌 의미 기반 검색으로, 고객 질문에 가장 적합한 정보를 빠르게 찾아 상담 품질 향상.  
    *   상담원 숙련도 향상 및 여러 상담원으로 연결되는 횟수 감소  
        - 신입 상담원도 AI의 도움으로 전문가 수준의 답변을 제공할 수 있으며, 고객이 문제 해결을 위해 여러 상담원을 거치지 않아도 됨.

3.  **추가 기능:**

    *   **자동 티켓 생성:** LLM이 상담 내용을 바탕으로 자동으로 문의 티켓의 내용을 채워 상담원의 업무 효율성 향상  
        - 상담 종료 후 수작업으로 티켓을 작성할 필요 없이, AI가 대화 요약과 문제 분류를 자동으로 완료해 후속 조치 시간 단축.  
    *   **제품 추천:** 고객 정보 기반 맞춤형 제품 추천  
        - 고객의 구매 이력, 선호도, 상담 맥락을 분석해 개인화된 제안을 제공, 예를 들어 "고객님께는 이 제품이 더 적합할 수 있습니다"와 같은 추천 가능.  
    *   **최적 행동 제시:** 상담 중 상담원에게 가장 적절한 다음 행동 제시 (예: 추가 정보 제공, 문제 해결 안내 등)  
        - 실시간으로 "고객에게 사과 후 보상 제안" 또는 "기술팀으로 이관 권장" 같은 구체적 가이드 제공.

### **23.4 기대 효과**

*   상담원 생산성 및 효율성 향상  
    - AI가 사전 작업과 정보 검색을 지원해 상담원이 문제 해결에만 집중 가능.  
*   고객 만족도 향상  
    - 신속하고 정확한 응대, 개인화된 경험 제공으로 고객 신뢰도 증가.  
*   상담원 교육 부담 감소  
    - AI가 실시간 지원과 피드백을 제공하므로 신입 상담원의 학습 곡선 단축.

## 24. Retrieval Augmented Generation (RAG) 개념
- 출처: [RAG Explained](https://www.youtube.com/watch?v=qppV3n3YlF8)

### **24.1 RAG의 비유**

*   **기자 (사용자):** 
    - 특정 주제에 대한 기사를 쓰고 싶어함. 
    - 예를 들어, 기자는 최신 기술 트렌드나 특정 사건에 대한 심층 보도를 준비 중일 수 있음.
*   **도서관 (데이터 소스):** 
    - 다양한 주제의 수많은 책 (데이터) 보유. 
    - 이곳에는 최신 연구 논문, 역사적 기록, 통계 자료 등 방대한 정보가 포함됨.
*   **사서 (RAG 시스템):** 
    - 어떤 책에 어떤 정보가 있는지 꿰뚫고 있음. 
    - 사서는 단순히 책을 나열하는 데 그치지 않고, 질문의 맥락을 이해해 가장 적합한 자료를 찾아냄.
*   **기자의 질문:** 
    - "특정 주제에 대한 책을 찾아주세요." 
    - 예를 들어, "2024년 AI 발전에 대한 자료를 알려주세요"와 같은 구체적인 요청일 수 있음.
*   **사서의 역할:** 
    - 질문에 맞는 책을 찾아 기자에게 제공. 
        - 사서는 방대한 도서관에서 관련성 높은 자료를 빠르게 골라내어 기자의 작업 효율성을 높임.
*   **결론:** 기자는 최신 정보를 찾는 전문가가 아니고, 사서는 기사를 쓰는 전문가가 아니지만, 협력을 통해 원하는 결과를 얻음. 이 과정에서 기자는 창의적 글쓰기에 집중하고, 사서는 정보 검색의 부담을 덜어줌으로써 상호 보완적인 관계가 형성됨.

### **24.2 RAG의 핵심 구성 요소**

*   **사용자 (User/Bot/Application):** 
    - 질문 또는 요청을 던지는 주체. (예: 비즈니스 분석가).
    -  예를 들어, 매출 데이터를 분석하려는 분석가나 고객 문의를 처리하는 챗봇이 이에 해당함.
*   **질문 (Prompt):** 
    - 사용자가 던지는 구체적인 질문. (예: "동북 지역 고객의 1분기 매출은 얼마였나요?"). 
    - 질문은 명확하고 구체적이어야 시스템이 정확한 답변을 도출할 수 있음.
*   **데이터 소스 (Data Sources):** 
    - LLM이 학습하지 않은 특정 비즈니스 데이터 (PDF, 이미지, 다른 비즈니스 어플리케이션 등). 
    - 예를 들어, 회사의 내부 보고서, 고객 피드백 이미지, ERP 시스템 데이터 등이 포함될 수 있음.
*   **벡터 데이터베이스 (Vector Database):** 
    - 구조적/비구조적 데이터를 수학적으로 표현 (embedding)하여 LLM이 이해하기 쉽게 만듦. 
    - 이는 텍스트나 이미지를 숫자 벡터로 변환해 의미적 유사성을 계산할 수 있게 함.
*   **대규모 언어 모델 (LLM):** 
    - 벡터 데이터베이스에서 추출한 데이터를 기반으로 질문에 대한 답변을 생성. 
    - LLM은 방대한 언어 이해 능력을 활용해 자연스럽고 맥락에 맞는 답변을 제공함.

### **24.3 RAG 작동 방식**

1.  사용자가 질문을 던짐. 예를 들어, "지난 분기 신제품 매출이 어땠나요?"라는 질문을 입력.
2.  RAG 시스템은 질문과 관련된 데이터를 벡터 데이터베이스에서 검색. 질문의 키워드와 의미를 분석해 관련 문서나 데이터를 찾아냄.
3.  검색된 데이터 (embedding)를 원래 질문에 추가하여 LLM에 전달. 이를 통해 LLM은 일반 지식뿐 아니라 최신 비즈니스 데이터를 반영한 답변을 준비할 수 있음.
4.  LLM은 보강된 질문을 기반으로 답변을 생성. 예를 들어, "지난 분기 신제품 매출은 5천만 달러로, 전년 대비 20% 증가했습니다"와 같은 구체적인 답변을 제공.
5.  새로운 데이터가 벡터 데이터베이스에 추가되면 embedding이 업데이트되어, 다음 질문에 더 정확한 답변을 제공할 수 있도록 함. 이는 시스템이 실시간으로 학습하며 최신성을 유지하게 함.

### **24.4 RAG 도입 시 고려 사항 (기업 고객의 우려 사항)**

*   **환각 (Hallucination) 및 부정확한 결과:** LLM이 사실과 다른 정보를 생성할 수 있다는 우려. 예를 들어, 실제 매출 데이터가 없는데도 임의의 숫자를 만들어 낼 가능성이 있음.
*   **편향 (Bias) 심화:** LLM이 기존의 편향된 정보를 답습하여 결과에 반영할 수 있다는 우려. 예를 들어, 특정 지역 고객 데이터를 과소평가하거나 과대평가하는 경향이 생길 수 있음.

### **24.5 RAG의 문제점 완화를 위한 방안**

*   **데이터 품질 관리:**
    *   벡터 데이터베이스에 입력되는 데이터의 품질이 중요 ("Garbage in, Garbage out"). 부정확하거나 오래된 데이터가 들어가면 결과도 신뢰할 수 없게 됨.
    *   데이터 정제, 거버넌스, 관리를 철저히 해야 함. 예를 들어, 중복 데이터 제거, 출처 확인, 최신성 유지 등의 프로세스가 필요함.
*   **LLM 선택:**
    *   학습 데이터에 대한 투명성이 확보된 LLM을 사용해야 함 (Black Box 모델 지양). 기업은 LLM이 어떤 데이터를 기반으로 학습했는지 알 권리가 있음.
    *   LLM 학습 데이터에 지적 재산권 침해 요소나 부정확한 정보, 편향을 유발하는 데이터가 없는지 확인해야 함. 예를 들어, 저작권 문제 있는 텍스트나 편파적인 기사가 포함되지 않도록 주의.
*   **데이터, AI 거버넌스, 데이터 관리가 필수적.** 이는 법적 리스크를 줄이고, 시스템의 신뢰성을 높이며, 장기적인 운영 안정성을 보장함.

### **24.6 결론**

RAG는 강력한 기술이지만, 데이터 품질, LLM 선택, 거버넌스라는 세 가지 요소를 모두 고려해야 비즈니스에 신뢰성 있는 결과를 제공할 수 있음. 이 세 요소가 조화를 이룰 때, RAG는 단순한 정보 검색을 넘어 비즈니스 의사결정을 지원하는 강력한 도구로 자리 잡을 수 있음.


