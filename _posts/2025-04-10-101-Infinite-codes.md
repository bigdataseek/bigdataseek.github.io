---
title: 28차시 1:Infinite Codes
layout: single
classes: wide
categories:
  - ML
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. 머신러닝 학습의 현실과 해결책
- 출처: [THIS is Why Machine Learning Is Hard For you](https://www.youtube.com/watch?v=QlbyGPVaRSE&t=48s)

### **1.1 흔한 오해**

*   **라이브러리 임포트와 `.fit()` 함수 호출만으로 쉽게 모델을 만들 수 있다는 생각.**  
    - 많은 초보자들은 `sklearn`이나 `TensorFlow` 같은 라이브러리를 사용하면 몇 줄의 코드로 강력한 모델을 구현할 수 있다고 믿습니다. 하지만 이는 단순히 "도구"를 사용하는 것일 뿐, 모델이 제대로 작동하려면 데이터 준비, 전처리, 적절한 알고리즘 선택 등이 선행되어야 합니다. 도구를 사용하는 방법만 배우는 것은 자동차 운전법을 배운 후 차량 정비나 연료 관리 없이 고속도로에 진입하는 것과 비슷합니다.

*   **데이터 과학자의 하루가 모델 튜닝과 커피숍 방문으로 채워져 있다는 환상.**  
    - 영화나 미디어에서는 데이터 과학자들이 항상 멋진 시각화를 만들거나 모델을 튜닝하며 여유롭게 일을 처리하는 모습을 보여줍니다. 그러나 현실에서는 데이터 수집, 전처리, 결측치 처리, 이상치 탐지 등 지루하고 반복적인 작업이 대부분입니다. 이러한 작업은 종종 전체 프로젝트 시간의 80% 이상을 차지합니다.

*   **단기간에 고수익을 올리는 ML 엔지니어가 될 수 있다는 기대.**  
    - 머신러닝은 높은 연봉과 빠른 성공을 약속하는 분야처럼 보일 수 있습니다. 하지만 실질적으로 성공하기 위해서는 깊은 이해와 경험, 그리고 끊임없는 학습이 필요합니다. 또한, ML 프로젝트는 실패 가능성이 높고, 결과를 검증하고 개선하는 데 많은 시간이 소요됩니다.


###  **1.2 핵심:** 모델 구현은 쉬운 부분이며, 진짜 어려움은 다른 곳에 있다.  
- `.fit()` 함수 호출로 모델을 훈련시키는 것은 마치 레고 블록을 조립하는 것처럼 간단하게 보일 수 있습니다. 하지만 모델이 실제로 문제를 해결하려면 데이터 품질, 피처 엔지니어링, 문제 정의, 비즈니스 목표와의 일치 여부 등을 고려해야 합니다. 이 과정에서 발생하는 복잡성과 불확실성이 머신러닝의 진정한 도전 과제입니다.

### **1.3 필요한 역량**

*   **코딩 능력:** 기본.  
    - 머신러닝은 코드를 통해 구현됩니다. Python, R, SQL 등의 언어를 자유롭게 다룰 수 있어야 하며, 효율적인 코드 작성 능력이 필수적입니다. 특히, 실제 환경에서는 성능 최적화와 유지보수가 중요합니다.

*   **통계적 사고:** 확률 분포, 가설 검정 이해.  
    - 머신러닝은 통계적 추론을 기반으로 합니다. 예를 들어, 데이터의 분포를 이해하지 못하면 잘못된 가정을 바탕으로 모델을 설계할 수 있으며, 이는 결국 부정확한 결과로 이어집니다. 또한, 모델의 신뢰성을 평가하기 위해 가설 검정과 같은 통계적 방법론이 필수적입니다.

*   **문제 정의:** 비즈니스 문제를 ML 문제로 전환하는 능력.  
    - 머신러닝은 기술적 도구일 뿐, 그 자체로는 가치를 창출하지 않습니다. 비즈니스 문제를 명확히 정의하고 이를 ML 문제로 변환하는 능력이 없다면, 아무리 좋은 모델을 만들어도 실질적인 영향을 미치기 어렵습니다.

*   **데이터 이해:** Garbage In, Garbage Out 방지.  
    - 데이터의 품질은 모델의 성능을 결정짓는 가장 중요한 요소입니다. 데이터가 불완전하거나 편향되어 있다면, 아무리 복잡한 알고리즘을 사용해도 의미 있는 결과를 얻을 수 없습니다. 따라서 데이터의 출처, 특성, 편향 등을 철저히 분석하는 것이 중요합니다.

*   **모델 선택:** 문제에 맞는 적절한 모델 선택 (복잡성이 항상 답은 아님).  
    - 모든 문제에 딥러닝을 적용하는 것은 비효율적일 수 있습니다. 때로는 간단한 선형 회귀나 의사결정 트리가 더 나은 성능을 발휘할 수 있습니다. 문제의 본질을 이해하고, 해당 문제에 적합한 모델을 선택하는 것이 핵심입니다.

*   **비즈니스 직관과 상식:** 실제 문제를 해결하는 모델 개발.  
    - 머신러닝 모델은 기술적 성능뿐만 아니라 비즈니스적 가치를 창출해야 합니다. 예를 들어, 모델이 99%의 정확도를 달성했더라도 비즈니스 목표와 일치하지 않는다면 실패한 프로젝트로 간주될 수 있습니다.

### **1.4 튜토리얼의 함정**

*   **깔끔한 데이터, 완벽한 시나리오만 다룸.**  
    - 대부분의 튜토리얼은 이미 전처리된 데이터를 제공하며, 모델링에 집중하도록 설계됩니다. 하지만 현실 세계에서는 데이터가 항상 완벽하지 않으며, 다양한 문제가 포함되어 있습니다. 이런 점을 간과하면 실제 문제를 해결하는 능력을 키우기 어렵습니다.

*   **실제 문제 해결 능력, 문제 해결 과정에서 발생하는 어려움 경험 부족.**  
    - 튜토리얼은 특정 문제를 해결하는 데 초점이 맞춰져 있지만, 실제 프로젝트에서는 예상치 못한 문제들이 계속해서 발생합니다. 이러한 문제를 해결하려면 경험과 창의적인 사고가 필요합니다.

*   **수학적 표기, 모델 성능 저하, 2AM 디버깅, 모델 작동 원리 이해 부족 등의 현실 외면.**  
    - 튜토리얼에서는 수학적 개념을 간략하게 다루거나 생략하는 경우가 많습니다. 하지만 실제 작업에서는 모델의 동작 원리를 깊이 이해하고, 성능 저하를 분석하며, 복잡한 디버깅 과정을 겪어야 합니다.

### **1.5 머신러닝 = 과학**

*   **단순 절차 암기가 아닌, 원리 이해가 중요.**  
    - 머신러닝은 단순히 코드를 따라 쓰는 작업이 아니라, 데이터와 알고리즘의 상호작용을 이해하는 과학적 접근이 필요합니다. 예를 들어, 경사하강법(Gradient Descent)의 원리를 이해하지 못하면 하이퍼파라미터 튜닝이나 모델 성능 개선에 어려움을 겪을 수 있습니다.

*   **레이저 포인터 사용법을 안다고 물리학자가 되는 것이 아닌 것처럼, 툴 사용법만 안다고 ML 전문가가 될 수 없음.**  
    - 라이브러리나 도구는 단순한 수단일 뿐입니다. 중요한 것은 문제를 해결하기 위한 과학적 사고와 방법론입니다. 예를 들어, `sklearn`의 `RandomForestClassifier`를 사용할 줄 안다고 해서 무조건 좋은 모델을 만들 수 있는 것은 아닙니다. 피처 선택, 데이터 분포, 모델 평가 지표 등에 대한 깊은 이해가 필요합니다.

*   **범죄 현장에 맞는 적절한 수사 방식을 아는 형사처럼, ML 문제에 대한 직관과 경험 필요.**  
    - 머신러닝 프로젝트는 범죄 수사와 유사합니다. 각 상황에 맞는 적절한 접근 방식을 선택하고, 문제를 체계적으로 분석하며, 데이터를 통해 가설을 검증해야 합니다. 이러한 과정은 단기간에 익힐 수 있는 것이 아니라, 지속적인 학습과 경험을 통해 얻어지는 능력입니다.

### **1.6 튜토리얼 지옥 탈출**

*   **실제 데이터:** Raw data, messy data 사용.  
    - 실제 데이터는 결측치, 이상치, 불균형 클래스 등 다양한 문제가 포함되어 있습니다. 이러한 데이터를 직접 처리하면서 데이터 전처리와 클렌징의 중요성을 체감할 수 있습니다. 이를 통해 현실 세계에서 발생할 수 있는 문제 해결 능력을 키울 수 있습니다.

*   **전체 파이프라인 구축:** 데이터 수집, 전처리, 모델링, 배포.  
    - 머신러닝 프로젝트는 단순히 모델을 학습시키는 것에 그치지 않습니다. 데이터를 어떻게 수집하고, 정제하고, 모델을 학습시키며, 최종적으로 서비스로 배포할 것인지 전체적인 파이프라인을 설계하고 구현하는 능력이 필요합니다. 이를 통해 프로덕션 환경에서의 문제를 미리 경험할 수 있습니다.

*   **모델 내부 이해:** 각 구성 요소의 역할 이해.  
    - 모델의 각 구성 요소(예: 활성화 함수, 손실 함수, 옵티마이저 등)가 어떤 역할을 하는지 이해하지 못하면, 모델이 실패했을 때 원인을 분석하거나 개선하기 어렵습니다. 예를 들어, 활성화 함수가 왜 필요한지, 특정 손실 함수가 어떤 상황에서 적합한지 이해하는 것이 중요합니다.

*   **문제 해결:** 기존 코드를 변형하거나, 새로운 문제에 적용.  
    - 튜토리얼을 따라하는 것에서 벗어나, 자신만의 문제를 정의하고 해결해보는 것이 중요합니다. 이를 위해 기존 코드를 수정하거나 새로운 데이터셋을 활용하여 독창적인 해결책을 찾아야 합니다. 이 과정에서 창의적 사고와 문제 해결 능력이 길러집니다.

### **1.7 문제 해결 능력 향상**

*   **문제 분해:** 큰 문제를 작은 하위 문제로 나누기.  
    - 복잡한 문제를 한 번에 해결하려고 하면 혼란스럽고 비효율적입니다. 예를 들어, "고객 이탈률을 낮추자"라는 목표는 데이터 수집, 타겟 변수 정의, 피처 엔지니어링, 모델 평가 등 여러 하위 문제로 나눌 수 있습니다. 각각의 하위 문제를 차례로 해결하면 전체 문제를 체계적으로 해결할 수 있습니다.

*   **유사 문제 활용:** 이전에 해결한 문제의 코드를 재사용 및 적용.  
    - 머신러닝에서 모든 문제를 처음부터 새로 시작할 필요는 없습니다. 예를 들어, 이미 구축한 분류 모델의 코드를 회귀 문제에 적응시킬 수 있습니다. 이때 중요한 것은 기존 코드를 단순히 복사-붙여넣기 하는 것이 아니라, 문제에 맞게 수정하고 확장하는 능력입니다.

*   **반복적인 개선:** 문제 해결 과정에서 발생하는 오류 수정.  
    - 머신러닝 프로젝트는 실패와 반복의 연속입니다. 모델이 예상대로 작동하지 않거나 결과가 부정확할 때마다 원인을 분석하고 개선하는 과정이 필요합니다. 예를 들어, 모델의 성능이 저조하다면 데이터 전처리 방식을 변경하거나, 더 적합한 알고리즘을 시도해볼 수 있습니다.

### **1.8 구체적인 팁**

*   **명확한 질문:** 해결하려는 문제를 명확하고 간결하게 정의.  
    - "매출을 증가시키자"와 같은 모호한 목표보다는 "30대 고객의 구매 전환율을 10% 높이자"와 같이 구체적인 목표를 설정해야 합니다. 이를 통해 프로젝트의 방향성을 명확히 하고, 성공 여부를 측정할 수 있습니다.

*   **탐색적 데이터 분석:** 타겟 변수의 초기 프록시 정의.  
    - 데이터를 분석하면서 타겟 변수와 관련된 주요 패턴이나 인사이트를 발견해야 합니다. 예를 들어, 고객 이탈 예측 문제에서는 특정 행동 패턴(예: 로그인 빈도 감소)이 타겟 변수와 강한 상관관계를 가질 수 있습니다. 이를 통해 초기 모델을 빠르게 구축할 수 있습니다.

*   **간단한 Baseline 모델 구축:** 쉬운 모델부터 시작하여 점진적으로 복잡도 증가.  
    - 복잡한 딥러닝 모델부터 시작하는 대신, 선형 회귀나 의사결정 트리 같은 간단한 모델로 시작하여 기준 성능을 설정합니다. 이를 바탕으로 점진적으로 모델의 복잡도를 높이며 성능을 개선할 수 있습니다.

*   **개선에 집중:** 한 번에 하나의 개선 사항 적용.  
    - 여러 가지 개선 사항을 동시에 적용하면 어떤 변화가 성능에 영향을 미쳤는지 알기 어렵습니다. 따라서 한 번에 하나씩 변화를 적용하고, 그 결과를 체계적으로 비교해야 합니다.

*   **원리 이해:** 각 알고리즘의 작동 방식과 사용 이유 설명.  
    - 알고리즘의 동작 원리를 이해하지 못하면, 모델이 실패했을 때 원인을 분석하기 어렵습니다. 예를 들어, K-평균 군집화(K-Means Clustering)를 사용할 때 데이터의 특성과 군집 수를 결정하는 방법을 이해해야 올바른 설정을 할 수 있습니다.

*   **쉬운 설명:** ML 개념을 5세 어린아이에게 설명하는 연습.  
    - 복잡한 개념을 쉽게 설명할 수 있다는 것은 그것을 완벽히 이해했다는 신호입니다. 예를 들어, "신경망은 뇌의 뉴런처럼 작동하며 입력을 받아 출력을 만든다"와 같이 직관적으로 설명하는 능력을 키워야 합니다.

### **1.9 프로젝트 기반 학습**

*   **실제 ML 파이프라인 구축:** 실제 데이터를 사용하고, 실제 문제 해결.  
    - Kaggle 대회나 공개 데이터셋을 활용하여 실제 데이터를 다루고, 머신러닝 파이프라인을 처음부터 끝까지 구축해보는 것이 중요합니다. 이를 통해 실전 경험을 쌓을 수 있습니다.

*   **실제 제약 조건 고려:** 데이터 드리프트 처리.  
    - 현실 세계에서는 데이터의 분포가 시간이 지남에 따라 변할 수 있습니다. 이를 데이터 드리프트(Data Drift)라고 하며, 이를 감지하고 대응하는 능력이 필요합니다.

*   **포트폴리오 구축:** 문제 해결 과정과 사고 과정을 보여주는 포트폴리오.  
    - 자신의 프로젝트를 문서화하고, 문제 해결 과정에서의 결정, 시행착오, 개선 사항 등을 기록하면 나중에 면접이나 프레젠테이션에서 유용하게 사용할 수 있습니다.

### **1.10 ML 엔지니어링 필수 스킬**

*   **데이터 스킬:** 데이터 정제, 피처 엔지니어링, 데이터 검증, 데이터셋 버전 관리.  
    - 머신러닝 프로젝트의 성공은 데이터의 품질에 크게 의존합니다. 데이터 정제는 결측치 처리, 이상치 제거, 데이터 형식 변환 등을 포함하며, 피처 엔지니어링은 데이터를 모델이 이해할 수 있는 형태로 변환하는 작업입니다. 또한, 데이터셋 버전 관리는 시간이 지남에 따라 데이터가 변경되더라도 이전 상태를 추적하고 복원할 수 있도록 도와줍니다. 이를 통해 실험의 재현성과 일관성을 보장할 수 있습니다.

*   **모델 개발:** 문제 제약 조건에 따른 알고리즘 선택, 하이퍼파라미터 튜닝, 모델 해석.  
    - 모든 알고리즘이 모든 문제에 적합한 것은 아닙니다. 예를 들어, 실시간 예측이 필요한 환경에서는 빠른 추론 속도를 제공하는 간단한 모델을 선택해야 할 수 있습니다. 또한, 하이퍼파라미터 튜닝은 모델의 성능을 극대화하는 데 중요한 과정이며, Grid Search, Random Search, Bayesian Optimization 같은 방법을 활용할 수 있습니다. 마지막으로, 모델 해석은 비즈니스 이해관계자에게 모델의 결정을 설명하고 신뢰를 얻는 데 필수적입니다. SHAP, LIME 같은 도구를 사용하여 모델의 동작 원리를 명확히 설명할 수 있어야 합니다.

### **1.11 결론**

*   **최신 논문 구현보다 실질적인 문제 해결 능력과 경험이 중요.**  
    - 최신 논문이나 기술을 따라가는 것도 중요하지만, 기본기를 탄탄히 하고 실제 문제를 해결하는 능력을 기르는 것이 더 우선되어야 합니다. 예를 들어, Transformer나 GAN 같은 최신 모델을 구현하는 것보다, 고객 이탈률을 낮추기 위한 실용적인 모델을 만드는 것이 더 큰 가치를 창출할 수 있습니다. 또한, 경험을 통해 실패로부터 배우고 문제 해결 능력을 키워야 합니다.

*   **포기하지 않고 꾸준히 학습하며, 커뮤니티에 적극적으로 참여.**  
    - 머신러닝은 끊임없이 발전하는 분야이므로, 새로운 개념과 기술을 배우는 자세가 필요합니다. 또한, Kaggle, GitHub, Stack Overflow 같은 커뮤니티에 참여하여 다른 사람들과 협력하거나 질문하면서 학습 효과를 극대화할 수 있습니다. 특히, 오픈소스 프로젝트에 기여하면 실전 경험을 쌓을 수 있는 동시에 네트워크를 확장할 수 있습니다.

*   **기본을 탄탄히 하고, 실질적인 기술을 개발하며, 실패로부터 배우는 자세가 중요.**  
    - 머신러닝은 단기간에 완벽하게 마스터할 수 없는 분야입니다. 따라서 통계, 선형대수, 미적분 같은 기본 개념부터 차근차근 다지고, 실전에서 바로 적용할 수 있는 실용적인 기술을 개발하는 것이 중요합니다. 또한, 실패는 학습 과정의 일부입니다. 실패를 두려워하지 말고, 그 원인을 분석하고 개선하는 과정을 통해 성장할 수 있습니다.

### **1.12 추가 고려사항**

머신러닝 학습 과정에서 다음과 같은 추가적인 요소들을 고려하면 더 나은 결과를 얻을 수 있습니다:

*   **윤리적 책임:**  
    - 머신러닝 모델은 사회에 긍정적이거나 부정적인 영향을 미칠 수 있습니다. 예를 들어, 편향된 데이터를 기반으로 한 모델은 특정 집단에 불공정한 결과를 초래할 수 있습니다. 따라서 데이터와 모델의 윤리적 영향을 고려하고, 공정성과 투명성을 유지하는 것이 중요합니다.

*   **팀 협업 능력:**  
    - 머신러닝 프로젝트는 종종 여러 전문가(데이터 엔지니어, 소프트웨어 개발자, 비즈니스 분석가 등)와 협력하여 진행됩니다. 따라서 효과적인 커뮤니케이션과 협업 능력이 필수적입니다. Git 같은 버전 관리 시스템을 사용하여 코드를 공유하고, 문서화를 통해 팀원들과 정보를 공유하는 것이 좋습니다.

*   **지속적인 피드백 루프:**  
    - 머신러닝 모델은 한번 배포되면 끝나는 것이 아니라, 지속적으로 모니터링하고 개선해야 합니다. 예를 들어, 모델의 성능이 시간이 지남에 따라 저하된다면, 데이터 드리프트나 모델의 오버피팅 여부를 확인하고 재학습할 필요가 있습니다.

*   **비즈니스 목표와의 연계:**  
    - 머신러닝은 기술적 도구일 뿐, 그 자체로는 가치를 창출하지 않습니다. 따라서 항상 비즈니스 목표와 연결하여 프로젝트를 설계하고 실행해야 합니다. 예를 들어, "정확도 95% 달성"이라는 목표보다는 "매출 10% 증가"와 같은 비즈니스 중심의 목표를 설정하는 것이 더 의미 있습니다.

### **1.13 읽으며 생각해볼 질문**

1. 내가 현재 공부 중인 머신러닝 주제는 실제 문제 해결에 어떻게 적용될 수 있을까?  
2. 내 포트폴리오에는 어떤 프로젝트가 포함되어 있으며, 이를 통해 어떤 역량을 보여줄 수 있을까?  
3. 내가 가장 어려움을 겪는 부분은 무엇이며, 이를 해결하기 위해 어떤 자원이나 도움을 활용할 수 있을까?

### **1.14 마무리**
- 머신러닝은 단순히 코드를 작성하거나 모델을 학습시키는 것 이상의 과정을 포함합니다. 데이터를 이해하고, 문제를 정의하며, 모델을 개발하고 평가하는 전체적인 과정을 체계적으로 학습해야 합니다. 또한, 실전 경험을 쌓고, 실패를 통해 배우며, 커뮤니티와 협력하는 자세가 성공적인 머신러닝 전문가로 성장하는 데 필수적입니다. 위에서 다룬 내용들을 바탕으로, 자신의 학습 계획을 세우고 꾸준히 실천한다면 머신러닝 분야에서 큰 성취를 이룰 수 있을 것입니다.

## 2. 17분 안에 배우는 머신러닝 핵심 알고리즘
- 출처: [All Machine Learning algorithms explained in 17 min](https://www.youtube.com/watch?v=E0Hmnixke2g&t=520s)

### **2.1 목표** 
- 주요 머신러닝 알고리즘에 대한 직관적인 이해를 제공하여 알고리즘 선택에 대한 막막함을 해소  
- 이 강의는 머신러닝 초보자들이 각 알고리즘이 어떤 상황에서 유용한지 빠르게 파악하고, 실무에서 적절한 도구를 선택할 수 있도록 돕는 것을 목표로 합니다.

### **2.2 머신러닝 정의 (위키백과)** 
- 데이터로부터 학습하고, 보지 못한 데이터에 일반화하여 명시적인 지시 없이도 작업을 수행할 수 있는 통계 알고리즘 개발 및 연구 분야  
- 즉, 머신러닝은 과거 데이터를 분석해 패턴을 찾아내고, 이를 바탕으로 새로운 상황에 스스로 적응하며 문제를 해결하는 기술입니다.

### **2.3 머신러닝의 분류**

1. **지도 학습 (Supervised Learning):**  
    * **정의:** 독립 변수 (feature/input)와 종속 변수 (target/output/label)가 모두 존재하는 데이터셋을 사용하여 학습  
      이는 마치 선생님이 정답을 알려주며 학생을 가르치는 과정과 비슷합니다.  
    * **목표:** 새로운 데이터에 대한 종속 변수 예측  
      학습된 모델을 통해 아직 보지 못한 데이터에 대해 정확한 결과를 예측하는 것이 핵심입니다.  
    * **예시:**  
        * 집의 특징(평수, 위치, 건축 연도 등)을 기반으로 집 가격 예측  
          예를 들어, 80평방미터, 강남 위치, 2010년 건축 주택의 가격을 추정.  
        * 이미지 특징(높이, 무게, 귀 크기, 눈 색깔 등)을 기반으로 고양이/개 분류  
          사진 속 동물이 고양이인지 강아지인지 구분하는 앱을 상상해보세요.  
    * **세부 분야:**  
        * **회귀 (Regression):** 연속적인 숫자 형태의 목표 변수 예측 (예: 집 가격)  
          온도, 주식 가격 등 숫자로 나타나는 값을 다룹니다.  
        * **분류 (Classification):** 이산적인 범주 형태의 목표 변수 예측 (예: 스팸/정상 메일)  
          참/거짓, 긍정/부정처럼 명확한 카테고리로 나누는 작업입니다.

2. **비지도 학습 (Unsupervised Learning):**  
    * **정의:** 목표 변수(정답)가 없는 데이터셋을 사용하여 학습  
      정답 없이 데이터 자체의 특성을 탐구하며, 마치 퍼즐 조각을 맞추듯 숨겨진 패턴을 찾아냅니다.  
    * **목표:** 데이터 내 숨겨진 구조, 패턴, 그룹(클러스터) 발견  
      예를 들어, 고객 데이터를 분석해 비슷한 구매 패턴을 가진 그룹을 식별할 수 있습니다.  
    * **예시:**  
        * 이메일을 여러 미지정 카테고리로 자동 분류  
          수신함에서 쇼핑, 업무, 개인 메일을 자동으로 정리한다고 생각해보세요.  
    * **세부 분야:**  
        * **클러스터링 (Clustering):** 유사한 데이터끼리 그룹화  
          비슷한 취향의 고객을 묶어 마케팅 전략을 세우는 데 유용합니다.

### **2.4 주요 알고리즘**

* **선형 회귀 (Linear Regression):**  
    * 가장 기본적인 회귀 알고리즘  
      단순하지만 강력한 도구로, 직선 하나로 데이터를 설명하려 합니다.  
    * 입력 변수와 출력 변수 간의 선형 관계를 모델링  
      예를 들어, 공부 시간과 시험 점수의 관계를 직선으로 나타냅니다.  
    * 실제 데이터와 예측 모델(회귀선) 사이의 거리(오차)를 최소화하는 선형 방정식 찾기  
      오차를 줄이는 것이 목표로, 최적의 직선을 찾는 수학적 과정입니다.  
    * 예: 사람의 키와 신발 사이즈 간의 관계  
      키가 클수록 신발 사이즈도 커지는 경향을 예측합니다.

* **로지스틱 회귀 (Logistic Regression):**  
    * 가장 기본적인 분류 알고리즘  
      회귀라는 이름이 붙었지만, 실제로는 분류 문제를 해결합니다.  
    * 범주형 출력 변수를 예측하기 위해 시그모이드 함수를 데이터에 적합  
      시그모이드 함수는 결과를 0과 1 사이의 확률로 변환합니다.  
    * 입력 변수 값에 따라 특정 클래스에 속할 확률을 제공  
      예를 들어, 70% 확률로 스팸 메일이라고 판단할 수 있습니다.  
    * 예: 키와 몸무게를 기반으로 성별 예측  
      남성인지 여성인지 확률적으로 구분합니다.

* **K-최근접 이웃 (K-Nearest Neighbors, KNN):**  
    * 회귀 및 분류에 모두 사용 가능한 직관적인 알고리즘  
      새로운 데이터 주변의 ‘이웃’을 보고 판단하는 단순한 아이디어입니다.  
    * 새로운 데이터 포인트의 목표 변수를 K개의 가장 가까운 이웃들의 평균(회귀) 또는 다수 클래스(분류)로 예측  
      가까운 이웃 5명의 의견을 묻는다고 생각해보세요.  
    * K 값 선택이 중요 (과소적합 vs 과대적합)  
      K가 너무 작으면 노이즈에 민감하고, 너무 크면 너무 일반화될 수 있습니다.

* **서포트 벡터 머신 (Support Vector Machine, SVM):**  
    * 분류 작업에 주로 사용되지만 회귀에도 사용 가능  
      데이터를 명확히 나누는 최적의 선이나 면을 찾습니다.  
    * 데이터 포인트를 최대한 잘 분리하는 결정 경계(decision boundary)를 찾음  
      두 그룹 사이의 간격(마진)을 최대화하는 것이 목표입니다.  
    * 결정 경계와 가장 가까운 데이터 포인트(support vector)를 활용  
      이 포인트들이 경계를 정의하는 핵심 열쇠입니다.  
    * 커널 함수를 사용하여 복잡한 비선형 결정 경계 생성 가능 (커널 트릭 활용)  
      선으로 안 되면 곡선으로 데이터를 나눌 수 있습니다.

* **나이브 베이즈 분류기 (Naive Bayes Classifier):**  
    * 베이즈 정리에 기반  
      확률론을 활용해 간단하면서도 효과적인 분류를 수행합니다.  
    * 각 클래스에서 단어 출현 확률을 계산하여 새로운 이메일을 스팸/정상으로 분류  
      “할인”이라는 단어가 자주 등장하면 스팸일 가능성이 높다고 판단합니다.  
    * 특징(단어)들이 서로 독립적이라는 (naive) 가정을 사용하므로 계산 효율성이 높음  
      현실에서는 완벽히 독립적이진 않지만, 실용적으로 잘 작동합니다.

* **결정 트리 (Decision Tree):**  
    * 데이터셋을 분할하는 일련의 예/아니오 질문으로 구성  
      마치 20문 20답 게임처럼 데이터를 쪼개 나갑니다.  
    * 트리 하단의 리프 노드(leaf node)들이 최대한 순수하도록 분할  
      한 그룹에 비슷한 데이터만 남도록 합니다.  
    * 예: 심장마비 고위험/저위험 환자 분류  
      나이, 혈압, 콜레스테롤 수치로 위험도를 판단합니다.

* **앙상블 (Ensemble):**  
    * 여러 개의 단순 모델을 결합하여 더 강력한 복잡한 모델 생성  
      혼자보다는 여럿이 머리를 맞대는 게 낫다는 철학입니다.  
    * **배깅 (Bagging):** 훈련 데이터의 여러 부분집합에서 여러 모델을 학습 (부트스트랩 사용)  
      데이터를 무작위로 뽑아 여러 모델을 훈련시킵니다.  
        * **랜덤 포레스트 (Random Forest):** 여러 결정 트리의 결과를 다수결 투표로 결합, 특징을 무작위로 제외하여 과적합 방지  
          나무 하나가 틀려도 숲 전체는 맞을 가능성이 높습니다.  
    * **부스팅 (Boosting):** 이전 모델의 오류를 수정하는 데 집중하는 방식으로 모델을 순차적으로 학습  
      실수를 반복하지 않도록 점진적으로 개선합니다.  
        * 정확도가 높지만 과적합 가능성이 높음, 훈련 속도 느림 (AdaBoost, Gradient Boosting, XGBoost)  
          XGBoost는 특히 경진 대회에서 자주 사용됩니다.

* **신경망 (Neural Network):**  
    * 선형 회귀와 로지스틱 회귀의 확장  
      인간 뇌의 뉴런을 모방한 구조에서 영감을 받았습니다.  
    * 입력 변수와 출력 변수 사이에 여러 개의 숨겨진 계층(hidden layer)을 추가하여 복잡한 특징을 자동으로 학습  
      숨겨진 계층이 많을수록 더 깊은 패턴을 파악합니다.  
    * 각 숨겨진 계층은 이전 계층의 출력을 기반으로 새로운 특징을 생성  
      점점 추상화된 정보를 만들어 냅니다.  
    * **심층 학습 (Deep Learning):** 여러 개의 숨겨진 계층을 가진 신경망  
      이미지 인식, 음성 처리 등에서 혁신을 일으켰습니다.

* **차원 축소 (Dimensionality Reduction):**  
    * 데이터셋의 특징(차원) 수를 줄이면서 정보 손실을 최소화  
      불필요한 데이터를 정리해 모델을 더 효율적으로 만듭니다.  
    * 특징 간의 상관 관계를 파악하고 중복된 차원을 제거하여 알고리즘 효율성 및 안정성 향상  
      예를 들어, 키와 몸무게가 비슷한 정보를 주면 하나만 남깁니다.  
    * **주성분 분석 (Principal Component Analysis, PCA):** 데이터 분산이 가장 큰 방향(주성분)을 찾아 새로운 특징으로 사용  
      데이터를 압축하면서도 중요한 정보만 유지합니다.

### **2.5 알고리즘 선택**  
* 문제 유형과 데이터 특성에 따라 적합한 알고리즘 선택  
  회귀 문제인지, 분류 문제인지, 데이터 크기가 큰지 등을 고려해야 합니다.  
* scikit-learn 치트 시트 활용  
  Python 라이브러리 scikit-learn에서 제공하는 알고리즘 선택 가이드를 참고하세요.

## 3. 데이터 과학/머신러닝 엔지니어를 위한 핵심 역량: 수학적 직관
- 출처: [How Math makes Machine Learning easy (and how you can learn it)](https://www.youtube.com/watch?v=wOTFGRSUQ6Q)

### **3.1 핵심 내용**

* 데이터 과학/머신러닝 분야에서 성공하기 위한 가장 중요한 역량은 **수학적 직관**이다.  
  - 단순히 모델을 구현하거나 도구를 사용할 줄 아는 수준을 넘어서, 데이터와 알고리즘의 근본적인 작동 원리를 이해하고 해석할 수 있는 능력을 의미한다.

* 알고리즘을 암기하고 도구를 사용하는 것보다 핵심 수학적 개념을 이해하는 것이 중요.  
  - 이는 모델을 ‘왜’ 사용하는지, 그리고 ‘어떻게’ 개선할 수 있는지를 스스로 판단하고 설명할 수 있게 해준다.

* 통계학적 직관은 문제에 적합한 알고리즘을 선택하고 모델을 개선하는 데 도움이 됨.  
  - 예를 들어, 데이터가 불균형할 때 어떤 지표를 사용해야 할지, 혹은 분산이 큰 데이터를 어떻게 처리할지를 직관적으로 판단할 수 있다.

### **3.2 필수 수학 분야 (중요도 순)**

1. **통계 및 확률:** 핵심 원리와 아이디어에 대한 이해가 중요.  
   - 데이터 분포, 표본 추정, 통계적 유의성 검정 등 데이터 기반 의사결정의 기반이 된다.

2. **선형 대수:** 특히 신경망 분야에 관심 있다면 필수.  
   - 행렬 연산은 신경망의 순전파, 역전파 등 핵심 동작에 직접적으로 관여한다.

3. **미적분학:** 기본적인 이해 필요.  
   - 경사 하강법을 비롯한 최적화 알고리즘의 핵심 원리인 미분 개념이 여기에 속한다.

4. **머신러닝 특정 개념:** 손실 함수, 경사 하강법, 정규화 등.  
   - 수학적 배경 위에서 이들 개념을 이해하면, 모델 성능을 정밀하게 조정할 수 있게 된다.

### **3.3 수학적 직관을 기르는 방법**

* 단순히 공식을 암기하지 말고 공식의 목적과 의미를 이해하려고 노력.  
  - 예를 들어, 평균 제곱 오차(MSE)는 왜 제곱을 하는지, 어떤 상황에서 적합한지를 고민해보자.

* 공식을 자연어로 풀어쓰고, 문제가 무엇을 해결하려 하는지 생각.  
  - “이 공식은 어떤 관계를 설명하는가?” 혹은 “이 식은 데이터에서 어떤 패턴을 찾으려 하는가?”와 같은 질문을 던져보자.

* 다양한 방법으로 문제를 해결해보고, 모델의 하이퍼파라미터가 의미하는 바를 이해.  
  - 정규화 강도, 학습률, 모델 복잡도 등 하이퍼파라미터 하나하나가 모델의 성능과 해석에 어떤 영향을 미치는지 직접 실험을 통해 체감해보는 것이 중요하다.

### **3.4 필수 개념**

* **확률 및 통계:**  
  확률 변수, 확률 분포, 데이터 시각화, 모집단과 표본, 큰 수의 법칙, 평균, 중앙값, 기댓값, 분산, 공분산, 상관관계, 중심 극한 정리, 정규 분포, 표준 편차, 통계적 유의성, z-점수, 가설 검정, 특이도, 민감도, 혼동 행렬, 다중 비교 문제, 조건부 확률, 베이즈 정리  
  - 데이터 분석에서 가설을 세우고 검증할 수 있는 힘을 길러준다.

* **선형 대수:**  
  벡터, 행렬, 행렬 연산 (덧셈, 뺄셈, 곱셈, 역행렬, 전치 행렬), 행렬의 랭크, 선형 독립성, 벡터 노름, 코사인 유사도  
  - 차원 축소, 피처 임베딩, 유사도 계산 등 다양한 ML 알고리즘에서 사용된다.

* **미적분학:**  
  도함수의 의미, 연쇄 법칙 등 기본적인 규칙  
  - 모델의 성능을 최적화하는 과정(예: 경사 하강법)에 핵심 역할을 한다.

* **머신러닝 특정 개념:**  
  손실 함수, 경사 하강법, 정규화, 훈련/테스트/검증 세트, 선형 회귀 (레이블, 가중치, 파라미터, 하이퍼파라미터, 검증, 교차 검증, 과적합, 과소적합), 편향-분산 트레이드오프  
  - 이론과 실습을 함께 익히며, 모델 선택과 성능 향상의 토대를 마련할 수 있다.

### **3.5 가장 중요한 개념**

* **편향-분산 트레이드오프:**  
  통계적 직관, 데이터 세트의 크기와 품질, 적절한 모델 선택 등을 통해 이해해야 함.  
  - 모델이 너무 단순하면 **편향**이 높고, 너무 복잡하면 **분산**이 높아지는 이 딜레마를 이해해야 좋은 모델을 만들 수 있다.

### **3.6 무료 학습 자료**

* **Khan Academy:** 통계, 선형 대수, 미적분학 강의 제공.  
  - 기초 개념부터 차근차근 설명해주므로 초보자에게 적합하다.

* **An Introduction to Statistical Learning:** 책과 유튜브 강의 제공.  
  - 실용적 사례와 함께 머신러닝 이론을 다루어 통계와 모델링을 동시에 배울 수 있다.

* **3Blue1Brown:** 복잡한 수학 및 머신러닝 개념을 시각적으로 설명하는 유튜브 채널.  
  - 추상적인 개념을 직관적으로 이해할 수 있도록 도와준다.

## 4. 머신러닝/데이터 과학 분야 진입을 위한 15가지 조언
- 출처: [15 Machine Learning Lessons I Wish I Knew Earlier](https://www.youtube.com/watch?v=espQDESe07w)

### 4.1 15가지 조언
**1.  가면 증후군(Imposter Syndrome):**
*   누구나 겪는 현상이므로 낙담하지 말 것.
*   모든 것을 알 필요는 없으며, 모르는 것을 인정하는 것이 중요.
*   질문하는 것을 두려워하지 말고, 항상 배우는 자세를 유지할 것.

**2.  기본 원리(Fundamentals):**
*   TensorFlow, PyTorch와 같은 프레임워크 사용에 앞서 핵심 개념을 숙지해야 함.
*   지도 학습/비지도 학습, 선형/로지스틱 회귀, 손실 함수, 최적화 기법, 편향-분산 트레이드오프 등을 이해해야 함.
*   수학적 기초(선형 대수, 미적분, 통계)를 튼튼히 하면 알고리즘 선택, 튜닝, 데이터 준비 등에 도움이 됨.

**3.  모든 것을 암기할 필요는 없음:**
*   온라인 문서와 자료를 활용하여 필요한 정보를 찾을 수 있음.
*   수학적 원리에 대한 직관을 키우는 것이 암기보다 중요.

**4.  모델링보다 데이터:**
*   데이터 전처리, 특성 공학, 모델 선택, 결과 해석 등이 더 중요.
*   데이터 품질이 모델 성능에 큰 영향을 미치므로 데이터 정제 및 전처리 기술을 숙지해야 함.
*   작더라도 깨끗하고 관련성 높은 데이터 세트가 더 중요.

**5.  비즈니스 문제 이해:**
*   머신러닝 모델 구축 전에 비즈니스 문제를 명확히 이해해야 함.
*   예: 고객 이탈 예측 모델을 만들 때, 이탈의 의미를 명확히 정의해야 함.
*   결과를 비기술적인 팀원에게 전달하고 실행 가능한 권장 사항을 제시할 수 있어야 함.

**6.  탐색적 데이터 분석(EDA) 및 시각화:**
*   데이터 세트 분석 및 시각화를 통해 패턴과 추세를 파악하고 데이터 품질을 개선해야 함.
*   변수 간 상관 관계, 이상치 등을 파악하여 모델에 미치는 영향을 평가해야 함.
*   데이터 구조를 이해하고 가정을 검증하며, 모델 해석 가능성을 높일 수 있음.
*   시각화를 통해 비기술적 이해 관계자와의 의사 소통을 촉진할 수 있음.

**7.  특성 공학(Feature Engineering):**
*   의미 있는 특성을 만들면 모델 성능에 큰 영향을 줄 수 있음.
*   기존 특성을 결합하거나 변환하여 새로운 특성을 생성하고, 스케일링, 결측값 처리 등을 수행해야 함.
*   PCA와 같은 기법을 사용하여 특성 수를 줄이고 과적합을 방지할 수 있음.
*   도메인 지식을 활용하여 특성을 생성하면 모델 성능을 향상시킬 수 있음.

**8.  알고리즘에 매몰되지 말 것:**
*   모델 해석 가능성과 설명 가능성을 간과하지 말아야 함.
*   복잡한 모델보다 단순한 모델이 더 나은 성능을 보일 수도 있음.
*   모델 결과를 이해하기 쉽게 설명하여 이해 관계자의 신뢰를 얻어야 함.
*   모든 문제에 맞는 단일 모델은 없으며, 다양한 접근 방식을 실험해야 함.

**9.  편향-분산 트레이드오프(Bias-Variance Trade-off) 및 검증:**
*   모델이 훈련 데이터에 얼마나 잘 맞는지와 새로운 데이터에 얼마나 잘 일반화되는지 간의 균형을 이해해야
*   편향은 모델 단순화로 인한 오류, 분산은 모델 과적합으로 인한 오류를 의미함.
*   검증 세트를 사용하여 모델 성능을 조기에 평가하고 과적합을 방지해야 함.
*   교차 검증을 통해 모델 성능을 더 정확하게 추정할 수 있음.
*   테스트 세트는 모델 성능을 최종적으로 평가하는 데 사용되며, 훈련 또는 검증에 사용되지 않아야 함.
*   데이터 누출을 방지하여 모델이 실제 시나리오에서 효과적으로 일반화되도록 해야 함.

**10. 전문화하기 전에 일반화:**
*   통계, 회귀, 트리 기반 알고리즘과 같은 기본 원리에 집중해야 함.
*   신경망, 자연어 처리, 컴퓨터 비전, 강화 학습 등 다양한 전문 분야를 탐색해야 함.
*   실제 프로젝트를 통해 기초를 다지고 열정을 발견해야 함.

**11. 데이터 과학은 팀 스포츠:**
*   다른 데이터 과학자, 엔지니어, 개발자, 도메인 전문가 등과 협력해야 함.
*   복잡한 아이디어를 명확하게 전달하고 비기술적인 관점을 경청하는 것이 중요.
*   버전 관리 시스템(Git)을 사용하여 코드, 데이터, 모델 변경 사항을 추적해야 함.

**12. 좋은 문서화는 시간을 절약함:**
*   코드, 데이터 소스, 결과를 문서화하면 자신과 팀의 시간을 절약할 수 있음.

**13. 평생 학습:**
*   머신러닝은 빠르게 진화하는 분야이므로 지속적으로 학습하고 새로운 기술에 적응해야 함.
*   특정 분야의 전문가가 되기보다는 학습 및 적응의 전문가가 되는 것이 중요.

**14. 머신러닝 이상의 AI:**
*   머신러닝 외에도 생성 AI, 프롬프트 엔지니어링, 데이터 엔지니어링, MLOps 엔지니어 등 다양한 AI 관련 역할이 존재함.

**15. 튜토리얼과 캐글 경쟁:**
*   기술을 연마하는 데 좋지만, 실제 데이터는 노이즈가 많고 불완전하며 불균형할 수 있음.
*   실제 비즈니스 문제를 해결하는 데 참여하여 머신러닝 프로젝트의 전체 라이프사이클을 이해해야 함.
*   오픈 소스 프로젝트, 프리랜서 작업, 인턴십 등을 통해 실제 경험을 쌓아야 함.

**16. 네트워크:**
*   머신러닝 분야에서 성공하려면 네트워킹이 중요함.
*   해커톤, 네트워킹 이벤트, 강좌 등에 참여하고 LinkedIn을 통해 사람들과 연결해야 함.
*   다른 사람에게 진정으로 관심을 가지고 다가가면 예상치 못한 기회를 얻을 수 있음.


## 5. 머신 러닝 학습 로드맵
- 출처: [Learn Machine Learning Like a GENIUS and Not Waste Time](https://www.youtube.com/watch?v=qNxrPri1V0I)

### **5.1 시작하기 전에: 마인드셋 구축**

* **현실적인 기대 설정:**
  * 3개월 만에 ML 엔지니어가 되는 것은 불가능에 가까운 목표입니다. 평균적으로 6개월~1년의 꾸준한 학습이 필요하며, 실제 업무 적용을 위해서는 더 많은 경험이 필요합니다.
  * 초보자 단계에서는 이론과 실습을 3:7 비율로 진행하는 것이 효과적입니다.

* **학습 방법론의 중요성:**
  * 기술의 빠른 진화 속도에 대응하기 위해 "학습하는 방법" 자체를 터득해야 합니다.
    * **적응력 강화:** 매주 새로운 라이브러리나 프레임워크가 등장하는 환경에서 빠르게 핵심 개념을 파악하는 기술이 필요합니다.
    * **문제 해결 중심 사고:** 실제 업무에서는 교과서적인 문제보다는 복잡한 비정형 문제가 대부분입니다. 데이터의 특성을 이해하고 창의적인 접근법을 개발하는 능력이 핵심입니다.
    * **스트레스 관리:** 새로운 문제에 직면했을 때 압도되지 않고 체계적으로 접근하는 방법을 터득해야 합니다.
    * **효율성 극대화:** Pareto 법칙을 적용해 핵심 20% 개념에 집중하여 80%의 결과를 얻는 전략이 필요합니다.

### **5.2 머신 러닝 기초 다지기: 체계적인 준비**

* **Python 프로그래밍:**
  * 선택 이유:
    * 데이터 과학 분야에서 68%의 점유율을 차지하는 사실상의 표준 언어입니다.
    * 직관적인 문법 구조로 초보자도 빠르게 기본기를 다질 수 있습니다.
  * 학습 범위:
    * 기본 문법 (변수, 자료형, 연산자)
    * 제어 구조 (조건문, 반복문)
    * 함수와 클래스 작성
    * 모듈화 프로그래밍
    * 예외 처리
  * 실습 환경:
    * Jupyter Notebook 설치 및 사용법 숙지
    * VS Code 또는 PyCharm과 같은 IDE 설정

* **Pandas 마스터링:**
  * 핵심 기능:
    * DataFrame 조작 (groupby, pivot_table 등)
    * 시계열 데이터 처리
    * 결측치 및 이상치 관리
  * 실제 적용:
    * 다양한 데이터 포맷(csv, json, excel) 처리
    * 메모리 최적화 기법
    * 대용량 데이터 처리 전략

* **첫 번째 데이터 분석 프로젝트:**
  * 단계별 접근:
    1. 문제 정의: 분석 목표 명확화
    2. 데이터 수집: 공공 데이터(Kaggle, UCI 등) 활용
    3. 탐색적 분석(EDA):
      - 기술 통계량 계산
      - 시각화(Matplotlib/Seaborn)
      - 상관관계 분석
    4. 인사이트 도출 및 시각화
  * 결과물:
    - Jupyter Notebook 문서화
    - 발표용 슬라이드 제작
    - GitHub에 포트폴리오 업로드

* **필수 수학 개념:**
  * **통계와 확률:**
    - 기술 통계(평균, 분산, 왜도, 첨도)
    - 확률 분포(정규, 이항, 포아송)
    - 가설 검정(p-value, 신뢰 구간)
  * **선형대수:**
    - 행렬 연산의 기하학적 의미
    - 고유값 분해 응용
  * **미적분:**
    - 경사하강법의 수학적 기반
    - 편미분의 실제 의미

### **5.3 핵심 머신 러닝 알고리즘: 이론과 실전**

* **알고리즘 학습 전략:**
  - 난이도별 접근:
    1. 지도 학습(회귀, 분류)
    2. 비지도 학습(클러스터링, 차원 축소)
    3. 앙상블 방법
  - 각 알고리즘별:
    * 수학적 배경 이해
    * hyperparameter 영향 분석
    * scikit-learn 구현
    * 성능 평가 지표 적용

* **Scikit-learn 심화:**
  - 파이프라인 구축
  - 모델 선택 기법
  - 교차 검증 전략
  - 특징 공학 자동화

### **5.4 종합 프로젝트 실행:**

* **전체 워크플로우 경험:**
  1. 문제 정의 및 메트릭 설정
  2. 데이터 수집 및 라벨링
  3. 특징 공학
  4. 모델 선택 및 훈련
  5. 성능 평가
  6. 배포 전략 수립

* **고급 기법:**
  - 하이퍼파라미터 튜닝
  - 모델 해석 가능성
  - 프로덕션 환경 고려사항

### **5.5 협업 생태계 구축**

* **버전 관리:**
  - Git을 이용한 코드 관리
  - 프로젝트 문서화 표준
* **커뮤니티 참여:**
  - Kaggle 경연 참가
  - 오픈소스 기여
  - 기술 블로그 운영

### **5.6 지속적인 성장 전략**

* **학습 계획:**
  - 주간 목표 설정
  - 피드백 루프 구축
* **커리어 개발:**
  - 포트폴리오 강화
  - 네트워킹 기회 활용

## 6. 머신러닝 기본 용어 정리
- 출처: [All Machine Learning Concepts Explained in 22 Minutes]()

**1. 인공지능 (AI):**

*   인간 지능을 모방하여 작업을 수행하는 기계의 능력.
    - AI는 단순히 프로그래밍된 규칙을 따르는 것을 넘어, 복잡한 상황에서 스스로 판단하고 적응할 수 있는 시스템을 포함합니다.
*   언어 이해, 이미지 인식, 문제 해결, 의사 결정 등을 포함.
    - 예를 들어, 번역 애플리케이션은 자연어 처리(NLP)라는 AI 분야를 활용하며, 자율주행차는 컴퓨터 비전과 의사결정 알고리즘을 통해 주변 환경을 인식합니다.
*   머신러닝 외에 규칙 기반 시스템 등 다양한 기술을 활용.
    - 초기 AI는 전문가 시스템과 같은 규칙 기반 접근법에 의존했으나, 현재는 머신러닝과 딥러닝이 AI의 핵심 기술로 자리 잡았습니다.

**2. 머신러닝 (ML):**

*   AI의 한 분야로, 명시적인 프로그래밍 없이 데이터로부터 학습하고 성능을 향상시키는 능력.
    - 머신러닝은 사람이 직접 규칙을 작성하지 않고도 데이터를 기반으로 패턴을 자동으로 찾아냅니다.
*   데이터 내 패턴과 관계를 파악하여 예측 또는 결정을 내림.
    - 예를 들어, 고객 행동 데이터를 분석하여 미래의 구매 가능성을 예측할 수 있습니다.

**3. 알고리즘 (Algorithm):**

*   컴퓨터가 문제를 해결하거나 작업을 수행하기 위해 따라야 하는 명확한 지침 또는 규칙의 집합.
    - 알고리즘은 일련의 연산 단계로 구성되며, 이를 통해 입력 데이터를 처리하고 출력 결과를 생성합니다.
    - 예: 정렬 알고리즘, 경사 하강법 알고리즘 등.

**4. 데이터 (Data):**

*   수집, 분석, 의사 결정, 예측 또는 통찰력 제공에 사용될 수 있는 정보.
    - 데이터는 현대 머신러닝의 핵심 자원이며, 고품질 데이터는 성공적인 모델 개발의 기초가 됩니다.
*   숫자, 텍스트, 이미지 등 다양한 형태가 존재.
    - 예: 판매 데이터(숫자), 고객 리뷰(텍스트), X-ray 영상(이미지).

**5. 모델 (Model):**

*   데이터의 패턴을 인식하고 예측 또는 분류를 수행하도록 학습된 수학적 표현.
    - 모델은 데이터를 기반으로 학습된 가중치와 함수로 구성됩니다.
*   입력과 출력 간의 매핑 함수.
    - 예: 주택 가격 예측 모델은 집의 크기, 위치 등의 입력을 받아 추정된 가격을 출력합니다.

**6. 모델 피팅/훈련 (Model Fitting/Training):**

*   모델의 예측과 실제 데이터 간의 일치도를 최적화하기 위해 모델의 파라미터를 조정하는 과정.
    - 훈련 중에는 오차를 줄이는 방향으로 모델이 점진적으로 개선됩니다.

**7. 훈련 데이터 (Training Data):**

*   머신러닝 모델을 학습시키는 데 사용되는 데이터의 하위 집합.
    - 모델이 데이터의 패턴을 학습하는 데 필요한 "교재" 역할을 합니다.
*   입력 예제와 해당 정답으로 구성됨.
    - 예: 손글씨 이미지와 그에 해당하는 숫자 레이블.

**8. 테스트 데이터 (Test Data):**

*   훈련 과정에서 사용되지 않은 별도의 데이터 집합.
    - 테스트 데이터는 모델의 일반화 성능을 평가하는 데 사용됩니다.
*   모델의 일반화 성능을 평가하는 데 사용됨.
    - 모델이 새로운 데이터에 얼마나 잘 적용될 수 있는지를 확인합니다.

**9. 데이터 누수 (Data Leakage):**

*   모델 훈련에 테스트 데이터의 일부가 포함되는 경우.
    - 데이터 누수는 모델이 테스트 데이터의 정보를 미리 "엿보게" 하여 성능을 과대 평가하게 만듭니다.
*   모델의 성능을 과대 평가할 수 있음.
    - 이를 방지하려면 데이터를 훈련 세트와 테스트 세트로 엄격히 분리해야 합니다.

**10. 지도 학습 (Supervised Learning):**

*   레이블이 지정된 예제로부터 학습하는 머신러닝 접근 방식.
    - 지도 학습은 입력과 출력 간의 관계를 학습하는 데 초점을 맞춥니다.
*   각 예제는 입력과 해당 정답으로 구성됨.
    - 예: 스팸 메일 필터링(입력: 이메일 내용, 출력: 스팸 여부).

**11. 비지도 학습 (Unsupervised Learning):**

*   레이블이 지정되지 않은 데이터에서 패턴과 구조를 찾는 머신러닝 접근 방식.
    - 비지도 학습은 데이터의 내재된 구조를 발견하는 데 유용합니다.
*   사전에 정의된 정답 없이 데이터 내 그룹 또는 관계를 발견.
    - 예: 고객 세그먼테이션(비슷한 행동 패턴을 가진 고객들을 그룹화).

**12. 강화 학습 (Reinforcement Learning):**

*   상호 작용과 피드백을 통해 학습하는 머신러닝의 한 분야.
    - 강화 학습은 에이전트가 환경과 상호 작용하며 보상을 극대화하는 방식으로 학습합니다.
*   보상과 처벌을 통해 최적의 행동 방식을 학습.
    - 예: 게임 AI(체스, 바둑) 또는 로봇 제어.

**13. 특징 (Feature):**

*   모델이 예측을 수행하는 데 사용되는 정보의 특정 속성 또는 조각.
    - 특징은 데이터에서 중요한 정보를 추출하는 데 사용됩니다.
*   예측 변수, 입력 변수, 독립 변수 또는 속성이라고도 함.
    - 예: 주택 가격 예측에서 '집의 크기', '위치', '방 개수' 등.

**14. 특징 공학 (Feature Engineering):**

*   모델의 성능을 향상시키기 위해 기존 원시 데이터로부터 새로운 정보성 특징을 생성하는 과정.
    - 예: 날짜 데이터에서 요일이나 계절 정보를 추출.
*   데이터의 표현력을 높이고 모델의 예측력을 강화.

**15. 특징 스케일링 (Feature Scaling):**

*   숫자 특징을 유사한 스케일로 변환하는 과정.
    - 다양한 스케일의 데이터가 있을 때, 모든 특징이 동일한 중요도를 갖도록 조정합니다.
*   정규화 (Normalization) 또는 표준화 (Standardization)라고도 함.
    - 예: 집 크기(평방미터)와 방 개수를 동일한 스케일로 변환.

**16. 차원 (Dimensionality):**

*   데이터 세트의 특징 (변수, 속성) 수.
    - 차원이 많으면 모델이 복잡해질 수 있지만, 너무 많은 차원은 과적합 위험을 증가시킵니다.

**17. 타겟 (Target):**

*   머신러닝 모델이 예측하려고 하는 것.
    - 지도 학습에서는 항상 목표 변수가 존재합니다.
*   종속 변수, 출력 변수, 반응 변수 또는 레이블이라고도 함.
    - 예: 스팸 분류 모델에서 '스팸 여부'.

**18. 인스턴스 (Instance):**

*   모든 특징과 타겟 값을 포함하는 완전한 데이터 단위.
    - 하나의 데이터 포인트를 의미하며, 데이터 세트의 행에 해당합니다.
*   샘플, 예제, 레코드, 데이터 포인트 또는 관측값이라고도 함.

**19. 레이블 (Label):**

*   지도 학습에서 인스턴스와 관련된 알려진 올바른 출력.
    - 모델이 학습하는 데 사용되는 "정답"입니다.
*   클래스, 타겟 값, 정답 또는 정답이라고도 함.

**20. 모델 복잡도 (Model Complexity):**

*   데이터 패턴을 캡처하는 모델의 능력에 대한 정교함의 정도.
    - 복잡도가 높은 모델은 더 많은 패턴을 학습할 수 있지만, 과적합 위험이 커집니다.

**21. 편향 (Bias):**

*   모델이 데이터의 기본 패턴에 대해 갖는 제한적이거나 유연하지 않은 가정.
    - 높은 편향은 모델이 데이터를 덜 유연하게 해석한다는 것을 의미합니다.

**22. 분산 (Variance):**

*   모델이 서로 다른 훈련 데이터 하위 집합에서 훈련될 경우 예측이 얼마나 변하는지.
    - 높은 분산은 모델이 훈련 데이터에 과도하게 적응했다는 신호일 수 있습니다.

**23. 편향-분산 트레이드오프 (Bias-Variance Trade-off):**

*   모델의 편향과 분산을 동시에 최소화하는 것 사이의 균형.
    - 이상적인 모델은 편향과 분산 모두를 적절히 조절하여 최적의 성능을 달성합니다.

**24. 노이즈 (Noise):**

*   데이터의 실제 기본 패턴을 나타내지 않는 임의 변동 또는 오류.
    - 노이즈는 모델의 성능을 저하시킬 수 있으며, 이를 제거하거나 줄이는 것이 중요합니다.

**25. 과적합 (Overfitting):**

*   모델이 훈련 데이터의 노이즈와 임의 변동을 학습하는 경우.
    - 과적합된 모델은 새로운 데이터에 대해 일반화 성능이 낮습니다.

**26. 과소적합 (Underfitting):**

*   모델이 데이터의 중요한 패턴을 캡처하기에 너무 단순한 경우.
    - 과소적합된 모델은 훈련 데이터에서도 성능이 낮습니다.

**27. 검증 (Validation):**

*   모델을 훈련하지 않은 데이터에 대한 성능을 평가하는 방법.
    - 검증은 모델의 일반화 성능을 확인하는 데 사용됩니다.

**28. 교차 검증 (Cross Validation):**

*   데이터를 여러 번 분할하여 모델을 반복적으로 훈련하고 검증하는 방법.
    - 예: k-fold 교차 검증은 데이터를 k개의 부분으로 나누고, 각 부분을 순차적으로 테스트 데이터로 사용합니다.

**29. 정규화 (Regularization):**

*   모델이 너무 복잡해지거나 훈련 데이터에 너무 밀접하게 피팅되지 않도록 제약을 추가하여 과적합을 방지하는 데 사용되는 기술.
    - 예: L1/L2 정규화는 모델 파라미터의 크기를 제한합니다.

**30. 배치 (Batch):**

*   모델 훈련의 단일 단계에서 함께 처리되는 훈련 데이터의 하위 집합.
    - 큰 데이터 세트를 작은 배치로 나누어 처리하면 메모리 효율성을 높일 수 있습니다.

**31. 반복 (Iteration):**

*   데이터의 한 배치를 통과하여 모델의 파라미터를 업데이트하는 단일 패스.
    - 반복은 모델이 점진적으로 학습하는 과정을 나타냅니다.

**32. 에폭 (Epoch):**

*   모델 훈련 중에 전체 훈련 데이터 세트를 통과하는 완전한 패스.
    - 여러 에폭을 거치면서 모델이 점점 더 데이터 패턴을 학습합니다.

**33. 파라미터 (Parameter):**

*   모델이 데이터로부터 훈련 중에 학습하는 값.
    - 예: 선형 회귀의 가중치와 편향.
*   모델 파라미터 또는 가중치라고도 함.

**34. 하이퍼파라미터 (Hyperparameter):**

*   훈련이 시작되기 전에 설정되는 학습 프로세스를 제어하는 데 사용되는 구성 설정.
    - 예: 학습률, 배치 크기, 은닉층 수 등.

**35. 비용 함수 (Cost Function):**

*   모델의 예측이 실제 값과 비교하여 얼마나 잘못되었는지에 대한 척도.
    - 비용 함수를 최소화하는 것이 모델 학습의 목표입니다.
*   손실 함수, 목적 함수 또는 오류 함수라고도 함.

**36. 경사 하강법 (Gradient Descent):**

*   모델 파라미터를 반복적으로 조정하여 오류를 최소화함으로써 머신러닝 모델을 훈련하는 데 사용되는 기본 최적화 알고리즘.
    - 경사는 오차를 줄이는 방향을 나타내며, 모델은 이 방향으로 파라미터를 업데이트합니다.

**37. 학습률 (Learning Rate):**

*   모델이 훈련 중에 오류에 대한 응답으로 파라미터를 조정하는 양을 결정하는 중요한 하이퍼파라미터.
    - 너무 높은 학습률은 발산을 유발하고, 너무 낮은 학습률은 학습 속도를 느리게 만듭니다.

**38. 평가 (Evaluation):**

*   모델을 훈련하지 않은 데이터에 대한 머신러닝 모델의 성능을 다양한 메트릭을 사용하여 측정하는 과정.
    - 정확도, 정밀도, 재현율, F1 점수 등이 대표적인 평가 지표입니다.


