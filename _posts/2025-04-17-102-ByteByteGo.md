---
title: 32차시 2:ByteByteGo
layout: single
classes: wide
categories:
  - ByteByteGo
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---



## 16. 시스템 디자인을 위한 주요 Latency 수치
- 출처: [Latency Numbers Programmer Should Know: Crash Course System Design #1](https://www.youtube.com/watch?v=FqR5vESuKe0)

### 16.1 **목표**
* 일반적인 Latency 수치에 대한 직관 개발  
  * 정확한 수치 암기보다 상대적 크기 비교에 집중 (예: L1 캐시 vs 메모리 접근 차이 = 10배)
  * 시스템 병목 현상 분석 시 Latency 계층 구조 이해 필수
* 기술 발전과 물리 법칙이 Latency에 미치는 영향  
  * 반도체 공정 미세화 → CPU/메모리 Latency 지속 감소 추세
  * 광케이블 속도 한계 → 대륙간 네트워크 Latency 물리적 하한 존재

### **16.2 시간 단위 심화 설명**

| 단위        | 과학적 표현       | 실제 예시                                  |
|-------------|------------------|-------------------------------------------|
| 1 ns        | 10⁻⁹초           | 빛이 30cm 이동하는 시간                     |
| 1 μs        | 10⁻⁶초           | 고음파 진동 1주기 (20kHz 기준)              |
| 1 ms        | 10⁻³초           | 인간의 깜빡임 속도(약 100-400ms)와 비교 가능 |

### **16.3 Latency 범위별 주요 작업 (상세 분석)**

| Latency 범위         | 주요 작업                                                                 | 기술적 배경                                                                 |
|----------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------------|
| Sub-nanosecond       | - CPU 레지스터 접근 (0.3ns)                                              | 전자 이동 속도 제약                                                         |
| 1-10 ns              | - L2 캐시 접근 (3-7ns)                                                   | SRAM 회로 설계 최적화 결과                                                   |
| 10-100 ns            | - DDR4 메모리 (80-100ns)                                                 | DRAM refresh 오버헤드 포함                                                  |
| 100ns-1μs           | - 시스템 콜 (Linux: 150-300ns)                                           | 커널/유저모드 전환 오버헤드                                                  |
| 1-10 μs             | - NVMe SSD 읽기 (4-8μs)                                                 | 3D NAND 플래시 셀 물리적 동작 시간                                            |
| 10-100 μs           | - Redis GET (50μs)                                                      | 네트워크 스택 + 메모리 접근 복합 비용                                         |
| 100μs-1ms           | - HDD 탐색 시간 (2-10ms)                                                 | 물리적 헤드 이동 시간 (평균 4-6ms)                                           |
| 1초 이상            | - 1TB HDD 순차 읽기 (≈2초)                                               | 대용량 데이터 이동 시 밴드폭 제약 (200MB/s 기준)                             |

### **16.4 참고사항 확장**
1. **클라우드 환경 변수**  
   - AWS 같은 퍼블릭 클라우드에서는 가상화 오버헤드로 Latency 10-20% 증가 가능
   - 멀티테넌시 환경에서의 노이즈 영향 고려 필요

2. **최신 기술 동향**  
   - CXL 메모리: 200-300ns 영역에서 새로운 계층 형성
   - RDMA: 네트워크 Latency를 5-10μs까지 감소

3. **디자인 시 고려사항**  
   ```python
   # Latency 최적화 예시: 배치 처리 vs 실시간 처리
   if latency_budget < 100μs:
       use_in_memory_cache()
   elif latency_budget < 10ms:
       use_ssd_optimized_db()
   else:
       consider_hdd_archiving()
   ```

4. **측정 방법론**  
   - 벤치마크 시 실제 워크로드 반영 중요 (인공 테스트는 오차 90% 이상 발생 가능)
   - P99/P999 Latency 모니터링이 평균값보다 더 유의미

5. **물리적 한계**  
   - 빛의 속도 제약: 뉴욕-런던 최소 Latency ≈ 28ms (해저 케이블 직선 경로 기준)
   - 양자 터널링 효과: 미래 기술 발전 시 10ps(피코초) 시대 개막 가능성

(수치 출처: 2023년 Intel/AMD 백서, ULProbe 벤치마크, Cloudflare 네트워크 측정 데이터 종합)

## 17. 마이크로서비스 아키텍처
- 출처: [What Are Microservices Really All About? (And When Not To Use It)](https://www.youtube.com/watch?v=lTAcCNbJ7KE)

### 17.1 **정의**  
*   대규모 애플리케이션을 느슨하게 결합된 여러 서비스로 구성하여 확장 가능하게 만드는 아키텍처.  
    *   모놀리식 아키텍처와 대비되며, 각 서비스는 특정 비즈니스 기능(도메인)에 집중하도록 설계됩니다.  
    *   클라우드 네이티브 환경과 DevOps 문화와 자연스럽게 결합되는 현대적 아키텍처 스타일입니다.  

### 17.2 **특징**  
*   **느슨한 결합 (Loosely Coupled):**  
    *   각 서비스는 독립적인 기능을 수행 (예: 쇼핑 카트, 결제, 사용자 프로필).  
    *   서비스 간 의존성을 최소화하여 변경 영향도를 낮추고 유연성을 확보합니다.  
    *   도메인 주도 설계(DDD)의 Bounded Context 개념과 밀접하게 연관됩니다.  

*   **명확한 인터페이스:**  
    *   서비스 간 통신은 REST API, GraphQL, gRPC 등 표준화된 프로토콜을 통해 이루어집니다.  
    *   인터페이스 계약(API 스펙)을 엄격히 관리하여 호환성을 유지해야 합니다.  

*   **작은 표면적 (Small Surface Area):**  
    *   단일 책임 원칙(SRP)을 적용해 각 서비스의 범위를 최소화합니다.  
    *   장애 발생 시 영향을 지역화(Local Failure)할 수 있어 시스템 전체의 안정성이 향상됩니다.  

*   **다양한 통신 방식:**  
    *   **동기식 통신 (RPC/gRPC):**  
        *   낮은 지연 시간이 필요한 경우 사용되지만, 서비스 간 강한 의존성이 생길 수 있습니다.  
        *   장애 전파(Cascading Failure) 위험을 줄이기 위해 Circuit Breaker 패턴 적용이 필수적입니다.  
    *   **비동기식 통신 (이벤트 스트리밍/메시지 브로커):**  
        *   Kafka, RabbitMQ 등을 이용해 이벤트 기반 아키텍처(EDA)를 구현합니다.  
        *   서비스 간 결합도를 극도로 낮추지만, 최종 일관성(Eventual Consistency)을 보장해야 합니다.  

*   **독립적인 배포:**  
    *   CI/CD 파이프라인을 통해 개별 서비스만 배포할 수 있어 릴리스 주기가 단축됩니다.  
    *   Blue-Green 배포, Canary 릴리스 등 고급 배포 전략을 적용하기 용이합니다.  

*   **독립적인 확장:**  
    *   트래픽 패턴에 따라 특정 서비스만 수평 확장(Scaling Out)할 수 있습니다.  
    *   Kubernetes, AWS ECS 등의 오케스트레이션 툴과 연동해 탄력적 확장이 가능합니다.  

*   **강력한 정보 은닉:**  
    *   각 서비스는 전용 데이터베이스(DB-per-Service)를 갖거나, 논리적으로 분리된 스키마를 사용합니다.  
    *   데이터 접근은 반드시 해당 서비스의 API를 통해서만 가능하도록 캡슐화합니다.  

### 17.3 **핵심 구성 요소**  
*   **API 게이트웨이:**  
    *   인증/인가, 로드 밸런싱, 요청 라우팅, 응답 병합(Aggregation) 등을 처리합니다.  
    *   Kong, Apigee, AWS API Gateway 등이 대표적인 솔루션입니다.  

*   **ID 공급자:**  
    *   OAuth 2.0, OpenID Connect 표준을 기반으로 중앙 집중식 인증을 관리합니다.  
    *   Keycloak, Auth0, AWS Cognito 등을 활용할 수 있습니다.  

*   **서비스 레지스트리 및 디스커버리:**  
    *   동적 환경에서 서비스 위치를 탐색하기 위해 Eureka, Consul, Zookeeper 등이 사용됩니다.  
    *   서비스 메시(Service Mesh) 아키텍처에서는 Istio, Linkerd가 추가적인 트래픽 제어 기능을 제공합니다.  

*   **모니터링 및 알림:**  
    *   분산 추적(Distributed Tracing)을 위해 Jaeger, Zipkin을 도입합니다.  
    *   메트릭 수집에는 Prometheus, Grafana, ELK 스택이 필수적입니다.  

*   **DevOps 툴링:**  
    *   Terraform으로 인프라를 코드화(IaC)하고, ArgoCD/GitOps로 지속적 배포를 구현합니다.  

### 17.4 **데이터베이스 분할의 단점**  
*   **분산 트랜잭션 관리:**  
    *   ACID 트랜잭션을 보장하려면 Saga 패턴이나 2PC(Two-Phase Commit) 같은 복잡한 메커니즘이 필요합니다.  
*   **데이터 중복과 일관성:**  
    *   여러 서비스에서 동일한 데이터를 관리할 경우, CQRS 패턴으로 읽기/쓰기 모델을 분리해야 합니다.  

### 17.5 **언제 사용해야 하는가?**  
*   **대규모 팀:**  
    *   Spotify, Netflix처럼 수백 명의 개발자가 협업할 때 팀 간 의존성을 줄입니다.  
*   **복잡한 도메인:**  
    *   도메인이 명확히 분리될 수 있을 때(예: 예약 시스템 vs 결제 시스템).  
*   **기술적 유연성 필요:**  
    *   서비스마다 다른 기술 스택(Polyglot)을 사용해야 하는 경우.  

### 17.6 **언제 사용하면 안 되는가?**  
*   **초기 단계 스타트업:**  
    *   마이크로서비스 오버헤드(관리 비용, 분산 시스템 복잡도)가 비즈니스 속도를 저하시킬 수 있습니다.  
*   **도메인 경계가 불분명할 때:**  
    *   서비스 간 빈번한 통신이 필요하면 모놀리식이 더 효율적일 수 있습니다.  

### 17.7 **스타트업을 위한 조언**  
*   **점진적 전환:**  
    *   모놀리스를 유지하되, 모듈화를 강화해 나중에 마이크로서비스로 분리하기 쉽게 설계합니다.  
*   **도메인 주도 설계 학습:**  
    *   Bounded Context, Aggregate Root 등 DDD 개념을 이해해 서비스 경계를 올바르게 정의합니다.  
*   **서비스 메시 도입 고려:**  
    *   Istio 같은 솔루션으로 서비스 간 통신의 복잡성을 추상화합니다.  


## 18. Apple Pay와 Google Pay의 민감한 카드 정보 처리 방식 비교
- 출처: [How Does Apple/Google Pay Work?](https://www.youtube.com/watch?v=cHv8LqkbPHk)

### 18.1 **개요**

*   Apple Pay와 Google Pay 모두 **토큰화(Tokenization)** 기술을 사용하여 실제 카드 정보 대신 일회성 토큰을 생성함으로써 보안을 강화함.  
    → *토큰화란?* 실제 카드 번호(PAN)를 무의미한 문자열로 대체하는 기술로, 유출되더라도 원본 데이터 복원 불가능.
*   둘 다 **카드 정보를 직접 기기에 저장하지 않음**(PAN 미저장 주장). 대신 **디바이스 계정 번호(DAN)** 또는 **디바이스 프록시 PAN(DPAN)**이라는 전용 토큰을 사용.
*   *핵심 차이점:* 토큰 저장 위치와 서버 연동 방식에서 기술적 차이 존재.

### **18.2 카드 정보 토큰화 과정 (상세 비교)**

| 특징             | Apple Pay                                                                                   | Google Pay                                                                                          |
|----------------|-------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| **시작 시점**          | 2013년 iOS 8.1부터 적용 (최초의 대중적 모바일 결제 서비스)                                                                                      | 2018년 본격 도입 (Android Pay와 Google Wallet 통합) <br>→ *역사적 배경:* 구글은 2011년 Google Wallet 출시했으나 NFC 보급 미흡으로 실패, 후속 기술로 발전 |
| **정보 수집 및 전송**    | 기기에서 카드 정보(PAN)를 **암호화된 HTTPS**로 Apple 서버에 전송 <br>→ *보안 강화:* TLS 1.2 이상 적용, 양방향 인증 수행                                                                 | 기기에서 카드 정보(PAN)를 **암호화된 HTTPS**로 Google 서버에 전송 <br>→ *주의점:* 구글은 사용자 결제 데이터를 서버에 저장할 수 있음을 공식 문서에 명시 |
| **서버 역할**          | 카드 정보로 은행 식별 후 은행에 안전하게 전송. <br>→ *중요 특징:* Apple은 토큰 생성 후 원본 PAN 즉시 폐기 주장 (Single-use token 정책)                                                                       | 카드 정보로 은행 식별 후 은행에 안전하게 전송. <br>→ *차이점:* 구글은 토큰 재사용 가능(Multi-use token)하며, 클라우드 동기화 기능 제공                                                                       |
| **토큰 생성 방식** | 은행이 PAN 검증 후 **TSP(Token Service Provider)**를 통해 기기 전용 토큰(DAN) 생성. <br>→ *TSP 예시:* Visa의 VTS, Mastercard의 MDES                                                                   | 은행이 PAN 검증 후 TSP를 통해 토큰(DPAN) 생성. <br>→ *유의사항:* Android 기기마다 다른 DPAN 발급 가능                                                                    |
| **토큰 저장 위치**       | **Secure Element** (보안 하드웨어 칩)에 안전하게 저장. <br>→ *보안 수준:* EAL5+ 인증 칩 사용, 생체 인증 연동 필수 <br>→ *Apple 서버 역할:* 단순 경로 제공(토큰 저장 없음)                                                                   | **Wallet 앱** 또는 **Google 클라우드**에 저장. <br>→ *보안 메커니즘:* 소프트웨어 기반 HCE 기술 사용 <br>→ *리스크:* 기기 분실 시 클라우드 복원 가능성 존재                                                               |



### **18.3 결제 과정 (단계별 비교)**

| 단계          | Apple Pay                                                                                                             | Google Pay                                                                                                                                    |
|-------------|-------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------|
| **1. 결제 시작**       | "Pay" 클릭 시 → Secure Element에서 DAN 추출 → **NFC**를 통해 POS 단말기로 전송. <br>→ *보안 프로세스:* Face ID/Touch ID로 2차 인증 필수                                                                   | Wallet 앱 실행 또는 클라우드에서 결제 토큰 호출 → **HCE(Host Card Emulation)**를 통해 NFC로 POS 단말기에 전송. <br>→ *HCE란?* 하드웨어 칩 없이 소프트웨어로 카드 에뮬레이션 구현                                                                          |
| **2. 결제 처리 흐름** | POS 단말기 → 가맹점 은행 → 결제 네트워크 (DAN 검증 및 TSP에 디토큰화 요청) → 카드 발급 은행 (결제 승인) <br>→ *특이점:* Apple은 거래 추적을 위한 독자적 트랜잭션 ID 추가 생성                                                         | POS 단말기 → 가맹점 은행 → 결제 네트워크 (DPAN 검증 및 TSP에 디토큰화 요청) → 카드 발급 은행 (결제 승인) <br>→ *추가 기능:* 구글은 거래 데이터를 Google Pay 앱에 기록하여 소비 패턴 분석 제공                                                         |



### **18.4 주요 차이점 (심화)**

*   **토큰 저장 위치:**  
    - Apple Pay: **Secure Element** (하드웨어 칩) → 오프라인 환경에서도 결제 가능.  
    - Google Pay: **Wallet 앱** 또는 **클라우드** → 인터넷 연결 필요할 수 있으나 기기 변경 시 유연성 높음.  
*   **서버 저장 정책:**  
    - Apple: "토큰은 기기 전용" 원칙 강조 (서버 백업 없음).  
    - Google: 클라우드 동기화 가능성 공개 → *장단점:* 편의성 ↑ but 잠재적 보안 리스크 존재.  
*   **결제 기술:**  
    - Apple Pay: **Secure Element + NFC** → 생체 인증 필수.  
    - Google Pay: **HCE + NFC** → 생체 인증 선택적 적용 가능.  



### **18.5 결론 및 선택 가이드**

*   **보안성:**  
    - Apple Pay의 Secure Element가 이론상 더 강력 (은행급 보안 칩 사용).  
    - Google Pay는 소프트웨어 의존도 높으나, 최신 Android는 Titan M2 칩으로 보완 중.  
*   **편의성:**  
    - Google Pay는 클라우드 백업으로 기기 변경 시 재등록 절차 간소화.  
    - Apple Pay는 생체 인증 필수로 사용자 불편 발생 가능성 있음.  
*   **호환성:**  
    - Google Pay는 Android 폰 외에도 Wear OS 스마트워치에서도 사용 가능.  
    - Apple Pay는 iOS/Mac/Watch 생태계 내에서 최적화.  

**▶ 사용자 맞춤형 선택 기준:**  
- "보안을 최우선" → Apple Pay (특히 금융 거래 빈번한 사용자).  
- "기기 간 연동 편리성" → Google Pay (다중 기기 사용자 또는 Android 유저).  
- *참고:* 국내는 ISP/BC 카드사 정책에 따라 일부 기능 제한될 수 있음.

## 19. 프록시 (Proxy)
- 출처: [Proxy vs Reverse Proxy (Real-world Examples)](https://www.youtube.com/watch?v=4NB0NDtOwIQ)

### 19.1 프록시 (Proxy) 란?
- 프록시는 클라이언트와 서버 사이에 위치하여 요청을 중개하는 서버로, 네트워크 트래픽의 중간 관리자 역할을 합니다. 이는 마치 우편 배달 대행 서비스와 유사한 개념으로, 발신자와 수신자 사이에서 안전하고 효율적인 통신을 보장합니다.

### 19.2  프록시 종류
1.**Forward Proxy (포워드 프록시)**:
* 정의:
    *   클라이언트 그룹과 인터넷 사이에 위치하는 게이트웨이 역할
    *   클라이언트 앞단 (내부 네트워크 → 인터넷)
    *   클라이언트의 요청을 중간에서 가로채 웹 서버와 통신 (클라이언트 대행,대리인)
    *   일반적으로 기업 내부망이나 학교 네트워크에서 많이 사용됨
* **사용 이유:**
    *   **온라인 ID 보호:** 
        - 클라이언트 IP 주소를 숨겨 추적을 어렵게 함. 예를 들어, 특정 국가에서만 접근 가능한 콘텐츠를 볼 때 사용
    *   **검열 우회:** 
        - 방화벽 외부의 프록시 서버를 통해 인터넷 접속 제한을 우회. 중국의 그레이트 파이어월을 우회하는 경우가 대표적
    *   **콘텐츠 차단:** 
        - 특정 콘텐츠에 대한 접근을 제한. 기업에서 업무 시간 중 SNS 접근 차단 등

* **특징:**
    *   일반적으로 클라이언트가 프록시 서버를 지정하도록 설정해야 함 (브라우저 설정 등)
    *   투명 프록시 (Transparent Proxy)는 레이어 4 스위치를 사용하여 특정 트래픽을 자동으로 프록시로 리디렉션 (클라이언트 설정 불필요)
    *   캐싱 기능을 통해 동일한 요청에 대한 응답 속도 향상 가능

2.**Reverse Proxy (리버스 프록시)**
* 정의:
    *   인터넷과 웹 서버 사이에 위치하는 방어벽 역할
    *   서버 앞단 (인터넷 → 웹 서버)
    *   클라이언트의 요청을 가로채 웹 서버와 통신 (웹 서버 대행, 접수처)
    *   대표적으로 Nginx, Apache HTTP Server, Cloudflare 등이 이 역할을 수행

* **사용 이유:**
    *   **웹 사이트 보호:** 
        - 웹 사이트의 IP 주소를 숨겨 DDoS 공격을 방어. 실제 서버 IP를 노출하지 않음으로써 직접적인 공격 차단
    *   **로드 밸런싱:** 
        - 트래픽을 여러 웹 서버에 분산시켜 서버 과부하를 방지. Round Robin, Least Connections 등 다양한 알고리즘 적용 가능
    *   **정적 콘텐츠 캐싱:** 
        - 정적 콘텐츠(이미지, CSS, JS 등)를 캐싱하여 빠른 응답 제공 및 원본 서버 부하 감소
    *   **SSL 암호화 처리:** 
        - SSL 핸드셰이크 처리를 대신하여 웹 서버의 부담을 줄임 (SSL Termination)
    *   **컨텐츠 압축:** 
        - 전송 데이터를 압축하여 대역폭 절약

* **특징:**
    *   최근 웹 사이트는 여러 계층의 리버스 프록시를 사용하는 경우가 많음
        *   **Edge Service:** Cloudflare와 같이 사용자 위치와 가까운 전 세계 여러 지역에 배치 (CDN 기능과 결합)
        *   **API Gateway/Load Balancer:** 호스팅 제공업체(AWS의 ALB, GCP의 Cloud Load Balancing 등)에서 제공하는 고급 트래픽 관리 기능
    *   마이크로서비스 아키텍처에서 각 서비스의 진입점 역할 수행
    *   A/B 테스트, 카나리아 배포 등에 활용 가능

### 19.3 **추가 설명**
- 프록시 서버는 OSI 7계층 모델에서 애플리케이션 계층(L7)에서 동작하지만, 경우에 따라 트랜스포트 계층(L4)에서 작동하기도 합니다.
- 현대 클라우드 환경에서는 프록시 기능이 서비스 메시(Service Mesh) 아키텍처의 사이드카 프록시(예: Istio의 Envoy)로 발전하고 있습니다.
- 프록시 사용 시 약간의 latency 증가가 발생할 수 있지만, 적절한 구성으로 전체적인 성능을 크게 향상시킬 수 있습니다.

## 20. API Gateway
- 출처: [What is API Gateway?](https://www.youtube.com/watch?v=6ULyxuHKxg8)

### **20.1 API Gateway란?**  

*   **애플리케이션 클라이언트를 위한 단일 진입점 (Single Point of Entry)**  
    - 모든 클라이언트 요청을 중앙에서 관리해 백엔드 서비스와 결합도를 낮추고, 일관된 인터페이스 제공  
*   **클라이언트와 백엔드 서비스 집합 사이에 위치**  
    - 마이크로서비스 아키텍처에서 각 서비스의 엔드포인트를 추상화하여 클라이언트가 복잡한 내부 구조를 알 필요 없도록 함  

### **20.2 API Gateway가 필요한 이유?**  

*   **다양한 핵심 기능 제공**  
    - 마이크로서비스 환경에서 트래픽 관리, 보안, 모니터링 등 공통 관심사(Cross-Cutting Concerns)를 효율적으로 처리  
    - 클라이언트별 최적화된 API 버전 제공 (e.g., 모바일/웹용 다른 응답 구조)  

### **20.3 API Gateway의 주요 기능**  

*   **인증 및 보안 정책 적용:**  
    - OAuth2, JWT 등을 통한 접근 제어, API 키 관리, DDoS 방어  
*   **로드 밸런싱 및 회로 차단 (Circuit Breaking):**  
    - 라운드 로빈, Least Connections 등 알고리즘으로 트래픽 분산  
    - 장애 발생 시 장애 서비스 격리 (e.g., Netflix Hystrix)  
*   **프로토콜 변환 및 서비스 디스커버리:**  
    - REST → gRPC, GraphQL → SOAP 등 프로토콜 브리징  
    - 동적 서비스 탐색 (e.g., Kubernetes 서비스 디스커버리 연동)  
*   **모니터링, 로깅, 분석 및 과금:**  
    - Prometheus, Grafana 연동을 통한 실시간 모니터링  
    - API 호출 횟수 기반 과금 (e.g., AWS API Gateway)  
*   **캐싱:**  
    - Redis 등을 활용한 응답 캐싱으로 백엔드 부하 감소  

### 20.4 **클라이언트 요청 처리 흐름**  

1.  **클라이언트 요청:**  
    - API Gateway로 HTTP 기반 요청 전송 (REST, GraphQL 등), WebSocket 지원 가능  
2.  **요청 검증:**  
    - HTTP 메서드, 패스 파라미터, 바디 포맷 검증 (e.g., Swagger/OpenAPI 스펙 기반)  
3.  **IP 및 헤더 검사:**  
    - 화이트/블랙리스트 필터링, Bot 탐지 (e.g., User-Agent 분석)  
4.  **인증 및 권한 부여:**  
    - OIDC 연동으로 SSO 지원, RBAC(Role-Based Access Control) 적용  
5.  **고급 Rate Limit 체크:**  
    - 토큰 버킷 알고리즘으로 API 호출 제한 (e.g., 1,000회/분)  
6.  **서비스 디스커버리:**  
    - 라우팅 규칙에 따라 마이크로서비스 매칭 (e.g., `/orders` → 주문 서비스)  
7.  **요청 변환 및 전달:**  
    - 헤더 추가/삭제, 페이로드 변환 (e.g., XML → JSON)  
8.  **응답 변환 및 반환:**  
    - 데이터 압축 (gzip), 필드 필터링 (e.g., 모바일 클라이언트용 필수 데이터만 반환)  

### **20.5 추가적으로 제공해야 할 중요한 서비스**  

*   **오류 추적 및 회로 차단:**  
    - 분산 추적 시스템 (e.g., Jaeger, Zipkin)과 연동해 장애 지점 분석  
*   **로깅, 모니터링 및 분석:**  
    - ELK 스택(Elasticsearch, Logstash, Kibana)으로 로그 집계  

### **20.6 배포 고려 사항**  

*   **다중 지역 배포:**  
    - Active-Active 구성으로 재해 복구(DR) 대비  
*   **클라이언트와 가까운 위치 배포:**  
    - CDN(Content Delivery Network)과 연계해 지연 시간 최적화  

### **20.7 결론**  
- API Gateway는 인프라의 중요한 구성 요소, 클라우드 환경에서 전 세계적으로 분산되어 배포되는 추세.  
- **클라우드 네이티브 솔루션:** AWS API Gateway, Kong, Apigee 등  
- **서비스 메시(Service Mesh)와의 차이점:** API Gateway는 North-South 트래픽, 서비스 메시는 East-West 트래픽 관리에 특화

## 21. GraphQL
- 출처: [What Is GraphQL? REST vs. GraphQL](https://www.youtube.com/watch?v=yWzKJPw_VzM)

### 21.1 **GraphQL이란?**  

*   **Meta(前 Facebook)에서 2012년 개발**한 API를 위한 **선언형 쿼리 언어**  
    * 클라이언트-서버 간 효율적인 데이터 통신을 목표로 설계  
*   **강력한 타입 시스템**을 기반으로 API 내 **데이터 스키마를 명시적으로 제공**  
    * 스키마는 클라이언트와 서버 간의 계약(contract) 역할  
*   **클라이언트 주도 데이터 요청**: 필요한 데이터의 **구조와 필드를 정확히 지정** 가능  
    * REST의 Over-fetching/Under-fetching 문제 해결  
*   **단일 엔드포인트**에서 **계층적 쿼리** 처리  
    * 여러 리소스 요청을 **단일 API 호출**로 통합 (네트워크 비용 감소)  
*   **CRUD+α 지원**:  
    * `Query`(조회), `Mutation`(생성/수정/삭제), `Subscription`(실시간 알림)  

### 21.2 **REST와의 비교**  

| 특징          | GraphQL                                                                 | REST                                                                 |
| ----------- | ----------------------------------------------------------------------- | -------------------------------------------------------------------- |
| **통신 방식**  | HTTP POST를 주로 사용 (단일 엔드포인트)                                      | HTTP 메서드(GET/POST/PUT/DELETE 등) 활용                                |
| **자원 식별**  | **GraphQL 스키마**로 데이터 모델 정의 (URL 경로 없음)                          | **URL 경로**로 리소스 식별 (예: `/users/1`)                              |
| **데이터 요청** | 클라이언트가 **필드 단위로 요청** (예: `{ user(id:1) { name, email } }`)       | 서버가 미리 정의한 **고정 응답 구조** (예: 전체 사용자 프로필 반환)                   |
| **장점**      |                                                                         |                                                                      |
|               | - **정밀한 데이터 요청**으로 **네트워크 효율성** ↑ (모바일 환경 유리)                 | - **간단한 설계**: 표준 HTTP 기능 활용 (캐싱, 인증 등)                          |
|               | - **관계형 데이터** 조회 최적화 (예: 사용자+게시글+댓글을 한 번에)                     | - **학습 곡선 낮음**: 도구 없이도 테스트 가능 (브라우저, Postman 등)               |
|               | - **API 버전 관리 불필요** (클라이언트가 필드 선택)                                | - **CDN 친화적**: GET 요청 캐싱 가능                                    |
| **단점**      |                                                                         |                                                                      |
|               | - **성능 관리 복잡**: 복잡한 쿼리 시 **서버 과부하** 가능 (Depth/Complexity 제한 필요) | - **N+1 문제** (예: 사용자 목록 + 각 사용자의 프로필을 별도 요청)                   |
|               | - **HTTP 캐싱 어려움**: POST 요청이 기본이므로 CDN/브라우저 캐싱 적용 불편              | - **Over-fetching**: 필요 없는 데이터 포함 (예: 전체 회원 정보 중 일부 필드만 사용)   |
|               | - **도구 의존성 높음**: 클라이언트 라이브러리(Apollo, Relay) 및 스키마 관리 필요          | - **Under-fetching**: 추가 데이터 필요 시 여러 엔드포인트 호출 (네트워크 비용 증가)   |



### 21.3 **GraphQL 사용 시 고려 사항**  

*   **트레이드오프 분석 필수**:  
    * 장점(유연성, 효율성) vs 단점(설계 복잡성, 성능 리스크)을 프로젝트 요구사항에 맞춰 평가  
*   **적합한 시나리오**:  
    * **다양한 클라이언트**(모바일/웹)가 **다양한 데이터**를 요청할 때  
    * **복잡한 관계형 데이터**를 **실시간**으로 처리해야 할 때 (예: SNS, 대시보드)  
*   **주의점**:  
    * **보안**: 쿼리 복잡도 제한(Query Depth Limit), Rate Limiting 필수  
    * **성능**: DataLoader로 N+1 문제 해결, Persistent Query로 쿼리 최적화  
    * **운영**: 스키마 변경 시 **백워드 호환성** 유지 (Deprecation 전략)  

### 21.4 **결론** 
- GraphQL은 **강력한 유연성**을 제공하지만, **신중한 설계**와 **운영 오버헤드**를 감수해야 합니다.  
- REST와 혼용하거나(예: 파일 업로드는 REST), **점진적 도입**을 고려하는 것도 방법입니다.

## 22. SSO (Single Sign-On)
- 출처: [What Is Single Sign-on (SSO)? How It Works](https://www.youtube.com/watch?v=O1cRJWYF-g4)

### 22.1 **정의**
* 하나의 ID로 여러 애플리케이션 및 서비스에 안전하게 접근할 수 있게 하는 인증 방식.
* 사용자 경험을 개선하고 보안을 강화하는 현대적 인증 솔루션으로, 기업 및 개인 사용자 모두에게 효율적인 접근성 제공.

### 22.2 **기본 개념**
* **Federated Identity:** 신뢰할 수 있는 독립된 시스템 간에 ID 정보를 공유하는 개념에 기반.
* 각 조직은 자체 사용자 관리 시스템을 유지하면서도 다른 시스템과 안전하게 사용자 신원 정보를 교환
* 사용자의 자격 증명 정보는 실제로 한 곳(Identity Provider)에서만 관리되며, 다른 시스템은 이를 신뢰

### 22.3 **작동 방식**
1. 사용자가 SSO가 통합된 애플리케이션(예: Gmail)에 접속.
   * 사용자는 평소처럼 웹 브라우저나 모바일 앱을 통해 서비스에 접근 시도.
2. 애플리케이션(Service Provider)은 사용자의 도메인을 확인하고 인증 요청을 브라우저로 보냄.
   * 이 단계에서 서비스 제공자는 사용자가 아직 인증되지 않았음을 감지함.
3. 브라우저는 사용자를 해당 회사의 Identity Provider(IdP)로 리디렉션.
   * 이 과정은 사용자에게 거의 보이지 않거나 매우 빠르게 진행됨.
4. IdP는 로그인 페이지를 표시하고 사용자가 인증 정보를 입력.
   * 이 페이지는 보통 회사 로고와 브랜딩이 적용된 맞춤형 페이지임.
5. 인증 성공 시, IdP는 사용자 정보 및 접근 권한을 담은 SAML assertion(또는 JWT)을 생성하여 브라우저로 반환.
   * 이 토큰에는 사용자 식별자, 권한, 세션 정보 등 중요 정보가 암호화되어 포함됨.
6. 브라우저는 해당 assertion을 Service Provider로 전달.
   * HTTP POST 또는 리디렉션을 통해 안전하게 전송됨.
7. Service Provider는 assertion의 서명을 확인하고, 사용자에게 해당 권한에 따라 리소스에 대한 접근 권한을 부여.
   * 디지털 서명 검증을 통해 토큰의 무결성과 출처를 확인함.
8. 다른 SSO 통합 애플리케이션(예: Workday) 접속 시, 이미 IdP에 로그인되어 있다면 로그인 과정 없이 해당 애플리케이션에 대한 assertion이 발급되어 접근이 허용.
   * 사용자는 이 과정을 'SSO 매직'으로 경험하며, 추가 로그인 없이 다른 서비스로 원활하게 이동함.

### 22.4 **주요 프로토콜**
* **SAML (Security Assertion Markup Language):**
  * XML 기반의 개방형 표준으로, 서비스 간 ID 정보 교환에 사용.
  * 주로 업무 환경에서 사용.
  * 기업 애플리케이션과의 통합에 최적화되어 있으며, 복잡한 인증 시나리오 처리 가능.
  * 세션 관리와 높은 보안 수준을 제공하지만 구현이 다소 복잡할 수 있음.

* **OpenID Connect:**
  * JWT (JSON Web Token)를 사용하여 서비스 간 ID 정보 공유.
  * 개인 Google 계정으로 YouTube 등에 로그인할 때 사용.
  * OAuth 2.0 프레임워크 위에 구축된 인증 레이어로, 모바일 애플리케이션 통합에 유리함.
  * 구현이 비교적 간단하고 가벼우며, 최신 웹 기술과의 호환성이 뛰어남.

### 22.5 **프로토콜 선택**
* 둘 다 안전한 방식이며, 상용 IdP들은 대부분 두 가지 모두 지원.
* 선택은 통합하려는 애플리케이션의 특성 및 통합 용이성에 따라 결정.
* 새 웹 애플리케이션 개발 시, Google, Facebook, Github 등 인기 있는 OpenID Connect 플랫폼과의 통합이 용이할 수 있음.
* 엔터프라이즈 환경에서는 SAML이 여전히 강력한 선택이며, 레거시 시스템과의 호환성이 좋음.
* 보안 요구사항, 기존 인프라, 개발 리소스를 고려하여 적절한 프로토콜 선정 필요.

### 22.6 **핵심 이점**
* 사용자는 여러 앱에 일일이 로그인할 필요 없이 한 번의 로그인으로 모든 서비스 이용 가능.
* 비밀번호 피로도 감소로 보안 강화 및 지원 비용 절감 효과.
* 중앙화된 인증 시스템으로 보안 정책 일관성 유지 및 관리 효율성 증대.
* 사용자 온보딩/오프보딩 프로세스 간소화로 인한 IT 관리 부담 경감.
* 규정 준수(컴플라이언스) 요구사항 충족에 도움이 되는 감사 추적 기능 제공.

## 23. CDN (콘텐츠 전송 네트워크)
- 출처: [What Is A CDN? How Does It Work?](https://www.youtube.com/watch?v=RI9np1LWzqw)

### **23.1 CDN이란?**

*   90년대 후반부터 사용된 기술로, 사용자에게 콘텐츠를 더 빠르게 전달하기 위해 개발됨. 특히 1998년 Akamai가 설립되면서 상업적 CDN 서비스가 본격화되었음.
*   원래는 정적 HTML 콘텐츠 전송 속도 향상이 목적이었으나, 현재는 HTTP 트래픽을 제공하는 모든 경우에 사용됨. 여기에는 동영상, 게임, 소프트웨어 업데이트, API 응답 등 다양한 데이터가 포함됨.

### **23.2 CDN을 사용해야 하는 이유**

*   **성능 향상:**
    *   콘텐츠를 사용자에게 더 가까이 위치시켜 사용자 체감 성능을 향상시킴. 지리적 거리에 따른 네트워크 지연시간(latency)을 크게 줄여 페이지 로딩 시간이 최대 50-70% 감소할 수 있음.
    *   사용자 참여와 유지에 매우 중요함. 웹사이트 로딩 시간이 3초를 넘으면 방문자의 약 40%가 이탈한다는 연구 결과가 있음.
*   **보안 강화:**
    *   대규모 네트워크 용량을 통해 DDoS 공격으로부터 효과적으로 보호함. 대형 CDN은 수십 Tbps의 트래픽을 처리할 수 있는 역량을 갖추고 있음.
    *   Anycast 네트워크 기반 CDN은 공격 트래픽을 분산시키는 데 특히 효과적임. 또한 WAF(웹 애플리케이션 방화벽)를 통합하여 XSS, SQL 인젝션과 같은 취약점 공격을 차단함.
*   **가용성 향상:**
    *   분산된 구조로 하드웨어 장애에 더 잘 대처할 수 있음. 한 서버나 데이터 센터에 문제가 생겨도 다른 위치에서 트래픽을 처리해 99.99% 이상의 가용성을 보장함.

### **23.3 CDN의 작동 방식**

*   **PoP (Point of Presence):** 전 세계에 분산된 CDN 서버 위치. 대형 CDN 제공업체의 경우 전 세계 100개 이상의 국가에 수백 개의 PoP를 운영하고 있음.
*   **Edge Server:** PoP 내부에 있는 서버로, 리버스 프록시 역할을 하며 콘텐츠 캐시를 보유. SSD와 최적화된 메모리 관리 시스템을 사용해 초고속 응답 시간을 제공함.
*   **라우팅 방식:**
    *   **DNS 기반 라우팅:** 각 PoP가 고유 IP 주소를 가지며, 사용자에게 가장 가까운 PoP의 IP 주소를 반환. GeoDNS와 같은 기술을 활용해 사용자의 지리적 위치, 네트워크 상태, 서버 부하 등을 고려하여 최적의 PoP를 선택함.
    *   **Anycast:** 모든 PoP가 동일한 IP 주소를 공유하며, 요청자에게 가장 가까운 PoP로 요청을 전송. BGP(Border Gateway Protocol) 라우팅을 활용해 네트워크 토폴로지상 가장 효율적인 경로로 트래픽을 유도함.

### **23.4 CDN의 주요 기능**

*   **콘텐츠 캐싱:** Edge Server에 정적 콘텐츠를 캐싱하여 사용자에게 빠르게 제공하고 원본 서버의 부하를 줄임. 다양한 캐싱 전략(TTL 기반, 조건부 캐싱 등)과 캐시 무효화 메커니즘을 지원하여 항상 최신 콘텐츠를 제공함.
*   **콘텐츠 최적화:** Javascript 번들 축소, 이미지 포맷 변환 (WebP, AVIF) 등 콘텐츠를 최적화함. 또한 HTTP/2, HTTP/3와 같은 최신 프로토콜 지원과 adaptive bitrate streaming을 통해 네트워크 상황에 맞는 최적의 콘텐츠 전달이 가능함.
*   **TLS 연결 종료:** Edge Server에서 TLS 연결을 종료하여 암호화된 TCP 연결 설정 시간을 단축함. OCSP stapling, TLS 세션 재사용 등의 기술로 초기 핸드셰이크 시간을 최대 40% 단축할 수 있으며, 최신 TLS 1.3 프로토콜 지원으로 보안성과 성능을 동시에 개선함.

## 24. gRPC
- 출처: [What is RPC? gRPC Introduction.](https://www.youtube.com/watch?v=gnchfOojMk4)

### 24.1 **정의**
* Google이 2016년에 공개한 오픈 소스 RPC (Remote Procedure Call) 프레임워크
  * 내부적으로는 구글이 수년간 마이크로서비스 아키텍처를 지원하기 위해 개발한 기술
  * 이미 검증된 기술을 오픈소스로 공유하여 산업 전반에 기여
* 오랜 기간 사용해 온 내부 RPC 인프라의 재작성 버전
  * 구글의 Stubby라는 내부 시스템을 현대화하고 일반화한 결과물
  * 대규모 분산 시스템 경험에서 얻은 교훈을 반영한 설계

### 24.2 **RPC 란?**
* **Local Procedure Call:** 프로세스 내에서 코드를 실행하기 위한 함수 호출
  * 동일한 메모리 공간 내에서 일어나는 전통적인 함수 호출 방식
  * 프로그래머에게 매우 친숙한 개념으로 직관적인 사용 가능
* **Remote Procedure Call:** 사용자가 로컬 함수 호출처럼 다른 컴퓨터에서 코드를 호출할 수 있도록 함
  * 네트워크 통신의 복잡성을 추상화하여 개발자가 분산 시스템을 쉽게 구현할 수 있게 함
  * 서로 다른 위치에 있는 서비스 간 통신을 마치 로컬 함수처럼 간단하게 만듦
* gRPC는 RPC의 대표적인 구현체
  * 현대적인 클라우드 네이티브 환경에 최적화된 RPC 프레임워크
  * 수많은 기업과 오픈소스 프로젝트에서 채택하여 사실상의 표준으로 자리매김

### 24.3 **gRPC의 인기 요인**

* **개발자 생태계:** 프로덕션 수준의 안정적이고 확장 가능한 API를 쉽게 개발 가능
  * 다양한 언어로 구현된 클라이언트/서버 라이브러리 제공 (Java, C++, Python, Go, Ruby, C#, Node.js 등)
  * 개발 생산성을 크게 향상시키는 도구와 플러그인 생태계
  * **Protocol Buffers:** 언어 및 플랫폼에 독립적인 구조화된 데이터 인코딩 메커니즘으로 gRPC의 핵심
    * 강력한 타입의 스키마 정의 지원
      * 명확한 계약을 통해 API 버전 관리와 호환성 유지가 용이
      * 컴파일 시점에 타입 오류 감지 가능으로 런타임 오류 감소
    * 다양한 프로그래밍 언어에 대한 데이터 액세스 클래스 생성 도구 지원
      * 한 번 정의하고 여러 언어로 코드 생성 가능
      * 언어 간 상호운용성 보장
    * RPC 메서드 파라미터 및 반환 유형 정의 가능
      * 서비스 인터페이스와 메시지 구조를 명확히 문서화
      * API 설계의 일관성 유지에 도움
    * 클라이언트 및 서버 코드 자동 생성
      * 반복적인 코드 작성을 줄이고 휴먼 에러 방지
      * 코드 일관성과 품질 향상
    * 클라이언트와 서버가 각자에게 적합한 프로그래밍 언어를 선택 가능
      * 폴리글랏 마이크로서비스 아키텍처 지원
      * 각 서비스의 특성에 맞는 최적의 언어 선택 가능

* **고성능:** 기본적으로 높은 성능 제공
  * 네트워크 리소스를 효율적으로 사용하여 지연 시간 최소화
  * 대용량 데이터 처리와 실시간 시스템에 적합한 성능 특성
  * **Protocol Buffers의 효율적인 이진 인코딩:** JSON보다 훨씬 빠름
    * 메시지 크기가 작아 네트워크 대역폭 사용 효율적
    * 파싱 및 직렬화/역직렬화 속도가 빠름
    * 데이터 표현이 압축적이고 최적화됨
  * **HTTP/2 기반:** 높은 확장성을 제공
    * 바이너리 프로토콜로 헤더 압축, 멀티플렉싱 지원
    * 지연 시간 감소와 리소스 효율성 향상
    * **HTTP/2 스트림을 사용, 단일 TCP 연결을 통해 여러 메시지 스트림 처리 가능**
      * 연결 설정 오버헤드 감소
      * HOL(Head-of-Line) 블로킹 문제 해결
    * **클라이언트와 서버 간의 적은 수의 TCP 연결로 많은 동시 RPC 호출 처리 가능**
      * 서버 리소스 효율적 사용
      * 확장성 있는 시스템 구축 가능

### 24.4**gRPC 작동 방식**

1. 클라이언트 (예: Order Service)가 gRPC 호출을 Payment Service (서버)로 보냄
   * 서비스 간 통신이 마치 로컬 함수 호출처럼 추상화됨
   * 네트워크 통신의 복잡성은 gRPC 프레임워크가 처리
2. 클라이언트 스텁 (gRPC 도구에 의해 생성된 클라이언트 코드) 호출
   * 스텁이 RPC 메소드의 인터페이스를 제공하여 클라이언트 코드 단순화
   * 통신 세부사항을 추상화하고 타입 안전성 보장
3. gRPC가 데이터를 Protocol Buffers로 인코딩하여 전송 계층으로 보냄
   * 효율적인 바이너리 형식으로 변환하여 메시지 크기 최소화
   * 언어 중립적인 형식으로 변환되어 다양한 환경 간 호환성 보장
4. HTTP/2 데이터 프레임 스트림으로 네트워크를 통해 데이터 전송
   * 헤더 압축과 바이너리 프로토콜로 네트워크 효율성 향상
   * 멀티플렉싱을 통해 단일 연결에서 여러 요청 병렬 처리
5. Payment Service가 패킷을 수신하고 디코딩하여 서버 애플리케이션 호출
   * 서버 측 스텁이 바이너리 메시지를 해당 언어의 객체로 변환
   * 서비스 구현체로 요청을 라우팅하여 비즈니스 로직 실행
6. 결과값을 Protocol Buffers로 인코딩하여 전송 계층으로 보냄
   * 응답 데이터도 동일한 효율적인 바이너리 형식으로 변환
   * 일관된 직렬화 메커니즘으로 양방향 통신 단순화
7. Order Service가 패킷을 수신하고 디코딩하여 클라이언트 애플리케이션으로 결과 전송
   * 클라이언트 측 스텁이 바이너리 응답을 적절한 객체로 변환
   * 비동기 처리를 지원하여 클라이언트 성능 최적화
8. gRPC는 JSON보다 5배 빠름
   * 효율적인 바이너리 인코딩과 HTTP/2의 성능 최적화 덕분
   * 특히 모바일 환경과 대규모 분산 시스템에서 성능 차이 두드러짐

### 24.5 **gRPC-Web**

* 브라우저에서 gRPC 호출을 가능하게 하는 기술 (프록시 필요)
  * 웹 클라이언트에서도 gRPC의 이점을 활용할 수 있게 해주는 확장
  * Envoy나 NGINX와 같은 프록시를 통해 브라우저 제약사항 우회
* gRPC와 완벽하게 호환되지는 않음
  * 브라우저의 HTTP/2 구현 제약으로 인한 일부 기능 제한
  * 서버 스트리밍은 지원하지만 클라이언트 스트리밍과 양방향 스트리밍은 완전히 지원하지 않음
  * 프록시 레이어가 추가되어 순수 gRPC보다 약간의 오버헤드 발생

### 24.6 **gRPC 사용 시기**

* **마이크로서비스 간 통신:** 다양한 프로그래밍 언어 지원으로 각 서비스에 적합한 언어 선택 가능
  * 서비스 간 명확한 계약 정의와 타입 안전성 보장
  * 고성능 통신으로 마이크로서비스 아키텍처의 오버헤드 감소
  * 다양한 유형의 통신 패턴(단항, 서버 스트리밍, 클라이언트 스트리밍, 양방향 스트리밍) 지원
* **모바일 클라이언트:** 에너지 및 대역폭 제약이 있는 환경에서 효율적인 성능 제공
  * 제한된 네트워크 환경에서 효율적인 통신으로 배터리 수명 연장
  * 작은 메시지 크기로 데이터 사용량 감소와 응답 시간 단축
  * 모바일 디바이스의 제한된 리소스를 효율적으로 활용

## 25. HTTPS 작동 방식
- 출처: [SSL, TLS, HTTPS Explained](https://www.youtube.com/watch?v=j9QmMEWmcfo)

### 25.1 **HTTPS 란?**

*   브라우저와 서버 간의 통신을 암호화하여 개인 정보(비밀번호, 카드 번호 등)를 보호하는 프로토콜로, 웹 브라우징 시 주소창에 자물쇠 아이콘으로 표시됩니다
*   HTTP 프로토콜의 확장판이며, TLS(Transport Layer Security)를 사용하여 데이터를 암호화함으로써 중간자 공격(man-in-the-middle attack)과 같은 보안 위협으로부터 사용자를 보호합니다

### 25.2 **HTTPS 작동 원리 (TLS Handshake)**

1.  **TCP 연결 설정:** 브라우저가 서버와 TCP 연결을 설정합니다. 이는 일반적으로 포트 443을 통해 이루어집니다(HTTP는 포트 80).
2.  **TLS Handshake 시작:**
    *   **Client Hello:** 브라우저가 지원하는 TLS 버전 및 암호화 방식(Cipher Suite) 목록을 서버에 전송하며, 무작위 바이트 문자열(Client Random)도 함께 보냅니다
    *   **Server Hello:** 서버가 선택한 TLS 버전 및 암호화 방식을 브라우저에 회신하고, 서버도 자체 무작위 바이트 문자열(Server Random)을 생성하여 전송합니다
    *   **인증서 전송:** 서버가 자신의 인증서(공개 키 포함)를 브라우저에 전송하며, 이 인증서는 CA(인증 기관)에 의해 디지털 서명되어 신뢰성을 보장합니다
3.  **세션 키 교환:**
    *   **비대칭 암호화 사용:** 브라우저는 서버의 공개 키를 사용하여 세션 키를 암호화하여 서버에 전송 (RSA 알고리즘 예시). 이때 브라우저는 인증서의 유효성을 CA의 공개 키로 검증합니다
    *   서버는 자신의 개인 키로 암호화된 세션 키를 해독하여 안전하게 브라우저와 동일한 키를 공유
4.  **대칭 암호화 통신:**
    *   클라이언트와 서버는 공유된 세션 키와 합의된 암호화 방식을 사용하여 데이터를 암호화/해독하며 안전하게 통신합니다. 이 시점부터 모든 HTTP 데이터는 암호화되어 전송됩니다

### 25.3 **대칭 암호화 vs. 비대칭 암호화**

*   **비대칭 암호화:** 공개 키와 개인 키를 사용하여 암호화/해독 (세션 키 교환에 사용)
    *   보안성이 높지만 계산 비용이 많이 듦 (AES에 비해 약 1000배 느림)
    *   RSA, ECC(타원곡선 암호화) 등의 알고리즘이 사용됩니다
*   **대칭 암호화:** 동일한 키를 사용하여 암호화/해독 (데이터 전송에 사용)
    *   계산 비용이 적게 들지만, 키 교환이 안전해야 함
    *   AES(Advanced Encryption Standard)가 가장 널리 사용되는 대칭 암호화 알고리즘입니다

### 25.4 **TLS 1.2 vs. TLS 1.3**

*   TLS 1.3은 TLS 1.2의 최적화 버전으로, Handshake 과정을 단축하여 통신 속도 향상 (1-RTT로 축소, 최대 40% 성능 향상)
*   TLS 1.3에서는 RSA 방식의 키 교환 방식은 더 이상 지원하지 않음 (Diffie-Hellman 방식이 더 일반적). 이는 RSA의 알려진 취약점 때문입니다
*   TLS 1.3은 0-RTT 재연결 기능을 제공하여 이전에 방문한 사이트에 더 빠르게 연결할 수 있습니다

### 25.5 **Diffie-Hellman 키 교환**

*   공개 키를 네트워크로 전송하지 않고도 공유 세션 키를 도출하는 고급 수학적 방법 사용
*   이산 로그 문제의 난해성에 기반하여 안전성을 보장하며, Perfect Forward Secrecy(PFS)를 제공하여 서버의 개인 키가 노출되더라도 과거 통신 내용을 보호합니다

### 25.6 **결론**
- HTTPS는 TLS Handshake를 통해 안전한 세션 키를 공유하고, 대칭 암호화를 사용하여 데이터를 암호화하여 안전한 통신을 제공합니다. 이는 인터넷 뱅킹, 온라인 쇼핑 등 민감한 정보를 다루는 모든 웹사이트에서 필수적인 보안 요소가 되었습니다.

## 26. 프로세스와 스레드의 차이점
- 출처: [FANG Interview Question \| Process vs Thread](https://www.youtube.com/watch?v=4rLW7zg21gI)

### **26.1 프로그램, 프로세스, 스레드 개념**

*   **프로그램:** 
    - 실행 가능한 파일 (코드, 명령어 집합)로, 하드디스크와 같은 저장 매체에 저장된 정적인 상태의 응용 소프트웨어입니다. 예를 들어, 워드 프로세서나 웹 브라우저의 실행 파일이 프로그램에 해당합니다.
*   **프로세스:** 
    - 프로그램이 메모리에 로드되어 실행되는 상태 (운영체제가 관리하는 자원 포함)로, 동적인 실행 인스턴스입니다. 프로세스는 독립적인 메모리 공간, 파일 핸들, 기타 시스템 자원을 할당받아 관리합니다. 하나의 프로그램(예: 크롬 브라우저)은 여러 개의 프로세스로 실행될 수 있습니다.
*   **스레드:** 
    - 프로세스 내에서 실행되는 단위 (프로세스는 최소 1개의 스레드(메인 스레드)를 가짐)로, CPU 실행의 가장 기본 단위입니다. 스레드는 프로세스의 자원을 공유하면서 병렬적으로 작업을 수행할 수 있게 해줍니다. 예를 들어, 워드 프로세서에서 문서 편집과 동시에 맞춤법 검사를 하는 것은 별도의 스레드로 처리될 수 있습니다.

### **26.2 주요 차이점 비교**

| 특징           | 프로세스                                   | 스레드                                      |
| -------------- | ------------------------------------------ | ------------------------------------------ |
| 메모리 주소 공간 | 독립적인 메모리 주소 공간을 가짐 (코드, 데이터, 힙 영역 별도) | 프로세스 내에서 메모리 주소 공간을 공유 (힙 영역 공유, 스택 영역만 독립적) |
| 독립성         | 한 프로세스의 오류가 다른 프로세스에 영향 X (운영체제 수준에서 격리됨) | 한 스레드의 오류가 전체 프로세스에 영향 O (같은 프로세스 내 모든 스레드가 영향 받음) |
| 자원 공유        | 프로세스 간 자원 공유 어려움 (IPC 메커니즘 필요: 파이프, 소켓, 공유 메모리 등) | 프로세스 내 스레드 간 자원 공유 용이 (전역 변수, 힙 메모리 등을 직접 접근 가능) |
| 생성/종료 비용 | 생성과 종료에 많은 시스템 리소스 필요 | 프로세스보다 생성과 종료가 빠르고 가벼움 (10배 이상 차이) |

### **26.3 스레드의 특징**

*   각 스레드는 고유한 스택을 가짐 (지역 변수, 함수 호출 정보 등을 독립적으로 관리)
*   레지스터, 프로그램 카운터, 스택 포인터 등은 스레드에 속함 (이를 스레드 로컬 스토리지, TLS라고도 함)
*   스레드 간 통신은 공유 메모리 공간을 통해 가능 (전역 변수나 힙 영역의 데이터를 통해 직접 통신)
*   각 스레드는 독립적인 실행 흐름을 가지지만, 동일한 프로세스 내의 코드와 데이터에 접근 가능
*   멀티 스레드 환경에서는 동기화 문제(경쟁 상태, 데드락 등)를 고려해야 함

### **26.4 컨텍스트 스위칭 (Context Switching)**

*   CPU에서 실행 중인 프로세스/스레드를 교체하는 작업으로, 현재 상태를 저장하고 다른 작업의 상태를 복원하는 과정
*   프로세스 간 컨텍스트 스위칭이 스레드 간 컨텍스트 스위칭보다 일반적으로 비용이 많이 듦 (메모리 페이지 교체 등의 작업 때문)
*   프로세스 컨텍스트 스위칭은 메모리 매핑 테이블, 캐시 플러시 등의 추가 작업이 필요하여 약 5-20배 더 비용이 큼
*   운영체제의 스케줄러는 컨텍스트 스위칭을 관리하며, 선점형(preemptive) 또는 협력적(cooperative) 방식으로 작동

### **26.5 컨텍스트 스위칭 비용 절감**

*   파이버, 코루틴 등의 메커니즘 활용 (복잡도 증가, 협력적 스케줄링 방식)
*   애플리케이션 자체에서 작업 스케줄링을 관리하며, 장시간 작업은 주기적으로 양보(yield)해야 함
*   스레드 풀을 사용하여 스레드 생성/소멸 비용 최소화 (Java의 ExecutorService, .NET의 ThreadPool 등)
*   비동기 프로그래밍 모델 적용 (Node.js의 이벤트 루프, Python의 asyncio 등)을 통해 소수의 스레드로 다수의 작업 처리
*   락-프리(lock-free) 알고리즘이나 CAS(Compare-And-Swap) 연산을 활용한 동기화 비용 절감

## 27. 인터넷 데이터 전송 방식
- 출처: [What is OSI Model \| Real World Examples](https://www.youtube.com/watch?v=0y6FtKsg6J4)

### **27.1 OSI 모델**

*   네트워크 통신을 7개의 추상화 계층으로 나눈 이론적 프레임워크.  
    - 각 계층은 상호 독립적으로 동작하며, 복잡한 통신 과정을 논리적으로 분리하여 이해 및 설계가 용이하도록 함.
*   각 계층은 특정 역할을 담당:
    *   **물리 계층:** 물리적 연결을 통해 raw bit 전송.  
        - 케이블, 커넥터, 전기 신호 등 하드웨어적인 부분을 다루며, 0과 1의 신호를 전기적 또는 광학적으로 송수신.
    *   **데이터 링크 계층:** raw bit을 프레임으로 구성하고, 정확한 목적지로 전달 (이더넷).  
        - 오류 검출, 흐름 제어, MAC 주소 기반의 장치 식별 기능을 포함. 스위치가 이 계층에서 동작함.
    *   **네트워크 계층:** 데이터 프레임을 다른 네트워크로 라우팅 (IP).  
        - 패킷 단위의 전송을 담당하며, 라우터가 이 계층에서 IP 주소를 기반으로 경로를 결정.
    *   **전송 계층:** 두 노드 간의 종단 간 통신 관리 (TCP, UDP).  
        - 데이터 흐름을 관리하고, 연결 설정/해제 및 오류 복구 등을 담당. TCP는 신뢰성, UDP는 속도에 중점.
    *   **세션/표현/응용 계층:** 실제로는 하나의 응용 계층으로 통합되어 사용 (HTTP).  
        - 사용자가 인식하는 최상위 계층으로, 데이터 형식 변환(표현), 연결 유지(세션), 실제 애플리케이션 서비스(응용)를 담당.

### **27.2 TCP/IP**

*   OSI 모델의 네트워크 및 전송 계층에서 중요한 역할 수행.  
    - 실질적으로 인터넷에서 사용하는 프로토콜 스택이며, OSI 모델보다 간결하게 구성됨.
*   **TCP:** 신뢰성 있는 종단 간 통신 제공.  
    *   데이터를 세그먼트로 나누어 전송하고, 각 세그먼트에 순서 번호를 부여.  
        - 데이터 손실이나 순서 뒤바뀜이 발생해도 정확히 재조립 가능.
    *   수신측에서 순서 번호를 사용하여 데이터를 재조립하고, 오류 검사 수행.  
        - 전송 실패 시 재전송 요청(ACK, 재전송 메커니즘)을 통해 신뢰성 확보.
*   **UDP:** TCP보다 간단하고 빠른 프로토콜.  
    *   오류 검사 및 재전송 기능이 없어 신뢰성은 떨어지지만, 속도가 중요할 때 사용.  
        - 실시간 통신(영상 스트리밍, 온라인 게임 등)에 자주 사용되며, 오버헤드가 적음.

### **27.3 데이터 전송 과정 (HTTP 요청 예시)**

1.  **응용 계층:** HTTP 헤더 추가.  
    - 브라우저나 서버 등 애플리케이션이 처리하는 영역으로, 요청 URL, 메서드(GET/POST), 쿠키 정보 등이 포함됨.
2.  **전송 계층:** TCP 헤더 추가 (출발지/목적지 포트, 순서 번호 포함). TCP 세그먼트 생성.  
    - 포트를 통해 어떤 애플리케이션과 통신할지를 구분하며, 신뢰성 있는 데이터 흐름을 위해 세그먼트화함.
3.  **네트워크 계층:** IP 헤더 추가 (출발지/목적지 IP 주소 포함).  
    - 라우팅 경로를 결정하는 핵심 정보로, 송수신 호스트의 네트워크 주소 지정.
4.  **데이터 링크 계층:** MAC 헤더 추가 (출발지/목적지 MAC 주소 포함, 라우팅 장비의 MAC 주소).  
    - 이더넷 프레임을 완성하며, 같은 네트워크 내에서 장치 간 전송을 위해 사용. ARP 프로토콜과 함께 동작.
5.  **물리 계층:** raw bit 형태로 네트워크를 통해 전송.  
    - 실제 신호(전기, 광)로 변환되어 케이블 또는 무선 매체를 통해 전송됨.
6.  수신 측에서는 위 과정을 역순으로 수행하여 HTTP 요청을 처리.  
    - 각 계층에서 헤더를 제거하며 상위 계층으로 전달, 최종적으로 웹 서버가 HTTP 요청을 수신하여 응답 처리.

### **27.4 OSI 모델의 실용성**

*   실제 사용 사례와 정확히 일치하지는 않지만, 네트워킹 제품을 설명하는 데 유용한 약어 (shorthand)로 널리 사용됨.  
    - 예를 들어, 문제 해결 시 어느 계층에 문제가 있는지 파악하거나, 장비의 기능 범위를 설명할 때 유용.
*   예: 클라우드 로드 밸런서 (L4: TCP 레벨, L7: HTTP/HTTPS 레벨).  
    - L4는 연결 상태, 포트 기반의 분산처리를 의미하고, L7은 콘텐츠 기반 라우팅, 쿠키 세션 유지 등 고급 처리 가능.

## 28. CAP 정리
- 출처: [CAP Theorem Simplified](https://www.youtube.com/watch?v=BHqjEjzAicA)

### **28.1 CAP 정리란?**

*   분산 시스템에서 **일관성(Consistency), 가용성(Availability), 파티션 내성(Partition Tolerance)** 간의 상충 관계를 설명하는 개념입니다.  
    - 이 세 가지 특성은 동시에 모두 만족시키기 어려우며, 특히 네트워크 장애(파티션)가 발생했을 때는 그 중 두 가지 특성만 선택해야 한다는 제약이 있습니다.

### **28.2 각 요소의 정의**

*   **일관성 (Consistency):** 모든 노드가 데이터에 대해 동일한 뷰를 가지는 속성입니다.  
    - 즉, 어떤 노드에 요청하든 항상 같은 결과가 반환되어야 하며, 최신의 정확한 데이터를 조회할 수 있어야 합니다.  
    - 예를 들어, 하나의 노드에서 데이터를 업데이트하면, 다른 모든 노드도 즉시 그 변경 사항을 반영해야 

*   **가용성 (Availability):** 시스템이 항상 사용자 요청에 응답할 수 있는 능력입니다.  
    - 이는 일부 노드에 장애가 발생하더라도 시스템이 계속 작동하여 사용자 요청에 응답해야 함을 의미
    - 사용자는 시스템을 항상 사용할 수 있어야 하며, "서비스 불가" 상태가 최소화되어야 합니다.

*   **파티션 내성 (Partition Tolerance):** 네트워크 파티션이 발생해도 시스템이 계속 운영될 수 있는 능력
    - 네트워크 파티션은 네트워크 장애로 인해 분산 시스템의 노드들이 서로 통신할 수 없는 상황을 의미
    - 이 경우에도 시스템이 완전히 중단되지 않고 최소한의 기능이라도 유지할 수 있어야 합니다.

### **28.3 네트워크 파티션 발생 시 선택**

*   **일관성 우선:** 파티션이 해결될 때까지 시스템을 사용할 수 없게 될 수 있습니다.  
    - 즉, 일관성을 보장하기 위해 일부 요청을 차단하거나 시스템 일부를 정지시킬 수 있습니다.  
    - 사용자는 잠시 동안 서비스를 이용할 수 없지만, 데이터의 정확성은 유지됩니다.

*   **가용성 우선:** 데이터 업데이트를 허용하여 데이터 불일치가 발생할 수 있습니다.  
    - 시스템은 계속 작동하고 사용자 요청을 처리하지만, 서로 다른 노드가 서로 다른 데이터를 가질 수 있어 일관성이 깨질 수 있습니다.  
    - 이로 인해 나중에 충돌 해결 및 동기화 과정이 필요합니다.

### **28.4 활용 예시**

*   **은행 ATM:**
    *   일관성 우선: 네트워크 단절 시 입출금을 막아 잔액의 정확성을 유지하지만, 고객은 ATM을 사용하지 못합니다.  
        - 이는 데이터의 정확성과 신뢰성이 중요한 금융 시스템에서 자주 선택되는 전략입니다.
    *   가용성 우선: 네트워크 단절 시에도 입출금을 허용하지만, 잔액 불일치가 발생할 수 있습니다.  
        - 예를 들어, 고객이 두 대의 ATM에서 동시에 잔액 초과 인출을 시도하면 시스템에 모순이 발생

*   **소셜 미디어 플랫폼:**
    *   일관성 우선: 네트워크 단절 시 댓글 기능을 막아 데이터 일관성을 유지합니다.  
        - 이는 사용자 간 의견 충돌이나 혼란을 방지하기 위한 전략입니다.
    *   가용성 우선: 네트워크 단절 시에도 댓글 작성을 허용하지만, 사용자들은 서로 다른 댓글을 볼 수 있다.
        - 이 경우, 나중에 서버가 동기화되면서 댓글이 합쳐지거나 충돌이 해결됩니다.

### **28.5 CAP 정리의 유용성**

*   분산 시스템 설계 시 **고려해야 할 중요한 trade-off**에 대해 생각하게 해주는 유용한 도구입니다.  
    - 특히 네트워크 장애 상황에서 어떤 속성을 더 중요하게 여길지에 따라 시스템의 방향성을 설정
*   하지만, 실제 시스템 설계는 더 복잡한 trade-off를 고려해야 하며, CAP 정리는 **trade-off의 전체적인 그림을 제공하지 못합니다.**  
    - 예를 들어, 지연 시간, 처리량, 복구 시간 등도 중요한 고려 요소입니다.

### **28.6 CAP 정리의 한계**

*   100% 가용성 또는 100% 일관성을 가정하지만, 현실에서는 일관성 및 가용성의 정도를 신중하게 고려
    - 예를 들어, '완전한 일관성' 대신 '최종 일관성(Eventual Consistency)'을 택하는 시스템도 많습니다.
*   정상적인 운영 환경 (네트워크 장애가 없는 경우)에서의 trade-off (예: 지연 시간과 일관성 간의 trade-off)는 고려하지 않습니다.  
    - 즉, CAP 정리는 파티션이 발생한 상황에만 초점, 일상적인 상황에서의 성능 이슈는 설명하지 못함.

### **28.7 대안: PACELC 정리**

*   정상적인 운영 환경에서의 trade-off를 다루는 PACELC 정리가 있습니다.  
    - PACELC는 "If there is a Partition (P), then choose between Availability (A) and Consistency (C), **Else**, choose between Latency (L) and Consistency (C)"라는 뜻으로, CAP보다 더 현실적인 시스템 설계 분석 프레임워크로 활용됩니다.


## 29. Kubernetes
- 출처: [Kubernetes Explained in 6 Minutes \| k8s Architecture](https://www.youtube.com/watch?v=TlHvYWVUZyc)


### **29.1 Kubernetes란?**

*   오픈 소스 컨테이너 오케스트레이션 플랫폼  
    - 여러 컨테이너를 체계적으로 관리하고 운영할 수 있도록 돕는 도구  
*   컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화  
    - 사람이 직접 하지 않아도 자동으로 애플리케이션을 배포하거나 확장하고, 상태를 유지

### **29.2 K8s라고 불리는 이유?**

*   "Kubernetes"에서 첫 글자 "k"와 마지막 글자 "s" 사이에 8개의 글자가 있기 때문에 축약해서 사용  
    - 개발자 커뮤니티에서 자주 사용되는 네이밍 방식이며, 간결하게 표현 가능

### **29.3 Kubernetes 클러스터**

*   컨테이너화된 애플리케이션을 실행하는 노드(머신)들의 집합  
    - 클러스터는 물리 또는 가상 머신 여러 대로 구성되며, 중앙에서 통합 관리  
*   **Control Plane**: 
    - 클러스터의 상태를 관리 (API 서버, etcd, 스케줄러, 컨트롤러 매니저)  
    - 클러스터 전체의 “두뇌” 역할을 하며, 모든 작업과 상태 변경을 결정하고 조율  
*   **Worker Nodes**: 
    - 컨테이너화된 애플리케이션 워크로드를 실행  
    - 실제로 사용자의 앱이 작동하는 서버들  
    *   **Pod**: Kubernetes에서 가장 작은 배포 단위, 하나 이상의 컨테이너를 호스팅하고 스토리지 및 네트워크 공유  
        - Pod는 동일한 목적의 컨테이너들을 함께 묶고, 내부 통신이 빠르며 동일한 네트워크 공간을 공유

### **29.4 Control Plane 핵심 구성 요소**

*   **API Server**: 
    - 클러스터와의 주요 인터페이스, RESTful API를 통해 클러스터 관리 요청 처리  
    - 사용자나 도구가 클러스터와 상호작용하는 창구 역할  
*   **etcd**: 
    - 분산 키-값 저장소, 클러스터의 지속적인 상태 저장  
    - 클러스터 설정, 배포 현황, 상태 정보 등을 저장하며 백업과 복구의 핵심  
*   **Scheduler**: 
    - Pod를 worker 노드에 스케줄링  
    - 현재 리소스를 고려해 최적의 위치에 Pod를 배치하는 결정자  
*   **Controller Manager**: 
    - 클러스터의 상태를 관리하는 컨트롤러 실행 (ex: replication controller, deployment controller)  
    - 설정한 "원하는 상태"와 실제 상태를 비교하여 자동으로 차이를 조정

### **29.5 Worker Node 핵심 구성 요소**

*   **Kubelet**: 
    - Control Plane과 통신, 노드에서 실행할 Pod에 대한 지시 수신 및 원하는 상태 유지  
    - 명령을 받아 Pod를 생성하고 상태를 주기적으로 보고  
*   **Container Runtime**: 
    - 컨테이너 이미지 풀링, 컨테이너 시작/중지 및 리소스 관리  
    - Docker, containerd 등과 같은 실제 컨테이너 실행 엔진  
*   **Kube-proxy**: 
    - 네트워크 프록시, 트래픽을 올바른 Pod로 라우팅, 로드 밸런싱 제공  
    - 외부에서 들어오는 요청을 적절한 내부 Pod로 전달하며, 네트워크 연결 유지

### **29.6 Kubernetes 사용 시 장단점**

*   **장점:**
    *   **확장성 및 고가용성:** 자동 롤백, 수평적 확장 기능 제공, 수요 변화에 빠르게 대응  
        - 시스템에 부하가 증가해도 자동으로 인스턴스를 늘리거나 줄임  
    *   **이식성:** 인프라에 관계없이 일관된 방식으로 애플리케이션 배포 및 관리, 온프레미스, 퍼블릭 클라우드, 하이브리드 환경에서 실행 가능  
        - 벤더 종속 없이 다양한 환경에서 동일한 방식으로 운영 가능  
*   **단점:**
    *   **복잡성:** 설정 및 운영이 복잡, 높은 수준의 전문 지식 및 리소스 필요  
        - YAML 파일, 네트워크 정책, 보안 설정 등 진입장벽이 있음  
    *   **비용:** 특정 최소 수준의 리소스 필요, 소규모 조직에는 과도할 수 있음  
        - 클러스터 자체가 리소스를 요구하며, 오버헤드가 발생할 수 있음

### **29.7 대안**

*   **Managed Kubernetes Service:** 
    - 클라우드 제공업체(Amazon EKS, GKE, AKS)에서 Control Plane 관리를 대행, 인프라 걱정 없이 애플리케이션 실행 가능, 중간 규모 조직에 적합  
    - 운영 복잡성을 줄이고, 빠르게 시작할 수 있는 옵션  
*   **소규모 조직:** 
    - "YAGNI (You Ain't Gonna Need It)" 원칙에 따라 Kubernetes 사용을 재고  
    - 지나치게 무거운 솔루션을 피하고, 단순한 구조로도 충분한 경우를 고려


## 30. CI/CD
- 출처: [CI/CD In 5 Minutes \| Is It Worth The Hassle: Crash Course System Design #2](https://www.youtube.com/watch?v=42UP1fxi2SY)

### **30.1 CI/CD란?**

*   Continuous Integration (CI)와 Continuous Delivery (CD)의 조합으로, 소프트웨어 개발 프로세스를 자동화하여 코드 커밋부터 배포까지의 과정을 효율적으로 관리한다.  
    - 예를 들어, 개발자가 코드를 GitHub에 push하면 자동으로 테스트가 실행되고, 이후 별도의 수동 작업 없이 프로덕션 서버에 배포될 수 있다.
*   수동 개입을 최소화하여 더 빠르고 안정적인 배포를 가능하게 한다.  
    - 사람이 개입하지 않기 때문에 실수 확률이 줄고, 반복적인 작업에서 오는 시간 낭비도 줄어든다.

### **30.2 CI (Continuous Integration)**

*   **정의:** 자동화를 통해 팀원들이 코드를 공유 저장소에 자주 통합하는 방식.  
    - 하루에도 여러 번 커밋하며, 충돌을 조기에 발견하고 해결할 수 있다.
*   **프로세스:** 코드 커밋 시 CI 서버에서 자동화된 워크플로우가 실행되어 코드의 안전성을 검증한다.  
    - 일반적으로 테스트 실행, 코드 스타일 검사, 빌드 여부 확인 등의 과정을 포함한다.
*   **핵심:** 충분한 테스트 커버리지를 갖춘 테스트 세트 유지 (품질과 개발 생산성 간의 균형 필요).  
    - 테스트가 너무 많으면 개발 속도가 느려지고, 너무 적으면 버그가 배포된다. 적절한 균형이 중요하다.
*   **주요 도구:**
    *   **소스 코드 관리:** GitHub 
        - 코드 버전 관리 및 협업을 위한 플랫폼.
    *   **CI 관리:** 
        - GitHub Actions, Buildkite, Jenkins, CircleCI, TravisCI 
        - 커밋 시 자동 워크플로우를 실행하는 도구들.
    *   **테스트 도구:**    
        - Jest (JS 유닛 테스트), Playwright, Cypress (웹 애플리케이션 통합 테스트) 
        - 각각의 테스트 레벨에 따라 선택적으로 사용.
    *   **빌드 도구:** Gradle (Java), Webpack (JS) 
        - 코드 실행 파일 또는 번들 생성에 사용됨.

### **30.3 CD (Continuous Delivery/Deployment)**

*   **정의:** CI를 통해 통합된 코드를 자동으로 배포하는 방식.  
    - Continuous Delivery는 테스트까지 완료된 코드를 *자동으로 릴리스 가능한 상태로* 유지하며, Continuous Deployment는 *실제로 자동 배포까지* 수행한다.
*   **구현의 어려움:** 
    - 실제 Continuous Deployment는 구현이 어렵고, 주로 stateless 시스템(API, 웹 서버 등)에 적용
    - 상태 정보(state)를 유지하지 않는 서비스일수록 롤백이나 재배포가 쉬워 자동화가 용이하다.
*   **리스크 관리:**
    *   **Feature Flags:** 
        - 새로운 기능을 코드 배포와 별도로 활성화/비활성화하여 문제 발생 시 빠르게 대처.  
        - 예: 사용자의 10%에게만 기능을 노출하거나, 문제가 생기면 즉시 끌 수 있음.
    *   **Canary Deployment:** 
        - 소규모 사용자 그룹에게 먼저 배포하여 실제 환경에서 테스트하고 문제점을 파악.  
        - 문제 발견 시 전체 배포를 중단하고 롤백 가능.
*   **복잡한 시스템:** 데이터베이스 백엔드, WebSocket 클러스터와 같은 stateful 시스템은 완전 자동 배포가 어려워 수동 배포 및 플랫폼 팀의 관리가 필요하다.  
    - 데이터 일관성, 연결 유지 등 상태를 관리해야 하기 때문에 단순 자동화로는 문제가 발생할 수 있음.
*   **주요 도구:**
    *   GitHub Actions, Buildkite, Jenkins (CI 도구와 동일) 
        - 배포 파이프라인도 이 도구들로 설정 가능.
    *   ArgoCD (Kubernetes 환경) 
        - 선언적 방식으로 Kubernetes 리소스를 Git 기반으로 자동 배포 가능.

### **30.4 CI/CD 도입의 가치**

*   **장점:** 더 나은 품질의 소프트웨어를 더 빠르게 배포 가능.  
    - 에러율 감소, 릴리즈 주기 단축, 팀 생산성 향상 등의 효과를 기대할 수 있다.
*   **고려 사항:** 시스템의 복잡성에 따라 구현 방법이 달라지며, 모든 상황에 맞는 만능 해결책은 아니다.  
    - 스타트업처럼 단순한 구조에선 빠르게 도입할 수 있지만, 레거시 시스템이나 대규모 모놀리식 아키텍처에선 신중한 접근이 필요하다.

