---
title: 9차시 3:Omnibus 3
layout: single
classes: wide
categories:
  - Utility
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. **AI 엔지니어링의 정의 및 발전**

* **기본 모델(Foundation Models)이란?** 거대하고 다양한 데이터로 미리 학습되어 여러 작업에 활용할 수 있는 AI 모델입니다. 예를 들어, 우리가 사용하는 챗GPT(GPT-4), 구글의 제미나이(Gemini) 같은 것들이죠. AI 엔지니어는 이 거대한 '기성품' 모델을 가져와서 우리 회사의 특정 목적에 맞게 '응용 프로그램'을 만드는 일을 합니다.

* **자가 지도 학습(Self-supervision):** 마치 아이가 책을 읽을 때 단어의 일부가 가려져 있어도 문맥을 통해 단어를 맞히는 것처럼, AI가 스스로 데이터의 일부를 예측하며 학습하는 방식입니다. 덕분에 사람이 일일이 데이터를 정리할 필요가 없어졌죠.

### **1.1 기본 모델(Foundation Models)**

* **Transformer 아키텍처와 어텐션 메커니즘:** 복잡한 개념이지만, 쉽게 말해 '가장 중요한 정보에 집중하는 기술'이라고 생각하면 됩니다. 사람이 대화할 때 문맥상 중요한 단어에 집중하는 것처럼, AI도 이 기술을 활용해 입력된 단어들 중 중요한 단어에 더 많은 '주의(attention)'를 기울여 정확도를 높입니다.

* **Chinchilla 스케일링 법칙:** '더 좋은 모델을 만들려면 얼마나 큰 모델과 얼마나 많은 데이터를 사용해야 하는가'에 대한 연구 결과입니다. 무작정 모델만 키우거나 데이터만 늘리는 게 아니라, 이 둘의 균형을 맞춰야 가장 효율적인 모델을 만들 수 있다는 것을 알려줍니다.

* **훈련 후 단계(post-training):** 모델을 처음 학습시킨 후, 더 유용하고 안전하게 만들기 위한 '마무리 작업'입니다. 예를 들어, 챗봇이 무해하고 유익한 대답을 하도록 사용자들의 피드백을 반영하는 과정이 여기에 포함됩니다.

* **샘플링 기법:** 모델의 답변이 항상 똑같지 않고 다양하게 나오도록 조절하는 방법입니다. **온도(Temperature)**는 높을수록 더 창의적이고 예측 불가능한 답변을, 낮을수록 정해진 답변을 내놓도록 합니다.

### **1.2 평가 (Evaluation)**

* **교차 엔트로피(cross-entropy)와 퍼플렉시티(perplexity):** 모델이 '다음 단어'를 얼마나 정확하게 예측하는지 측정하는 지표입니다. 예를 들어, "하늘이 파랗다"라는 문장에서 '파랗다'를 예측했을 때, 모델의 예측이 확실할수록 이 값들은 낮아집니다.

* **AI 심사위원(AI Judges):** 사람이 일일이 AI 모델의 답변을 평가하는 대신, 다른 AI 모델이 대신 평가하도록 하는 방법입니다. 빠르고 비용이 저렴하지만, 평가를 하는 AI 모델 자체의 편향이 결과에 영향을 줄 수 있습니다.

### **1.3 프롬프트 엔지니어링 (Prompt Engineering)**

* **프롬프트 공격(Prompt attacks):** AI 모델을 속이거나 악용하여 의도치 않은 답변을 유도하는 행위입니다.
    * **프롬프트 주입(Prompt injection):** 사용자가 악의적인 프롬프트를 넣어 모델의 원래 지시를 무시하게 만듭니다.
    * **탈옥(Jailbreaking):** 모델의 안전장치를 우회하여 모델이 원래는 해서는 안 되는 답변을 하도록 유도합니다.

### **1.4 검색 증강 생성 (Retrieval Augmented Generation, RAG)**

* **RAG란?** AI 모델이 인터넷이나 데이터베이스 같은 '외부 지식'을 활용해 답변을 만드는 기술입니다. 마치 학생이 교과서나 참고 자료를 보면서 문제를 푸는 것과 같습니다.
    * **리트리버(retriever):** 외부 자료 중에서 질문과 관련된 정보를 찾는 역할을 합니다.
    * **생성기(generator):** 리트리버가 찾은 정보를 바탕으로 최종 답변을 만듭니다.

### **1.5 에이전트 (Agents)**

* **에이전트란?** 사람의 지시를 받아 스스로 생각하고 행동하는 AI 시스템입니다. 예를 들어, '오늘 날씨 확인하고, 약속 장소 근처 맛집 예약해 줘'라고 하면, 날씨 API를 호출하고, 식당 예약 웹사이트에 접속해 예약을 완료하는 것과 같은 일을 해냅니다.

### **1.6 미세 조정 (Fine-tuning)**

* **미세 조정(Fine-tuning)과 RAG의 차이:**
    * **미세 조정:** 모델의 '행동 방식' 자체를 바꿉니다. 예를 들어, 문장을 항상 특정 형식에 맞춰 쓰게 하거나, 특정 문체를 사용하게 할 때 사용합니다.
    * **RAG:** 모델이 '새로운 정보'를 알게 합니다. 예를 들어, 최신 뉴스나 회사 내부 문서를 참고하여 답변하게 할 때 사용합니다.

* **PEFT(Parameter Efficient Fine-Tuning):** 모델 전체를 재학습시키는 대신, 일부 중요한 부분만 학습시켜 효율을 높이는 기술입니다. 마치 거대한 건물 전체를 고치는 대신, 필요한 부분만 집중적으로 수리하는 것과 같습니다. **LoRA**가 가장 대표적인 예입니다.

### **1.7 추론 최적화 (Inference Optimization)**

* **추론이란?** AI 모델이 사용자의 질문에 답하는 과정, 즉 실제로 작동하는 것을 의미합니다.
* **지연 시간(Latency)과 처리량(Throughput):**
    * **지연 시간:** 질문을 보내고 답변을 받기까지 걸리는 시간입니다. **TTFT(Time to First Token)**는 첫 단어가 나오는 데 걸리는 시간, **TPOT(Time Per Output Token)**는 이후 단어가 나오는 데 걸리는 시간을 의미합니다.
    * **처리량:** 정해진 시간 동안 얼마나 많은 요청을 처리할 수 있는지를 나타냅니다.

### **1.8 완전한 AI 애플리케이션 아키텍처**

* **가드레일(Guard rails):** AI 시스템이 부적절하거나 유해한 내용을 생성하지 않도록 막아주는 안전장치입니다.
* **오케스트레이터(Orchestrator):** 복잡한 AI 파이프라인을 관리하고 조율하는 도구입니다. 마치 오케스트라의 지휘자처럼, 여러 컴포넌트(RAG, 에이전트 등)가 서로 잘 협력하도록 돕습니다.
