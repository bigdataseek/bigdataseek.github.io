---
title: 48차시 1:Miscellaneous
layout: single
classes: wide
categories:
  - Miscellaneous
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. 머신 러닝의 모든 개념
- 출처: [18분 만에 머신 러닝의 모든 개념을 설명합니다!](https://www.youtube.com/watch?v=V5fF2Fr_9fo&t=3s)

### 1.1 **데이터란?**
- **데이터**: 숫자, 텍스트, 이미지, 소리 등 컴퓨터가 분석할 수 있는 정보.
- **정형 데이터**: 엑셀처럼 행과 열로 깔끔하게 정리된 데이터 (예: 나이, 성별).
- **비정형 데이터**: 자유로운 형태의 데이터 (예: 사진, 동영상, 텍스트).
- **특징(Features)**: 데이터를 설명하는 개별 정보 (예: 사람의 나이, 키, 몸무게).
- **관측치(Observations)**: 데이터의 한 줄 또는 한 개의 기록 (예: 한 사람의 정보).

### 1.2 **기계 학습과 관련 개념**
- **인공지능(AI)**: 컴퓨터가 사람처럼 생각하거나 문제를 해결하도록 만드는 기술. 기계 학습은 AI의 한 부분.
- **기계 학습(ML)**: 데이터를 보고 패턴을 찾아 예측하거나 결정을 내리는 기술 (예: 스팸 이메일 구분).
- **심층 학습(Deep Learning)**: 기계 학습의 한 종류로, 신경망을 사용해 복잡한 패턴을 학습 (예: 음성 인식).
- **데이터 과학**: 데이터를 분석해 문제를 해결하는 분야. 기계 학습, 통계 등을 사용.
- **모델**: 데이터를 학습해 예측을 만드는 수학적 도구 (예: 집값 예측 모델).
- **타겟 변수**: 모델이 예측하려는 값 (예: 집값, 스팸 여부).

### 1.3 **기계 학습의 종류**
기계 학습은 데이터를 학습하는 방식에 따라 세 가지로 나뉩니다:

1. **지도 학습(Supervised Learning)**: 정답이 포함된 데이터로 학습.
   - **분류(Classification)**: 범주를 예측 (예: 고양이/강아지 구분).
   - **회귀(Regression)**: 숫자를 예측 (예: 집값 예측).
   - **클래스 불균형**: 특정 범주 데이터가 너무 적어 모델이 편향될 수 있음.

2. **비지도 학습(Unsupervised Learning)**: 정답 없이 데이터의 패턴을 찾음.
   - **클러스터링(Clustering)**: 비슷한 데이터를 그룹화 (예: 비슷한 취향의 고객 묶기).

3. **강화 학습(Reinforcement Learning)**: 시행착오를 통해 보상을 받으며 학습 (예: 게임 플레이 로봇).


### 1.4 **모델 학습과 최적화**
- **학습(Training)**: 모델이 데이터를 보고 예측을 개선하는 과정.
- **파라미터**: 모델이 학습하며 조정하는 값 (예: 선의 기울기).
- **손실 함수**: 예측과 실제 값의 차이를 측정 (예: 예측한 집값과 실제 집값 차이).
- **최적화**: 손실을 줄이도록 파라미터를 조정 (예: 경사 하강법 사용).
- **경사 하강법**: 손실을 줄이기 위해 파라미터를 조금씩 조정하는 방법.
- **하이퍼파라미터**: 학습 전에 설정하는 값 (예: 학습 속도, 모델 복잡도).
- **모델 평가**: 모델이 얼마나 잘 예측하는지 숫자로 확인.

### 1.5 **모델 성능과 문제점**
- **에포크**: 전체 데이터를 한 번 훑는 과정.
- **학습률**: 모델이 얼마나 빠르게 학습할지 결정. 너무 크거나 작으면 문제 발생.
- **배치 크기**: 한 번에 학습하는 데이터의 양.
- **일반화**: 새로운 데이터에서도 잘 예측하는 능력.
- **과적합(Overfitting)**: 학습 데이터에 너무 맞춰져 새로운 데이터에서 성능이 떨어짐.
- **과소적합(Underfitting)**: 너무 단순해서 데이터 패턴을 못 찾음.
- **편향-분산 트레이드오프**: 모델이 너무 단순하거나 복잡하지 않도록 균형을 맞추는 것.


### 1.6 **데이터 준비와 검증**
- **훈련-검증-테스트 분할**:
  - **훈련 세트**: 모델 학습에 사용.
  - **검증 세트**: 모델 조정에 사용.
  - **테스트 세트**: 최종 성능 평가에 사용.
- **데이터 섞기**: 데이터를 무작위로 섞어 대표성을 높임.
- **추론**: 학습된 모델로 새로운 데이터 예측.
- **조기 종료**: 과적합 방지를 위해 학습을 일찍 멈춤.
- **정규화**: 모델이 너무 복잡해지지 않도록 제한.
- **데이터 누수**: 테스트 데이터가 학습에 실수로 포함되는 문제.


### 1.7 **데이터 전처리와 특징 공학**
- **데이터 인코딩**: 텍스트나 범주 데이터를 숫자로 변환.
  - **원-핫 인코딩**: 순서 없는 범주에 사용 (예: 색상: 빨강, 파랑).
  - **순서형 인코딩**: 순서 있는 범주에 사용 (예: 크기: 소, 중, 대).
- **이상치**: 다른 데이터와 많이 다른 값 (예: 나이가 999세).
- **결측 데이터**: 누락된 데이터.
- **특징 스케일링**: 숫자 데이터를 비슷한 범위로 조정 (예: 나이와 소득을 비슷한 스케일로).
- **차원의 저주**: 특징이 너무 많아 학습이 어려워지는 문제.
- **차원 축소**: 특징 수를 줄여 학습 효율성을 높임.
- **특징 공학**: 모델 성능을 높이기 위해 새로운 특징을 만들거나 수정.
- **데이터 증강**: 데이터를 변형해 더 많은 데이터를 만듦 (예: 이미지 회전).
- **앙상블 학습**: 여러 모델을 합쳐 더 나은 예측을 만듦.

### 1.8 요약
기계 학습은 데이터를 통해 컴퓨터가 학습해 문제를 해결하는 기술입니다. 데이터를 준비하고(전처리), 적절한 학습 방식(지도/비지도/강화)을 선택해 모델을 만들고, 성능을 평가하며 최적화합니다. 과적합, 과소적합, 데이터 누수 같은 문제를 피하고, 특징 공학과 데이터 증강으로 성능을 높입니다. 이 모든 과정은 데이터를 이해하고, 모델을 잘 설계하며, 최적의 예측을 목표로 합니다.
