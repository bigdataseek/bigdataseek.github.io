---
title: 24차시 1:IBM TECH(Kubernetes Essentials)
layout: single
classes: wide
categories:
  - Kubernetes Essentials
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. Docker vs. Kubernetes
- 출처: [쿠버네티스 vs. 도커](https://www.youtube.com/watch?v=2vMEQ5zs1ko&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN)


### **1.1 흔한 오해**

*   Docker와 Kubernetes 중 하나만 선택해야 한다는 오해가 있음.  
    * 많은 개발자와 기업들이 Docker와 Kubernetes를 경쟁 관계로 오해하지만, 이 둘은 서로 다른 목적과 기능을 제공합니다. 
    * Docker는 애플리케이션 컨테이너화를 위한 도구이고, Kubernetes는 그 컨테이너를 대규모로 관리하기 위한 플랫폼입니다.  
*   **사실:** Kubernetes는 기존 Docker 컨테이너와 워크로드를 활용하여 확장 시 발생하는 복잡성 문제를 해결
    * 예를 들어, Docker로 만든 컨테이너를 Kubernetes에 통합하면, 컨테이너의 배포, 확장, 장애 복구 등을 자동화할 수 있어 수작업으로 관리할 때보다 훨씬 효율적입니다.

### **1.2 Docker를 이용한 애플리케이션 배포**

*   **예시 애플리케이션:** React (Frontend), Node.js, Java (DB Access), Python/Flask (API)  
    * 이처럼 다양한 기술 스택으로 구성된 애플리케이션은 각각의 환경 설정과 종속성을 컨테이너로 묶어 일관성 있게 배포할 수 있습니다. 
    * 예를 들어, React는 프론트엔드 UI를, Python/Flask는 백엔드 API를 담당하며, 이들을 Docker로 개별 컨테이너화합니다.  
*   **서버 스택:** Hardware, OS (Ubuntu), Docker Daemon  
    * 하드웨어 위에 Ubuntu와 같은 운영체제가 설치되고, 그 위에서 Docker Daemon이 컨테이너를 실행
    * Docker Daemon은 컨테이너의 생성, 실행, 종료 등 모든 생명주기를 관리하는 핵심 엔진입니다.  
*   Docker build, Docker push (Registry),SSH, Docker run/Compose 사용하여 컨테이너 배포 및 확장.  
    * 개발자는 먼저 `Docker build`로 컨테이너 이미지를 생성하고, 이를 Docker Hub와 같은 레지스트리에 `Docker push`로 업로드합니다. 
    * 이후 서버에 SSH로 접속해 `Docker run`으로 컨테이너를 실행하거나, 여러 컨테이너를 조율하기 위해 `Docker Compose`를 사용할 수 있습니다.

### **1.3 Docker 사용 시 확장(Scaling)의 어려움**

*   애플리케이션 로드 증가 시, 단순 서버 증설 방식은 한계에 부딪힘.  
    * 트래픽이 늘어날 때 서버를 추가로 띄우는 방식은 비용과 시간이 많이 들 뿐만 아니라, 서버 간의 부하 분산이나 장애 처리가 수동으로 이루어져 비효율적입니다.  
*   새로운 마이크로서비스 추가 시 통합 문제 발생.  
    * 예를 들어, 새로운 기능을 추가하기 위해 마이크로서비스를 도입하면, 기존 시스템과의 네트워크 연결이나 설정 조정이 복잡해질 수 있습니다. Docker만으로는 이를 쉽게 해결하기 어렵습니다.  
*   마이크로서비스 아키텍처의 장점인 개별 컴포넌트 확장이 어려움.  
    * 마이크로서비스는 각 컴포넌트가 독립적으로 확장 가능해야 하지만, Docker만 사용할 경우 이를 수작업으로 관리해야 하므로 시간이 오래 걸리고 실수 위험이 커집니다.

### **1.4 Kubernetes를 이용한 오케스트레이션**

*   Kubernetes는 기존 Docker 컨테이너를 활용하면서 서버 자원을 효율적으로 관리하고 오케스트레이션함.  
    * Kubernetes는 Docker 컨테이너를 기본 단위로 사용하며, 이를 클러스터라는 서버 집합에 배치하고 필요에 따라 자원을 동적으로 할당합니다. 이를 통해 서버 사용 효율성을 극대화합니다.  
*   **Kubernetes 구성 요소:** Worker Node (서버), Master Node (전체 관리)  
    * Worker Node는 실제 컨테이너가 실행되는 개별 서버이고, Master Node는 클러스터 전체를 관리하며 배포 계획, 상태 모니터링, 장애 복구 등을 담당합니다.

### **1.5 Kubernetes의 주요 장점**

*   **배포 (Deployment):**  
    *   애플리케이션의 인스턴스 수, 리소스 제한, 재시작 정책 등을 정의하는 Kubernetes Deployment를 통해 배포를 자동화하고 관리.  
        * 예를 들어, 트래픽이 많을 때 인스턴스 수를 5개로 늘리거나, CPU 사용량을 제한해 자원을 효율적으로 사용하도록 설정할 수 있습니다.  
    *   Deployment는 애플리케이션과 함께 생존하며, 문제가 발생하면 자동으로 복구.  
        * 컨테이너가 비정상 종료되면, Kubernetes가 이를 감지하고 자동으로 새로운 컨테이너를 띄워 서비스 중단을 최소화합니다.  
*   **개발 (Development):**  
    *   Kubernetes는 각 마이크로서비스에 대한 로드 밸런서를 배포하고, 서비스 레지스트리 및 디스커버리 기능을 제공.  
        * 이를 통해 마이크로서비스 간 통신이 간편해지고, 특정 서비스에 과부하가 걸리면 로드 밸런서가 트래픽을 분산합니다.  
    *   애플리케이션들은 Kubernetes Service를 통해 서로 통신 가능 (Service A, B, C).  
        * 예를 들어, 프론트엔드(React)가 백엔드(Flask)와 통신할 때, Kubernetes Service가 안정적인 엔드포인트를 제공해 직접 IP를 관리할 필요가 없습니다.  
*   **모니터링 (Monitoring):**  
    *   CPU 로드, 로그 등 기본적인 모니터링 기능 제공.  
        * Kubernetes는 각 컨테이너의 CPU와 메모리 사용량을 실시간으로 추적하며,문제가 생기면 경고
    *   Istio와 같은 오픈 소스 도구를 활용하여 애플리케이션에 대한 심층적인 모니터링 가능.  
        * Istio는 트래픽 흐름, 지연 시간, 오류율 등을 분석해 애플리케이션 성능을 더 깊이 이해

### **1.6 결론**

*   Docker와 Kubernetes는 상호 보완적인 관계.  
    * Docker는 컨테이너를 만들고 실행하는 데 강점을, Kubernetes는 이를 대규모로 운영하고 관리하는 데 강점을 가집니다.  
*   Kubernetes는 Docker 컨테이너를 확장하고 운영 복잡성을 해결하는 데 도움을 줌.  
    * 특히 트래픽 증가나 장애 발생 시, Kubernetes가 자동으로 대응하므로 개발자가 운영에 신경 쓸 필요가 줄어듭니다.  
*   작은 애플리케이션이라도 확장 가능성을 고려한다면 Kubernetes를 사용하는 것이 좋음.  
    * 초기에는 Docker만으로 충분할 수 있지만, 미래의 성장 가능성을 고려하면 Kubernetes를 도입해 두는 것이 장기적으로 더 유리합니다.

## 2. 컨테이너 기술
- 출처: [컨테이너화 설명](https://www.youtube.com/watch?v=0qotVMX-J5s&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=2)

### **2.1 컨테이너 기술의 역사**  
- 컨테이너 기술은 애플리케이션의 배포 및 실행 환경을 표준화하고 격리하는 데 중점을 둔 가상화 기술이다.  
- 컨테이너의 개념은 1970년대 UNIX의 `chroot` 명령어에서 비롯되었으며, 이후 다양한 기술적 발전을 거쳐 현대적인 컨테이너 환경이 구축되었다.  

- **2008년**, 리눅스 커널에 **C-그룹(Control Groups, cgroups)** 이 도입되면서, 프로세스의 리소스 사용을 제한하고 격리할 수 있는 기반이 마련됨.  
- 같은 시기 등장한 **Namespace 기능**은 프로세스가 서로 격리된 환경에서 실행될 수 있도록 지원하여 컨테이너 기술의 핵심 요소가 됨.  
- **2013년 Docker 등장**: 컨테이너 기술을 더욱 단순화하고 표준화하면서 폭발적인 인기를 끌었으며, 이후 **Kubernetes**와 같은 오케스트레이션 도구와 결합되어 클라우드 네이티브 환경의 핵심 기술로 자리 잡음.  
- 현재는 **Docker, Podman, containerd, CRI-O** 등 다양한 컨테이너 런타임이 존재하며, **Kubernetes**를 중심으로 컨테이너 오케스트레이션이 표준화됨.

### **2.2 VM(Virtual Machine) 방식의 문제점**  

전통적인 가상 머신(VM) 방식은 물리 서버에서 여러 개의 운영체제(OS)를 실행하여 애플리케이션을 격리하는 방식으로, 여전히 널리 사용되지만 몇 가지 근본적인 문제점을 가진다.

- **무거운 구조**:  
  - VM은 각 애플리케이션마다 별도의 **Guest OS**를 포함해야 하므로, 이미지 크기가 커지고 실행 속도가 느려짐.  
  - 예를 들어, Node.js 애플리케이션을 VM에서 실행할 경우, 애플리케이션뿐만 아니라 Guest OS와 필요한 모든 라이브러리가 포함되므로 용량이 증가함.  

- **리소스 낭비**:  
  - 동일한 애플리케이션을 여러 VM에 배포할 경우, 각각의 VM이 독립적인 OS를 실행하기 때문에 불필요한 중복이 발생하고, 하드웨어 리소스가 비효율적으로 사용됨.  
  - 이를 통해 서버의 운영 비용이 증가하고, 확장성이 제한됨.  

- **환경 불일치 문제**:  
  - 개발 환경(로컬)과 운영 환경(프로덕션) 간의 차이로 인해, 애플리케이션 배포 후 예상치 못한 오류가 발생할 가능성이 높음.  
  - 특히 **Agile 개발 방식, DevOps, CI/CD** 환경에서는 일관된 실행 환경을 유지하는 것이 중요한데, VM 방식은 이를 어렵게 만듦.

### **2.3 컨테이너 방식의 장점**  

컨테이너 기술은 VM의 단점을 해결하면서, 효율적이고 유연한 애플리케이션 배포 방식을 제공한다.  

1. **컨테이너 생성 과정 (3단계)**
컨테이너는 기본적으로 **설정 파일(Dockerfile)** 을 기반으로, 이미지를 만들고 이를 실행하는 3단계 과정을 거친다.
    - **Manifest (설정 파일)**: 컨테이너의 동작을 정의하는 **Dockerfile** 또는 **Kubernetes manifest YAML** 파일을 작성.  
    - **Image (컨테이너 이미지)**: 설정 파일을 기반으로 컨테이너를 실행하기 위한 **Docker 이미지**(또는 OCI 이미지)를 생성.  
    - **Container (실행 환경)**: 이미지에서 실제 컨테이너를 실행하며, 애플리케이션과 필요한 라이브러리를 포함하여 독립적인 실행 환경을 제공.  

2. **VM 대비 컨테이너의 주요 장점**
- **경량성**:  
  - VM과 달리 **Guest OS가 불필요**, 애플리케이션과 필수 라이브러리만 포함돼 실행 속도가 빠름.
  - 한 서버에서 실행할 수 있는 컨테이너 수가 VM보다 훨씬 많음.  
- **리소스 효율성**:  
  - 여러 컨테이너가 **공통 OS 커널을 공유**하므로, **CPU, RAM 등의 리소스 낭비를 최소화**하고 더 많은 애플리케이션을 실행 가능.  
- **확장성(Scalability)**:  
  - 컨테이너를 **필요한 만큼 동적으로 확장/축소** 가능하여 트래픽 증가 시 빠르게 대응할 수 있음.  
  - Kubernetes 등 컨테이너 오케스트레이션 도구를 활용하면 자동 확장(Auto Scaling)이 가능.  
- **클라우드 네이티브 아키텍처 지원**:  
  - **모듈화**: 애플리케이션을 독립적인 컨테이너 단위로 나누어 **마이크로서비스 아키텍처(MSA)** 구현이 용이함.  
  - **리소스 공유**: 사용하지 않는 리소스를 다른 컨테이너에서 활용 가능하여 효율적 운영 가능.  
- **CI/CD 및 DevOps 친화적**:  
  - 컨테이너 기반 배포를 활용하면 **개발-테스트-배포 환경이 일관되게 유지**되어 배포 프로세스를 단순화할 수 있음.  
- **이식성(Portability)**:  
  - 컨테이너는 OS 및 하드웨어에 상관없이 **어디서나 동일한 방식으로 실행 가능**하므로,  
    - 로컬 개발 환경 → 클라우드 → 온프레미스 데이터센터로 손쉽게 이동 가능.  

### **2.4 컨테이너 활용 예시**  

컨테이너 기술은 다양한 애플리케이션 배포 시나리오에서 활용될 수 있으며, 대표적인 사례는 다음과 같다.  

- **Node.js 애플리케이션 컨테이너화**  
  - VM에서 실행할 때보다 **더 가볍고 빠르게 배포** 가능하며, **개발 환경과 운영 환경의 차이를 최소화**
  - 다수의 컨테이너를 실행하여 **부하 분산(Load Balancing) 및 자동 확장** 적용 가능.  

- **Python 애플리케이션 및 외부 서비스 연동**  
  - 예를 들어, 이미지 분석 API를 사용하는 Python 애플리케이션을 컨테이너로 배포하면,  
    - 추가적인 의존성 설치 없이 손쉽게 배포 가능.  
    - 컨테이너 간 네트워크 설정을 통해 외부 서비스(Cognitive API 등)와 효율적으로 연동 가능.  
  - AI/ML 모델 배포 시, 특정 환경(Python 버전, TensorFlow/PyTorch 등)에 종속되지 않고 실행

- **Kubernetes를 활용한 대규모 배포**  
  - **수천 개 이상의 컨테이너를 동적으로 관리**하며,  
  - 자동 확장(Auto Scaling), 자동 복구(Self-healing), 서비스 디스커버리(Service Discovery)제공.  
  - 클라우드 환경(AWS, GCP, Azure) 및 온프레미스 환경에서 유연하게 운영 가능.  

### **2.5 결론**  

- 컨테이너 기술은 기존의 VM 방식이 가진 단점을 보완하면서도, **경량성, 이식성, 확장성, 리소스 효율성** 등의 장점을 제공하여,  현대 소프트웨어 개발 및 배포 환경에서 필수적인 기술로 자리 잡았다.  
- 특히 **마이크로서비스 아키텍처(MSA), DevOps, CI/CD, 클라우드 네이티브 환경**을 구현하는 데 핵심적인 역할을 하고 있다.  


## 3. Kubernetes Managed Services 아키텍처 및 마이크로서비스 배포
- 출처: [Kubernetes Explained](https://www.youtube.com/watch?v=aSrqRSk43lY&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=3)


### 3.1 Kubernetes Managed Services 아키텍처 구성 요소

* **Kubernetes 마스터 (클라우드 측)**
  * API 서버: 
    - Kubernetes 클러스터의 중앙 제어 지점으로, 모든 워크로드 실행 및 관리 작업의 기반이 됩니다. 
    - 이 서버는 워크로드가 클러스터 내에서 어떻게 실행되고 관리될지를 정의하는 핵심 기능을 제공하며, 사용자 및 시스템 구성 요소로부터의 모든 요청을 처리합니다.

* **Kubernetes 워커 노드 (고객 관리 측)**
  * kubelet: 
    - 각 워커 노드에서 실행되는 에이전트로, 노드 내에서 컨테이너화된 애플리케이션이 정상적으로 실행되도록 스케줄링하고 관리합니다. 
    - kubelet은 마스터로부터 받은 지시에 따라 컨테이너 라이프사이클을 관리하며, 노드의 상태를 지속적으로 모니터링하여 마스터에게 보고합니다.

### 3.2 Kubernetes 사용 이유

* 현대적인 클라우드 네이티브 애플리케이션은 수십 또는 수백 개의 마이크로서비스로 구성될 수 있으며, Kubernetes는 이러한 복잡한 마이크로서비스 생태계를 효율적으로 관리할 수 있는 강력한 플랫폼을 제공합니다.
* Kubernetes는 마이크로서비스 간의 네트워크 통신을 자동화하고 최적화하며, 트래픽 증가에 따른 서비스 확장을 신속하게 처리할 수 있는 기능을 제공하여 애플리케이션의 성능과 가용성을 향상시킵니다.

### 3.3 마이크로서비스 배포

* **YAML**: 
    - Kubernetes에서는 YAML 형식의 선언적 구성 파일을 사용하여 API 서버로 전송되는 모든 리소스를 정의합니다. 
    - 이 방식은 인프라스트럭처를 코드로 관리하는 현대적인 DevOps 접근 방식을 지원합니다.

* **Pod**: 
  * Kubernetes에서 가장 기본적인 배포 단위로, 워커 노드에서 단일 또는 여러 관련 컨테이너를 실행하는 최소 논리 단위입니다.
  * YAML 매니페스트를 통해 Pod를 정의할 수 있으며, 컨테이너 이미지, 리소스 요구사항, 환경 변수, 레이블 등 다양한 속성을 지정할 수 있습니다.
  * `kubectl` 명령줄 도구를 사용하여 이러한 매니페스트를 API 서버로 푸시하면, 스케줄러가 적절한 워커 노드를 선택하여 Pod를 배포합니다.
  * 각 Pod는 클러스터 내에서 고유한 내부 IP 주소를 할당받아 통신할 수 있지만, 이 IP는 Pod가 재시작될 때마다 변경됩니다.

* **Deployment**: 
  * Pod의 "desired state"(원하는 상태)를 선언적으로 정의하고 관리하는 상위 수준의 추상화입니다.
  * Deployment는 지정된 수의 Pod 복제본이 항상 실행되도록 보장하며, Pod에 장애가 발생하거나 노드에 문제가 생겼을 때 자동으로 새로운 Pod를 생성합니다.
  * YAML 매니페스트에서는 Pod 템플릿, 원하는 복제본 수, 업데이트 전략, Selector 등을 정의하여 애플리케이션의 배포 방식을 제어합니다.
  * `kubectl`을 통해 Deployment 매니페스트를 API 서버로 푸시하면, Deployment 컨트롤러가 지속적으로 상태를 모니터링하고 원하는 상태를 유지하도록 관리합니다.

* **Service**: 
  * Pod 집합에 대한 안정적인 네트워크 엔드포인트를 제공하여 서비스 검색 및 통신을 용이하게 하는 추상화 계층입니다.
  * YAML을 사용하여 Service를 정의할 때는 Selector를 통해 대상 Pod를 지정하고, 포트 매핑 및 Service Type 등을 구성합니다.
  * `kubectl`을 통해 Service 매니페스트를 API 서버로 푸시하면, 지정된 Selector와 일치하는 모든 Pod에 트래픽을 분산하는 서비스가 생성됩니다.
  * 기본적으로 Service는 Cluster IP를 할당받아 클러스터 내부에서의 통신을 지원하며, 이 IP는 Pod의 생명주기와 독립적으로 유지됩니다.
  * Kubernetes의 KubeDNS 또는 CoreDNS 서비스를 통해 각 Service는 이름 기반 DNS 레코드를 자동으로 할당받아, 마이크로서비스 간에 서비스 이름만으로 상호 접근이 가능해집니다.

### 3.4 외부 접근

* 최종 사용자가 애플리케이션에 접근할 수 있도록 하기 위해, 프론트엔드 서비스의 Type을 LoadBalancer로 설정하여 클라우드 제공자의 로드 밸런서를 프로비저닝하고 외부 IP 주소를 할당받을 수 있습니다. 이를 통해 인터넷을 통한 안정적인 접근이 가능해집니다.

### 3.5 핵심 구성 요소 요약

* **Pod**: 컨테이너화된 애플리케이션의 최소 실행 단위로, 단일 또는 밀접하게 관련된 여러 컨테이너를 포함
* **Deployment**: Pod의 선언적 업데이트와 확장성을 제공하는 상위 수준 리소스로, 애플리케이션의 롤아웃 및 롤백을 관리합니다.
* **Service**: Pod 집합에 대한 안정적인 네트워크 엔드포인트를 제공하여, 동적으로 변하는 Pod 환경에서도 일관된 접근성을 보장합니다.

### 3.6 결론

* Kubernetes의 마스터 및 워커 노드 아키텍처와 함께 Pod, Deployment, Service와 같은 핵심 구성 요소를 활용함으로써, 기존의 애플리케이션 배포 방식을 넘어선 혁신적인 DevOps 워크플로우를 구현할 수 있습니다.

## 4. Helm: Kubernetes 패키지 관리자
- 출처: [Helm 란 무엇입니까?](https://www.youtube.com/watch?v=fy8SHvNZGeE&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=4)

### **4.1 Helm의 핵심 개념**

*   Kubernetes용 패키지 관리자 (차트 기반 배포 시스템)
*   복잡한 애플리케이션 스택을 "차트" 단위로 추상화하여 배포 프로세스 표준화
*   선언적 구성 관리와 템플릿 엔진의 결합으로 환경별 설정 분리 가능

### **4.2 상세 사용 시나리오 분석 (e-커머스 플랫폼 사례)**

*   프론트엔드: 
    *   Node.js 웹 애플리케이션 (Horizontal Pod Autoscaler 연동)
    *   ReplicaSet을 통한 무중단 배포 (rollingUpdate 전략)
*   백엔드:
    *   MongoDB 복제셋 구성 (3-node cluster with arbiter)
    *   PersistentVolumeClaim을 활용한 영구 스토리지 연동
*   네트워킹:
    *   NodePort 서비스 (30000-32767 포트 범위)
    *   Ingress Controller와의 연동 가능성

### **4.3 기존 Kubernetes 배포 방식의 한계**

*   Manifest 파일 관리 복잡성:
    *   환경별 YAML 파일 증식 (dev/staging/prod)
    *   리소스 간 의존성 수동 관리
*   변경 관리 문제:
    *   배포 버전 컨트롤 부재
    *   롤백 메커니즘 미비
*   팀 협업 어려움:
    *   구성 파라미터 공유 메커니즘 부족
    *   배포 아티팩트 재사용성 저하

### **4.4 Helm의 진화된 기능**

*   구조적 관리 체계:
    *   Chart.yaml: 메타데이터 관리
    *   templates/: 쿠버네티스 리소스 템플릿 디렉토리
    *   values.yaml: 기본 구성값 계층 구조
*   고급 템플릿 기능:
    *   Flow Control (if/with/range)
    *   Named Templates (partials)
    *   Sprig 함수 라이브러리 지원
*   생태계 통합:
    *   Helm Hub를 통한 공식 차트 저장소
    *   ArtifactHub 연동

### **4.5 향상된 Helm 3 아키텍처**

1.  **Client-Side 아키텍처:**
    *   Tiller 제거 (RBAC 문제 해결)
    *   Helm Library 직접 통합
2.  **보안 강화:**
    *   OCI 레지스트리 지원
    *   서명 검증 기능
3.  **성능 개선:**
    *   3-way strategic merge patch
    *   릴리스 관리 최적화

### **4.6 개선된 명령어 세트**

*   의존성 관리:
    *   `helm dependency update`
    *   `helm dependency build`
*   배포 모니터링:
    *   `helm status --show-resources`
    *   `helm get manifest`
*   릴리스 관리:
    *   `helm history --max`
    *   `helm uninstall --keep-history`

### **4.7 실무 적용 전략**

*   GitOps 워크플로우 연동:
    *   ArgoCD/Flux와의 통합
    *   Helmfile을 활용한 배포 자동화
*   멀티 클러스터 관리:
    *   values-overrides.yaml 활용
    *   Kustomize와의 하이브리드 구성
*   CI/CD 파이프라인 통합:
    *   Helm test 연동
    *   Chart Museum 연동

### **4.8 진화하는 생태계**

*   CNCF Graduated Project (2020)
*   Plugin 시스템 (helm-diff, helm-secrets)
*   Kubernetes Operator 패턴과의 융합

### **4.9 최적 실무 가이드**

1.  차트 버전 관리 전략 (SemVer 준수)
2.  values.schema.json을 활용한 구성 검증
3.  Helm lint를 통한 정적 분석
4.  Library Chart를 이용한 코드 재사용

## 5. Kubernetes vs. OpenShift 비교
- 출처: [Kubernetes와 OpenShift](https://www.youtube.com/watch?v=cTPFwXsM2po&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=5)


### **5.1 주요 내용**
- **Kubernetes:**  
  - Kubernetes는 컨테이너화된 애플리케이션의 배포, 확장, 관리를 자동화하기 위한 오픈 소스 플랫폼
  - 기본적으로 컨테이너 오케스트레이션 시스템으로 설계되었으며, 다양한 환경(클라우드, 온프레미스 등)에서 사용할 수 있습니다.  
  - Kubernetes는 "선언적 구성"이라는 개념을 기반으로 동작합니다. 
    - 즉, 사용자가 원하는 상태를 정의하면 Kubernetes가 이를 자동으로 유지하려고 합니다. 
    - 이로 인해 높은 유연성과 확장성을 제공하지만, 초기 설정과 운영이 복잡할 수 있습니다.

- **OpenShift:**  
  - OpenShift는 Red Hat에서 제공하는 쿠버네티스 기반 엔터프라이즈 플랫폼입니다. 
  - OKD(Origin Kubernetes Distribution)라는 오픈 소스 버전도 존재하며, Kubernetes 위에 추가적인 기능과 도구를 통합하여 제공합니다.  
  - OpenShift는 Kubernetes의 기능을 확장하여 DevOps 프로세스를 간소화하고, 보안 및 관리 기능을 강화했습니다. 특히, 기업 환경에서 요구되는 표준화된 워크플로우와 자동화 도구를 제공합니다.

---

### **5.2 비교 항목**

1. **1. 배포**
- **Kubernetes:**  
  - Kubernetes는 사용자가 직접 CI/CD 파이프라인을 구성해야 하며, 이를 위해 다양한 도구(GitHub Actions, Jenkins, ArgoCD 등)를 조합해야 합니다. 
  - 이 과정은 유연성을 제공하지만, 복잡하고 시간이 많이 소요될 수 있습니다.  
- **OpenShift:**  
  - OpenShift는 S2I(Source-to-Image)와 같은 내장 도구를 통해 CI/CD 파이프라인을 자동화
  - 이를 통해 개발자는 코드를 작성하고 배포하는 데 집중할 수 있으며, 복잡한 설정을 감소

2. **2. 애플리케이션 관리**
- **Kubernetes:**  
  - 기본적으로 제공되는 Kubernetes Dashboard는 기능이 제한적이며, 고급 모니터링 및 로깅 기능을 사용하려면 추가 도구를 설치해야 합니다. 
  - 이는 사용자에게 많은 선택권을 제공하지만, 적절한 솔루션을 찾기 위해 많은 조사가 필요
- **OpenShift:**  
  - OpenShift는 기본적으로 웹 콘솔과 모니터링 도구(EFK 스택, Prometheus 등)를 제공 
  - 이를 통해 운영팀은 애플리케이션 상태를 쉽게 모니터링하고 문제를 해결

3. **3. 노드 구성**
- **Kubernetes:**  
  - Kubernetes에서는 새로운 노드를 클러스터에 추가하거나 스케일링을 하기 위해 별도의 스크립트나 도구를 개발해야 합니다. 
  - 이는 유연성을 제공하지만, 초기 설정과 운영이 복잡할 수 있습니다.  
- **OpenShift:**  
  - OpenShift는 Ansible Playbook을 기반으로 한 자동화 도구를 제공하여, 새로운 노드를 쉽게 추가하고 자동 스케일링을 지원합니다. 
  - 이는 특히 대규모 클러스터를 운영할 때 유용합니다.

4. **4. 보안**
- **Kubernetes:**  
  - Kubernetes는 기본적으로 보안 기능을 제공하지만, 이를 사용하려면 사용자가 직접 설정해야
  - 이는 높은 자유도를 제공하지만, 보안 구성에 대한 전문 지식이 필요합니다.  
- **OpenShift:**  
  - OpenShift는 보안 모범 사례를 기본적으로 적용하여, 사용자가 별도의 설정 없이도 안전한 환경을 제공받을 수 있습니다. 
  - 예를 들어, 컨테이너가 root 권한으로 실행되지 않도록 제한하거나, 네임스페이스 단위로 보안 정책을 적용합니다.

### **5.3 결론**
- OpenShift는 Kubernetes를 기반으로 구축되었으며, 엔터프라이즈 환경에서 Kubernetes를 더 쉽게 사용할 수 있도록 다양한 기능을 제공합니다.
- OpenShift는 표준화된 방식을 통해 개발 및 운영을 단순화하지만, Kubernetes에 비해 유연성이 떨어질 수 있습니다.
- 개인 및 소규모 IT 팀에게는 OpenShift가 복잡한 작업을 간소화하여 유용할 수 있습니다.
- OpenShift의 기반이 되는 Kubernetes에 대한 이해가 중요합니다.
  

## 6. 컨테이너 오케스트레이션
- 출처: [컨테이너 오케스트레이션 설명](https://www.youtube.com/watch?v=kBF6Bvth0zw&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=6)

### **6.1 배경**

* **컨테이너 기술 및 Kubernetes 소개 이력:** 
    - 과거 컨테이너 기술의 등장과 함께 Kubernetes는 컨테이너 관리의 표준으로 자리 잡았습니다. 
    - 컨테이너 기술은 애플리케이션 개발 및 배포 방식을 혁신했고, Kubernetes는 이러한 컨테이너들을 효율적으로 관리하고 확장하는 데 필수적인 도구가 되었습니다.
* **컨테이너 오케스트레이션의 필요성:** 
    - 단일 컨테이너 환경에서는 문제가 없지만, 복잡한 애플리케이션을 여러 컨테이너로 나누어 관리해야 하는 마이크로서비스 아키텍처 환경에서는 컨테이너 오케스트레이션이 필수적입니다. 
    - 컨테이너 오케스트레이션은 컨테이너의 배포, 확장, 네트워킹, 모니터링 등을 자동화하여 개발 및 운영 효율성을 극대화합니다.

### **6.2 개발자의 관점**

* **집중 영역:** 개발자는 애플리케이션 스택(Frontend, Backend, Database)과 각 컨테이너 내부의 애플리케이션 로직, 운영체제, 의존성 관리에 집중합니다.
* **컨테이너 내부 요소:** 컨테이너 내부는 애플리케이션 코드, 필요한 라이브러리 및 종속성, 운영체제 환경을 포함합니다. 개발자는 이러한 요소들을 컨테이너 이미지로 패키징하여 일관된 실행 환경을 보장합니다.

### **6.3 운영팀의 관점**

* **관심사:** 운영팀은 전체 애플리케이션 스택과 이를 구성하는 컨테이너, VM/Worker Node, Master Node를 포함한 인프라 전반을 관리합니다.
* **컨테이너 오케스트레이션 플랫폼의 역할:**
    * **배포 (Deploying):** 
        - Kubernetes와 같은 컨테이너 오케스트레이션 플랫폼은 개발자가 만든 컨테이너 이미지를 VM/Worker Node에 배포하고 실행합니다.
    * **확장 (Scaling):** 
        - 트래픽 증가와 같은 상황에 따라 마이크로서비스 인스턴스 수를 자동으로 조절하여 컴퓨팅 자원을 효율적으로 사용합니다. 
        - 예를 들어, Frontend은 2배, Backend와 Database는 각각 3배로 확장하여 성능을 유지
    * **네트워킹:** 
        - 컨테이너 간의 통신과 외부 서비스 접근을 위한 네트워킹 기능을 제공합니다. 
        - 각 컨테이너를 대표하는 서비스를 생성하고, 로드 밸런싱 및 서비스 디스커버리를 자동화하여 복잡한 네트워크 구성을 단순화합니다. 
        - Frontend은 외부에, Backend/Database는 내부에 노출하여 보안성을 강화할 수 있습니다.
    * **통찰력 (Insight):** 
        - Prometheus, Istio와 같은 오픈소스 기술과 연동하여 애플리케이션 운영 상태에 대한 심층적인 통찰력을 제공합니다. 
        - Pod 장애 발생 시 자동 복구 기능을 통해 안정성을 높이고, 서비스 메시를 통해 마이크로서비스 간의 통신 흐름을 시각화하여 성능 문제나 보안 취약점을 발견할 수 있습니다. 
        - 예를 들어, Frontend -> Backend -> Database 순서의 통신에서 Frontend -> Database 직접 접근과 같은 비정상적인 통신을 감지하고, Istio, Kiali 등을 활용하여 각 서비스의 운영 상태(OPS)를 모니터링할 수 있습니다.

### **6.4 컨테이너 오케스트레이션의 중요성**

* 운영팀(SRE)의 역할 증가: 
    - 마이크로서비스 아키텍처의 복잡성이 증가함에 따라 운영팀의 역할이 더욱 중요해지고 있습니다. 
    - 컨테이너 오케스트레이션은 운영팀이 대규모 애플리케이션을 효율적으로 관리하고 안정적으로 운영하는 데 필수적인 도구입니다.
* 운영 환경의 안정성 확보: 
    - 컨테이너 오케스트레이션은 자동화된 배포, 확장, 네트워킹, 모니터링 기능을 통해 운영 환경의 안정성을 확보하고 장애 발생 시 빠른 복구를 지원합니다.

### **6.5 결론:** 
- 컨테이너 오케스트레이션은 마이크로서비스 아키텍처 환경에서 애플리케이션 개발 및 운영 효율성을 극대화하는 핵심 기술입니다. 
- 개발자와 운영팀은 컨테이너 오케스트레이션을 통해 애플리케이션의 안정성과 성능을 향상시키고, 개발 및 운영 생산성을 높일 수 있습니다.


## 7. Kubernetes Ingress
- 출처: [Kubernetes Ingress in 5 mins](https://www.youtube.com/watch?v=NPFbYpb0I7w&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=7)

### **7.1 핵심 내용**

1.  **Service란?**
    - Kubernetes에서 **Service**는 여러 Pod을 묶어 하나의 네트워크 엔드포인트처럼 동작하도록 만드는 개념입니다. 즉, Pod 간의 통신을 원활하게 하고, 클러스터 내부 또는 외부에서 접근할 수 있도록 해줌
        *   **로드 밸런싱 제공:** 여러 Pod이 동일한 서비스에 속하면 자동으로 트래픽을 분산  
        *   **YAML 파일(`service.yaml`)로 정의:** 필요한 설정을 코드로 관리 가능  
        *   **타입 (Type)에 따라 외부 접근 방식이 달라짐** (아래 설명 참고)  

2.  **Service Type 종류**
    - Kubernetes에서 Service는 **어떤 방식으로 외부에서 접근할 수 있는지**에 따라 다음과 같이 나뉨

    *   **Cluster IP (기본값)**
        *   클러스터 내부에서만 접근 가능 (내부 서비스 간 통신용)
        *   `kubectl port-forward` 명령을 사용해 로컬 머신에서 접근 가능
        *   외부에서 직접 접근할 수 없는 보안성이 높은 서비스에 적합

    *   **Node Port**
        *   클러스터 내 모든 Node의 특정 포트(예: 31000~32767)를 통해 서비스에 접근 가능
        *   각 Node의 **공인 IP 주소와 포트**를 이용해 외부에서도 접근 가능  
        *   일반적인 구조:
            ```
            <Node_IP>:<NodePort> → Service → Pod
            ```
        *   **제약 사항**
            *   서비스 당 하나의 포트만 할당 가능 (유연성이 낮음)
            *   Node의 IP 주소가 변경되면 접근 방식도 변경될 수 있음 (관리 부담 증가)

    *   **Load Balancer**
        *   클라우드 환경(AWS, GCP, Azure 등)에서 사용 가능
        *   클라우드 제공자가 자동으로 **외부 로드 밸런서 (NLB, ELB 등)** 를 생성하여 트래픽을 관리  
        *   외부 사용자는 **로드 밸런서의 공인 IP 주소**를 통해 서비스에 접근 가능  
        *   **제약 사항**
            *   서비스마다 개별적인 로드 밸런서를 생성하므로 비용 증가 가능  
            *   여러 개의 서비스가 존재할 경우 관리가 복잡해질 수 있음  

3.  **Ingress Resource란?**
    - **Ingress**는 Kubernetes에서 서비스들을 더 효율적으로 외부에 노출할 수 있도록 도와주는 리소스
    - 간단히 말해, **단일 IP 주소로 여러 서비스를 관리하고 트래픽을 특정 경로(Path)나 도메인(Domain)에 따라 라우팅할 수 있도록 해줍니다.**  

        *   `ingress.yaml` 파일로 정의 (`kind: Ingress`)
        *   **규칙 기반 라우팅:**  
            - 특정 URL 또는 도메인 요청을 올바른 서비스로 전달 (Nginx Reverse Proxy와 유사)  
            - 예: `serviceb.app.com`은 Service B로, 그 외에는 Service A로 라우팅  

        *   **동작 방식**
            1.  외부 로드 밸런서(External Load Balancer)를 생성
            2.  특정 도메인(예: `app.com`)으로 들어오는 요청을 감지
            3.  정의된 **라우팅 규칙**에 따라 올바른 서비스로 트래픽 전달  

        *   **Ingress의 주요 기능**
            *   **단일 IP 주소로 여러 서비스 라우팅 가능** → 개별적인 로드 밸런서가 필요 없음  
            *   **Path 기반 라우팅** → `/api`는 Backend 서비스로, `/web`은 Frontend 서비스로 연결 가능  
            *   **TLS (HTTPS) 지원** → 보안 강화를 위해 Let's Encrypt 등의 인증서를 적용 가능  
            *   **가상 호스트 (Virtual Hosts) 지원** → 여러 도메인을 단일 Ingress에서 관리 가능  

### **7.2 결론**
- 기본적인 Service Type은 Kubernetes 내부 또는 외부에서 개별 서비스에 접근하는 방법을 제공하지만, 여러 서비스를 효과적으로 노출하고 관리하려면 **Ingress가 필수적**입니다.  
- Ingress를 활용하면 **단일 IP 주소로 여러 서비스를 운영할 수 있고**, 추가적인 **로드 밸런서 비용을 줄일 수 있으며**, **다양한 라우팅 기능을 활용할 수 있다는 점**에서 매우 효율적인 방식입니다.

## 8. Istio 소개
- 출처: [Istio 무엇입니까?](https://www.youtube.com/watch?v=1iyFq2VaL5Y&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=8)

### **8.1 Istio란?**

*   Istio는 오픈 소스 플랫폼을 기반으로 설계된 독립적인 서비스 메시 솔루션으로, 분산 시스템에서 마이크로서비스 간의 연결성과 관리를 단순화합니다.  
*   이 플랫폼은 트래픽 관리(예: 라우팅, 분산), 정책 실행(접근 제어 및 속도 제한 등), 그리고 텔레메트리 수집(성능 모니터링 및 로그 데이터)과 같은 핵심 기능을 제공하여 운영 효율성을 높입니다.  
*   Istio는 Kubernetes, Nomad, Consul과 같은 다양한 환경에서 실행될 수 있다

### **8.2 서비스 메시란?**

*   서비스 메시는 마이크로서비스 아키텍처에서 각 서비스들이 상호작용하는 네트워크를 의미하며, 애플리케이션의 구성 요소들이 데이터를 주고받는 방식을 체계적으로 관리합니다.  
*   이는 서비스 간 통신의 규칙과 통제 영역을 정의하여, 복잡한 시스템에서도 안정성과 예측 가능성을 확보할 수 있도록 돕습니다.

### **8.3 Istio의 필요성**

*   마이크로서비스 기반 시스템이 점점 더 복잡해지면서, 서비스 간 통신을 효과적으로 제어하고 문제를 신속히 해결할 수 있는 도구가 필수적으로 요구됩니다. Istio는 이러한 요구를 충족하며 운영 복잡성을 줄이는 데 기여합니다.

### **8.4 Istio의 주요 기능**

*   **로드 밸런싱:** HTTP, TCP, WebSocket 등 다양한 프로토콜의 트래픽을 효율적으로 분산시켜 시스템 부하를 최적화합니다.  
*   **세밀한 통제:** 트래픽에 대한 사용자 정의 규칙 설정, 재시도 로직, 장애 조치(failover), 그리고 결함 주입(fault injection)을 통해 시스템의 안정성과 테스트 가능성을 높입니다.  
*   **접근 제어:** 클라우드 네이티브 애플리케이션 환경에서 보안 정책을 관리하고 실행하여, 허가되지 않은 접근을 차단합니다.  
*   **가시성:** 로깅, 메트릭, 분산 추적 그래프 등을 통해 시스템 상태를 실시간으로 모니터링하며 문제를 빠르게 진단할 수 있도록 지원합니다.

### **8.5 Istio 구성 요소**

*   **Pilot:**  
    *   Istio 서비스 메시의 두뇌 역할을 하는 핵심 구성 요소로, 트래픽 흐름을 지능적으로 관리합니다.  
    *   AB 테스팅, 카나리아 배포(소규모 사용자 그룹 대상으로 신규 기능 테스트), 타임아웃 설정 등 고급 배포 전략을 지원하여 서비스 안정성과 유연성을 보장합니다.  
*   **Citadel:**  
    *   서비스 메시 내 보안을 책임지는 요소로, 인증서 발급을 위한 CA(Certificate Authority)를 내장
    *   서비스 간 통신을 암호화하고, 여러 Kubernetes 클러스터가 상호작용하는 환경에서도 안전한 연결을 유지할 수 있도록 돕습니다.  
*   **Mixer:**  
    *   Istio의 모든 Sidecar 프록시와 연동되는 중앙 허브 역할, 시스템 전반의 데이터를 수집하고 처리
    *   수집된 텔레메트리 데이터를 Pilot으로 전달하여 모니터링 및 시각화를 가능하게 하고, 플러그인 구조를 통해 Prometheus나 Grafana 같은 타사 도구와의 통합을 지원합니다.


## 9. Kubernetes Opeators
- 출처: [Kubernetes Opeators](https://www.youtube.com/watch?v=i9V4oCa5f9I&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=9)

### **9.1 Operator Framework란?**

*   쿠버네티스(Kubernetes) 또는 OpenShift에서 복잡한 애플리케이션 관리를 용이하게 하는 프레임워크
    - Operator Framework는 쿠버네티스 환경에서 애플리케이션의 배포, 관리, 확장을 자동화하고 단순화하기 위해 설계된 도구입니다. 
    - 특히 데이터베이스, 메시지 큐 같은 상태 기반(stateful) 애플리케이션처럼 복잡한 운영 요구사항이 있는 경우에 유용합니다. 이를 통해 수작업으로 처리해야 했던 작업을 줄이고 일관된 운영 환경을 제공
*   CoreOS에서 2016년에 처음 소개 (현재는 Red Hat 및 IBM의 일부) 
    - CoreOS라는 컨테이너 중심의 운영체제 개발사가 처음 제안한 이 개념은 이후 Red Hat에 인수되며 발전했고, IBM이 Red Hat을 인수하면서 IBM Cloud의 핵심 기술 중 하나로 자리 잡았습니다. 현재는 오픈소스 커뮤니티와 기업 모두에서 널리 사용됩니다.

### **9.2 쿠버네티스 컨트롤 루프(Control Loop)**

*   쿠버네티스의 핵심 동작 방식
    - 컨트롤 루프는 쿠버네티스가 클러스터를 원하는 상태로 유지하는 기본 메커니즘으로, 시스템의 안정성과 자가 치유(self-healing)를 보장합니다.
*   **Observe (관찰):** 클러스터의 현재 상태를 확인  
    - 쿠버네티스는 주기적으로 Pod, 노드 등의 상태를 모니터링하여 현재 구성 환경 파악
*   **Diff (비교):** 원하는 상태와 실제 상태 간의 차이점을 비교 
    - 사용자가 정의한 리소스 스펙(예: Pod 수, 이미지 버전 등)과 실제 클러스터 상태 대조해 차이를 식별
*   **Act (행동):** 차이점을 해소하기 위해 필요한 조치를 수행
    - 차이가 발견되면 Pod를 생성하거나 삭제, 리소스를 재배치하는 등의 작업을 자동으로 실행하여 원하는 상태를 만듭니다.

### **9.3 Operator 미사용 시 애플리케이션 배포**

*   사용자가 YAML 파일을 직접 작성하여 애플리케이션 스펙 정의 (ex: Deployment)
    - 애플리케이션의 Pod 수, 컨테이너 이미지, 포트 설정 등을 YAML 형식으로 수동으로 작성해야.
*   Deployment를 쿠버네티스 클러스터에 배포
    - 작성한 YAML 파일을 `kubectl apply` 명령어로 클러스터에 적용하면 배포가 시작됩니다.
*   컨트롤 루프에 의해 Pod 생성
    - 쿠버네티스의 기본 컨트롤러가 YAML에 명시된 대로 Pod를 생성하고 유지합니다.
*   복잡한 애플리케이션의 경우 여러 YAML 파일을 관리해야 하며, 변경시마다 직접 수정 필요
    - 상태 기반 애플리케이션(예: MySQL)은 PVC(Persistent Volume Claim), ConfigMap 등 추가 리소스가 필요해 파일 수가 늘어나고, 버전 업그레이드나 설정 변경 시마다 모든 파일을 일일이 수정해야 하는 번거로움이 있습니다.

### **9.4 Operator 사용 시 애플리케이션 배포**

*   **Operator 설치:** 팀에서 직접 개발하거나 OperatorHub에서 기존 Operator 사용  
    - OperatorHub는 오픈소스 Operator를 제공하는 마켓플레이스로, PostgreSQL, Redis 같은 인기 애플리케이션용 Operator를 쉽게 가져올 수 있습니다.
*   **Operator Lifecycle Manager (OLM) 필요:** 설치된 Operator 관리  
    - OLM은 Operator의 설치, 업그레이드, 삭제를 관리하는 도구, 복잡한 의존성이나 버전 관리를 자동화.
*   **Operator 구성 요소:**
    *   **CRD (Custom Resource Definition):** 사용자가 정의하는 커스텀 리소스  
        - CRD는 쿠버네티스의 기본 리소스(예: Pod, Deployment)를 확장하여 애플리케이션별 요구사항(예: 데이터베이스 복제본 수)을 정의할 수 있게 합니다.
    *   **Controller:** 커스텀 컨트롤 루프를 실행하여 CRD에 따라 동작하는 Pod  
        - Operator의 컨트롤러는 CRD를 감시, 정의된 상태에 맞춰 Pod를 생성, 조정하는 로직을 실행.
*   사용자는 Operator에 대한 YAML 파일(ex: MyApp)만 작성하고 클러스터에 배포 
    - 예를 들어, MySQL Operator라면 데이터베이스 이름과 복제본 수만 지정하면 됩니다.
*   Operator가 컨트롤 루프를 관리하며 필요한 Deployment 및 Pod 생성
    - Operator가 내부적으로 필요한 리소스를 생성하고 관리하므로 사용자는 세부적인 YAML 작성을 건너뛸 수 있습니다.
*   Operator를 사용하면 최종 사용자는 노출된 구성만 관리하고, Operator가 애플리케이션 상태를 관리하므로 관리가 더 용이하고 확장성이 향상됨
    - 복잡한 업그레이드, 백업, 장애 복구 같은 작업도 Operator가 자동으로 처리해줘 운영 부담이 감소

### **9.5 Operator 개발 방법**

*   **Operator SDK:** Operator 개발 도구
    - Red Hat이 제공하는 이 SDK는 Go, Ansible, Helm 기반으로 Operator를 쉽게 만들 수 있도록 CLI와 템플릿을 제공합니다.
*   **Helm Operator:** Helm 차트를 Operator로 변환하여 사용
    - 기존 Helm 차트(패키지화된 쿠버네티스 리소스)를 활용해 빠르게 Operator를 생성할 수 있다.

### **9.6 Operator 성숙도 단계**

1.  **Basic Install:** 필요한 리소스 프로비저닝
    - 단순히 애플리케이션 설치만 지원하는 초기 단계입니다.
2.  **Upgrade:** 마이너 및 패치 버전 업그레이드 지원 (Helm 해당)  
    - 소프트웨어 버전 업데이트를 자동화하며, Helm 기반 Operator가 주로 이 수준을 충족합니다.
3.  **Full Lifecycle:** 스토리지 및 앱 라이프사이클 관리, 백업 및 복구 지원 (Go 또는 Ansible 필요)  
    - 백업, 복구, 스토리지 관리 같은 고급 기능을 포함하며, Go나 Ansible로 더 정교한 로직을 구현합니다.
4.  **Insights:** 상세 메트릭, 분석 및 로깅 제공 (Go 또는 Ansible 필요)
    - 애플리케이션 성능 모니터링과 문제 진단을 위한 데이터를 제공합니다.
5.  **Autopilot:** 자동 스케일링, 구성 튜닝 및 자동 문제 식별 (Go 또는 Ansible 필요)
    - 리소스 사용량에 따라 자동 확장하거나 문제를 사전에 감지해 수정하는 최상위 단계입니다.

### **9.7 추가 정보**

*   OperatorHub에서 다양한 Operator 확인 가능
    - PostgreSQL, Kafka 등 다양한 애플리케이션용 Operator가 공개되어 있어 필요에 맞게 선택 가능.
*   Operator SDK를 사용하여 Helm, Go 또는 Ansible로 Operator 개발 가능
    - 개발자는 자신의 기술 스택에 맞춰 Operator를 커스터마이징할 수 있습니다.

## 10. Docker vs. Podman 비교
- 출처: [Podman vs. Docker](https://www.youtube.com/watch?v=Xx588nbshlM&list=PLOspHqNVtKABAVX4azqPIu6UfsPzSu2YN&index=11)


### **10.1 Docker**

*   **정의:**  
    * 컨테이너 기술을 개척하고 대중화한 업계 표준으로, 애플리케이션 배포와 관리를 간소화하는 플랫폼.  
    * 컨테이너 기반 환경을 쉽게 구축할 수 있도록 돕는 종합적인 생태계를 제공.

*   **구성 요소:**  
    * **Dockerfile:** 컨테이너 이미지를 빌드하기 위한 설정 파일로, 애플리케이션 환경을 코드로 정의
    * **Images:** 컨테이너 실행에 필요한 모든 요소(애플리케이션 코드, 라이브러리, 종속성 등)를 포함한 불변의 패키지.  
    * **Docker Engine:** 컨테이너 실행을 담당하는 핵심 엔진으로, 백그라운드에서 동작하는 데몬 프로세스가 컨테이너를 관리.  

*   **아키텍처:**  
    * 클라이언트-서버 구조로 동작하며, 사용자가 CLI나 Docker Desktop을 통해 명령을 내리면 백그라운드에서 Docker Daemon이 이를 처리.  

*   **장점:**  
    * **컨테이너 기술의 선구자 및 업계 표준**: 가장 널리 사용되며, 다양한 기업 및 개발자 커뮤니티에서 지원.  
    * **풍부한 자료 (문서, 사용자 그룹, 가이드)** : 학습 자료가 많아 초보자도 쉽게 접근 가능.  
    * **Docker Swarm과 같은 고유 기능 제공** : 내장된 오케스트레이션 기능으로 여러 컨테이너를 관리

*   **단점:**  
    * **루트 권한으로 데몬 프로세스 실행 (보안 취약점 가능성)** : 만약 공격자가 Docker Daemon을 해킹하면 시스템 전체가 위험해질 수 있음.  
    * **루트 권한 없이는 Docker 명령어 실행 불가** : 일반 사용자가 실행하려면 추가적인 설정(rootless mode)이 필요함.  

### **10.2 Podman**

*   **정의:**  
    * 컨테이너 엔진으로서 Docker와 유사한 기능을 제공하지만, 보안을 강화한 설계.  
    * 백그라운드 데몬 없이 컨테이너를 직접 실행하는 방식으로 동작.  

*   **구성 요소:**  
    * **Images, Containers:** Docker와 동일하게 OCI(Open Container Initiative) 표준을 따름.  
    * **Pods:** Kubernetes의 개념을 차용하여 여러 개의 컨테이너를 하나의 단위로 묶어 동일한 네트워크와 볼륨을 공유할 수 있음.  

*   **아키텍처:**  
    * 데몬리스(daemonless) 방식으로 동작하며, 사용자가 명령어를 실행할 때마다 개별적으로 컨테이너를 직접 실행 및 관리.  
    * 사용자가 실행할 때 필요한 프로세스만 동작하여 보안성을 높이고 리소스 사용을 절감할 수 있음.  

*   **장점:**  
    * **데몬리스 아키텍처로 보안 강화** : 백그라운드에서 지속적으로 실행되는 데몬이 없으므로, 공격 대상이 줄어들어 보안성이 높아짐.  
    * **기본적으로 루트리스(rootless) 실행** : 컨테이너를 비특권 사용자(non-root)로 실행할 수 있어 보안 리스크 감소.  
    * **Kubernetes로의 전환 용이 (Pod 매니페스트 활용)** : Kubernetes 환경과 자연스럽게 연계 가능하여 클러스터 관리가 쉬움.  
    * **Docker와 유사한 명령어 지원** : 기존 Docker 사용자가 쉽게 적응할 수 있으며, Podman push, pull 등 대부분의 명령어가 동일.  

*   **단점:**  
    * **Docker Swarm과 같은 Docker 고유 기능 없음** : 기본적으로 Kubernetes 연계를 염두에 둔 설계로, Docker Swarm과 같은 기능이 필요하다면 대체 솔루션을 찾아야 함.  

### **10.3 공통점**

*   **OCI (Open Container Initiative) 표준 기반**
    - 두 엔진 모두 OCI 표준을 따르므로, 같은 이미지 포맷을 사용 가능.  
*   **다양한 운영체제 지원** 
    - Mac, Windows, Linux 환경에서 실행 가능 (Docker는 Docker Desktop, Podman은 Podman Desktop 또는 CLI 사용).  
*   **멀티 컨테이너 애플리케이션 지원** 
    - Docker는 Docker Compose, Podman은 Podman Compose를 통해 여러 컨테이너를 조합하여 실행 가능.  

### **10.4 선택 기준**

*   **Docker를 선택해야 하는 경우:**  
    * 컨테이너 기술을 처음 배우는 초보자.  
    * Docker Swarm을 사용하여 간단한 컨테이너 오케스트레이션을 원할 때.  
    * 기존 Docker 기반 개발 및 배포 환경을 유지해야 하는 경우.  

*   **Podman을 선택해야 하는 경우:**  
    * 데몬 프로세스가 없는 환경을 선호하는 경우.  
    * Kubernetes 기반으로 컨테이너를 운영할 계획이 있는 경우.  
    * 보안을 중요하게 생각하며, 루트리스 실행을 기본적으로 활용하고 싶은 경우.  

### **10.5 결론**  
- Docker와 Podman은 모두 강력한 컨테이너 엔진이며, 특정 사용자의 요구 사항과 우선순위에 따라 적합한 도구를 선택하는 것이 중요하다. 
- Docker는 여전히 가장 널리 사용되는 컨테이너 플랫폼이며, 풍부한 생태계와 학습 자료를 제공한다. 
- 반면, Podman은 보안성과 Kubernetes 연동 측면에서 장점을 가지며, 기업 환경에서 보안 요구사항이 높은 경우 적합한 대안이 될 수 있다.