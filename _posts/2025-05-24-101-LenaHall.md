---
title: 46차시 1:LenaHall
layout: single
classes: wide
categories:
  - LenaHall
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. Retrieval Augmented Generation (RAG) 아키텍처
- 출처:[RAG Architectures Crash Course](https://www.youtube.com/watch?v=FbGMxel0g2I&t=4s)

### 1.1 **목표**:더 정확하고 신뢰할 수 있으며 유용한 AI 애플리케이션 구축  
RAG는 대규모 언어 모델(LLM)의 생성 능력과 외부 지식 소스를 결합하여, 최신 정보에 기반한 정확하고 맥락에 맞는 응답을 제공하는 것을 목표로 합니다. 이를 통해 환각(hallucination) 문제를 줄이고, 사용자에게 신뢰할 수 있는 결과를 전달하며, 다양한 도메인에서 유용성을 극대화합니다.

### 1.2 **RAG의 이점**  
RAG는 LLM이 내부 지식에만 의존하지 않고 외부 데이터를 검색하여 응답을 생성함으로써 여러 장점을 제공.  
* **사용자 만족도 향상**: 관련성 높은 정보를 제공하여 사용자가 원하는 답변을 더 쉽게 얻을 수 있습니다. 예를 들어, 최신 뉴스나 특정 도메인 지식을 반영한 응답은 사용자 경험을 크게 개선합니다.  
* **시간 절약**: 대량의 정보를 수동으로 검색할 필요 없이, RAG가 자동으로 관련 문서를 찾아 제공함으로써 사용자의 시간과 노력을 줄입니다.  
* **정확한 AI 결과 보장**: 검색된 데이터에 기반한 응답 생성으로, LLM의 부정확하거나 허구의 정보를 최소화하여 신뢰성을 높입니다.

### 1.3 **기본 RAG vs 고급 RAG**  
RAG는 구현 방식에 따라 기본 RAG와 고급 RAG로 나뉩니다. 아래 표는 두 접근 방식의 차이를 비교하며, 고급 RAG가 더 복잡한 요구 사항을 충족하기 위해 추가적인 기능을 포함함을 보여줍니다.

| 특징            | 기본 RAG                                                                 | 고급 RAG                                                                                                                                                                                                 |
|---------------|-------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **프로세스**      | 문서 임베딩 → 쿼리 임베딩 → 유사 문서 검색 → 프롬프트 보강 → 응답 생성 | 다단계 검색, 동적 쿼리 재구성, 관련성 필터링/재정렬, 자체 수정 메커니즘, 특정 사용 사례를 위한 특수 아키텍처. 예: 쿼리 분해, 검색 결과의 재평가, 여러 소스에서 정보를 통합하여 응답 품질을 극대화. |
| **제한 사항**     | 모든 문서를 동일하게 취급, 쿼리 유형에 적응하지 않음, 검증/개선 메커니즘 부재, 단일 검색 단계에 의존. 이로 인해 복잡한 쿼리나 최신 정보 요구 시 성능이 저하될 수 있음. | 제한 사항을 극복하기 위해 다단계 검색과 피드백 루프를 도입. 예: 검색된 정보의 품질을 평가하고, 필요 시 추가 검색을 수행하거나 쿼리를 재구성하여 더 정확한 결과를 도출. |
| **적용 분야**     | 일반적인 애플리케이션 (예: 간단한 FAQ, 기본적인 정보 검색).              | 정확성이 중요한 애플리케이션 (예: 법률 문서 분석, 의료 진단 지원, 최신 뉴스 기반 응답 생성).                                                                                         |

### 1.4 **다양한 RAG 아키텍처**  
RAG는 특정 사용 사례와 요구 사항에 따라 다양한 아키텍처로 구현될 수 있습니다. 아래 표는 각 아키텍처의 설명, 장점, 적합한 사용 사례를 상세히 정리한 것입니다.

| 아키텍처                          | 설명                                                                                                                                                                                                 | 장점                                                                                                                                                                                                 | 적합한 사용 사례                                                                                                                                                                                                 |
|---------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **캐시 증강 생성 (Cache Augmented Generation)** | 관련 문서를 미리 로드하고 추론 상태(키-값 캐시)를 저장하여 중복 처리를 방지. 예: 자주 묻는 질문에 대해 캐시된 결과를 재사용하여 응답 속도를 높임.                                                                                         | 반복적인 쿼리에 대한 지연 시간 감소, 계산 효율성 증대. 특히 동일한 질문이 반복되는 환경에서 서버 부하를 줄이고 빠른 응답을 제공.                                                                                                  | 예측 가능한 쿼리 패턴, 빠른 응답 속도 최적화, 유사한 질문이 빈번한 경우 (예: 고객 지원 챗봇), 계산 효율성이 중요한 애플리케이션.                                                                                                           |
| **에이전트 기반 RAG (Agentic RAG)**        | LLM이 복잡한 쿼리를 하위 쿼리로 분해하고, 여러 검색 단계를 수행하며, 다양한 정보 유형에 대해 다른 검색 전략을 적용. 예: "회사 재무 상태" 쿼리를 재무 보고서 검색과 뉴스 검색으로 나누어 처리.                                                  | 복잡한 쿼리에 대한 다단계 추론, 다양한 정보 유형에 맞춘 검색, 불완전한 쿼리 처리, 정 Sophisticated 정보 합성. 이를 통해 복잡한 문제 해결 능력이 향상됨.                                                                                   | 복잡한 쿼리, 다양한 정보 유형에 대한 검색 필요 (예: 연구 보고서 작성), 초기 쿼리가 불완전한 경우, 정교한 정보 합성이 필요한 사용 사례 (예: 정책 분석).                                                                                              |
| **교정 RAG (Corrective RAG)**            | 검색된 정보를 검증하고 개선하는 메커니즘 추가. 관련성 및 정확성을 확인하고, 모순되는 정보를 필터링하며, 초기 검색 결과를 기반으로 쿼리 재구성. 예: 잘못된 정보가 포함된 검색 결과를 걸러내고 추가 검색 수행.                                       | 정확성 향상, 모순되는 정보 소스 처리, 다양한 정보 품질 관리. 특히 신뢰할 수 없는 소스에서 정보를 가져올 때 유용.                                                                                                       | 정확성이 중요한 애플리케이션 (예: 의료 정보 제공), 모순될 가능성이 있는 정보 소스, 정보 품질이 사용 사례마다 다른 경우 (예: 법률 자문).                                                                                                     |
| **자기 성찰 RAG (Self-Reflective RAG)**   | 모델이 자체 성능을 평가하고 검색 전략을 조정하는 피드백 루프 사용. 예: 응답이 부정확하면 쿼리를 재구성하거나 검색 매개변수를 조정. 성공 및 실패 사례를 학습하여 점진적으로 성능 개선.                                                  | 정확도 향상, 다양한 쿼리 유형 처리, 시간 경과에 따른 시스템 개선, 모호한 쿼리 의도 처리. 이를 통해 시스템이 스스로 학습하며 성능이 향상됨.                                                                                          | 정확도가 중요한 애플리케이션, 다양한 사용자 쿼리 유형, 시간이 지남에 따라 개선해야 하는 시스템 (예: 교육 플랫폼), 쿼리 의도가 모호한 경우.                                                                                                     |
| **RAG 퓨전 (RAG Fusion)**              | 밀집 검색, 희소 검색, 하이브리드 접근 방식을 병렬로 사용하고, 다양한 임베딩 모델을 활용하여 검색 결과의 품질과 다양성을 향상. 예: 텍스트와 이미지 콘텐츠를 함께 검색하여 종합적인 응답 생성.                                           | 다양한 콘텐츠 유형 처리, 검색 방법의 상호 보완적 강점 활용, 정확도와 재현율 모두 개선. 복잡한 쿼리에 대해 더 포괄적인 결과를 제공.                                                                                             | 다양한 콘텐츠 유형이 있는 애플리케이션 (예: 멀티미디어 검색), 서로 보완적인 검색 방법, 정확도와 재현율 모두 필요한 사용 사례, 복잡하고 다면적인 쿼리 처리 (예: 제품 추천 시스템).                                                                               |
| **시간 증강 검색 (Temporal Augmented Retrieval)** | 시간 민감한 정보를 처리하기 위해 시간 인식을 통합. 문서 최신성을 고려하고, 최신 정보에 가중치를 부여. 예: 최신 뉴스를 우선적으로 검색하여 실시간 정보 제공.                                                              | 시간 관련 정보 처리, 정보 최신성 유지, 시간 제약 조건이 있는 쿼리 처리. 특히 빠르게 변화하는 도메인에서 유용.                                                                                                     | 뉴스 애플리케이션, 최신 이벤트 분석, 금융 또는 시장 데이터 애플리케이션, 정보가 빠르게 변경되는 도메인 (예: 주식 시장 분석), 시간 컨텍스트가 중요한 경우.                                                                                       |
| **계획 후 RAG (Plan then RAG)**         | 검색 작업 전에 계획 단계를 도입. 복잡한 쿼리를 하위 질문으로 나누고, 검색 순서를 결정하며, 정보를 종합. 예: "기업 인수 분석" 쿼리를 재무, 법률, 시장 동향으로 분해하여 단계적으로 검색.                                       | 복잡한 연구 질문 처리, 다단계 추론 필요, 쿼리 분해를 통한 결과 개선. 체계적인 접근으로 복잡한 문제 해결 가능.                                                                                                     | 여러 검색 단계가 필요한 복잡한 연구 질문 (예: 학술 연구), 다중 홉 추론 질문을 처리하는 애플리케이션, 쿼리 분해가 결과를 향상시키는 사용 사례.                                                                                                |
| **그래프 RAG (Graph RAG)**             | 지식 그래프를 사용하여 검색 및 추론 프로세스 강화. 정보가 엔터티와 관계로 구성된 그래프로 표현되고, 관계 경로를 따라 검색 수행. 예: "기업 A와 B의 관계" 쿼리에 대해 기업 간 파트너십 정보를 그래프로 추적.                      | 엔터티 간 복잡한 관계 처리, 관계 정보 강조, 구조화된 컨텍스트 제공. 특히 구조화된 데이터가 중요한 경우 유용.                                                                                                     | 엔터티 간 복잡한 관계가 있는 애플리케이션 (예: 소셜 네트워크 분석), 관계 정보가 중요한 사용 사례 (예: 공급망 분석).                                                                                                          |
| **Flare**                             | 응답 품질 개선을 위해 활성 검색 증강 생성을 통합. 생성 중 주장을 식별하고 검증을 위해 추가 검색 수행. 예: 역사적 사건에 대한 응답 생성 시, 사실 확인을 위해 추가 자료 검색.                                              | 환각 최소화, 고수준의 사실 정확도 필요. 사실 확인을 통해 신뢰성을 높이고, 장문형 콘텐츠에서 오류를 줄임.                                                                                                      | 높은 사실 정확도를 요구하는 애플리케이션 (예: 학술 글쓰기), 환각을 피해야 하는 경우, 많은 사실 주장이 포함된 장문형 콘텐츠와 검증이 중요한 도메인 (예: 저널리즘).                                                                                   |
| **컨텍스트 검색 (Contextual Retrieval)** | 검색 전에 문서 청크에 메타데이터, 섹션 제목, 주변 텍스트 등 추가 컨텍스트를 포함하여 관련성 향상. 예: 법률 문서에서 특정 조항을 검색할 때, 문서 구조와 메타데이터를 활용해 정확한 조항을 찾음.                                     | 구조화된 문서 처리, 복잡한 문서 처리, 중요한 컨텍스트 유지. 단순 청킹에서 손실될 수 있는 정보를 보존하여 검색 품질 향상.                                                                                              | 구조화되고 복잡한 문서가 있는 애플리케이션 (예: 법률 또는 기술 문서 검색), 문서 구조가 중요한 컨텍스트를 제공하는 경우, 특수 용어 또는 개념이 있는 도메인 (예: 의학 문헌).                                                                 |

### 1.5 **적절한 RAG 아키텍처 선택 기준**  
RAG 아키텍처를 선택할 때는 애플리케이션의 요구 사항을 신중히 고려해야 합니다.  
* **쿼리 유형**: 단순 사실 쿼리(예: "수도 이름")는 기본 RAG로 충분하지만, 복잡한 다단계 추론 쿼리(예: "정책 변화의 경제적 영향")는 에이전트 기반 RAG나 계획 후 RAG가 적합.  
* **정확성 요구 사항**: 의료나 법률처럼 정확성이 중요한 경우, 교정 RAG나 Flare와 같은 아키텍처가 필요.  
* **콘텐츠 유형**: 텍스트, 이미지, 그래프 등 다양한 콘텐츠를 다룰 경우 RAG 퓨전이 적합.  
* **시간 관련성**: 최신 정보가 중요한 경우(예: 뉴스 앱), 시간 증강 검색이 필수.  
* **처리량 요구 사항**: 높은 처리량이 필요한 경우(예: 실시간 챗봇), 캐시 증강 생성으로 효율성을 높일 수 있음.

### 1.6 **구현 고려 사항**  
RAG 시스템을 설계하고 구현할 때 다음 요소를 고려해야 합니다.  
* **청킹 전략**: 문서를 어떻게 나눌지 결정.  
  * **고정 크기 청킹**: 일정한 크기로 문서를 분할. 구현이 간단하지만 의미적 맥락이 손실될 수 있음.  
  * **의미론적 청킹**: 문장의 의미를 고려하여 분할. 관련성을 높이지만 계산 비용이 증가.  
  * **계층적 청킹**: 문서의 구조(예: 섹션, 단락)를 활용해 분할. 복잡한 문서에 적합.  
  * **최적 청크 크기**: 사용 사례에 따라 100-1000 토큰 범위에서 실험. 예: 짧은 FAQ는 작은 청크, 긴 연구 보고서는 큰 청크가 적합.  
* **임베딩 모델**: 문서와 쿼리를 벡터로 변환하는 모델 선택. 모델 품질, 차원, 도메인 특성(예: 의료 데이터용 특화 모델), 다국어 지원, 비용 및 지연 시간을 고려.  
* **벡터 데이터베이스**: 확장성, 쿼리 속도, 유지 관리 복잡성, 고급 기능(메타데이터 필터링, 하이브리드 검색 등), 통합성을 평가. 예: Pinecone, Weaviate, FAISS.  
* **프롬프트 구조**: 컨텍스트 배치(검색된 문서의 위치), 지시 명확성(명확한 질문 유도), 소스 속성(출처 명시)으로 응답 품질을 높임.  
* **평가 지표**: 시스템 성능을 평가하기 위한 기준.  
  * **관련성 (Relevance)**: 검색된 문서가 쿼리와 얼마나 관련 있는지.  
  * **정확성 (Accuracy)**: 응답이 사실적으로 정확한지.  
  * **완전성 (Completeness)**: 쿼리의 모든 측면을 다루는지.  
  * **근거 (Groundedness)**: 응답이 검색된 컨텍스트에 의해 뒷받침되는지.  

### 1.7 **평가 방법**  
RAG 시스템의 성능을 평가하기 위해 다양한 방법을 사용할 수 있습니다.  
* **인간 평가**: 전문가가 응답의 품질을 직접 평가. 정확하지만 비용과 시간이 많이 듦.  
* **자동화된 지표**: ROUGE, BLEU 등으로 텍스트 유사성을 측정. 빠르고 객관적이지만 의미적 품질을 완전히 반영하지 못할 수 있음.  
* **A/B 테스트**: 두 가지 RAG 설정을 비교하여 사용자 선호도 확인.  
* **사용자 피드백**: 실제 사용자 경험을 바탕으로 시스템 개선.  

### 1.8 **RAG 프레임워크**  
* LangChain, LlamaIndex와 같은 프레임워크는 RAG 구현을 간소화합니다.  
  * **LangChain**: 데이터 인덱싱, 검색, 프롬프트 관리, 에이전트 기반 워크플로우를 지원.  
  * **LlamaIndex**: 고급 인덱싱 및 쿼리 처리 기능 제공, 특히 구조화된 데이터에 강력.  
  이러한 프레임워크는 데이터 소스 통합, 검색 최적화, 평가 도구를 제공하여 개발 속도를 높입니다.

### 1.9 **결론**  
RAG 시스템은 정확하고 관련성 높으며 유용한 응답을 제공하기 위해 반복적인 평가와 지속적인 개선이 필요합니다. 다양한 RAG 아키텍처(기본 RAG부터 고급 아키텍처까지)와 구현 고려 사항(청킹, 임베딩, 데이터베이스 등)을 신중히 선택하면, 특정 사용 사례와 요구 사항에 맞는 강력한 시스템을 구축할 수 있습니다. 예를 들어, 의료 애플리케이션에서는 교정 RAG를, 실시간 뉴스 앱에서는 시간 증강 검색을 활용하여 최적의 성능을 달성할 수 있습니다.

## 2. Java와 Spring AI를 활용한 검색 증강 생성(RAG) 시스템 구축
- 출처: [Master RAG Data Prep: ETL with Java, Spring AI, Pinecone and MongoDB](https://www.youtube.com/watch?v=wHF2SNPiFGQ)

### 2.1 **주요 내용**

*   **RAG 시스템의 중요성:**
    *   대부분 기업이 AI 기능을 원하지만, 실제로 엔터프라이즈급 RAG 시스템을 구축할 개발자는 부족.
        *  RAG 시스템은 단순한 챗봇을 넘어, 비즈니스 데이터를 활용해 정확하고 맥락에 맞는 답변을 제공하는 AI 시스템을 구현하는 데 필수적입니다. 예를 들어, 고객 지원 시스템에서 고객의 질문에 대해 회사 정책이나 제품 정보를 기반으로 정확한 답변을 제공할 수 있습니다.
    *   RAG 시스템을 마스터하면 AI를 활용하여 실질적인 결과를 도출하는 개발자가 될 수 있음.
        *  RAG 시스템을 능숙히 다루는 개발자는 고객 맞춤형 솔루션, 자동화된 문서 분석, 또는 데이터 기반 의사결정 지원 시스템을 구축하여 기업의 경쟁력을 높일 수 있습니다.

*   **RAG 시스템의 필요성:**
    *   LLM(Large Language Model)은 환각 현상(hallucination)을 일으키고, 특정 비즈니스 데이터를 이해하지 못함.
        *  LLM은 일반적인 지식에 기반한 답변을 생성하지만, 특정 기업의 내부 데이터나 최신 정보를 반영하지 못해 부정확한 답변을 내놓을 수 있습니다. 예를 들어, 최신 제품 매뉴얼이나 내부 규정을 반영하지 못하면 잘못된 정보를 제공할 가능성이 있습니다.
    *   RAG는 실제 데이터를 기반으로 AI 응답을 생성하여 이러한 문제를 해결.
        *  RAG는 외부 데이터 소스(예: 회사 문서, 데이터베이스)를 활용해 LLM의 응답을 보강함으로써 신뢰성과 정확성을 높입니다. 이는 특히 금융, 의료, 법률 등 정확도가 중요한 산업에서 필수적.
    *   RAG를 통해 고객 지원, 코드 어시스턴트, 재무 자문 등 다양한 분야에서 AI 활용 가능.
        *  예를 들어, 고객 지원에서는 고객 문의에 대해 회사의 최신 FAQ나 매뉴얼을 기반으로 답변을 생성하고, 코드 어시스턴트에서는 개발 문서를 참조해 정확한 코드 예시를 제공할 수 있습니다.

*   **벡터 데이터베이스의 역할:**
    *   전통적인 데이터베이스는 정확한 일치 또는 키워드 검색에만 유용하며, 의미론적 이해에 한계가 있음.
        *  전통적인 SQL 데이터베이스는 키워드 매칭에 의존하기 때문에, 사용자의 질문 의도를 파악하거나 문맥에 맞는 결과를 반환하는 데 한계가 있습니다. 예를 들어, "결제 오류 해결 방법"이라는 쿼리에 대해 단순히 "결제"라는 단어가 포함된 문서만 반환할 수 있습니다.
    *   벡터 데이터베이스는 텍스트뿐만 아니라 의미를 저장하여, 사용자의 의도를 파악하고 관련 문서 검색 가능.
        *  벡터 데이터베이스는 텍스트를 고차원 벡터로 변환하여 의미적 유사성을 계산합니다. 이를 통해 "결제 오류"와 관련된 문서뿐만 아니라 "결제 문제", "결제 실패"와 같은 유사한 문맥의 문서도 검색할 수 있습니다.

*   **RAG 시스템의 핵심 단계:**
    1.  **검색(Retrieval):** 벡터 데이터베이스에서 관련 문서 검색.
        *  이 단계에서는 사용자의 쿼리를 벡터로 변환한 뒤, 벡터 데이터베이스에서 가장 유사한 문서들을 찾아냅니다. 예를 들어, "주문 취소 방법"을 묻는 쿼리에 대해 관련 매뉴얼이나 FAQ를 검색합니다.
    2.  **증강(Augmentation):** 검색된 컨텍스트와 사용자 쿼리 결합.
        *  검색된 문서의 내용을 사용자 쿼리와 함께 LLM에 입력하여, 쿼리와 관련된 맥락을 제공합니다. 이는 LLM이 일반적인 답변 대신 데이터에 기반한 구체적인 답변을 생성하도록 돕습니다.
    3.  **생성(Generation):** LLM이 데이터 기반 응답 생성.
        *  LLM은 검색된 문서와 쿼리를 바탕으로 자연스럽고 정확한 답변을 생성합니다. 예를 들어, "주문 취소는 구매 후 7일 이내에 가능하며, 고객 포털에서 진행할 수 있습니다"와 같은 답변을 생성할 수 있습니다.

*   **Spring AI의 활용:**
    *   Spring AI는 RAG 시스템 구축의 복잡성을 추상화하고, 개발자에게 유용한 패턴 제공.
        *  Spring AI는 복잡한 벡터 데이터베이스 통합, 임베딩 생성, 검색 로직 등을 단순화하여 개발자가 비즈니스 로직에 집중할 수 있도록 돕습니다.
    *   다양한 벡터 데이터베이스(Pine Cone, Chroma, PostgreSQL, Azure Cosmos DB, MongoDB Atlas 등) 지원.
        *  Spring AI는 여러 벡터 데이터베이스를 공통 인터페이스로 지원하므로, 특정 데이터베이스에 종속되지 않고 유연하게 시스템을 설계할 수 있습니다.
    *   `VectorStore` 인터페이스를 통해 다양한 벡터 데이터베이스 구현과 상호 작용하는 공통 API 제공.
        *  `VectorStore` 인터페이스는 벡터 데이터의 저장, 검색, 관리 작업을 표준화된 방식으로 처리하여, 개발자가 데이터베이스별로 별도의 코드를 작성할 필요를 줄여줍니다.

*   **구현 예시:**
    *   **문서 수집(Document Ingestion):**
        *   `FileSystemResource`와 `TikaDocumentReader`를 사용하여 파일 시스템에서 문서를 읽어옴.
            *  예를 들어, PDF, Word, 텍스트 파일 등 다양한 형식의 문서를 읽어와 텍스트로 추출합니다. 이는 기업의 매뉴얼, 계약서, FAQ 문서 등을 처리하는 데 유용합니다.
        *   `TokenTextSplitter`를 사용하여 문서를 작은 청크로 분할.
            *  긴 문서를 작은 단위(예: 문장 또는 단락)로 나누어 벡터화하면 검색 정확도가 높아집니다. 예를 들어, 100페이지 분량의 매뉴얼을 500개의 작은 청크로 나눌 수 있습니다.
        *   `VectorStore.add()` 메서드를 사용하여 청크와 임베딩을 벡터 데이터베이스에 저장.
            *  각 청크는 텍스트를 벡터로 변환한 임베딩과 함께 저장되어, 이후 유사도 검색에 활용됩니다.
    *   **유사도 검색(Similarity Search):**
        *   `SearchRequest.Builder`를 사용하여 검색 파라미터(쿼리, Top K 등)를 설정.
            *  Top K는 검색 결과로 반환할 문서의 개수를 지정하며, 쿼리의 세부 설정(예: 유사도 임계값)을 통해 결과를 최적화할 수 있습니다.
        *   `VectorStore.similaritySearch()` 메서드를 사용하여 쿼리와 유사한 문서 검색.
            *  이 메서드는 쿼리를 벡터로 변환한 뒤, 데이터베이스에 저장된 벡터들과의 코사인 유사도 등을 계산하여 가장 관련성 높은 문서를 반환합니다.

*   **벡터 데이터베이스 교체:**
    *   Spring AI를 사용하면 코드 변경 없이 벡터 데이터베이스를 쉽게 교체 가능. (예: Pine Cone에서 MongoDB로 변경)
        *  Spring AI의 추상화된 인터페이스를 통해, 데이터베이스별로 다른 API를 학습할 필요 없이 동일한 코드로 다양한 데이터베이스를 사용할 수 있습니다. 이는 비용, 성능, 또는 스케일링 요구사항에 따라 데이터베이스를 선택할 때 유리합니다.

*   **향후 내용:**
    *   검색 결과를 지능적인 응답으로 변환하는 질문-답변 어드바이저 구축.
        *  질문-답변 어드바이저는 검색된 문서를 기반으로 사용자에게 자연스러운 대화 형식의 답변을 제공하며, 예를 들어, "주문 취소 정책이 궁금합니다"라는 질문에 대해 간결하고 정확한 답변을 생성합니다.
    *   더욱 정교한 RAG 파이프라인을 위한 검색 증강 어드바이저 구현.
        *  검색 증강 어드바이저는 검색 결과를 최적화하거나, 복잡한 쿼리를 여러 단계로 나누어 처리하여 더 정확한 결과를 도출합니다.
    *   개선된 검색을 위한 다중 쿼리 확장(Multi-Query Expansion) 기술 적용.
        *  다중 쿼리 확장은 사용자의 쿼리를 다양한 방식으로 재구성하여 더 많은 관련 문서를 검색하거나, 모호한 쿼리의 의도를 명확히 파악하는 데 사용됩니다.

### 2.2 **핵심 문장**

*   Spring AI를 활용하여 Java 환경에서 RAG 시스템을 구축하는 방법을 배우면, AI를 통해 실질적인 비즈니스 가치를 창출하는 개발자가 될 수 있습니다.
    *  Spring AI를 사용하면 복잡한 AI 시스템 구축 과정이 간소화되며, 비즈니스 데이터를 활용한 AI 솔루션을 빠르게 배포할 수 있어 개발자의 시장 경쟁력을 강화할 수 있습니다.
*   벡터 데이터베이스는 RAG 시스템에서 중요한 역할을 하며, Spring AI는 다양한 벡터 데이터베이스를 지원하여 개발자가 유연하게 선택할 수 있도록 합니다.
    *  벡터 데이터베이스는 의미 기반 검색을 가능하게 하며, Spring AI의 유연한 지원 덕분에 개발자는 프로젝트 요구사항에 맞는 최적의 데이터베이스를 선택할 수 있습니다.
*   문서 수집, 유사도 검색, 응답 생성 등 RAG 시스템의 핵심 단계를 Spring AI를 사용하여 구현하는 방법을 배우면, AI 기반 애플리케이션 개발 능력을 향상시킬 수 있습니다.
    *  이러한 기술은 단순한 챗봇을 넘어, 고객 지원, 문서 관리, 데이터 분석 등 다양한 도메인에서 AI를 활용한 고급 애플리케이션 개발로 이어질 수 있습니다.
