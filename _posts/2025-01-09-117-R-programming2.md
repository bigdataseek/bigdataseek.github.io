---
title: 1차시 17(빅데이터 분석):R Programming Basic 2 
layout: single
classes: wide
categories:
  - R programming
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 9. **Time Series**

```R
# 대한민국의 1인당 GDP와 전체 GDP 데이터를 분석하고, 2018년부터 2022년까지의 국민총생산을 예측하는 과정

# 필요한 패키지 설치 및 로드
# 'WDI' : 세계은행(World Bank) 데이터베이스에서 경제 지표를 조회하는 패키지
# 'forecast': 시계열 데이터 예측 및 분석을 위한 포괄적 도구 제공
if (!require("WDI")) install.packages("WDI")
if (!require("forecast")) install.packages("forecast")
library(WDI)
library(forecast)

# 세계은행 데이터에서 대한민국의 1960년부터 2017년까지의 GDP 데이터 수집
# indicator: 두 가지 경제 지표
# "NY.GDP.PCAP.CD": 1인당 GDP (현재 US$)
# "NY.GDP.MKTP.CD": 국내총생산(GDP) (현재 US$)
gdp_data <- WDI(
  country = "KR",
  indicator = c("NY.GDP.PCAP.CD", "NY.GDP.MKTP.CD"), 
  start = 1960,
  end = 2017
)

# 데이터 열 이름 변경 및 확인
colnames(gdp_data) <- c("Country", "ISO2", "ISO3", "Year", "PerCapitaGDP", "TotalGDP")
head(gdp_data)

# 대한민국의 1인당 GDP 데이터 추출 및 시계열 변환
korea_gdp <- gdp_data$PerCapitaGDP
korea_ts <- ts(korea_gdp, start = min(gdp_data$Year), end = max(gdp_data$Year))

# ARIMA 모델 적합 및 예측
arima_model <- auto.arima(korea_ts)
future_forecast <- forecast(arima_model, h = 5) # 향후 5년 예측

# 예측 결과 출력 및 시각화
print(future_forecast)
plot(future_forecast, main = "대한민국 1인당 GDP 예측 (2018~2022)")
```
```
> head(gdp_data)
      Country ISO2 ISO3 Year PerCapitaGDP   TotalGDP
1 Korea, Rep.   KR  KOR 1960    158.27414 3958811881
2 Korea, Rep.   KR  KOR 1961     93.83138 2417628737
3 Korea, Rep.   KR  KOR 1962    106.15970 2814615385
4 Korea, Rep.   KR  KOR 1963    146.30249 3988461538
5 Korea, Rep.   KR  KOR 1964    123.60637 3459019943
6 Korea, Rep.   KR  KOR 1965    108.72311 3120861499

> print(future_forecast)
     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
2018       33032.08 31453.23 34610.93 30617.44 35446.72
2019       33634.80 31089.91 36179.69 29742.73 37526.88
2020       34452.14 31436.18 37468.10 29839.63 39064.65
2021       35624.44 32225.77 39023.11 30426.63 40822.25
2022       36769.24 32888.00 40650.48 30833.39 42705.08
# 80% 신뢰수준에서의 예측 범위
# 95% 신뢰수준에서의 예측 범위
# 한국 1인당 GDP가 꾸준히 성장할 것이나, 먼 미래일수록 예측 불확실성이 커진
```

1. **데이터 수집**: `WDI` 패키지를 사용하여 세계은행 데이터에서 대한민국의 1960년부터 2017년까지의 1인당 GDP와 전체 GDP 데이터를 가져옵니다.
2. **데이터 정리**: 데이터 열 이름을 명확하게 변경하고, 대한민국의 1인당 GDP 데이터만 추출하여 시계열 객체로 변환합니다.
   - ts(): 시계열 객체 생성 함수
   - korea_gdp: 시계열로 변환할 GDP 데이터
   - start = min(gdp_data$Year): 시작 연도 = 데이터의 가장 이른 연도
   - end = max(gdp_data$Year): 종료 연도 = 데이터의 가장 최근 연도   
3. **예측 모델 생성**: `auto.arima` 함수를 사용하여 ARIMA 모델을 자동으로 적합시킵니다.
   - arima_model <- auto.arima(korea_ts)
      - 자동 ARIMA 모델 생성
      - 한국 GDP 시계열 데이터를 분석하여 최적의 ARIMA 모델 파라미터를 자동 선택
      - 과거 패턴을 학습하는 모델 구축   
4. **예측 수행**: 적합된 모델을 기반으로 향후 5년(2018~2022년)의 1인당 GDP를 예측합니다.
   - future_forecast <- forecast(arima_model, h = 5)
      - 향후 5년 GDP 예측 수행
      - 학습된 ARIMA 모델을 기반으로 미래 GDP 값 예측
5. **시각화**: 예측 결과를 그래프로 표시하여 직관적으로 확인할 수 있도록 합니다.


## 10. **Clustering**

```R
# Load the iris dataset and prepare it for clustering
data(iris)
df <- iris
df$Species <- NULL  # Remove the species labels for unsupervised clustering

# Perform K-means clustering with 3 clusters
set.seed(123)  # Ensure reproducibility of results
kmeans_result <- kmeans(df, centers = 3)

# Summarize and interpret the clustering results
print(kmeans_result)  # Display clustering details
summary(kmeans_result)  # Provide a summary of cluster statistics
cluster_comparison <- table(iris$Species, kmeans_result$cluster)  # Compare true species with clusters
print(cluster_comparison)

# Visualize the clusters using Sepal.Length and Sepal.Width
plot(df[c("Sepal.Length", "Sepal.Width")], 
     col = kmeans_result$cluster, 
     pch = 19, 
     main = "K-means Clustering (Sepal Dimensions)",
     xlab = "Sepal Length", 
     ylab = "Sepal Width")
```
```
> print(kmeans_result)  # Display clustering details
K-means clustering with 3 clusters of sizes 50, 62, 38

Cluster means:
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1     5.006000    3.428000     1.462000    0.246000
2     5.901613    2.748387     4.393548    1.433871
3     6.850000    3.073684     5.742105    2.071053

Clustering vector:
  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [44] 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2
 [87] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3
[130] 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3 3 2

Within cluster sum of squares by cluster:
[1] 15.15100 39.82097 23.87947 
 (between_SS / total_SS =  88.4 %)
# 88.4%의 설명력 (between_SS / total_SS)

Available components:
[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"    


> summary(kmeans_result)  # Provide a summary of cluster statistics
             Length Class  Mode   
cluster      150    -none- numeric
centers       12    -none- numeric
totss          1    -none- numeric
withinss       3    -none- numeric
tot.withinss   1    -none- numeric
betweenss      1    -none- numeric
size           3    -none- numeric
iter           1    -none- numeric
ifault         1    -none- numeric

> print(cluster_comparison)            
              1  2  3
  setosa     50  0  0
  versicolor  0 48  2
  virginica   0 14 36
```

1. **데이터 준비**: `iris` 데이터셋을 불러와 `df` 변수에 저장하고, 군집화를 위해 `Species` 열을 제거합니다.
2. **군집화 수행**: `kmeans` 함수로 데이터를 3개의 군집으로 나누며, `set.seed(123)`을 사용해 결과의 재현성을 보장합니다.
   - K-평균 군집화 알고리즘을 실행하여 데이터를 3개의 그룹으로 자동 분류
3. **결과 확인**: 군집화 결과를 출력하고, 요약 정보를 제공하며, 실제 종과 군집 간의 대응 관계를 표로 비교합니다.
4. **시각화**: `Sepal.Length`와 `Sepal.Width`를 기준으로 산점도를 그려 군집별로 색상을 다르게 표현합니다. 이를 통해 군집의 분포를 직관적으로 확인할 수 있습니다.



## 11. **Derived Variable**

```R
# 패키지 설치 및 로드
install.packages("nycflights13") # 뉴욕 출발 항공편 데이터를 포함한 교육용 실제 데이터셋 제공
install.packages("dplyr")
library(nycflights13)
library(dplyr)

# 데이터 구조 및 열 이름 확인
# nycflights13: 패키지 이름 (2013년 뉴욕 항공편 데이터를 포함한 꾸러미)
# flights: 실제 데이터셋 이름 (항공편 기록을 담은 데이터프레임)
str(flights)
colnames(flights)

# 데이터를 tibble 형식으로 변환
flights_df <- as_tibble(flights)

# 도착 지연과 출발 지연의 차이를 계산하여 새로운 열 추가
flights_with_gain <- flights_df %>%
  mutate(gain = arr_delay - dep_delay)

# 결과 확인
flights_with_gain
```
```
> str(flights)
tibble [336,776 × 19] (S3: tbl_df/tbl/data.frame)
 $ year          : int [1:336776] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ...
 $ month         : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ...
 $ day           : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ...
 $ dep_time      : int [1:336776] 517 533 542 544 554 554 555 557 557 558 ...
 $ sched_dep_time: int [1:336776] 515 529 540 545 600 558 600 600 600 600 ...
 $ dep_delay     : num [1:336776] 2 4 2 -1 -6 -4 -5 -3 -3 -2 ...
 $ arr_time      : int [1:336776] 830 850 923 1004 812 740 913 709 838 753 ...
 $ sched_arr_time: int [1:336776] 819 830 850 1022 837 728 854 723 846 745 ...
 $ arr_delay     : num [1:336776] 11 20 33 -18 -25 12 19 -14 -8 8 ...
 $ carrier       : chr [1:336776] "UA" "UA" "AA" "B6" ...
 $ flight        : int [1:336776] 1545 1714 1141 725 461 1696 507 5708 79 301 ...
 $ tailnum       : chr [1:336776] "N14228" "N24211" "N619AA" "N804JB" ...
 $ origin        : chr [1:336776] "EWR" "LGA" "JFK" "JFK" ...
 $ dest          : chr [1:336776] "IAH" "IAH" "MIA" "BQN" ...
 $ air_time      : num [1:336776] 227 227 160 183 116 150 158 53 140 138 ...
 $ distance      : num [1:336776] 1400 1416 1089 1576 762 ...
 $ hour          : num [1:336776] 5 5 5 5 6 5 6 6 6 6 ...
 $ minute        : num [1:336776] 15 29 40 45 0 58 0 0 0 0 ...
 $ time_hour     : POSIXct[1:336776], format: "2013-01-01 05:00:00" "2013-01-01 05:00:00" ...

> colnames(flights)
 [1] "year"           "month"          "day"            "dep_time"       "sched_dep_time"
 [6] "dep_delay"      "arr_time"       "sched_arr_time" "arr_delay"      "carrier"       
[11] "flight"         "tailnum"        "origin"         "dest"           "air_time"      
[16] "distance"       "hour"           "minute"         "time_hour"   

> flights_with_gain
# A tibble: 336,776 × 20
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay
   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>     <dbl>
 1  2013     1     1      517            515         2      830            819        11
 2  2013     1     1      533            529         4      850            830        20
 3  2013     1     1      542            540         2      923            850        33
 4  2013     1     1      544            545        -1     1004           1022       -18
 5  2013     1     1      554            600        -6      812            837       -25
 6  2013     1     1      554            558        -4      740            728        12
 7  2013     1     1      555            600        -5      913            854        19
 8  2013     1     1      557            600        -3      709            723       -14
 9  2013     1     1      557            600        -3      838            846        -8
10  2013     1     1      558            600        -2      753            745         8
# ℹ 336,766 more rows
# ℹ 11 more variables: carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,
#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,
#   time_hour <dttm>, gain <dbl>
```

1. **패키지 설치 및 불러오기**:  
   - `nycflights13` 패키지(뉴욕 항공편 데이터 포함)와 `dplyr` 패키지를 설치하고 로드합니다.
2. **데이터 확인**:  
   - `flights` 데이터셋을 사용하며, `str()`과 `colnames()`로 데이터 구조와 열 이름을 확인합니다.
3. **데이터 변환**:  
   - `flights` 데이터를 `tibble` 형식으로 변환하여 현대적인 데이터프레임으로 처리합니다.
   - 대용량 항공편 데이터를 현대적이고 효율적인 tibble 형식으로 변환하여 데이터 분석 작업을 더 편리하게
      - glimpse(flights_df)  # 구조 파악 용이
      - print(flights_df)     # 스마트한 출력
4. **새로운 열 추가**:  
   - `mutate()` 함수를 사용해 `arr_delay`(도착 지연 시간)에서 `dep_delay`(출발 지연 시간)를 뺀 값을 `gain`이라는 새 열로 추가합니다.  
   - `%>%` 파이프 연산자를 활용하여 코드를 더 간결하게 작성합니다.

## 12. **Ensemble Analytics**

```R
# Ensemble Analytics - RandomForest를 활용한 분류 모델 예제

# 1. 필요한 패키지 설치 및 로드
# 랜덤 포레스트(Random Forest) 앙상블 머신러닝 알고리즘 구현
install.packages("randomForest")
library(randomForest)

# 2. 데이터셋 확인 및 준비
data(iris) # iris 데이터셋 로드
set.seed(123) # 재현성을 위한 시드 설정
sample_idx <- sample(c(TRUE, FALSE), size = nrow(iris), replace = TRUE, prob = c(0.7, 0.3))
train_data <- iris[sample_idx, ] # 훈련 데이터 (70%)
test_data <- iris[!sample_idx, ] # 테스트 데이터 (30%)

# 3. RandomForest 모델 학습
rf_model <- randomForest(Species ~ ., data = train_data, ntree = 100, importance = TRUE)

# 4. 모델 평가 및 결과 확인
print(rf_model) # 모델 요약 정보 출력
importance(rf_model) # 변수 중요도 확인
confusion_matrix <- table(test_data$Species, predict(rf_model, test_data)) # 혼동 행렬 생성
print(confusion_matrix) # 혼동 행렬 출력
```
```
> print(rf_model) # 모델 요약 정보 출력

Call:
 randomForest(formula = Species ~ ., data = train_data, ntree = 100,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 100
No. of variables tried at each split: 2

        OOB estimate of  error rate: 1.89%
Confusion matrix:
           setosa versicolor virginica class.error
setosa         35          0         0  0.00000000
versicolor      0         35         1  0.02777778
virginica       0          1        34  0.02857143
# OOB 오차율: 1.89% (매우 우수한 정확도), Out-of-Bag: 학습에 사용되지 않은 데이터로 계산한 오차
# versicolor와 virginica 종을 97% 이상 정확하게 구분하는 매우 정확한 분류 모델

> importance(rf_model) # 변수 중요도 확인
                setosa versicolor virginica MeanDecreaseAccuracy MeanDecreaseGini
Sepal.Length  3.435299   1.290024  5.447233             5.463811         8.776757
Sepal.Width   3.040703   2.020818  1.619235             3.521191         1.553977
Petal.Length 10.459137  14.899501 14.941142            18.477600        32.850704
Petal.Width   9.556921  12.607617 11.018361            14.663038        26.789003
# MeanDecreaseAccuracy (정확도 기여도)
# MeanDecreaseGini (불순도 감소): 값이 클수록 중요
# 가장 중요한 변수:
# Petal.Length (꽃잎 길이): 모든 지표에서 1위
# Petal.Width (꽃잎 너비): 모든 지표에서 2위

> print(confusion_matrix) # 혼동 행렬 출력
               setosa versicolor virginica
  setosa         15          0         0
  versicolor      0         11         3
  virginica       0          1        14
# 행(Row): 실제 값 (True)
# 열(Column): 예측 값 (Predicted)
```

1. **패키지 설치 및 로드**: `randomForest` 패키지를 설치하고 불러옵니다.
   - 높은 예측 정확도: 다수 결정트리의 앙상블
   - 과적합 방지: 배깅(Bagging)과 랜덤 특성 선택
   - 변수 중요도: 예측에 기여하는 변수 순위 제공
   - 자동 결측값 처리: 내부적으로 결측값 대체
2. **데이터 준비**: `iris` 데이터셋을 사용하며, `set.seed`를 통해 무작위 샘플링의 재현성을 보장합니다. 데이터를 70% 훈련, 30% 테스트로 나눕니다.
   - sample(): 무작위 샘플링 함수
   - c(TRUE, FALSE): 선택할 값 (TRUE=훈련셋, FALSE=테스트셋)
   - prob = c(0.7, 0.3): TRUE 70%, FALSE 30% 비율
3. **모델 학습**: `randomForest` 함수를 사용해 분류 모델을 생성합니다. `ntree=100`으로 트리 개수를 설정하고, `importance=TRUE`로 변수 중요도를 계산합니다.
4. **결과 확인**: 모델 요약 정보와 변수 중요도를 출력하며, 훈련 데이터에 대한 예측 결과를 혼동 행렬로 확인합니다.


## 13. **Prediction Error**

```R
# 데이터 확인
data(mtcars)
head(mtcars, 3)
str(mtcars)
?mtcars

# 선형 회귀 모델 생성: 연비(mpg)와 차중(wt) 간의 관계 분석
# lm()은 정규분포 데이터 전용, glm()은 다양한 데이터 유형에 사용 가능한 일반화된 모델입니다.
model <- lm(mpg ~ wt, data = mtcars)
summary(model)

# 회귀 계수 및 기본 결과 확인
coef(model)
# 학습된 모델(model)이 훈련 데이터에 대해 예측한 값(fitted values) 중 처음 5개 관측치의 결과를 추출
fitted_values <- fitted(model)[1:5]  # 처음 5개 관측값의 예측값
residuals_values <- residuals(model)[1:5]  # 처음 5개 관측값의 잔차
confint(model)  # 회귀 계수의 신뢰구간
deviance(model)  # 모델의 편차

# 새로운 데이터에 대한 예측
# 3,500파운드 자동차의 연비를 예측하고 그 불확실성을 구간으로 추정
new_data <- data.frame(wt = 3.5) #무게 3,500파운드 자동차 데이터 생성
predicted_value <- predict(model, newdata = new_data) # 모델로 예측한 평균 연비값
manual_prediction <- coef(model)[1] + coef(model)[2] * 3.5 # 수동 계산: 37.285 + (-5.344) × 3.5
confidence_interval <- predict(model, newdata = new_data, interval = "confidence") # 평균 연비의 신뢰구간
prediction_interval <- predict(model, newdata = new_data, interval = "prediction") # 개별 자동차 연비의 예측구간

# 시각화 및 진단
par(mfrow = c(2, 2)) #없어도 2 by 2 그림이 그려짐(default 임)
plot(model)

# 잔차 정규성 검정
shapiro_test <- shapiro.test(residuals(model))
shapiro_test

# 잔차 독립성 검정 (Durbin-Watson 테스트)
if (!require(lmtest)) install.packages("lmtest", dependencies = TRUE)
library(lmtest)
dw_test <- dwtest(model)
dw_test
```
```
> head(mtcars, 3)
               mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1

> str(mtcars)
'data.frame':	32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...

> summary(model)
Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,	Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
#계수 해석:
#  절편(37.285): 무게가 0일 때 예상 연비 (이론적 값)
#  기울기(-5.345): 무게 1,000파운드 증가시 연비 5.345 감소

# 모델 적합도:
#  R² = 0.7528: 무게가 연비 변동의 75%를 설명
#  p-value = 1.29e-10: 통계적으로 매우 유의미한 관계

# 잔차(오차) 분석:
#  잔차 표준오차 = 3.046: 예측값과 실제값 평균 차이
#  잔차 분포가 대체로 균등 (-4.54 ~ 6.87)

# 결론:
# "자동차 무게와 연비는 강한 음의 상관관계를 가지며, 무게만으로 연비 변동의 75%를 설명할 수 있는 매우 유의미한 모델"

> fitted_values
        Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive Hornet Sportabout 
         23.28261          21.91977          24.88595          20.10265          18.90014 

> residuals_values
        Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive Hornet Sportabout 
       -2.2826106        -0.9197704        -2.0859521         1.2973499        -0.2001440 

> confint(model)  # 회귀 계수의 신뢰구간
                2.5 %    97.5 %
(Intercept) 33.450500 41.119753
wt          -6.486308 -4.202635
# 무게가 0인 자동차의 연비는 33.45 ~ 41.12 mpg 사이일 것이다
# 무게가 1,000파운드 증가할 때 연비는 4.20 ~ 6.49 mpg 감소한다
# 무게 증가가 연비 감소로 이어진다는 것이 통계적으로 매우 신뢰할 수 있는 관계임

> deviance(model)  # 모델의 편차
[1] 278.3219
# 모델의 총 잔차 제곱합(RSS) = 278.32
# sum(residuals(model)^2)
# 모델이 설명하지 못하는 총 오차량

> coef(model)
(Intercept)          wt 
  37.285126   -5.344472 
# 회귀모델의 계수(Coefficients) - 회귀직선의 방정식
# 자동차 무게가 1,000파운드 늘어날 때마다 연비가 약 5.3 mpg씩 체계적으로 감소한다

> shapiro_test
	Shapiro-Wilk normality test

data:  residuals(model)
W = 0.94508, p-value = 0.1044
# 잔차가 정규분포에서 유의하게 벗어나지 않음
# 선형회귀 모델의 정규성 가정이 충족됨

> dw_test
	Durbin-Watson test
data:  model
DW = 1.2517, p-value = 0.0102
alternative hypothesis: true autocorrelation is greater than 0
# 잔차에 양의 자기상관이 존재한다, (p-value < 0.05)
# 모델의 독립성 가정이 충족되지 않음
```

1. **데이터 확인**:  
   - `head(mtcars, 3)`과 `str(mtcars)`로 데이터 구조를 파악하고, `?mtcars`로 도움말을 확인.

2. **선형 회귀 모델 생성**:  
   - `lm(mpg ~ wt, data = mtcars)`로 차량 무게(`wt`)와 연비(`mpg`) 간의 선형 관계를 모델링.

3. **모델 결과 분석**:  
   - `coef(model)`로 회귀 계수 확인.  
   - `fitted(model)`과 `residuals(model)`로 예측값과 잔차 계산.  
      - fitted(): 학습 데이터의 예측값
         - fitted_values <- fitted(model) 
      - predict(): 새로운 데이터의 예측값  
         - new_predictions <- predict(model, newdata = new_cars)  
   - `confint(model)`으로 회귀 계수의 신뢰구간 추정.
   - `deviance(model)`으로 모델의 편차 계산

4. **예측**:  
   - `predict()` 함수를 사용해 새로운 데이터(`wt = 3.5`)에 대한 예측 수행.  
   - 수동으로 예측값 계산 및 신뢰구간/예측구간 포함 예측.

5. **시각화 및 진단**:  
   - `par(mfrow = c(2, 2))`는 R에서 그래프를 2행 2열(2×2)로 나누어 동시에 표시하도록 설정하는 명령어
   - `plot(model)`은 회귀 모델(lm 등)의 진단용 그래프(잔차, Q-Q 플롯 등)를 자동으로 4개 생성합니다.
      - 이때 `par(mfrow = c(2, 2))`를 생략해도 `plot(model)`은 기본적으로 2×2 배열로 그래프를 그림
   

6. **잔차 진단**:  
   - `shapiro.test()`로 잔차의 정규성 검정.  
      - 선형회귀 모델의 잔차가 정규분포를 따르는지 검정하는 코드
      - 회귀분석의 가정 충족 여부 확인
      - p-value > 0.05: 잔차가 정규분포를 따른다 (가정 만족)
   - `lmtest`: 선형 회귀모델의 가정 검정을 위한 진단 도구 제공
   - `dwtest()`로 잔차의 독립성 검정(`lmtest` 패키지 필요).  
      - DW ≈ 2면 자기상관 없음, DW < 1.5면 양의 자기상관
      - 1.2517은 1.5보다 작음 → 양의 자기상관 존재
      - 회귀모델의 독립성 가정 위반
   - 회귀모델의 독립성 가정 위반이란?
      - 연속된 관측치의 잔차가 서로 상관되어 있어 모델의 독립성 가정이 충족되지 않음
      - 오차가 무작위적이지 않음
      - mpg ~ wt 모델만으로는 충분히 설명 불가
   - 잔차 독립성 위반 ->  mpg에 영향을 끼치는 누락된 변수 추가(hp 혹은 cyl)
      - 잔차의 체계적 패턴 감소 기대
      - 잔차 독립성 가정 충족 가능성 향상

7. **예측오류와 잔차**:
    - **잔차**: 학습 데이터 내에서의 오차로, 모델의 적합성을 평가.
    - **예측오류**: 새로운 데이터에서의 오차로, 모델의 일반화 성능을 평가.
    - **관계**: 잔차를 최소화하는 것이 예측오류를 줄이는 데 도움이 되지만, 과적합을 방지해야 함.

## 14. **K-Flod**

```R
# 패키지 설치 및 로드
# party: 의사결정나무(Decision Tree) 및 조건부 추론 트리(Conditional Inference Trees) 기반의 모델을 구축하기 위한 패키지
# caret: 머신러닝 모델의 전처리, 학습, 평가를 통합적으로 지원하는 범용 패키지
if (!require("party")) install.packages("party")
if (!require("caret")) install.packages("caret")
library(party)
library(caret)

# 데이터 확인
data(iris)
head(iris)
str(iris)

# 3-fold 교차 검증 설정
set.seed(123) # 재현성을 위한 시드 설정
folds <- createFolds(iris$Species, k = 3, list = TRUE, returnTrain = TRUE)

# 정확도 저장용 벡터 초기화
# numeric()으로 0으로 채워진 숫자형 벡터를 생성
accuracy_list <- numeric(length(folds))

# 교차 검증 루프
for (i in seq_along(folds)) {
  train_index <- folds[[i]] # 학습 데이터 인덱스
  # nrow() 함수: 데이터 프레임 또는 행렬의 행(row) 개수를 반
  test_index <- setdiff(1:nrow(iris), train_index) # 테스트 데이터 인덱스
  
  # 데이터 분할
  train_data <- iris[train_index, ] #,(쉼표) 뒤가 비어있으므로 모든 열을 포함
  test_data <- iris[test_index, ]
  
  # 모델 생성 및 예측
  # ctree() - 조건부 추론 나무(Conditional Inference Tree) 함수
  # Species ~ . - Species를 종속변수로, 나머지 모든 변수(. )를 독립변수로 사용
  model <- ctree(Species ~ ., data = train_data)
  predictions <- predict(model, newdata = test_data)
  
  # 혼동 행렬 및 정확도 계산
  # table() 함수를 사용해 예측값(predictions)과 실제값(test_data$Species)을 비교하여 분류 모델의 성능을 평가하기 위한 행렬
  # diag(confusion_matrix): 혼동 행렬의 대각선 요소를 추출하여 올바르게 예측한 샘플 수를 구함.
  # sum(confusion_matrix): 혼동 행렬 전체 요소의 합, 즉 전체 샘플 수.
  confusion_matrix <- table(Predicted = predictions, Actual = test_data$Species)
  print(confusion_matrix)
  accuracy_list[i] <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
}

# 결과 출력
cat("테스트 데이터 크기:", nrow(test_data), "\n")
cat("학습 데이터 크기:", nrow(train_data), "\n")
cat("각 폴드별 정확도:", accuracy_list, "\n")
cat("평균 정확도:", mean(accuracy_list), "\n")
```
```
       Actual
Predicted    setosa versicolor virginica
  setosa         17          0         0
  versicolor      0         15         0
  virginica       0          2        16
            Actual
Predicted    setosa versicolor virginica
  setosa         16          0         0
  versicolor      0         15         1
  virginica       0          1        16
            Actual
Predicted    setosa versicolor virginica
  setosa         15          0         0
  versicolor      2         13         3
  virginica       0          4        14

> # 결과 출력
> cat("테스트 데이터 크기:", nrow(test_data), "\n")
테스트 데이터 크기: 51 

> cat("학습 데이터 크기:", nrow(train_data), "\n")
학습 데이터 크기: 99 

> cat("각 폴드별 정확도:", accuracy_list, "\n")
각 폴드별 정확도: 0.96 0.9591837 0.8235294 

> cat("평균 정확도:", mean(accuracy_list), "\n")
평균 정확도: 0.9142377 
```

1. **패키지 사용**: `caret` 패키지의 `createFolds` 함수를 사용하여 데이터를 교차 검증용으로 나눕니다.
   - 3-fold 교차 검증을 위한 훈련 데이터 인덱스를 생성
      - iris$Species를 기준으로 데이터를 3등분(k = 3)합니다.
      - returnTrain = TRUE이므로 훈련에 사용할 데이터의 인덱스를 반환합니다.
      - list = TRUE이므로 결과가 리스트 형태로 저장됩니다.
   - 결과적으로 olds에는 3개의 fold가 생성되며, 각 fold는:
      - 2/3는 훈련 데이터 (해당 fold에서 선택된 인덱스)
      - 1/3는 검증 데이터 (선택되지 않은 인덱스)
2. **데이터 분할**: `createFolds`는 학습 데이터 인덱스를 반환하므로, `setdiff`를 사용해 테스트 데이터 인덱스를 추출합니다.
3. **모델링 및 평가**: 각 폴드에서 `ctree` 모델을 학습하고, 혼동 행렬을 통해 정확도를 계산합니다. `diag` 함수를 사용해 혼동 행렬의 대각선 요소(정답 수)를 추출합니다.
4. **결과 출력**: 각 폴드별 정확도와 전체 평균 정확도를 출력합니다. `cat` 함수를 사용해 결과를 명확히 표시합니다.


## 15. **Confusion Matrix**

```R
# Load necessary libraries and dataset
# rpart: 의사결정나무(decision tree) 모델을 생성하고 분석하는 데 사용되는 패키지입니다. 주로 분류(classification)와 회귀(regression) 문제를 해결
library(rpart)
library(caret)
data(iris)

# Inspect the dataset
print(head(iris, 10))
print(summary(iris))

# Split the data into training (70%) and testing (30%) sets
set.seed(123) # For reproducibility
# caret 패키지의 createDataPartition 함수를 사용하여 iris 데이터셋의 Species 열을 기반으로 
# 데이터의 70%를 훈련 세트,결과를 리스트가 아닌 벡터 형태로, 훈련 세트에 포함될 데이터의 인덱스를 저
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]

# Train a decision tree model using rpart
# rpart(): 의사결정나무를 만드는 함수
# Species(종)를 목표 변수로, 꽃받침 길이/너비, 꽃잎 길이/너비를 예측 변수로 사용
# method = "class": 분류(classification) 문제를 해결하기 위한 모델
decisionTreeModel <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, 
                           data = trainData, method = "class")

# Evaluate the model on the training data
trainPred <- predict(decisionTreeModel, trainData, type = "class")
confusionMatrix(trainPred, trainData$Species)

# Visualize the decision tree
# rpart.plot:의사결정나무(decision tree)를 시각화
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(decisionTreeModel)

# Evaluate the model on the test data
testPred <- predict(decisionTreeModel, testData, type = "class")
confusionMatrix(testPred, testData$Species)
```
```
> decisionTreeModel
n= 105 
node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 105 70 setosa (0.33333333 0.33333333 0.33333333)  
2) Petal.Length< 2.6 35  0 setosa (1.00000000 0.00000000 0.00000000) *
3) Petal.Length>=2.6 70 35 versicolor (0.00000000 0.50000000 0.50000000)  
6) Petal.Width< 1.65 36  2 versicolor (0.00000000 0.94444444 0.05555556) *
7) Petal.Width>=1.65 34  1 virginica (0.00000000 0.02941176 0.97058824) *

> confusionMatrix(trainPred, trainData$Species)
Confusion Matrix and Statistics

Reference
Prediction   setosa versicolor virginica
  setosa         35          0         0
  versicolor      0         34         2
  virginica       0          1        33

Overall Statistics                                          
               Accuracy : 0.9714          
                 95% CI : (0.9188, 0.9941)
    No Information Rate : 0.3333          
    P-Value [Acc > NIR] : < 2.2e-16       
                  Kappa : 0.9571          
Mcnemar's Test P-Value : NA              
# Accuracy (정확도): 97.14%로, 전체 예측 중 올바르게 분류한 비율.
# 95% CI: 정확도의 95% 신뢰구간(91.88%~99.41%).
# No Information Rate (NIR): 무작위 예측 시 기대되는 정확도(33.33%, 클래스 균등 가정).
# P-Value [Acc > NIR]: 모델의 정확도가 NIR보다 유의미하게 높음을 나타냄(p < 2.2e-16).
# Kappa: 0.9571로, 우연히 맞춘 경우를 보정한 모델의 일치도(높을수록 좋음).

Statistics by Class:

                     Class: setosa Class: versicolor Class:virginica
Sensitivity                 1.0000            0.9714           09429
Specificity                 1.0000            0.9714           09857
Pos Pred Value              1.0000            0.9444           09706
Neg Pred Value              1.0000            0.9855           09718
Prevalence                  0.3333            0.3333           03333
Detection Rate              0.3333            0.3238           03143
Detection Prevalence        0.3333            0.3429           03238
Balanced Accuracy           1.0000            0.9714           09643


> confusionMatrix(testPred, testData$Species)
Confusion Matrix and Statistics

            Reference
Prediction   setosa versicolor virginica
  setosa         15          0         0
  versicolor      0         14         2
  virginica       0          1        13

Overall Statistics
                                         
               Accuracy : 0.9333         
                 95% CI : (0.8173, 0.986)
    No Information Rate : 0.3333         
    P-Value [Acc > NIR] : < 2.2e-16      
                  Kappa : 0.9            
   Mcnemar's Test P-Value : NA             

Statistics by Class:
                  Class: setosa Class: versicolor Class: virginica
Sensitivity                1.0000            0.9333           0.8667
Specificity                1.0000            0.9333           0.9667
Pos Pred Value             1.0000            0.8750           0.9286
Neg Pred Value             1.0000            0.9655           0.9355
Prevalence                 0.3333            0.3333           0.3333
Detection Rate             0.3333            0.3111           0.2889
Detection Prevalence       0.3333            0.3556           0.3111
Balanced Accuracy          1.0000            0.9333           0.9167
# Sensitivity(재현율)
```

1. **데이터 확인**: `head`와 `summary`를 사용하여 데이터셋의 구조와 요약 통계를 출력합니다.
2. **패키지 및 데이터 준비**: `rpart`와 `caret` 패키지를 사용하며, `createDataPartition` 함수로 데이터를 훈련 및 테스트 세트로 분할합니다.
3. **모델 학습**: `rpart`를 사용해 의사결정나무 모델을 학습하며, 입력 변수로 꽃받침과 꽃잎의 길이/너비를 사용합니다.
4. **모델 평가**: 훈련 및 테스트 데이터에 대해 혼동 행렬(`confusionMatrix`)을 생성하여 모델 성능을 평가합니다.
5. **시각화**: `rpart.plot`을 사용해 의사결정나무를 시각화합니다. 



## 16. **ROC**

```R
# 1. 필요한 패키지 설치 및 로드
# pROC: ROC 곡선(Receiver Operating Characteristic)을 시각화, 분석, 비교하는 도구로, AUC(곡선 아래 면적) 계산과 통계 검정을 지원
# mlbench: 머신러닝 벤치마크용 인공/실제 데이터셋(예: UCI 저장소 데이터)을 제공하는 컬렉션
install.packages("caret")
install.packages("pROC")
install.packages("mlbench")

library(caret)
library(pROC)
library(mlbench) # Sonar 데이터

# 2. 데이터셋 로드 및 탐색
data(Sonar)
summary(Sonar)
prop.table(table(Sonar$Class)) # 클래스 비율 확인

# 3. 데이터 분할
set.seed(123)
# times = 1: 분할을 한 번만 수행.
trainIndex <- createDataPartition(Sonar$Class, p = .7, list = FALSE, times = 1)
sonarTrain <- Sonar[trainIndex, ]
sonarTest <- Sonar[-trainIndex, ]

# 4. 의사결정나무 모델 학습
library(rpart)
decision_tree <- rpart(Class ~ ., data = sonarTrain, method = "class")


# 5. 테스트 데이터에 대한 예측 (확률)
# type = "prob": 예측 결과로 클래스 확률을 반환.
# [, 2]: 두 번째 열(클래스 중 하나, 예: 양성 클래스)의 확률만 선택.
predictions <- predict(decision_tree, newdata = sonarTest, type = "prob")[, 2]

# 6. ROC 곡선 생성 및 시각화
# sonarTest$Class(실제 클래스 레이블)와 predictions(예측 점수/확률)를 입력으로 roc 곡선을 계산
roc_curve <- roc(sonarTest$Class, predictions)

plot(roc_curve, main = "ROC Curve for Sonar Data",
     col = "#1c61b6",  # 곡선 색상
     lwd = 2,           # 곡선 두께
     print.auc = TRUE)  # AUC 값 표시
```
```
> head(Sonar, n=2)
      V1     V2     V3     V4     V5     V6     V7     V8     V9    V10    V11    V12
1 0.0200 0.0371 0.0428 0.0207 0.0954 0.0986 0.1539 0.1601 0.3109 0.2111 0.1609 0.1582
2 0.0453 0.0523 0.0843 0.0689 0.1183 0.2583 0.2156 0.3481 0.3337 0.2872 0.4918 0.6552
     V13    V14    V15    V16  V17    V18    V19    V20    V21    V22    V23    V24    V25
1 0.2238 0.0645 0.0660 0.2273 0.31 0.2999 0.5078 0.4797 0.5783 0.5071 0.4328 0.5550 0.6711
2 0.6919 0.7797 0.7464 0.9444 1.00 0.8874 0.8024 0.7818 0.5212 0.4052 0.3957 0.3914 0.3250
     V26    V27    V28    V29    V30    V31    V32    V33    V34    V35    V36    V37
1 0.6415 0.7104 0.8080 0.6791 0.3857 0.1307 0.2604 0.5121 0.7547 0.8537 0.8507 0.6692
2 0.3200 0.3271 0.2767 0.4423 0.2028 0.3788 0.2947 0.1984 0.2341 0.1306 0.4182 0.3835
     V38    V39    V40    V41    V42    V43    V44    V45    V46    V47    V48    V49
1 0.6097 0.4943 0.2744 0.0510 0.2834 0.2825 0.4256 0.2641 0.1386 0.1051 0.1343 0.0383
2 0.1057 0.1840 0.1970 0.1674 0.0583 0.1401 0.1628 0.0621 0.0203 0.0530 0.0742 0.0409
     V50    V51    V52    V53    V54    V55    V56   V57    V58    V59    V60 Class
1 0.0324 0.0232 0.0027 0.0065 0.0159 0.0072 0.0167 0.018 0.0084 0.0090 0.0032     R
2 0.0061 0.0125 0.0084 0.0089 0.0048 0.0094 0.0191 0.014 0.0049 0.0052 0.0044     R

> prop.table(table(Sonar$Class)) # 클래스 비율 확인
        M         R 
0.5336538 0.4663462 

> decision_tree
n= 146 
node), split, n, loss, yval, (yprob)
      * denotes terminal node
1) root 146 68 M (0.53424658 0.46575342)  
2) V11>=0.19795 91 23 M (0.74725275 0.25274725)  
4) V27>=0.8191 43  2 M (0.95348837 0.04651163) *
5) V27< 0.8191 48 21 M (0.56250000 0.43750000)  
10) V52>=0.0069 37 11 M (0.70270270 0.29729730)  
20) V37< 0.4705 26  3 M (0.88461538 0.11538462) *
21) V37>=0.4705 11  3 R (0.27272727 0.72727273) *
11) V52< 0.0069 11  1 R (0.09090909 0.90909091) *
3) V11< 0.19795 55 10 R (0.18181818 0.81818182)  
6) V4>=0.0515 14  6 M (0.57142857 0.42857143) *
7) V4< 0.0515 41  2 R (0.04878049 0.95121951) *
# loss: 노드에서의 분류 오류(작을수록 좋음).
# yval: 노드의 예측 클래스 (M 또는 R).
# yprob: 각 클래스(M, R)에 속할 확률 (예: (0.53424658 0.46575342)).

# 루트 노드: 전체 데이터(n=146)를 시작점으로, V11>=0.19795 조건으로 두 갈래로 나눔.
# 왼쪽 가지 (V11>=0.19795): 91개 샘플, 클래스 M이 우세(74.7%). 이후 V27, V52, V37 조건으로 더 분할.
#   최종적으로 단말 노드(* 표시)에서 클래스 M 또는 R로 예측.
# 오른쪽 가지 (V11<0.19795): 55개 샘플, 클래스 R이 우세(81.8%). V4 조건으로 추가 분할.
#    최종 단말 노드에서 클래스 M 또는 R로 예측. 
```

1. **패키지 관리**: `if` 조건문을 사용하여 `rpart` 패키지가 설치되어 있지 않을 경우 자동으로 설치하고 로드합니다.
2. **데이터 탐색**: `summary()` 함수를 통해 데이터의 요약 정보를 출력하며, `prop.table()`로 클래스 비율을 확인합니다.
3. **모델 학습**: `rpart` 함수에서 `method = "class"`를 명시적으로 지정하여 분류 문제임을 강조합니다. 
4. **예측**: `predict()` 함수의 `type = "prob"` 옵션을 사용하여 확률값을 추출합니다.
5. **성능 평가**: `ROCR` 패키지를 활용하여 정확도와 ROC 곡선을 시각화합니다.


## 17. **Model Evaluation**

```R
# 필요한 패키지 설치 및 로드
# 이진 분류 모델의 성능 평가를 위한 대표적인 패키지
install.packages("ROCR")
library(ROCR)

# 타이타닉 데이터셋 불러오기 및 초기 확인
data(Titanic) # R에 내장된 "Titanic" 데이터셋을 불러옵니다
Titanic #자료형은 table 
titanic_data <- as.data.frame(Titanic) #불러온 데이터를 데이터프레임 형식으로 변환
head(titanic_data)


# 데이터 전처리: 각 행을 개별 승객으로 확장
# titanic_data 데이터 프레임의 각 행을 Freq 열에 지정된 횟수만큼 반복하여 새로운 데이터 프레임 expanded_data를 생성
expanded_data <- titanic_data[rep(1:nrow(titanic_data), titanic_data$Freq), ]
expanded_data <- expanded_data[, -which(names(expanded_data) == "Freq")] # Freq 열 제거
# which(...): Freq 열의 인덱스를 반환
expanded_data$Survived <- ifelse(expanded_data$Survived == "Yes", 1, 0) # 생존 여부를 이진 값으로 변환

# 데이터 요약 및 확인
head(expanded_data)
summary(expanded_data)

# 학습 및 테스트 데이터 분할 (70% 학습, 30% 테스트)
set.seed(123) # 재현성을 위한 시드 설정
# 데이터셋의 행 인덱스를 무작위로 샘플링하여 70%를 훈련 데이터 인덱스(train_indices)로 선택
# floor(): 소수점을 버려 정수로 만듦
train_indices <- sample(1:nrow(expanded_data), size = floor(0.7 * nrow(expanded_data)))
train_data <- expanded_data[train_indices, ]
test_data <- expanded_data[-train_indices, ]

# 로지스틱 회귀 모델 학습
logistic_model <- glm(Survived ~ Class + Sex + Age, data = train_data, family = binomial)
summary(logistic_model)

# 테스트 데이터로 예측 수행
# 로지스틱 회귀 모델(logistic_model)을 사용해 테스트 데이터(test_data)에 대해 예측 확률을 계산
predicted_prob <- predict(logistic_model, newdata = test_data, type = "response")

# ROC 곡선 및 AUC 계산
# ROCR 패키지 사용, 모델의 예측 확률(predicted_prob)과 실제 레이블(test_data$Survived)을 입력으로 받아, ROC 곡선 분석을 위한 예측 객체를 생성하고 roc_pred 변수에 저장
roc_pred <- prediction(predicted_prob, test_data$Survived)

# performance 함수를 사용해 TPR(True Positive Rate, 민감도)와 FPR(False Positive Rate, 1-특이도)를 계산하는 코드
roc_perf <- performance(roc_pred, measure = "tpr", x.measure = 
"fpr")

# ROC 곡선의 성능을 평가하여 AUC(Area Under the Curve) 값을 계산
# performance 함수가 반환한 객체에서 AUC 값(실제 수치)을 추출
auc_value <- performance(roc_pred, measure = "auc")@y.values[[1]]

# ROC 곡선 시각화
plot(roc_perf, col = "blue", main = "ROC Curve")
abline(a = 0, b = 1, lty = "dotted") #플롯에 직선을 추가,y = x인 점선 직선
legend("bottomright", legend = paste("AUC =", round(auc_value, 3)), col = "blue", lty = 1)

# 결과 저장
# cbind는 열 단위로 데이터를 결합
# test_data 데이터프레임에 predicted_prob라는 예측 확률 값을 새로운 열(Predicted_Probability)로 추가하
results <- cbind(test_data, Predicted_Probability = predicted_prob)
head(results)
write.csv(results, file = "titanic_logistic_results.csv", row.names = FALSE)
#row.names = FALSE는 행 번호를 CSV 파일에 포함시키지 않도록 설정합니다.
```

```
> head(titanic_data)
  Class    Sex   Age Survived Freq
1   1st   Male Child       No    0
2   2nd   Male Child       No    0
3   3rd   Male Child       No   35
4  Crew   Male Child       No    0
5   1st Female Child       No    0
6   2nd Female Child       No    0

> head(expanded_data)
    Class  Sex   Age Survived
3     3rd Male Child        0
3.1   3rd Male Child        0
3.2   3rd Male Child        0
3.3   3rd Male Child        0
3.4   3rd Male Child        0
3.5   3rd Male Child        0

> summary(expanded_data)
  Class         Sex          Age          Survived    
 1st :325   Male  :1731   Child: 109   Min.   :0.000  
 2nd :285   Female: 470   Adult:2092   1st Qu.:0.000  
 3rd :706                              Median :0.000  
 Crew:885                              Mean   :0.323  
                                       3rd Qu.:1.000  
                                       Max.   :1.000  

> summary(logistic_model)
Call:
glm(formula = Survived ~ Class + Sex + Age, family = binomial, 
    data = train_data)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.3962     0.3366   1.177   0.2391    
Class2nd     -1.0229     0.2305  -4.437 9.12e-06 ***
Class3rd     -1.8106     0.2034  -8.904  < 2e-16 ***
ClassCrew    -1.0390     0.1891  -5.495 3.90e-08 ***
SexFemale     2.4132     0.1644  14.682  < 2e-16 ***
AgeAdult     -0.7399     0.3025  -2.446   0.0144 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1918.8  on 1539  degrees of freedom
Residual deviance: 1509.9  on 1534  degrees of freedom
AIC: 1521.9

Number of Fisher Scoring iterations: 4
# 로지스틱 회귀 모델(glm, binomial family)의 요약 결과
# 모델 구조: Survived ~ Class + Sex + Age는 생존 여부(Survived)를 클래스(1st, 2nd, 3rd, Crew), 성별, 연령대(Adult 등)로 예측
# 계수(Coefficients):
# - Estimate: 각 변수의 영향력(로그 오즈 비율). 예: SexFemale (2.4132)은 여성일 경우 생존 가능성이 높음을 의미.
# - Std. Error: 추정치의 표준 오차(작을수록 추정치 신뢰도 높음).
# - z value: 계수의 통계적 유의성(절대값 클수록 유의미).
# - Pr(>|z|): p-값(작을수록 유의미). ***, **, *는 각각 p < 0.001, 0.01, 0.05로 유의미함을 나타냄.
# - 주요 결과:
#     - Class2nd, Class3rd, ClassCrew: 1등석 대비 생존 가능성 낮음(음수 계수, 유의미).
#     - SexFemale: 여성일 경우 생존 가능성 매우 높음(강한 양수 계수, 매우 유의미).
#     - AgeAdult: 성인일 경우 생존 가능성 약간 낮음(음수 계수, 유의미).
# 모델 적합도:
# - Null deviance: 독립변수 없는 모델의 편차(1918.8).
# - Residual deviance: 현재 모델의 잔차 편차(1509.9). 값이 작을수록 모델이 데이터 잘 설명.
# AIC: 모델의 적합성을 평가하는 기준(작을수록 좋음). 여기선 1521.9.
# Fisher Scoring iterations: 모델 수렴까지 반복 횟수(4번).

> head(results)
     Class  Sex   Age Survived Predicted_Probability
3.2    3rd Male Child        0             0.1955424
3.4    3rd Male Child        0             0.1955424
3.6    3rd Male Child        0             0.1955424
3.14   3rd Male Child        0             0.1955424
3.20   3rd Male Child        0             0.1955424
3.21   3rd Male Child        0             0.1955424
```
0. `ROCR` 패키지
   - ROC 곡선: 거짓 양성률(FPR)에 대한 참 양성률(TPR)의 변화를 그린 곡선입니다.
   - AUC (Area Under Curve): ROC 곡선 아래의 면적으로, 모델의 전체적인 성능을 하나의 숫자로 요약합니다 (1에 가까울수록 좋음).
1. **데이터 전처리**:  
   - `Titanic` 데이터셋을 개별 승객 단위로 확장하여 `Freq` 열을 제거하고, `Survived`를 이진 값(0 또는 1)으로 변환합니다.

2. **데이터 분할**:  
   - 전체 데이터를 학습용(`train_data`)과 테스트용(`test_data`)으로 나누며, 층화 추출 없이 랜덤 샘플링을 사용합니다.

3. **모델 학습**:  
   - `glm` 함수를 사용해 로지스틱 회귀 모델을 학습하며, 독립 변수로 `Class`, `Sex`, `Age`를 사용합니다.

4. **예측 및 평가**:  
   - 테스트 데이터에 대한 생존 확률을 예측하고, ROC 곡선을 그립니다.  
   - AUC 값을 계산하고, 이를 그래프에 표시합니다.  
   - 최종 결과는 CSV 파일로 저장됩니다.  
