---
title: 43차시 1:Zachary
layout: single
classes: wide
categories:
  - Zachary
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. PocketFlow

- 출처:[I built PocketFlow!](https://www.youtube.com/watch?v=0Pv5HVoVBYE)

### 1.1 **PocketFlow 개요 및 핵심 개념**

*   **무엇인가**: PocketFlow는 대규모 언어 모델(LLM) 에이전트를 위한 프레임워크입니다.
*   **크기 및 특징**: 코드는 단 100줄에 불과하며, 오픈 소스 Python 라이브러리입니다. 노드를 정의하고 그래프를 생성하며 확장 기능을 가지고 있습니다.
*   **그래프 활용 이유**: 그래프는 에이전트 워크플로우(예: 채널링, 검색 증강 생성(RAG) 등)를 구축하는 데 매우 유연하기 때문에 사용됩니다.
*   **핵심 아이디어**:
    *   **노드(Nodes)**: 
        *   기본적인 계산 단위입니다. LLM 호출, 텍스트 임베딩 생성, 외부 도구 호출 등 필요한 모든 작업을 수행할 수 있습니다. 노드는 전처리(Share Store에서 데이터 읽기), 실행(작업 수행), 후처리(결과를 Share Store에 쓰기)의 세 단계를 거칩니다.
    *   **배칭(Batching)**: 
        *   노드는 배치 모드로 실행될 수 있으며, 여러 입력을 동시에 처리할 때 유용합니다. 예를 들어, 큰 파일의 여러 청크를 임베딩할 때 사용될 수 있습니다. 배치 노드는 전처리에서 항목 목록을 반환하고, 실행은 목록의 각 항목에 대해 한 번씩 호출되며, 후처리에서는 항목 목록과 실행 결과 목록을 입력으로 받습니다.
    *   **플로우(Flows)**: 
        *   여러 노드를 그래프와 같은 구조로 연결하여 워크플로우를 만듭니다. 복잡한 문제를 더 간단하게 나누거나, 노드의 후처리 메서드에 작성된 에이전트적 동작에 기반하여 분기할 수 있습니다. 일반적으로 시작 노드를 지정하고 `Run` 함수를 호출하여 시작합니다. 플로우는 중첩되거나 분기되거나 단순한 노드 시퀀스일 수 있습니다.
    *   **Share Store**: 
        *   모든 노드는 Share Store를 통해 통신합니다. 이는 인메모리 객체부터 관계형 데이터베이스까지 무엇이든 될 수 있습니다.

### 1.2 **개발 배경 및 동기**

*   **개인적인 시작**: 
    *   PocketFlow는 LLM 에이전트가 다른 에이전트를 구축하게 하려는 저자(Zach)의 개인적인 시도(hack)로 시작되었습니다.
*   **연구 경험**: 
    *   저자는 수년간 AI 연구원으로 활동하며 10개 이상의 AI 프로젝트를 진행하고 여러 논문을 발표했으며, 각 프로젝트는 수백 번의 반복적인 수정과 시행착오를 거쳤는데, 이는 매우 시간 소모적이고 노동 집약적이었습니다. 이 경험을 통해 LLM 에이전트가 유용하다면 에이전트 구축을 돕는 데 사용될 수 있지 않을까 생각하게 되었습니다.
*   **Cursor AI와의 문제점**: 
    *   Cursor AI는 AI와 대화하며 프로젝트를 구축하는 새로운 프로그래밍 패러다임을 제공하지만, LangChain과 같은 대규모 프레임워크와 함께 사용했을 때 Cursor가 이해하기 어려워 복잡한 문제에서 환각을 일으키거나 실수를 하는 문제가 있었습니다.
*   **PocketFlow의 탄생**: 
    *   저자는 Cursor가 더 작고 간단한 프레임워크에서 놀라울 정도로 잘 작동한다는 것을 발견했고, 그래프와 Share Store 추상화만 포함하는 작은 프레임워크를 만들었습니다. Cursor AI는 이 프레임워크를 즉시 이해하고 자체적으로 에이전트 구축을 시작했으며, 이를 1년간 개선하여 생산성을 크게 향상시켰습니다. 지난 크리스마스 연휴 동안 이를 독립적인 프로젝트로 만들기로 결정하고 코드를 리팩토링한 결과 100줄의 코드만 필요하다는 것을 깨달았습니다.

### 1.3 **Cursor AI와의 연동**

*   **목표**: LLM 에이전트가 사용자를 위해 에이전트를 직접 구축하게 하는 것입니다.
*   **설정**: Cursor AI 에이전트가 PocketFlow와 원활하게 작동하도록 컨텍스트를 제공해야 합니다. 이를 위해 PocketFlow GitHub 저장소에서 제공하는 문서를 포함하는 `cursor_rules` 파일을 생성해야 합니다.
*   **Cursor의 역할**: PocketFlow 자체는 최소한으로 설계되었기 때문에 LLM 호출, 텍스트 임베딩 생성 또는 외부 API 호출과 같은 유틸리티 함수를 기본적으로 포함하지 않습니다. Cursor AI는 이러한 부분을 채워줄 수 있습니다.
    *   Cursor에게 LLM 호출 및 텍스트 임베딩 함수 구현을 요청할 수 있습니다.
    *   Cursor에게 특정 작업(예: 에세이 요약)을 수행하는 노드 구현을 요청할 수 있습니다.
    *   Cursor에게 디렉토리의 모든 파일 요약과 같은 배치 노드 구현을 요청할 수 있습니다.
    *   Cursor에게 검색 증강 생성 챗봇과 같은 플로우 구현을 요청할 수 있습니다. Cursor가 생성한 RAG 플로우는 임베딩 준비, 관련 문서 찾기, 질문 답변의 세 가지 노드로 구성되었습니다.

### 1.4 결론
PocketFlow는 LLM 에이전트 구축을 위한 100줄의 **작고 유연한 그래프 기반 프레임워크**이며, 그 **최소한의 크기**가 Cursor AI와 같은 도구가 **에이전트를 대신 구축하도록 돕는 데 핵심적인 역할**을 한다는 것입니다.


## 2. AI 기반 코드베이스 지식 구축 도구
- 출처:[This AI Explains ANY Codebase in 5 Minutes](https://www.youtube.com/watch?v=AFY67zOpbSo&t=62s)

**AI 기반 코드베이스 지식 구축 도구**를 구축하는 과정과 핵심 기술인 **PocketFlow**, **에이전트 코딩**에 대해 설명

### **2.1 문제 상황: 새로운 코드베이스 이해의 어려움**

*   새로운 코드베이스를 접할 때, 수백 개의 파일과 수천 개의 함수 속에서 길을 잃고 시작점을 찾기 곤란.
*   개발자들은 코드를 작성하는 시간보다 읽는 시간이 10대 1 이상으로 훨씬 많으며, 이는 코드의 기능, 구성 요소 간 연결 방식, 설계 의도 등 기본적인 질문에 답을 찾는 데 많은 시간을 소모한다는 것을 의미합니다.
*   이는 매우 좌절스럽고 시간 및 재능의 낭비입니다.
*   기존 AI 도구(예: 단순 프롬프트 또는 Cursor AI 단독 사용)는 복잡한 코드베이스를 전체적으로 이해하는 데 어려움을 겪으며, 코드 레벨의 단편적이거나 표면적인 정보만 제공하여 환각이나 실수를 유발하기도 합니다. 코드 조각 목록이 아니라 시스템이 왜 그렇게 구성되었고 각 부분이 어떻게 연결되는지에 대한 "큰 그림" 이해가 필요합니다.

### **2.2 해결책: AI 기반 코드베이스 지식 구축 도구**

*   제공된 소스의 저자(Zachary Huang)는 새로운 코드베이스를 읽고 **간단하고 초보자 친화적인 튜토리얼로 변환**하는 AI 기반 시스템을 **단 하루 만에 구축**했습니다.
*   이 시스템은 어떤 저장소에도 적용 가능하며, 복잡한 코드베이스를 명확하고 직관적인 설명으로 변경.

### **2.3 핵심 기술 및 개념**

*   **PocketFlow**:
    *   이 시스템 구축의 **"비밀 병기"**입니다.
    *   단 **100줄의 코드**로 구성된 **작고 강력한 AI 워크플로우 프레임워크**입니다. 누구나 몇 분 안에 이해.
    *   LangChain이나 LlamaIndex와 유사하지만 훨씬 더 간단하고 투명한 **그래프 추상화**를 사용합니다.
    *   **노드(Nodes)**: 
        *   기본적인 계산 단위입니다. 요리 스테이션과 같이 특정 작업을 처리합니다 (예: 코드 다운로드, AI 호출, 임베딩 생성). 노드는 **전처리, 실행, 후처리**의 세 단계를 거칩니다.
    *   **플로우(Flows)**: 
        *   레시피처럼 노드들을 연결하여 워크플로우를 만듭니다. 조건에 따라 분기하거나 여러 노드를 순차적으로 실행할 수 있습니다.
    *   **Share Store**: 
        *   모든 노드가 데이터를 공유하고 통신하는 중앙 저장소입니다. 중앙 조리대와 같습니다.
    *   PocketFlow의 투명하고 최소한의 설계는 복잡성 없이 AI 워크플로우를 쉽게 파악하고 이해.

*   **에이전트 코딩(Agentic Coding)**:
    *   대규모 언어 모델 시스템을 구축하는 **새로운 개발 패러다임**입니다.
    *   사용자는 **고수준 시스템 설계(워크플로우 디자인, 명확한 처리 단계 정의)**에 집중하고, **AI가 모든 구현 세부 사항과 실제 코드를 작성**합니다.
    *   당신은 설계도(디자인)를 만드는 **건축가**이고, AI는 설계도를 기반으로 구축하는 **건설팀**입니다.
    *   PocketFlow처럼 구조가 명확하고 간단할 때, AI 에이전트가 디자인을 빠르게 이해하고 효율적으로 기술 구현을 처리할 수 있습니다.
    *   Cursor와 같은 도구와 원활하게 작동하려면 PocketFlow 문서가 포함된 규칙 파일(`cursor_rules`)을 제공해야 합니다.

*   **Cursor AI**:
    *   AI와 대화하며 프로젝트를 구축하는 데 사용되는 도구입니다.
    *   PocketFlow와 함께 사용하여 **에이전트 코딩**을 실현합니다.
    *   **채팅 모드**: 시스템 디자인 단계에서 아이디어를 다듬고 상세한 디자인 문서를 작성하는 데 사용됩니다.
    *   **에이전트 모드**: 디자인 문서를 기반으로 **PocketFlow 워크플로우의 노드 코드를 자동으로 생성**하는 데 사용됩니다. 단 몇 분 만에 구현 코드를 생성할 수 있습니다.

*   **시스템 디자인 전략: Overview-Zoom-in 접근 방식**:
    *   코드베이스를 이해하기 위한 핵심 전략입니다.
    *   **Overview 단계**: 
        *   AI가 코드베이스 전체를 체계적으로 스캔하여 **핵심 추상화(개념)**를 식별하고 이들 간의 **관계**를 파악한 후, 논리적인 튜토리얼 개요를 구성합니다. 전체 아키텍처와 주요 구성 요소의 상호작용을 포착하는 넓은 시야의 스냅샷과 같습니다.
    *   **Zoom-in 단계**:  
        *   AI가 각 추상화에 대해 **심층적으로 파고들어** 상세한 설명, 예시, 실용적인 코드 스니펫을 제공합니다.
    *   이 구조화된 접근 방식은 경험 많은 개발자가 코드를 학습하는 방식과 유사하여 명확성과 깊이를 동시에 제공합니다.

### **2.4 시스템 구축 과정 (Overview-Zoom-in 전략 적용)**

*   **디자인 단계 (Cursor 채팅 모드 활용)**:
    *   "AI 기반 코드베이스 지식 구축 도구를 위한 상세 디자인 문서를 작성해줘"와 같은 프롬프트를 사용.
    *   Cursor는 Overview-Zoom-in 전략에 따라 핵심 추상화 식별, 관계 파악, 논리적 순서 결정, 각 추상화에 대한 상세 설명 구성 등의 디자인을 생성합니다.

*   **구현 단계 (Cursor 에이전트 모드 활용)**:
    *   Cursor를 에이전트 모드로 전환하고 "디자인 문서를 기반으로 구현해줘"와 같은 명령을 입력합니다.
    *   Cursor는 PocketFlow 워크플로우와 필요한 노드 코드를 자동으로 생성합니다. 예시 워크플로우의 노드들은 다음과 같습니다:
        *   **Fetch Repo**: 
            *   저장소 URL을 Share Store에서 가져와 관련 파일을 다운로드하고 코드베이스를 Share Store에 저장합니다.
        *   **Identify Abstractions**: 
            *   다운로드된 코드베이스를 가져와 AI가 주요 클래스, 모듈 등 핵심 추상화를 식별하고 Share Store에 저장합니다.
        *   **Analyze Relationships**: 
            *   추상화와 코드베이스를 로드하여 AI가 가져오기, 메서드 호출, 상속 등의 관계를 분석하고 관계 지도를 Share Store에 저장합니다.
        *   **Order Chapters**: 
            *   추상화와 관계 정보를 바탕으로 개념을 제시할 가장 논리적인 순서를 결정하고 Share Store에 게시합니다.
        *   **Write Chapters** (배치 노드): 
            *   각 추상화에 대해 상세한 튜토리얼 챕터를 작성합니다. 배치 처리를 통해 각 추상화를 순차적으로 처리하며, 활용 사례, 간결한 코드 스니펫, 예시, 다이어그램, 비유 등을 포함하여 이해도를 높입니다.
        *   **Combined Tutorial**: 
            *   Share Store의 모든 챕터, 다이어그램, 개요 등을 모아 색인 페이지와 시각적 개요를 포함하는 잘 구성된 튜토리얼 디렉토리로 컴파일하고 완료된 튜토리얼 위치를 Share Store에 저장.

### **2.5 결과 및 효과**

*   이 시스템은 단 몇 분 만에 복잡한 코드베이스를 매력적이고 초보자 친화적인 튜토리얼로 변환합니다.
*   결과물에는 명확한 개요, 핵심 개념 설명, 구성 요소 연결을 보여주는 시각적 지도 등이 포함됩니다.
*   PocketFlow의 투명한 파이프라인과 에이전트 코딩을 통해, 사용자는 큰 그림 설계에 집중하고 AI가 구현을 처리함으로써 멀티스텝 AI 워크플로우를 **며칠이 아닌 몇 시간 안에 설계하고 배포**할 수 있습니다.
*   이를 통해 복잡한 코드베이스에 압도당하는 일 없이, 어떤 저장소든 구조화되고 따라하기 쉬운 튜토리얼로 만들 수 있습니다.

### 2.6 **요약**
이 소스는 복잡한 코드베이스를 이해하는 어려움을 해결하기 위해, 작고 투명한 그래프 기반 프레임워크인 **PocketFlow**와 AI가 코드를 구현하는 **에이전트 코딩** 패러다임, 그리고 **Overview-Zoom-in** 디자인 전략을 활용하여 **AI 기반 튜토리얼 생성 시스템**을 구축하는 방법을 설명합니다. 특히 Cursor AI와 같은 도구를 활용하여 디자인(채팅 모드) 및 구현(에이전트 모드) 과정을 효율화함으로써, 단 하루 만에 강력한 시스템을 만들 수 있음을 보여줍니다.

## 3. Google A2A vs Anthropic MCP
- 출처:[Google A2A vs Anthropic MCP](https://www.youtube.com/watch?v=wrCF8MoXC_I&t=14s)

AI 시스템이 외부 도구와 상호작용하고 다른 AI 에이전트와 협력하는 방식의 발전을 설명하며, 특히 **MCP와 A2A라는 두 가지 주요 프로토콜**에 초점을 맞추고 있습니다.

### **3.1 초기 단계: 함수 호출 (Function Calling)**

*   2023년 OpenAI가 **함수 호출** 기능을 출시하면서 AI 모델이 처음으로 외부 세계와 통신하고, 코드를 실행하며, 서비스를 사용할 수 있게 되었습니다.
*   이를 통해 ChatGPT 플러그인이 등장하며 AI를 Instacart, Slack 등과 연결하는 등 AI를 텍스트 생성 외에 실제로 유용하게 만드는 첫걸음이었습니다.
*   AI 모델은 기본적인 계산이나 실시간 정보(날씨, 주가)를 알지 못하고 이메일을 쓸 수는 있지만 실제로 보낼 수는 없었기에 함수 호출이 필요했습니다.
*   함수 호출은 AI에게 필요한 작업을 처리할 수 있는 "전문가 전화번호부"를 주는 것과 같았습니다.
*   작동 방식은 개발자가 도구를 구축하고, AI에게 어떤 도구가 있는지 설명하고, AI가 사용자의 요청에 따라 적절한 도구와 인수를 선택하면, 시스템이 실제 코드를 실행하는 4단계로 요약할 수 있습니다.

###  **3.2 함수 호출의 문제점: 표준 부재**

*   가장 큰 문제점은 **표준이 전혀 없었다는 것**입니다.
*   AI 제공업체마다 함수 매개변수를 설명하는 방식이 달랐고 (예: OpenAI의 매개변수 객체 vs. DBS Cloud의 입력 스키마), 이는 도구의 호환성을 즉시 떨어뜨렸습니다.
*   하나의 도구를 만들어서 여러 AI 모델(GPT-4, Claude, Gemini 등)과 쉽게 작동하게 할 수 없었고, 사용자 정의 도구를 추가하는 데 제약이 있었으며, 새로운 AI 시스템이 나올 때마다 통합 방식을 재작성해야 할 가능성이 있었습니다.
*   Python 기반 AI가 JavaScript로 작성된 도구를 사용하는 것과 같은 복잡성도 있었습니다.
*   산업계는 AI가 클라우드에서 실행되든 로컬에서 실행되든 관계없이 모든 공급업체에서 도구와 쉽게 연결될 수 있는 **보편적인 방법, 공통 언어**를 절실히 필요로 했습니다. 이러한 **표준화 혼란**이 MCP가 해결하고자 한 문제였습니다.

### **3.3 Anthropic의 MCP (Model Contest Protocol)**

*   2024년 11월에 출시된 MCP는 **표준화 문제**를 정면으로 해결하기 위해 등장했습니다.
*   MCP는 AI 시스템이 누가 만들었든 관계없이 모든 외부 도구와 통신할 수 있는 **보편적인 인터페이스, 공통 언어**를 만듭니다. "AI를 위한 USB-C 포트" 혹은 "AI를 위한 블루투스"와 같다고 비유할 수 있습니다.
*   MCP의 핵심 아이디어는 시스템을 **서버**와 **클라이언트**라는 두 개의 별개 부분으로 분할하는 것입니다.
    *   **MCP 서버**: 
        *   도구(계산기 코드, 데이터베이스 연결 등)가 실제로 상주하는 곳이며, AI 모델 자체와 완전히 분리되어 실행됩니다. 어떤 언어로든 작성할 수 있습니다.
    *   **MCP 클라이언트**: 
        *   AI 에이전트와 함께 상주하며 다리 역할을 합니다. 서버에 어떤 도구가 있는지 확인하고, AI가 MCP 표준을 사용하여 요청 형식을 올바르게 지정하도록 도우며, 이러한 요청을 서버로 보내고 결과를 받는 역할을 합니다.
*   이러한 명확한 분리는 도구를 사용하는 AI 모델과 **완전히 독립적으로 도구를 개발, 업데이트 및 배포**할 수 있다는 장점을 제공합니다.
*   **MCP 워크플로우**:
    1.  함수 구현: 
        *   MCP 서버에서 도구 함수를 구현합니다.
    2.  함수 목록화: 
        *   클라이언트 측에서 `list_tools`와 같은 표준 MCP 명령을 사용하여 서버에 도구 목록을 요청합니다. 서버는 MCP 표준에 따라 서식화된 도구 설명을 응답합니다.
    3.  함수 선택: 
        *   클라이언트 측에서 AI 모델을 사용하여 사용자의 요청에 따라 올바른 도구 이름과 필요한 입력 매개변수를 결정합니다. 사용 가능한 도구가 하드코딩된 것이 아니라 MCP 서버에서 직접 온다는 것이 핵심 차이점입니다.
    4.  함수 호출: 
        *   클라이언트는 대상 도구 이름과 필요한 매개변수를 MCP 서버로 보냅니다. 서버는 해당 함수를 찾아 실행하고, 결과를 MCP 표준에 따라 클라이언트로 다시 보냅니다.
*   **MCP의 주요 이점**:
    *   **보편적인 호환성**: 
        *   MCP 도구 서버를 한 번 구축하면, Open AI, Anthropic, Google 등 어떤 MCP 호환 에이전트든 변경 없이 사용할 수 있습니다. 어떤 MCP 호환 에이전트든 사용 가능한 모든 MCP 도구를 즉시 사용할 수 있습니다. **벤더 사일로**를 무너뜨립니다.
    *   **구현의 자유**: 
        *   MCP는 클라이언트와 서버 간의 통신만 표준화하므로, 내부 구현은 자유롭습니다. 도구 구현을 업데이트하거나 버그를 수정해도 MCP 인터페이스가 동일하게 유지되는 한 AI 에이전트 코드는 수정할 필요가 없습니다. 각 구성 요소가 독립적으로 발전할 수 있습니다.
*   MCP는 **정밀하고 잘 정의된 단일 단계 작업**에 탁월하며, 안정성과 명확한 계약이 필요할 때 유용합니다.

### **3.4 Google의 A2A (Agent to Agent Protocol)**

*   MCP가 AI 에이전트를 도구에 연결하는 데 강력하지만, **하나의 에이전트나 도구만으로는 너무 복잡한 작업** (예: 하와이 여행 전체 계획)을 처리할 때는 한계가 있습니다. 여러 종류의 전문 지식이 함께 작업해야 합니다.
*   2024년 4월에 출시된 A2A는 이러한 문제를 해결하도록 설계되었습니다. A2A는 서로 다른 전문 AI 에이전트가 **직접 대화하고, 작업을 위임하며, 팀으로 협력**할 수 있도록 합니다.
*   MCP가 에이전트를 도구(계산기)에 연결한다면, A2A는 에이전트를 **다른 에이전트**에 연결합니다. MCP가 에이전트가 전문 도구를 사용하게 한다면, A2A는 에이전트가 전문 에이전트와 상담하게 합니다.
*   **A2A 워크플로우 (하와이 여행 계획 예시)**:
    1.  에이전트 탐색: 
        *   메인 개인 비서 에이전트가 A2A 클라이언트를 사용하여 필요한 전문 에이전트(여행 전문가, 예산 분석가, 현지 가이드 등)를 찾습니다. 각 A2A 에이전트는 자신이 잘하는 것을 설명하는 "에이전트 카드"(이력서나 명함)를 발행합니다.
    2.  작업 위임: 
        *   개인 비서 에이전트가 전문가 에이전트에게 작업을 생성하고 보냅니다. MCP와 달리 A2A 작업은 종종 **자연어**로 설명됩니다 (예: "X에서 하와이까지의 저렴한 항공편과 6월 5일 동안 마우이의 호텔 옵션을 찾아줘"). 전문 에이전트는 자신의 지능을 사용하여 이 고수준 지침을 이해하고 실행합니다.
    3.  모니터링 및 결과: 
        *   위임만으로는 충분하지 않으므로 개인 비서 에이전트는 코드(의 예시 참조)를 통해 작업 상태를 확인합니다. A2A 작업은 보류(pending), 실행 중(running), 완료(completed) 또는 실패(failing)와 같은 **수명 주기**를 가집니다. 작업은 오래 실행될 수 있으며, 요청한 에이전트는 상태를 확인하고, 실행 시간을 확인하며, 심지어 **최종 완료 전에 부분 결과나 진행 상황 업데이트**를 받을 수도 있습니다.
    4.  통합: 
        *   개인 비서 에이전트는 다른 전문가로부터 받은 모든 결과(여행 계획, 활동 제안, 예산 확인 등)를 수집하여 하나의 일관된 최종 계획으로 지능적으로 결합합니다.

### **3.5 MCP와 A2A의 시너지 효과**

*   MCP와 A2A는 **경쟁자가 아니라 서로 보완적**입니다.
*   개인 비서 에이전트는 A2A를 사용하여 전문가 팀을 조정하고, 각 전문가 에이전트는 MCP를 사용하여 필요한 특정 도구에 연결합니다. (예: 여행 에이전트는 MCP를 사용하여 항공편/호텔 API에 연결하고, 예산 에이전트는 MCP를 사용하여 계산기 도구에 연결).
*   이러한 **계층적 접근 방식**을 통해 지능형 에이전트 간의 고수준 협업을 처리하는 동시에, MCP는 에이전트와 특정 비지능형 도구 간의 저수준 연결을 처리할 수 있습니다.
*   이러한 조합은 복잡하고 다면적인 문제를 해결할 수 있는 **매우 정교한 AI 시스템**을 구축할 수 있게 합니다.

### **3.6 두 프로토콜의 세 가지 주요 기술적 차이점**

"MCP는 AI를 도구에 연결하고 A2A는 에이전트를 에이전트에 연결한다"는 단순한 설명은 충분하지 않습니다. 근본적인 설계 방식에 차이가 있습니다.

1.  **통신 스타일 (Communication Style)**:
    *   **MCP**: 
        *   **구조화된 스키마**를 사용합니다. 매우 정밀한 양식을 작성하는 것과 같습니다. 통화량, 목적지 통화, 금액과 같은 매개변수를 도구 정의와 정확히 일치시켜 제공해야 합니다. 해석의 여지가 없습니다. **정확성이 필수적**인 재무 거래, 과학 계산 등 예측 가능하고 효율적인 고용량 표준화된 요청에 적합.
    *   **A2A**: 
        *   주로 **자연어**를 사용합니다. 특정 매개변수를 보내는 대신 작업 객체 내에 "100달러는 캐나다 달러로 얼마인가요?"와 같은 자연어 메시지를 보냅니다. 수신 에이전트는 자체 지능을 사용하여 요청을 이해합니다. 요청 방식에 변화가 있어도 유능한 에이전트라면 이해해야 합니다. 복잡성과 모호성에 적합하며, 정확한 함수 매개변수로 깔끔하게 떨어지지 않거나 요구 사항이 달라질 수 있는 작업에 더 적합합니다. 마치 명확한 질문이 필요하면 물어보고 요청의 변화를 처리할 수 있는 전문가와 대화하는 것과 같습니다.

2.  **작업 관리 (Task Management)**:
    *   **MCP**: 
        *   **단일 호출 작업(single-shot operations)**인 함수 호출을 기반으로 합니다. 클라이언트가 도구를 호출하고 데이터나 오류와 같은 직접적인 응답을 기대하는 빠른 단일 상호 작용에 사용됩니다. 각 호출은 독립적이고 상태 비저장(stateless)이며, 결과를 즉시 받아야 할 때 적합합니다.
    *   **A2A**: 
        *   **완전한 작업 수명 주기**를 관리합니다. 작업이 시간이 걸리고 여러 단계를 거친다는 것을 명시적으로 이해합니다. 프로토콜 자체는 보류 중, 실행 중, 완료됨, 실패와 같은 상태를 정의하며, 작업은 장기 실행될 수 있습니다. 요청하는 에이전트는 상태를 확인하고, 실행 시간을 확인하며, 결정적으로 최종 완료 전에 **부분 결과 또는 진행 상황 업데이트**를 받을 수 있습니다. 연구 작업, 보고서 생성, 하와이 여행 계획과 같이 복잡하고 다단계적인 작업에 필수적입니다.

3.  **기능 설명 (Capability Description)**:
    *   **MCP**: 
        *   종종 JSON 스키마를 사용하여 **정밀한 함수 사양**으로 기능을 정의합니다. 특정 함수의 사용 방법에 대한 상세한 기술 매뉴얼과 같습니다. 필요한 매개변수(수신자, 제목, 본문 등), 데이터 유형, 제약 조건, 필수 여부 등을 정확히 명시하며 우연에 맡기지 않습니다.
    *   **A2A**: 
        *   **에이전트 카드**라고 하는 것을 사용하여 기능을 더 **일반적으로** 설명합니다. 이름, "전문적으로 이메일 작성, 보내기 및 관리 지원"과 같은 일반적인 설명, "이메일 작성", "이메일 정리"와 같은 더 넓은 에이전트 스킬 목록을 제공하며, "후속 이메일 초안 작성" 또는 "받은 편지함 정리 지원"과 같은 처리 가능한 작업에 대한 자연어 설명 및 예시를 포함합니다. 특정 함수 목록보다는 전문 분야를 설명하는 전문적인 이력서 또는 서비스 설명과 같습니다.

*   이것은 철학의 근본적인 차이를 반영합니다. MCP는 **'어떻게'**에 초점을 맞춰 도구가 특정 미리 정의된 작업을 정확한 지침을 사용하여 수행하는 방법을 알려줍니다. 반면 A2A는 **'무엇을'**에 초점을 맞춰 에이전트가 어떤 기능을 가지고 있고 어떤 목표를 달성할 수 있는지 설명하며, 에이전트의 전문 지식을 사용하여 작업을 완료하는 가장 좋은 방법을 스스로 결정하도록 신뢰합니다.

### **3.7 결론: 언제 무엇을 사용할 것인가?**

*   이러한 차이는 MCP와 A2A가 **서로 다른 작업에 완벽하게 적합**하며 함께 사용할 때 엄청나게 강력.
*   **MCP**: 
    *   다른 AI 시스템에서 **특정 도구에 대한 안정적이고 표준화된 액세스**가 필요한 경우 환상적인 선택.
*   **A2A**: 
    *   **여러 지능형 에이전트를 포함하는 복잡한 워크플로우**를 오케스트레이션하고, 서로에게 작업을 위임하는 경우 A2A가 프레임워크를 제공합니다.
*   가장 강력한 접근 방식은 종종 **두 가지를 결합하는 것**입니다. A2A는 고수준의 에이전트 조정을 위해 사용하고, MCP는 해당 개별 에이전트가 계산기, API 호출, 데이터베이스 쿼리와 같은 **표준화된 도구를 사용하여 특정 작업을 안정적으로 실행**하는 데 사용합니다.
*   이러한 프로토콜의 장점, 약점 및 기본 철학을 이해하는 것이 핵심이며, 이를 통해 더 유능하고 견고하며 지능적인 AI 솔루션을 구축하기 위한 정보에 입각한 결정을 내릴 수 있습니다.


##  4. 인공지능(AI) 에이전트 12개를 활용하여 사회적 추론 게임을 플레이
- 출처:[I built 12 LLM Agents to Play Among Us?](https://www.youtube.com/watch?v=iViYFOdqd0Y&t=2491s)

이 프로젝트의 핵심은 인공지능(AI) 에이전트 12개를 활용하여 사회적 추론 게임을 플레이하는 것입니다. 목표는 AI가 단순히 예측 가능하거나 반복적인 행동만 하는 것이 아니라, **음모를 꾸미고, 거짓말하며, 동맹을 맺고, 서로 배신하는 등 인간과 유사한 사회적 상호작용**을 할 수 있는지 탐구하는 것이었습니다.

### 3.1 **게임 개요 및 규칙:**

*   **참가자:** 12명의 플레이어 (인간 플레이어 1명 + AI 에이전트 11명).
*   **역할:**
    *   **검은 흑막 살인자 (Blackened killers):** 3명. 비밀리에 협력하여 다른 플레이어를 제거합니다.
    *   **진실 탐구자 (Truth seeker):** 1명. 매일 밤 한 플레이어를 조사하여 무고한지 또는 검은 흑막인지 알아낼 수 있습니다.
    *   **수호자 (Guardian):** 1명. 매일 밤 한 플레이어를 보호할 수 있지만, 같은 대상을 두 밤 연속 보호할 수는 없습니다.
    *   **학생 (Students):** 7명. 무고한 시민으로, 생존하고 검은 흑막을 찾아내야 합니다.
*   **게임 진행:** 매일 밤과 낮 주기로 진행됩니다.
    *   **밤 단계:** 검은 흑막은 희생자를 선택하고, 진실 탐구자는 조사하고, 수호자는 보호합니다.
    *   **아침:** 밤 동안 무슨 일이 일어났는지 발표됩니다 (사망자 등).
    *   **학급 재판 (Class Trial):** 생존한 플레이어들이 모여 토론하고, 증거를 제시하고, 서로를 비난하거나 변호합니다. 밤에 사망자가 발생했다면 그 용의자를 찾는 데 집중합니다.
    *   **투표 (Voting):** 토론 후 모든 플레이어가 투표합니다. 가장 많은 표를 받은 플레이어는 처형되고 그의 실제 역할이 공개됩니다.
*   **승리 조건:**
    *   **팀 희망 (Team Hope - 무고한 학생, 진실 탐구자, 수호자):** 세 명의 검은 흑막을 모두 성공적으로 찾아내어 투표로 처형시키면 승리합니다.
    *   **팀 절망 (Team Despair - 검은 흑막):** 남은 팀 희망 멤버 수와 같거나 그보다 많아지면 승리합니다.
*   이 게임은 지능, 속임수, 심리적 조작의 끊임없는 싸움입니다.
*   이 프로젝트 전체 (게임, AI 프레임워크)는 **오픈 소스**로 공개되어 있습니다.

### 3.2 **단간론파 캐릭터 활용 및 AI 개발:**

*   **동기:** 기존 게임의 NPC는 종종 스크립트만 따르고 개성이 부족하여 단조롭게 느껴집니다. 개발자는 **살아있고 역동적인 AI 에이전트**를 만들고 싶었습니다.
*   **캐릭터 선택:** **단간론파** 시리즈의 캐릭터들이 사용되었습니다. 이 캐릭터들은 매우 독특하고 종종 기발한 성격, 고유한 말투, 복잡한 동기를 가지고 있어 AI 실험에 이상적인 기반을 제공했습니다.
*   **성격 구현:** AI 에이전트가 단간론파의 개성을 구현하도록 하기 위해 **풍부하고 상세한 프로필**이 필요했습니다. 이 프로필에는 배경 이야기, 핵심 성격 특성, 말투, 독특한 습관, 두려움, 동기 등이 포함됩니다. 이러한 상세한 맥락 덕분에 대규모 언어 모델이 특정 캐릭터에게 진정성 있는 응답을 생성할 수 있습니다.
*   **프로필 작성:** 초기 프로필 작성을 위해 **다른 AI(ChatGPT)**의 도움을 받았습니다. 단간론파 위키와 같은 자료를 참고하여 캐릭터별 모놀로그, 성격 요약 등을 Python 딕셔너리 형태로 생성하도록 요청했습니다. 이후 개발자가 직접 수정하고 특정 감정 상태에서의 대화 예시 등을 추가하여 **포괄적인 브리핑 문서**를 만들었습니다.
*   **시각 및 청각 요소:** 캐릭터 스프라이트(spriters-resource.com에서 수급)와 독특한 음향 효과 및 음성 클립(sounds-resource.com에서 수급)을 통합하여 경험을 더욱 역동적이고 몰입감 있게 만들었습니다.

### 3.3 **AI 아키텍처 및 데이터 관리:**

*   **핵심 AI 모델:** 각 AI 에이전트의 기반 지능은 **Google의 Gemini 2.5 Flash**를 사용했습니다. 이 모델은 추론 능력이 뛰어나고 미묘한 언어를 잘 이해하며, 11개의 AI 에이전트가 동기화되어 응답하는 데 중요한 **속도가 빠르기 때문**에 선택되었습니다. 각 AI 에이전트는 기본적으로 고유한 캐릭터 프로필을 가지고 설정된 대규모 모델의 인스턴스입니다.
*   **게임 구조:** 게임 백엔드는 거의 순수한 **Python**으로 구현되었으며, **Streamlit**이 프론트엔드 표시와 백엔드 상태 관리를 모두 처리했습니다. Streamlit은 AI 및 게임 마스터 로직에 집중할 때 인터랙티브 웹 애플리케이션을 빠르게 구축하는 데 유용합니다.
*   **상태 기계 (State Machine):** 게임 진행의 핵심은 상태 기계 개념입니다. Streamlit의 세션 상태 변수가 게임의 현재 단계(예: 밤 단계, 학급 재판, 투표 등)를 보유하며, 애플리케이션은 이 상태를 확인하여 해당 단계에 특화된 로직을 실행합니다. 예를 들어, 검은 흑막 토론 단계에서는 해당 AI 에이전트들이 비밀리에 대화하도록 관리합니다. 모든 중요한 동적 정보(현재 상태, 날짜, 생존 캐릭터, 행동 기록 등)는 Streamlit 세션 상태에 저장됩니다.
*   **정보 비대칭성 (Information Asymmetry):** 사회적 추론 게임에서 **모두가 같은 정보를 가지고 있지 않다는 것**이 중요합니다. 이를 위해 **엄격한 데이터 관리**를 통해 각 AI에게 접근 가능한 정보 흐름을 제어합니다.
*   **게임 기억:** 게임의 공식적인 기록은 **인메모리 SQLite 데이터베이스**를 사용하여 구현되었습니다. 여기에는 캐릭터의 역할, 생존 여부 등을 기록하는 테이블과 **행동 기록 (actions table)**이 있습니다. 이 테이블은 모든 비공개 생각, 공개 발언, 투표, 비밀 검은 흑막 토론 내용, 진실 탐구자의 조사 결과 등을 게임 날짜와 단계별로 타임스탬프와 함께 기록하는 핵심 요소입니다.

### 3.4 **AI 의사 결정 및 개선:**

*   **AI 의사 결정 로직:** 각 AI의 턴 또는 특정 의사 결정 시점은 자체 제작한 소형 프레임워크인 **PocketFlow**의 **노드 (node)** 개념으로 처리됩니다. PocketFlow 노드는 세 단계로 작동하며 공유 정보 저장소(Streamlit 세션 상태 및 데이터베이스 연결)와 상호 작용합니다.
    *   **전처리 (Pre-processing):** 정보 제어가 일어나는 핵심 단계입니다. 데이터베이스의 행동 기록을 **세밀하게 필터링**하여 현재 AI 에이전트가 **알아야 할 정보만**을 기반으로 **고유하고 개인화된 현실**을 구축합니다. 예를 들어:
        *   모든 AI는 자신의 **비공개 생각 기록**을 검토할 수 있습니다 (개인 일기처럼).
        *   모든 AI는 학급 재판 등 공개 단계에서의 **공개 발언 및 투표**를 볼 수 있습니다.
        *   검은 흑막 AI는 **다른 검은 흑막 팀원들의 비밀 대화와 계획**을 볼 수 있습니다.
        *   영웅(진실 탐구자, 수호자) AI는 자신의 **비밀 조사 결과나 보호 결과**를 개인적으로 통보받습니다.
        *   이러한 **세심한 필터링** 덕분에 각 AI는 **고유한 정보 관점**에서 작동하며 진정한 추론과 잠재적 속임수가 가능해집니다.
    *   **실행 (Execution):** 개인화된 기록, 캐릭터 프로필, 역할, 현재 게임 상황 등을 바탕으로 대규모 언어 모델(Gemini)에게 **풍부한 프롬프트**를 구성하여 제공합니다. AI는 이 프롬프트에 기반하여 내부 생각과 공개적인 행동(발언, 투표 등)을 생성합니다.
    *   **후처리 (Post-processing):** 대규모 모델의 출력을 처리합니다. AI의 비공개 생각은 데이터베이스에 기록되어 미래에 AI만 접근할 수 있게 되고, 공개적인 행동은 행동 기록 테이블에 기록되어 다른 AI가 다음 전처리 단계에서 볼 수 있게 됩니다. 이 과정이 AI의 움직임으로 게임 세계를 업데이트하는 루프를 완성합니다.
*   **AI 행동 개선 (In-context learning playbook):** AI가 항상 전략적으로 현명하거나 캐릭터에 일관되게 행동하는 것은 아닙니다. 이를 개선하기 위해 **프롬프트에 간결하고 상황에 맞는 전략적 힌트**를 삽입했습니다. 이 힌트는 AI의 역할과 현재 게임 단계에 맞춰져 있습니다. 예를 들어:
    *   진실 탐구자가 위험을 느낄 때: "오늘 밤 죽을 것 같다면 모든 것을 공개하라. 누가 검은 흑막이고 누가 희망으로 확인되었는지."
    *   검은 흑막이 대상을 고를 때: "누구를 죽일까? 혼란을 야기하기 위해 의심스러운 플레이어를 살려두거나, 수호자가 방금 누군가를 보호했다면 다음 밤에 그 플레이어를 다시 노리는 것도 고려해라."
    *   수호자의 보호가 성공했을 때: "아무도 죽지 않았다면 네가 보호한 대상은 희망일 가능성이 높다. 하지만 네 역할은 후반까지 비밀로 유지해라."
    *   이 힌트들은 AI가 반드시 따라야 하는 **엄격한 지침이 아니라 전략적인 조언**이며, AI는 캐릭터 프로필 및 게임 기록과 함께 이를 고려하여 **캐릭터 특성에 맞으면서도 전략적으로 흥미로운 결정**을 내리도록 유도됩니다.
*   **속도 최적화:** 11개의 AI 에이전트가 대규모 모델 호출을 순차적으로 기다리면 게임 진행이 매우 느려집니다.
    *   대화처럼 순서가 중요한 부분(검은 흑막 논의, 학급 재판 발언)에서는 AI가 순차적으로 행동해야 합니다.
    *   투표처럼 **독립적인 행동**에서는 **PocketFlow의 비동기 병렬 배치 흐름 (asynchronized parallel batch flow)** 기능을 사용하여 여러 AI가 동시에 사고하고 투표할 수 있도록 했습니다. 이는 대기 시간을 대폭 줄여 게임을 훨씬 빠르고 반응성 있게 만듭니다.
*   **플레이어 재미와의 균형 (Plot Armor):** 때때로 AI의 순수한 전략적 사고는 인간 플레이어에게 재미없는 결과(예: 게임 초반에 즉시 제거되는 것)를 초래할 수 있습니다. 이를 개선하기 위해 인간 플레이어 캐릭터(개발자가 플레이할 때)에게 약간의 **'플롯 아머 (Plot Armor)'**를 도입했습니다. 이는 검은 흑막 AI의 프롬프트에 추가된 작은 지침으로, 인간 플레이어 캐릭터를 초반에 목표로 삼지 않도록 **부드럽게 유도**합니다. 이는 AI의 전략적 최적성을 약간 제한하지만, 인간 플레이어가 실제로 게임에 참여하고 즐길 기회를 더 많이 제공하기 위한 **의도적인 조정**입니다.

### 3.5 **핵심 요약 및 결론:**

*   **인물 성격이 가장 중요:** AI 에이전트에게 풍부하고 뚜렷한 캐릭터 프로필을 제공하는 것이 고유한 행동을 이끌어내는 핵심입니다.
*   **정보 비대칭성이 핵심:** 비밀, 추론, 숨겨진 역할이 있는 게임에서 각 AI가 무엇을 알고 모르는지를 세심하게 관리하는 것이 필수적입니다.
*   **체계적인 AI 의사 결정:** PocketFlow와 같은 프레임워크를 사용하여 각 AI에게 명확하고 반복 가능한 처리 과정(전처리-실행-후처리)을 제공하면 혼란을 줄이고 개발 관리가 쉬워집니다.
*   **프롬프트 엔지니어링은 예술:** 강력한 모델을 사용하더라도 상세한 캐릭터 프로필, 개인화된 기록, 전략적 힌트 등을 포함한 완벽한 프롬프트를 만드는 것은 지속적인 개선 과정입니다.
*   **AI 우수성과 플레이어 재미의 균형:** 순수한 AI 전략이 항상 인간 플레이어에게 즐거운 경험을 제공하는 것은 아니므로, 전반적인 경험을 향상시키기 위해 AI 행동을 조정하는 디자인 결정이 필요합니다.

개발자는 AI가 전투에서 더 스마트해지는 것을 넘어 **더 풍부한 내러티브, 더 믿을 수 있는 캐릭터, 새롭고 예측 불가능한 사회적 역학**을 만들어내어 싱글 플레이어 게임조차 살아있는 것처럼 느끼게 할 수 있다고 믿습니다.

이 프로젝트는 **오픈 소스**이며, GitHub에서 코드를 다운로드하여 직접 게임을 실행하고 플레이하거나 탐구할 수 있습니다.