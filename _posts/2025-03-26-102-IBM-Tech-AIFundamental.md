---
title: 17차시 2:IBM TECH(AI Fundamental)
layout: single
classes: wide
categories:
  - IBM TECH
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 11. 엔터프라이즈 Generative AI의 실제 비용
- 출처: [What Makes Large Language Models Expensive?](https://www.youtube.com/watch?v=7gMg98Hf3uM&list=PLOspHqNVtKADfxkuDuHduUkDExBpEt3DF&index=16)


### 11.1 엔터프라이즈 Generative AI의 비용
챗GPT와 같은 소비자용 챗봇 LLM 구독을 넘어, 기업은 Generative AI 도입 시 발생하는 모든 비용 요소를 종합적으로 고려해야 합니다. 이는 단순히 모델 사용 비용뿐만 아니라 인프라 구축, 운영, 유지보수, 확장성 및 데이터 관리와 관련된 다양한 요소를 포함합니다.

### **11.2 사용 사례 (Use Case)**

*   Generative AI를 도입하기 전에 **비즈니스 목표와 기대 효과**를 명확하게 정의해야 합니다.
*   다양한 사용 사례는 서로 다른 **데이터 입력 방식**, **출력 형태**, **처리 속도**, **컴퓨팅 자원**을 요구할 수 있습니다.
*   **제안:** 초기 단계에서는 **파일럿 프로젝트**를 통해 **기대 성능과 실제 효과**를 검증하는 것이 중요합니다.  
    *   실험을 통해 문제점을 식별하고, Generative AI가 적절한 솔루션인지 평가해야 합니다.  
    *   다양한 모델을 테스트하면서 **비용 대비 성능이 가장 적합한 모델**을 선택합니다.


### **11.3 모델 크기 (Model Size)**

*   **모델의 크기와 복잡성**은 비용에 직접적인 영향을 미칩니다.  
    *   **예:** 대형 모델(수천억 개의 파라미터)은 고사양 GPU를 다량으로 요구하며, 이는 곧 높은 비용
*   모델 크기가 클수록 훈련 및 추론 과정에서 **더 많은 연산 자원**이 필요합니다.
*   벤더별로 모델 크기에 따른 **다양한 가격 정책**을 제공합니다.  
*   **핵심:** 필요 이상의 대형 모델을 선택하는 것은 불필요한 비용 증가를 초래할 수 있으므로, **사용 사례에 가장 적합한 모델**을 선택하는 것이 중요합니다.
*   **확인사항:** 벤더가 지속적으로 모델을 개선하고 최적화하고 있는지 확인하여 **미래 확장성**을 고려해야.


### **11.4 사전 훈련 비용 (Pre-training Costs)**

*   **대규모 LLM을 처음부터 구축 및 훈련하는 것**은 막대한 연산 자원과 시간이 소요됩니다.
*   **예시:** GPT-3 사전 훈련에는 1,000개 이상의 GPU가 30일 동안 사용되었으며, 비용이 약 **460만 달러 이상** (670억)소요되었습니다.
*   직접 훈련을 수행하는 대신 **이미 사전 훈련된 모델을 활용하는 것**이 비용 절감에 효과적입니다.  
    *   오픈소스 LLM (예: Llama 3, Mistral, Falcon 등) 또는 **벤더에서 제공하는 API 기반 모델**을 활용하는 것이 일반적입니다.
*   **결론:** 사전 훈련된 모델을 활용하면서 필요 시 **추가 튜닝(Fine-tuning)** 을 고려하는 것이 비용 절감

### **11.5 추론 비용 (Inferencing Costs)**

*   **추론(추론 연산, Inference)** 은 모델이 입력 프롬프트를 처리하고 결과를 생성하는 과정입니다.
*   **비용 산정 방식:** 추론 비용은 프롬프트 입력과 생성된 출력의 **토큰 수**에 따라 결정됩니다.  
    *   **토큰(Token):** LLM이 처리하는 정보 단위 (1 토큰 ≈ 3/4 단어).
*   **추론 비용을 절감하는 방법:**
    *   **짧고 효과적인 프롬프트 작성 (Prompt Engineering)**  
    *   **적절한 모델 선택** (대형 모델이 항상 최선은 아님)
    *   **캐싱(Cache) 활용** (동일한 요청 반복 시 API 비용 절감)
*   **주요 개념:**  
    *   **토큰화 (Tokenizer):** 텍스트를 모델이 이해할 수 있도록 토큰으로 변환하는 과정.  
    *   **프롬프트 엔지니어링 (Prompt Engineering):** 원하는 응답을 얻기 위해 효과적인 입력을 설계하는 기술.

### **11.6 모델 튜닝 (Tuning)**

*   기본 모델을 특정 **업무 또는 도메인**에 최적화하는 과정입니다.
*   **튜닝 비용 산정 방식:**  
    *   모델 크기에 따라 시간당 비용이 다르게 책정됩니다.
    *   **레이블 데이터 확보 비용**도 추가로 고려해야 합니다.
*   **튜닝 방법:**
    *   **미세 조정 (Fine-tuning):** 전체 모델 파라미터를 재조정하는 방식. 높은 연산 비용 발생.
    *   **PEFT (Parameter-Efficient Fine-Tuning):** 모델 변경을 최소화하면서도 성능을 최적화하는 방식 (예: LoRA, Prefix Tuning).
*   **튜닝의 장점:**  
    *   **성능 향상:** 기본 모델보다 특정 도메인에서 정확도가 개선됨.  
    *   **비용 절감:** 더 작은 모델을 최적화하여 운영 비용을 절감할 수 있음.

### **11.7 모델 호스팅 (Hosting)**

*   모델을 사용하기 위해서는 클라우드 또는 자체 서버에서 **호스팅(운영 환경 구축)** 이 필요합니다.
*   **모델 호스팅 방식:**
    *   **추론 API 사용:** 자체 모델을 호스팅하지 않고, 벤더의 API를 호출하여 모델을 사용할 경우. **토큰 기반 과금**.
    *   **직접 호스팅:** 사내 GPU 서버에서 모델을 직접 운영하는 방식. **시간 단위 또는 인스턴스 단위 과금**.
*   **확인사항:** 벤더 또는 클라우드 파트너가 **다양한 모델 호스팅 옵션을 제공하는지** 확인해야 합니다.


### **11.8 배포 (Deployment)**

*   기업의 **보안 정책, 데이터 민감도, 확장성 요구사항**에 따라 배포 방식이 달라집니다.
*   **배포 방식 비교:**
    *   **SaaS (Software as a Service):**  
        *   **장점:** 예측 가능한 구독료, 유지보수 불필요, 자동 업데이트, 확장성 보장  
        *   **단점:** 데이터 보안 및 커스터마이징 제약
    *   **온프레미스 (On-premise):**  
        *   **장점:** 데이터 보호, 보안 및 성능 최적화 가능  
        *   **단점:** 높은 초기 구축 비용 및 유지보수 부담 (GPU 서버 구매 필요)
*   **제안:** **클라우드 기반**과 **온프레미스 환경**을 모두 지원하는 **하이브리드 모델**을 고려할 수 있습니다.  
    *   벤더가 여러 배포 옵션을 제공하는지 확인하는 것이 중요합니다.

---

### **11.9 Generative AI 도입 시 고려해야 할 핵심 요소**

*   단순히 모델 구독 비용뿐만 아니라 **사전 훈련, 추론, 튜닝, 호스팅 및 배포 비용**까지 포함하여 총 소유 비용(TCO, Total Cost of Ownership)을 평가해야 합니다.
*   기업의 AI 전략과 목표에 맞는 **최적의 모델과 배포 방식**을 선택하는 것이 비용 절감의 핵심입니다.
*   **초기 도입 시 파일럿 프로젝트를 통해 실효성을 검증**하고, **점진적으로 확장하는 접근법**이 바람직합니다.


## 12. 머신러닝(ML)의 일상생활 활용 10가지 사례
- 출처: [Ten Everyday Machine Learning Use Cases](https://www.youtube.com/watch?v=CiSaY2xl9V4&list=PLOspHqNVtKADfxkuDuHduUkDExBpEt3DF&index=17)

### **12.1 머신러닝 개요**
*   머신러닝은 인공지능(AI)의 핵심 하위 분야로, 데이터로부터 학습하고 자동으로 개선되는 알고리즘과 통계 모델을 개발하는 기술
*   현재 글로벌 기술 시장에서 급속도로 성장 중이며, 산업 전반에 혁신적인 변화를 주도
*   전문가들은 2029년까지 머신러닝 시장 규모가 2,000억 달러에 도달할 것으로 전망하며, 이는 기술의 실용성과 잠재력을 반영

### **12.2 머신러닝 활용 사례**
1. **자연어 처리(NLP)**
    *   **고객 서비스:** AI 챗봇은 24시간 텍스트 기반 문의를 처리하고, 복잡한 문제의 경우 인간 상담원에게 원활하게 연결
    *   **음성 비서:** Siri, Alexa, Google Assistant 등은 자연어 이해 능력을 통해 복잡한 음성 명령을 정확하게 해석하고 실행
    *   **자동 자막:** 실시간 음성-텍스트 변환 기술로 Slack, YouTube 등 플랫폼에서 접근성과 콘텐츠 이해도 향상

2. **모바일 앱**
    *   Spotify: 개인의 음악 취향과 청취 패턴을 분석하여 정교한 개인화된 음악 추천
    *   LinkedIn: 사용자의 프로필, 경력, 관심사를 기반으로 최적화된 채용 정보 제공

3. **스마트폰**
    *   인물 사진 배경 흐림 효과: 딥러닝 모델을 활용해 피사체와 배경을 정확하게 분리
    *   얼굴 인식 잠금 해제: 3D 얼굴 인식 기술로 보안성과 편의성 동시 제공
    *   사진 라이브러리 이미지 검색: 객체 인식 기술로 사람, 장소, 사물 등 자동 태깅 및 검색

4. **금융 거래**
    *   신용카드 부정 거래 탐지: 실시간 거래 패턴 분석을 통한 이상 징후 신속 포착
    *   주식 시장 거래: 현대 금융 시장의 60~73%가 머신러닝 기반 알고리즘 트레이딩에 의존

5. **사이버 보안**
    *   지능형 위협 탐지 시스템: 네트워크 트래픽 분석을 통한 사이버 공격 예측 및 실시간 대응
    *   이상 행동 패턴 식별로 데이터 보호 강화

6. **교통**
    *   Google Maps: 실시간 교통 데이터 분석으로 최적의 경로, 소요 시간, 교통 상황 제공
    *   Uber, Lyft: 고급 매칭 알고리즘으로 운전자와 승객 간 최적의 연결 제공

7. **이메일**
    *   스팸 메일 필터링: 정교한 ML 알고리즘으로 악성 메일과 정상 메일 구분
    *   지능형 자동 완성: 사용자의 이메일 작성 패턴 학습을 통한 맞춤형 제안

8. **헬스케어**
    *   의료 영상 진단: 유방암, 폐암 등 질병의 조기 발견 및 진단 정확도 향상
    *   방사선 판독 시간 단축 및 의료진의 진단 보조
    *   개인화된 치료 계획 수립 지원

9. **마케팅/영업**
    *   데이터 기반 리드 생성 및 잠재 고객 예측
    *   검색 엔진 최적화(SEO) 전략 개발
    *   Netflix와 같은 기업의 개인 맞춤형 콘텐츠 추천 시스템

## 13. LLM 크기와 효율성 비교 분석
- 출처:[Large Language Models: How Large is Large Enough?](https://www.youtube.com/watch?v=7a2s3_wkiWo&list=PLOspHqNVtKADfxkuDuHduUkDExBpEt3DF&index=18)

### **13.1 주요 질문:** LLM은 크기가 클수록 항상 좋을까?
- **결론:** 반드시 그렇지는 않다. 특정 사용 사례에서는 도메인 특화 모델이 더 나은 선택일 수 있다.
- **비유:**
  - **공룡:** 거대한 크기에도 불구하고 멸종
  - **개미:** 작은 크기에도 불구하고 전문성과 효율성으로 번성

### **13.2 LLM의 세 가지 주요 속성 비교:**

| 속성     | 대형 모델 (예: 1750억 파라미터) | 소형 모델 (도메인 특화, 예: 130억 파라미터) | 장점                                                                   |
| -------- | ------------------------------ | ------------------------------------- | -------------------------------------------------------------------- |
| **비용**   | 284,000 kWh (학습)             | 153,000 kWh (학습)                     | 소형 모델은 학습에 필요한 CPU 시간이 1/10 수준으로 비용 효율적           |
| **지연 시간** | 느림 (예: 700억 파라미터)        | 빠름 (예: 130억 파라미터)                | 소형 모델이 대형 모델보다 3배 빠름                                        |
| **정확도** | 0.59 (금융 서비스 작업)        | 0.57 (금융 서비스 작업)                | 도메인 특화 데이터로 학습된 소형 모델은 대형 모델과 유사한 정확도를 보임 |

### **13.3 핵심 내용**

*   대형 LLM은 뛰어난 성능을 보이지만, 비용, 지연 시간, 정확도 측면에서 항상 최적은 아닐 수 있다.
*   도메인 특화 모델은 특정 분야에 특화되어 효율성과 정확도를 높일 수 있다.
*   LLM 선택 시 사용 사례를 고려하여 적절한 모델을 선택해야 한다.
*   도메인 특화 모델은 정확도, 지연 시간, 비용 측면에서 경쟁력 있는 대안이 될 수 있다.


## 14. AI 기반 UBA (User Behavior Analytics)를 활용한 내부자 위협 탐지 및 대응
- 출처:[Fight Insider Threats with AI-infused SIEM](https://www.youtube.com/watch?v=aXMPqfZt1gk&list=PLOspHqNVtKADfxkuDuHduUkDExBpEt3DF&index=19)

### **14.1 내부자 위협**

1. **문제점**
*   내부자 위협은 현대 조직의 사이버 보안에서 가장 심각하고 복잡한 리스크 중 하나로, 단순한 외부 공격과는 달리 조직 내부자의 의도적 또는 비의도적 악용으로 인해 발생한다. 평균 피해 비용이 490만 달러에 달하는 이유는 내부자 위협이 기존 보안 시스템의 방어선을 우회할 수 있기 때문이다.
*   기존 보안 시스템은 데이터 침해를 식별하고 대응하는 데 수일에서 수개월의 긴 시간이 소요되며, 이는 조직에 심각한 재정적, 평판적 손실을 초래할 수 있다.

2. **해결책**
*   AI와 머신러닝 기술을 활용한 고급 UBA (User Behavior Analytics)를 SIEM (Security Information and Event Management) 솔루션과 통합함으로써, 내부자 위협을 실시간으로 신속하고 정확하게 탐지하고 선제적으로 대응한다. 이는 단순한 모니터링을 넘어 예측적 보안 접근 방식을 구현한다.

### **14.2 UBA 작동 방식**

*   딥러닝 및 고급 머신러닝 알고리즘을 활용하여 사용자의 행동 패턴을 다차원적으로 분석한다. 네트워크 접속, 데이터 다운로드, 시스템 상호작용 등 다양한 행동 지표를 실시간으로 학습하고 평가한다.
*   최소 7일 이상의 지속적인 학습 기간 동안 개인별, 부서별, 조직 전체의 정상 행동 기준을 설정한다. 이를 통해 통계적으로 유의미한 이상 징후를 더욱 정밀하게 탐지할 수 있다.
*   QRadar SIEM과 같은 통합 솔루션은 UBA 애플리케이션을 내장하여 보안 분석가가 잠재적 내부자 위협이나 계정 탈취 상황을 즉각적으로 식별하고 대응할 수 있도록 지원한다.

### **14.3 QRadar SIEM 데모(:IBM 솔루션)**
1. **UBA 대시보드**
    *   AI 알고리즘을 통해 위험도를 다차원적으로 계산하고 우선순위가 지정된 직원 목록을 제공한다. 각 위험 점수는 다양한 행동 패턴, 시스템 접근 이력, 데이터 처리 특성 등을 종합적으로 고려한다.
    *   보안 관리자는 고위 권한 직원, 민감한 데이터 접근 그룹 등을 위한 맞춤형 감시 목록을 동적으로 생성할 수 있다.
    *   QRadar의 "오펜스" 경고 시스템은 위협의 심각성과 잠재적 영향력을 즉시 시각화한다.
    *   시간에 따른 위험 변화와 리소스별 위험 트렌드를 심층 분석할 수 있다.

2. **위험 직원 분석**
    *   개별 직원의 보안 관련 이력을 360도 관점에서 종합적으로 분석한다.
    *   관련된 모든 보안 사건(오펜스)을 연대기적으로 추적하고 상관관계를 분석한다.
    *   사용자의 이벤트 타임라인을 세분화하여 의심스러운 활동의 맥락을 정밀하게 파악한다.

3. **최근 오펜스 분석**
    *   보안 위협의 잠재적 속성을 머신러닝 기반으로 심층 분석한다.
    *   MITRE ATT&CK 프레임워크와 연계하여 공격의 전술적 기술을 자동으로 매핑하고 분류한다.
        -  MITRE ATT&CK란:사이버 공격자의 공격 전술 및 기술에 대한 지식 기반 프레임워크
    *   위협 행위자, 악성코드, 핵심 위험 자산을 신속하고 정확하게 식별한다.

4. **AI 기반 조사 가속화**
    *   구조화 및 비구조화된 대규모 데이터에서 의미 있는 인사이트를 추출한다.
    *   기존 수동 조사 방식 대비 조사 시간을 획기적으로 단축한다(수시간/수일 → 수분).
    *   보안 팀은 반응적 대응에서 벗어나 사전 예방적 보안 전략 수립에 집중할 수 있다.
    *   자연어 처리 기술을 활용한 인사이트 제공으로 복잡한 보안 이벤트를 직관적으로 이해
    *   오펜스 관계 그래프를 통해 위협의 전체적인 연결 관계를 시각화한다.
    *   인간 피드백 루프를 통해 지속적으로 AI 분석 모델을 개선하고 강화한다.

### **14.4 결론**
*   QRadar SIEM의 AI 기반 UBA 솔루션은 단순한 기술적 도구를 넘어 조직의 사이버 보안 전략을 근본적으로 혁신한다.
*   보안 분석가들은 반복적이고 지루한 수동 작업에서 해방되어, 더욱 전략적이고 창의적인 보안 대응에 집중할 수 있게 된다.
*   궁극적으로는 조직의 디지털 자산을 보호하고, 잠재적 위험을 미연에 방지하는 지능형 보안 생태계를 구축할 수 있다.