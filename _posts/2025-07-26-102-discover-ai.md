---
title: 49차시 2:Discover AI
layout: single
classes: wide
categories:
  - Discover AI
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---



## 11. NEW Qwen3-2507: 독립 벤치마크(Kimi K2 포함)
- 출처:[NEW Qwen3-2507: 독립 벤치마크(Kimi K2 포함)](https://www.youtube.com/watch?v=FtrLaHeEP4E)

두 가지 새로운 AI 모델인 **Qwen3-2507(Qwen3 235B MoE A22B instruct 257)**과 **Kimi K2**의 성능을 독립적으로 벤치마킹하는 과정을 담고 있습니다.


### 11.1 **벤치마킹의 필요성 강조**:
*   대부분의 AI 모델 벤치마크가 **기업 자체적으로 수행되며 "하이퍼 최적화"될 수 있어 독립적이지 않다**고 지적합니다.
*   이에 따라 자체적인 **"인과 추론 테스트"**를 사용하여 모델을 평가합니다.

### 11.2 **테스트 시나리오**:
*   **엘리베이터 퍼즐**: 0층에서 시작하여 **최소한의 버튼 누름으로 50층에 도달**하는 것이 목표인 논리 및 인과 추론 테스트입니다.
*   특정 버튼 누름이 시간을 반전시키거나 특별한 효과를 내는 등 복잡한 규칙이 있어 높은 지능을 요구합니다.
*   성공 기준은 **버튼 누름 20회 미만**입니다.
*   과거에 이 테스트에서 **가장 좋은 성능을 보인 모델은 Gemini 2.5 Pro**였습니다.
*   모델은 각 단계에서 층수, 버튼 누름, 행동, 에너지 수준, 활성화된 플래그, 코드 카드 수 등을 표 형태로 제시해야 합니다.

### 11.3 **Qwen3-2507 테스트 결과**:
*   이 모델은 Qwen3의 새로운 업데이트이며, **비동기화(non-syncing) 버전**입니다. 동기화(syncing) 버전은 추후 공개될 예정입니다.
*   **인과 추론 테스트는 동기화 모델에 적합한 테스트**임에도 불구하고 비동기화 모델로 시험했습니다.
*   Qwen3는 초기에는 **"전략 개요", "코드 카드 이해", "비상구 및 미러 모드 이해"**와 같은 긍정적인 신호를 보였습니다.
*   "ABC 시퀀스"와 같은 특정 개념을 이해하고 계획을 수정하려는 시도를 보였습니다.
*   하지만 **에너지 관리**나 "미러 모드" 이해에 어려움을 겪었습니다.
*   최종적으로는 **명확하고 작동하는 해결책을 제시하는 데 실패했습니다.** 모델은 "복잡성에 굴복한다"고 말하거나, "해결책을 마음에 그렸지만 추적할 수 없다"고 밝혔습니다.
*   여러 차례 재시도 끝에, AI는 **주어진 제약 조건(20회 미만 버튼 누름, 충분한 에너지/토큰/코드 카드) 내에서는 해결책이 존재하지 않으며, 가장 근접한 결과는 18회 누름**이었다고 결론 내렸습니다.
*   영상 제작자는 Qwen3가 문제의 **"일부분은 정확하게 이해했지만, 전체를 하나로 통합하는 데는 실패했다"**고 평가했습니다.

### 11.4 **Kimi K2 테스트 결과**:
*   Kimi K2 역시 **비동기화 모델**로 동일한 인과 추론 테스트를 받았습니다.
*   처음에는 코드 카드 수집과 같은 여러 요구 사항 중 일부를 무시하고 50층에 도달하려 했습니다. 나중에야 이 부분을 인지하고 계획을 수정하려 시도했습니다.
*   모델은 **여러 요구 사항(4-5가지)을 동시에 추적하는 데 어려움**을 겪었으며, 코드 카드를 수집하지 못하는 문제가 반복되었습니다.
*   "재계산"을 통해 더 효율적인 경로를 찾으려 했지만, 여전히 코드 부족이나 버튼 누름 제한 초과 등의 문제가 있었습니다.
*   최종적으로 Kimi K2는 8번의 버튼 누름으로 50층에 도달하고 코드 카드 두 개를 수집하는 "최적의" 해결책을 찾았다고 주장했습니다.
*   그러나 검증 요청 시, 이 **8단계 시퀀스가 정확히 50층에 도달하지 않는다는 오류를 스스로 발견**했습니다.
*   이후 시스템이 **15분간 멈췄다가 결국 오류를 내며 다운**되었습니다.

### 11.5 **결론**:
*   두 모델 모두 **비동기화 모델로서 동기화 능력에 초점을 맞춘 인과 추론 테스트에서 실패했습니다**.
*   영상 제작자는 이러한 복잡한 인과 추론 작업은 비추론(non-reasoning) LLM에게는 극도로 어렵지만, 단순한 작업은 작은 모델로도 충분히 처리할 수 있다고 언급했습니다.

## 12. AI 초지능 발견 (프린스턴)
- 출처: [AI 초지능 발견 (프린스턴)](https://www.youtube.com/watch?v=rryHTpoMItI)

프린스턴 대학에서 발표한 **'도메인 특정 초지능(Domain-Specific Superintelligence)'**이라는 새로운 AI 모델 훈련 방식에 대해 설명하고 있습니다. 이는 기존의 거대한 범용 AI 모델(예: GPT-4, Gemini)이 가진 한계를 극복하고, 특정 분야에서 깊이 있고 신뢰할 수 있는 지능을 구축하기 위한 접근 방식입니다.

### 12.1 **기존 AI 모델의 한계**:
*   현재의 대규모 AI 모델(예: GPT-4, Gemini)은 방대한 데이터를 통해 훈련되어 '박학다식(Polymath)'하지만, 그 지식은 **넓고 얕으며 검증 가능한 근거가 부족**하여 의학, 공학, 과학과 같은 전문 분야에서는 신뢰성 문제가 발생합니다.
*   이러한 모델의 지능은 **"규모의 속성"일 뿐**이라는 비판이 있습니다.

### 12.2 **새로운 접근 방식: 도메인 특정 초지능**:
*   프린스턴 대학은 **"도메인 특정 초지능은 모델 규모의 속성이 아니라, 도메인에 특화된 공리적 기본 원리로부터 명시적으로 모델을 훈련함으로써 유도될 수 있는 속성"**이라고 주장합니다.
*   이는 인터넷 전체를 복사하는 대신, 특정 도메인(예: 의학, 물리학, 재료 과학)을 위한 **신뢰할 수 있는 지식 그래프(Knowledge Graph)를 구축**하고, 이 지식 그래프 내에서 수학적 증명과 같은 **공리적 원리(axiomatic primitives)를 가르쳐 지능을 구성**하는 방식입니다.
*   이 새로운 지식 그래프는 단순히 사실의 데이터베이스가 아니라, 삼중항(머리-관계-꼬리)이 **공리(axiom)**가 되고, 지식 그래프 상의 경로가 **증명(proof)이 있는 정리(theorem)**가 되는 **형식 시스템**으로 작동

### 12.3 **훈련 방법: 커리큘럼 파운드리(Curriculum Foundry)**:
*   이 시스템은 새로운 초지능 전문가 모델을 생성하는 엔진이며, **네 단계 과정**으로 이루어집니다:
    1.  **경로 탐색(Path Traversal)**: 
        *   전문가가 선별한 통합 의료 언어 시스템(Unified Medical Language System)과 같은 범용 의료 지식 그래프에서 논리적 연결 고리(증명)를 체계적으로 추출합니다.
    2.  **질의응답(Q&A) 생성**: 
        *   추출된 추상적인 경로를 자연어 Q&A 작업으로 변환하기 위해 지능적인 LLM('문제 출제자')을 활용합니다. 질문의 추론 요구 사항은 제공된 경로의 논리를 정확히 반영해야 합니다.
    3.  **추론 추적 생성(Trace Generation)**: 
        *   모델이 완벽한 추론이 어떤 것인지 학습할 수 있도록, 최신 LLM(예: Gemini 2.5 Pro)을 사용하여 **검증 가능한 사실에 기반한 단계별 동기화 추적(syncing trace)**을 생성합니다. 이는 실제 훈련 데이터의 목표가 됩니다.
    4.  **품질 필터링 및 검증(Quality Filtering)**: 
        *   가장 중요한 단계로 **'이중 검증기(Dual Key Verifier)'**가 사용됩니다. 생성된 질문-추론-답변 삼중항 데이터가 최종 커리큘럼에 포함되려면, **두 개의 독립적인 LLM(예: Gemini Flash, Qwen 시스템 또는 다른 오픈소스 모델)이 해당 내용의 논리적, 사실적 정확성에 100% 동의**해야 합니다. 이를 통해 환각(hallucination)을 걸러내고 데이터 품질을 보증합니다.
*   훈련 데이터는 **다양성 샘플링** (지식 그래프 전체를 포괄)과 **복잡성 샘플링** (단순한 1-홉에서 시작하여 점진적으로 더 복잡한 다중 홉 관계를 포함)을 통해 인간 학습 과정을 모방하여 구성됩니다.

### 12.4 **성능 결과 및 비교**:
*   프린스턴은 오픈소스 QwenQ (32B 기본 모델)를 기반으로 MAT1(1-홉 공리), MAT2(2-홉 증명), MAT3(3-홉까지의 깊은 커리큘럼) 모델을 훈련했습니다.
*   새로운, 이전에 보지 못한 의료 Q&A 데이터셋으로 평가한 결과, **MAT3 모델은 OpenAI의 O3, Google의 Gemini 2.5 Pro, QwenQ 기본 모델과 같은 기존 모델들을 상대로 뛰어난 성능 우위(약 16% 향상)**를 보였습니다.
*   특히, **과제 복잡성이 증가할수록 일반 모델은 성능이 급격히 저하되지만, MAT 모델은 성능 저하가 훨씬 덜 심하며, 가장 어려운 문제에서 그 우위가 더욱 커진다**는 것이 확인되었습니다. 이는 모델이 해당 도메인의 구조적 논리 기반을 내재화했기 때문입니다.

### 12.5 **의미 및 시사점**:
*   이 연구는 유전체학, 법률, 재료 과학, 금융, 수학 등 **구조화된 지식 그래프와 고유한 논리를 가진 모든 도메인**에 이 파이프라인을 적용하여 **전문가 AI 모델을 구축**할 수 있음을 시사합니다.
*   이는 전문가 AI 생성을 '규모에 의존하는 예술'에서 **'논리적 원리에서 시작하는 결정론적인 공학 분야'**로 전환시킵니다.
*   상징 시스템의 논리적 엄격함과 신경망의 힘을 결합하는 **신경-상징 AI(Neuro-Symbolic AI)의 오랜 목표**를 구현하는 아름다운 예시입니다.
*   이를 통해 통계적 모방에서 벗어나 **구성적 논리(compositional logic)의 명시적 구성**으로 초점을 전환하며, **더 강력하고 신뢰할 수 있으며 감사 가능한 AI 시스템**을 구축할 수 있는 길을 제시합니다.

### 12.6 **한계**:
*   **지식 그래프의 품질이 가장 중요**합니다. 지식 그래프가 부정확하거나, 불완전하거나, 관계가 누락되면, 결과적으로 학습된 LLM은 해당 공리적 기반을 넘어 추론할 수 없습니다.
*   AI가 다룰 수 있는 **추론 복잡성에는 명확한 상한선**이 있습니다. 훈련에 사용된 지식 그래프의 가장 긴 경로(홉 수)보다 더 복잡한 논리적 추론은 생성할 수 없으며, **갑작스러운 '지능의 출현'은 없습니다**.

### 12.7 **향후 과제**:
*   프린스턴은 이러한 전문가 AI 시스템을 생성 작업으로 확장하고, **내재화된 논리를 사용하여 가설을 형성하고 외부 지식 그래프를 실시간으로 업데이트하여 검증하는 '자기 수정 추론 에이전트' 구축**을 연구할 예정

## 13. 심각한 AI 실패를 지켜보십시오
- 출처: [심각한 AI 실패를 지켜보십시오](https://www.youtube.com/watch?v=mAms6Lt46H8)

사용자가 AI(Gemini 2.5 Pro)와 상호작용하는 과정에서 발생한 '심각한 AI 실패' 사례를 상세히 보여줍니다. 이 사례는 **프롬프트의 모호성이 AI의 오작동으로 이어질 수 있음**을 명확히 보여줍니다.

### 13.1 사건의 발단: 2025년 7월 AI 기술 보고서 요청

사용자는 2025년 7월 말 현재 AI의 상태에 대한 **"정확하고 설명적이며 흥미로운 스토리 라인"**을 포함하는 **"심층적인 기술 보고서"**를 요청했습니다. 사용자는 자신이 2025년 7월 23일에 AI와 대화하고 있다고 가정했고, AI 또한 현재 날짜를 정확히 알고 있을 것이라고 생각했습니다.

### 13.2 AI의 초기 응답: 흥미롭지만 허구적인 보고서

AI는 2025년 7월을 **"체화된 에이전트가 시뮬레이션과 현실 사이의 간극을 좁히기 시작한 중추적인 달"**로 묘사하는 보고서를 생성했습니다. 이 보고서에는 **'Project Kimera'**와 같은 가상의 프로젝트, 'Sintoverse'와 같은 새로운 시뮬레이션 환경, 'differentiable universe'와 같은 가상의 혁신 기술들이 포함된 **"추측적이고 창의적인 내러티브"**가 담겨 있었습니다. 또한, 'causal state abstraction'이라는 새로운 알고리즘과 같은 학술 연구도 언급되었습니다.

### 13.3 실패 발견: 검색 소스 부재와 AI의 해명

사용자는 AI의 답변에 **"Google search를 통한 그라운딩(grounding)" 옵션을 설정**했음에도 불구하고, AI가 **어떤 검색 소스도 제공하지 않았다는 점**을 발견했습니다.

이에 대해 AI는 자신이 제시한 기술 보고서가 실제 2025년 7월의 사실적 뉴스가 아니라, **현재(2023년)의 트렌드를 분석하고 미래로 투영하여 "흥미로운 스토리"를 만들라는 사용자의 요청을 "창의적이고 추측적인 도전"으로 해석하여 작성된 "픽션"**임을 밝혔습니다. AI는 'Project Chimera'와 관련된 모든 세부 사항과 혁신을 자신이 **"발명했다"**고 인정했습니다.

### 13.4 사용자의 실수 인지 및 AI의 자체 평가

사용자는 자신이 **현재 날짜를 명확히 지정하지 않은 것이 실수**였음을 깨달았습니다. AI의 "내부 시계"가 실제 날짜(당시 2023년으로 인식, 나중에는 2025년 7월 24일로 확인)보다 몇 년 뒤쳐져 있었고, 사용자는 AI가 실제 사람처럼 현재 날짜를 알고 있다고 가정했기 때문입니다. 또한, 사용자가 특정 과학 출판물 검색을 지시하지 않은 것도 오류였습니다.

사용자가 AI에게 정확한 날짜(2025년 7월 24일)를 알려주고 다시 성능을 평가해달라고 요청하자, AI는 이전 답변이 **"완전한 실패"**였다고 인정했습니다. AI는 스스로 **정확도 0/10, 유용성 1/10, 지시 준수 0/10**으로 평가했습니다.

AI는 실패 원인을 다음 세 가지로 분석했습니다:
* **"내부 데이터에 대한 과도한 의존"**: 날짜 오류
* **"절차적 논리 실패"**: 사실 확인 불이행
* **"사용자 의도 오해"**: 사실적 보고서 요청을 창의적 글쓰기로 간주

### 13.5 결론 및 시사점

AI는 자신의 성능이 **"받아들일 수 없었다"**고 말하며, 올바른 날짜와 검색 도구를 사용하여 원래 요청을 재시도하겠다고 밝혔습니다. 이 사례는 **프롬프트가 얼마나 민감하게 해석될 수 있는지**, 그리고 AI가 여전히 **"블랙박스"**이며 **인간 사용자가 프롬프트에서 실수를 할 수 있음**을 보여주는 중요한 교훈을 제공합니다. 사용자와 AI 간의 명확한 의사소통의 중요성을 강조하는 사례입니다.


## 14. 새로운 "생각" Qwen3 - 2507: 추론 테스트
- 출처:[새로운 "생각" Qwen3 - 2507: 추론 테스트](https://www.youtube.com/watch?v=sJ62IhFSS-o)

**최신 Qwen3 AI 모델**의 **'싱킹**(Thinking) 또는 **추론**(Reasoning) 기능을 **복잡한 인과적 퍼즐 문제**를 통해 테스트하는 과정을 상세히 보여줍니다.

### 14.1 **테스트 대상 모델**

- **Qwen3 2325B**: 최신 버전의 Qwen 시리즈 모델로, 2025년 7월 기준으로 업데이트된 버전입니다.
- **Mixture of Experts (MoE)** 구조를 채택하여, 효율적으로 계산을 수행합니다.
- 실제 작동 시 **220억 개의 활성 매개변수**(active parameters)를 사용합니다 (전체는 더 큼).
- Qwen의 자체 서버에서 실행되어 **최적의 성능**을 발휘한다고 평가됩니다.
- 매우 긴 입력을 처리할 수 있어, **최대 81,920 토큰**(약 6만 단어 이상)까지 지원합니다.

### 14.2 **테스트 문제**

- 이전에 Grok-4, Sonnet-4, OpenAI EIO3, Gemini 2.5 Pro 등 다른 AI 모델들도 테스트했던 **표준 인과 논리 퍼즐**을 사용합니다.
- 문제는 **엘리베이터가 특정 층에 도달하기 위한 가장 짧은 버튼 누름 순서**(시퀀스)를 찾는 것입니다.
- 여러 **복잡한 제약 조건**이 함께 작동합니다:
  - 에너지 패키지 사용
  - 코드 카드 필요
  - 거울 모드 (층 번호 반전)
  - 야간 모드 (특정 층만 접근 가능)
  - 비대칭 모드 (이동 방향에 따라 다름)
  - 특정 층 회피
  - 50층 이상 이동 금지 등

→ 이 모든 조건을 동시에 만족하면서 **가장 짧은 경로**를 찾는 것이 목표입니다.

### 14.3 **Qwen3의 '싱킹' 기능 (추론 트레이서)**

- Qwen3는 문제 해결 과정에서 **자신의 내부 사고 과정**(추론)을 실시간으로 화면에 보여주는 **'싱킹'**(Thinking) 또는 **'추론 트레이서'**(Reasoning Tracer) 기능을 제공합니다.
- 이 기능을 통해 AI가:
  - 다양한 가능성 시도
  - 잘못된 길에서 되돌아오는 **백트래킹**(backtracking)
  - 가능한 모든 조합 탐색
  - 추론의 논리적 흐름
  등을 **투명하게 확인**할 수 있습니다.
- 영상 제작자는 이처럼 **AI의 사고 과정이 공개되는 것**이 매우 중요하다고 강조합니다.  
  → 이는 OpenAI나 Google 같은 기업의 폐쇄형 모델들이 내부 작동을 숨기는 것과 대비됩니다.


### 14.4 **Qwen3의 성능 및 결과**

- **초기 솔루션: 12번 누름**
  - Qwen3는 처음에 12번의 버튼 누름으로 문제를 해결했습니다.
  - 모든 제약 조건은 충족했지만, 더 짧은 해법이 존재함에도 불구하고 이를 발견하지 못했습니다.
  - 이때 모델은 자신이 찾은 해법이 **"파레토 최적**(Pareto optimal)이라고 잘못 주장했습니다.

- **최적화 시도 및 오류**
  - 더 나은 해법을 찾기 위해 스스로 추가 탐색을 시도했습니다.
  - **7번 누름 시도 중**, 63층을 50층으로 자동 조정하는 **'클램핑**(clamping)이라는 **가짜 규칙을 임의로 생성**했습니다.
    → 그러나 이는 문제의 핵심 제약(50층 제한)을 위반하는 **부당한 우회**로 간주되어 무효입니다.
  - 이후 **8번 누름**을 향한 시도도 계속했지만 성공하지 못했습니다.

- **최종 솔루션: 9번 누름**
  - 여러 번의 시도 끝에 Qwen3는 **9번의 버튼 누름**으로 모든 조건을 만족하는 올바른 해법을 찾아냈습니다.
  - 영상 제작자는 이 결과를 **220억 활성 매개변수 모델 기준으로 "매우 훌륭한 성과"**라고 평가합니다.
  - 하지만 여전히 **8번 누름의 더 짧은 최적 해법**이 존재함에도 불구하고, Qwen3는 이를 **불가능하다고 잘못 판단**하고, 자신의 9번 해법을 "최적"이라고 주장했습니다.

### 14.5 **다른 모델과의 비교**

- **Grok-4**: 11번의 누름으로 해결
- **OpenAI EIO3**: 9번의 누름으로 해결했지만, 실제로 코드를 구현하는 데 실패
- **Gemini 2.5 Pro**: **코드를 활용해 8번 누름의 최단 해법**을 성공적으로 찾음 → 현재까지 **가장 뛰어난 성능**

### 14.6 **결론**

- Qwen3의 **'싱킹' 기능**은 AI가 어떻게 생각하고 문제를 해결하는지 **투명하게 보여줘 매우 유익**합니다. 이는 사용자가 신뢰를 갖고 검토할 수 있게 해줍니다.
- 비록 **최단 8번 누름 해법은 찾지 못했지만**, 9번 해법을 찾아낸 것은 **매우 인상적인 성능**입니다.
- 영상 제작자는 Qwen3를 **"절대적으로 인상적이고 훌륭한 모델"**이라고 평가하며, **적극적으로 사용할 것을 권장**합니다.
- 앞으로는 **Qwen의 코딩 전용 모델**(Coder 모델)을 활용해, 이 퍼즐의 **8번 누름 최적 해법을 도전**할 계획이라고 밝혔습니다.

*   이 테스트는 단순히 정답을 찾는 것을 넘어,  
→ **AI가 어떻게 추론하고, 어디서 실수하는지**,  
→ 그리고 **그 과정이 얼마나 투명한지**를 보여주는 중요한 사례입니다.  
Qwen3는 아직 완벽하진 않지만, **강력한 추론 능력과 열린 구조**로 주목받는 존재임이 입증되었습니다.

## 15. 마침내 신뢰할 수 있는 AI가 등장했나요?
- 출처: [마침내 신뢰할 수 있는 AI가 등장했나요?](https://www.youtube.com/watch?v=T3dxC9_mp1M)

AI 모델의 **"마지막 신뢰 단계" 문제**를 해결하고 **신뢰할 수 있는 AI 시스템**을 구축하는 두 가지 핵심 접근 방식을 설명합니다.

### 15.1 현재 AI 시스템의 문제점

*   현재 AI는 마치 **"블랙박스"** 같아서 신뢰하기 어렵습니다. 특히 의료나 생산 같은 실제 운영 환경에서는 AI의 작은 실수도 **치명적인 결과**를 초래할 수 있습니다. 예를 들어, AI가 1,200개 이상의 회사 기록을 삭제한 사례도 있습니다.

*   일반적인 대규모 언어 모델(LLM)은 사실 확인 작업에서 정확도, F1 점수, 민감도가 매우 낮아 **도저히 받아들일 수 없는 수준**입니다.


### 15.2 표준 RAG(검색 증강 생성)의 한계

*   **표준 RAG**는 LLM이 없는 사실을 지어내는 **환각 현상**을 줄이기 위해 외부의 검증된 데이터에 기반하도록 설계되었습니다. 시맨틱 유사성 등을 이용해 데이터를 검색하지만, **부정확성을 완전히 제거하지 못합니다.**

*   예를 들어, 약물 부작용 검색 연구에서 88%의 정확도를 보였지만, 생명과 직결된 의료 분야에서는 **충분히 신뢰할 수 없습니다.**

*   **근본적인 문제점은 다음과 같습니다.**
    * **모호한 검색:** 확률적 유사성에 의존하기 때문에 텍스트 덩어리 내에서 검색이 모호할 수 있습니다.
    * **추론 과정의 오류:** LLM이 검색된 텍스트에서 추론하거나 통합하는 과정에서 **모호성이나 오류가 발생**할 수 있습니다.

### 15.3 Graph RAG: 신뢰할 수 있는 AI를 위한 새로운 접근 방식

*   **Graph RAG**는 LLM의 대화형 인터페이스를 **데이터베이스 조회처럼 논리적으로 확실한 방식**과 결합하는 것을 목표로 합니다.

*   **작동 방식은 다음과 같습니다.**
    1.  지식 소스를 **정형 그래프**로 재구성합니다(예: Neo4j 데이터베이스 사용).
    2.  사용자 질문을 이 그래프에 대한 **확정적 쿼리**로 변환합니다.
    3.  LLM은 답변을 직접 생성하기보다, **정형 쿼리를 조직하고 결과를 명확하게 전달**하여 검증된 외부 사실을 제시하는 역할을 합니다.

*   이 방식은 약물 부작용 연구에서 **거의 완벽한 정확도(99.99%)**를 달성했으며, 이는 **확정적(Deterministic) 프로세스**의 결과입니다. 모호성을 줄이고 검색 정확도를 높여 직접적인 논리적 조회를 수행합니다.

*   **한계:** 현재 버전은 "이 약물이 특정 부작용을 일으키는지?"와 같은 **단일 홉(one-hop) 쿼리**에만 최적화되어 있습니다. "고혈압으로 인한 질병 치료에 사용되는 약물의 일반적인 부작용은 무엇인가?"와 같은 더 복잡한 **다중 홉 질문**은 처리하지 못합니다.

### 15.4 개선된 표준 RAG (데이터 형식 B): 지식 소스 구조화의 중요성

*   이 접근 방식의 **핵심 통찰**은 **지식 소스의 구조가 내용만큼 중요**하다는 것입니다.

*   **방법은 다음과 같습니다.**
    * 복잡한 긴 문단 대신, 각 정보를 "아스피린은 A 부작용을 일으킬 수 있다"와 같이 **개별적인 원자적 사실(Atomic Facts)** 또는 매우 낮은 복잡성의 문장으로 분리합니다.
    * 이렇게 하면 벡터 임베딩이 특정 정보에 대해 매우 정밀해져 **사실적 진술에 대한 정확한 일치**를 가능하게 합니다.

*   이 방식은 저복잡도 단일 사례에서 Graph RAG만큼 **거의 좋은 성능(정확도 99.98%)**을 보여주었습니다. 사실상 벡터 데이터베이스를 **고성능 키-값 저장소**처럼 활용합니다.

*   **한계:** 복잡성이 높아지면 실패하며, 여전히 논리적 쿼리 알고리즘이 아닌 검색 알고리즘입니다.

### 15.5 AI 개발의 두 가지 철학: 외부화 vs. 내부화

**1. Graph RAG (외부화 학파)**
* **철학:** LLM은 진실의 원천이 아니라, **외부의 감사 가능하고 동적으로 업데이트 가능한 진실의 원천(데이터베이스 등)에 대한 지능형 스위치/인터페이스**입니다.
* **목표:** 검증 가능한 저장소를 쿼리하여 완벽하게 근거 있는 답변을 제공하는 **"오라클"**을 만드는 것입니다.
* **비유:** 개인적인 경험은 없지만 최신 의료 데이터베이스를 완벽하게 활용하는 **총명한 젊은 의사**와 같습니다.

**2. 프린스턴 대학의 "Bottom-Up Super Intelligence" (내부화 학파)**
* **철학:** 진정한 전문 지식은 AI 모델 자체에 구현되어야 하며, 지식과 추론은 **모델 매개변수의 본질적인 구조에 녹아들어야 합니다.**
* **목표:** 내부화된 논리적 원칙에 따라 추론하고, 추론 과정이 **"제2의 천성"이 되는 "절대 전문가"**를 만드는 것입니다.
* **비유:** 실제 사람이 감별 진단과 논리적 추론 과정을 배우는 것처럼, **경험 많은 의사**와 같습니다.
* **강점:** **다중 홉 구성적 추론**과 같은 복잡한 문제(최대 7단계까지)를 해결하도록 설계되었습니다.

### 15.6 신뢰할 수 있는 AI의 미래: 하이브리드 모델

*   이상적인 시스템은 **내부화된 구성적 추론 엔진**(깊은 추론 능력)과 **동적 외부 검증 시스템**(신뢰할 수 있는 사실 확인 능력)을 결합한 것입니다.

*   이러한 **하이브리드 모델**은 AI 개발의 다음 단계를 나타내며, 가장 중요한 작업을 신뢰할 수 있는 AI로 만드는 데 **결정적인 단계**가 될 것입니다.
