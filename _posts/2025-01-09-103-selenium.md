---
title: 1차시 3(빅데이터 분석):Selelium 
layout: single
classes: wide
categories:
  - web scraping
tags:
  - html
  - beautifulsoup
  - selenium
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. 셀레늄 (Selenium) 웹 자동화: 웹사이트를 로봇처럼 조종하기

여러분, 웹사이트에서 반복적으로 해야 하는 작업들(로그인, 버튼 클릭, 정보 입력, 스크롤 등)이 너무 귀찮을 때 없으셨나요? 또는 어떤 웹사이트는 특정 버튼을 눌러야만 숨겨진 정보가 나타나는 경우가 있죠? 이럴 때 우리 대신 웹사이트를 조작해 줄 똑똑한 도구가 바로 \*\*셀레늄(Selenium)\*\*입니다\!

### 1.1. 셀레늄이 뭐예요?

셀레늄은 파이썬으로 웹사이트를 **사람처럼 조종**하고 필요한 정보를 찾아오는 강력한 도구예요.

  * **웹사이트와 직접 놀아줘요!**

      * 이전에는 웹사이트에 "정보 보여줘\!" 하고 요청만 보내고 받은 HTML 코드(웹사이트의 설계도)를 분석해서 데이터를 얻었어요. 이걸 "클래식 웹 스크래핑"이라고 불러요. (마치 웹사이트에 편지만 보내는 것과 같죠.)
      * 하지만 셀레늄은 달라요. 마치 실제 사람이 웹 브라우저(크롬, 파이어폭스 등)를 열고, 마우스로 클릭하고, 키보드로 글자를 입력하고, 페이지를 아래로 스크롤하는 것처럼 **웹사이트와 직접 상호작용**해요. 이걸 "인터랙티브 웹 스크래핑"이라고 해요.

  * **언제 셀레늄이 필요할까요?**

      * **숨겨진 정보 찾기:** 어떤 웹사이트는 여러분이 스크롤을 내리거나, 특정 버튼을 클릭하거나, 마우스를 올려놓아야만 정보가 나타나는 경우가 있어요. 클래식 스크래핑으로는 이런 정보를 가져올 수 없지만, 셀레늄은 가능해요!
      * **웹 게임 자동화:** 웹 기반 게임에서 반복적인 클릭이나 조작을 대신 해주는 '봇'을 만들 때도 셀레늄이 필요해요.
      * **자동 로그인, 게시글 작성:** 매번 같은 아이디/비밀번호를 입력하고 게시글을 쓰는 등의 반복 작업을 자동화하고 싶을 때 유용해요.
      * **웹사이트 기능 테스트:** 개발자가 웹사이트의 버튼들이 잘 작동하는지, 로그인 과정에 문제가 없는지 등을 자동으로 테스트할 때도 사용해요.

### **1.2. Selenium의 기본 개념**
Selenium은 웹 브라우저를 자동화하여 동적 콘텐츠를 포함한 웹 페이지와 상호작용

- **WebDriver**: 브라우저를 제어. selenium 4부터 자동으로 chrome을 설정(수동 다운로드 불필요)
- **요소 선택**: `find_element`와 `find_elements`를 사용하여 HTML 요소를 찾는 방법.
- **동작 수행**: 클릭, 입력, 스크롤 등의 기본 동작.
- **대기(Wait)**: 페이지 로딩이나 요소가 나타날 때까지 기다리는 방법.


## 2. **로그인(login) 연습**
로그인 페이지에서 사용자 이름과 비밀번호를 입력하고 로그인 버튼을 클릭하는 방법을 연습할 수 있습니다.

### 2.1 자동 로그인 실습 사이트

*   URL: [https://the-internet.herokuapp.com/login](https://the-internet.herokuapp.com/login)

```python
from selenium import webdriver
from selenium.webdriver.common.by import By

# WebDriver 설정, 

driver = webdriver.Chrome()

try:
    # 로그인 페이지 접속
    driver.get("https://the-internet.herokuapp.com/login")

    # 사용자 이름과 비밀번호 입력
    username_input = driver.find_element(By.ID, "username")
    password_input = driver.find_element(By.ID, "password")

    username_input.send_keys("tomsmith")  # 올바른 사용자 이름
    password_input.send_keys("SuperSecretPassword!")  # 올바른 비밀번호

    # 로그인 버튼 클릭
    login_button = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
    login_button.click()

    # 로그인 성공 메시지 확인
    success_message = driver.find_element(By.ID, "flash").text
    print(success_message)

finally:
    # WebDriver 종료
    driver.quit()
```

### 2.2 **학습 포인트**
1. **웹 요소 조작**: `find_element`와 `send_keys`, `click`을 사용하여 입력 필드에 데이터를 입력하고 버튼을 클릭하는 방법 학습.  
2. **데이터 추출**: `text` 속성을 활용해 웹 페이지에서 텍스트 데이터를 추출하고 결과를 확인하는 방법 익히기.  
3. **특정 요소 선택**: `By.ID`, `By.CSS_SELECTOR` 등 다양한 로케이터 전략을 사용하여 원하는 웹 요소를 정확히 선택하는 기술 습득.  
4. **자동화 프로세스 구현**: 로그인과 같은 일련의 작업을 자동화하여 실용적인 웹 상호작용을 구현하는 방법 학습.  
5. **리소스 관리**: `try-finally` 구문과 `driver.quit()`을 통해 WebDriver 세션을 안전하게 종료하고 리소스를 정리하는 중요성 이해.


## **3. 데이터 수집 연습**

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

# ChromeDriver 설정
driver = webdriver.Chrome()

try:
    # Wikipedia 접속
    driver.get("https://en.wikipedia.org/wiki/Squid_Game_season_2")
    time.sleep(2)  # 페이지 로딩 대기

    # 제목과 내용 추출
    title = driver.find_element(By.TAG_NAME, "h1").text
    contents = driver.find_elements(By.CSS_SELECTOR, "#mw-content-text p")
    print(f"제목: {title}")
    for i, content in enumerate(contents):
        if i in [1, 2]:
            print(content.text)       

finally:
    # WebDriver 종료
    driver.quit()

```

### 3.1 **학습 포인트**
1. **데이터 추출**: `text` 속성을 사용하여 텍스트 데이터 추출.
2. **특정 요소 선택**: `find_element`,`find_elements`를 사용하여 원하는 정보만 추출.
3. **실용성**: 실제 웹사이트에서 유용한 정보를 수집하는 방법 학습.

## 4. duckduckgo 검색 사이트 이용하기
*   Google 검색창에서 검색어를 입력하고 결과값을 확인하려 했으나 **봇 감지(CAPTCHA)**에 걸림
*   DuckDuckGo는 Google이나 Bing처럼 정보를 검색할 수 있는 웹 검색 엔진입니다. 하지만 다음과 같은 점에서 차별화
    *   봇 감지 없음:	Google과 달리 Selenium 등 자동화 도구에 CAPTCHA를 거의 띄우지 않음
    *   빠른 로딩:	JavaScript 로딩이 적어 자동화 테스트에 적합
    *   간단한 구조:	검색 결과의 HTML 구조가 단순해서 크롤링/스크래핑 용이

```python
def search_duckduckgo():

	# 드라이버 실행
	driver = webdriver.Chrome()
	# 구글 홈페이지로 이동!

	driver.get("https://duckduckgo.com/")
	print(f"현재 페이지 제목: {driver.title}") # 로봇이 접속한 웹사이트의 제목을 확인해요.


	# 1. 검색창 찾기
	# 웹사이트의 각 부분(버튼, 입력창 등)은 고유한 이름(ID, class, name 등)이나 위치(XPath)를 가지고 있어요.
	# 구글 검색창은 'name' 속성이 'q'인 경우가 많아요.
	try:
		search_box = driver.find_element(By.NAME, "q") # By.NAME을 이용해서 'q'라는 이름을 가진 요소를 찾아요.
		print("검색창을 찾았습니다!")

		# 2. 검색어 입력하기
		search_query = "Selenium Python"
		search_box.send_keys(search_query) # 찾은 검색창에 'Selenium Python'이라고 입력해요.
		print(f"검색어 '{search_query}'를 입력했습니다.")

		# 3. 검색 실행 (엔터 키 누르기)
		search_box.submit() # 입력한 검색어를 제출(엔터)해서 검색을 시작해요.
		print("검색을 실행했습니다.")

		# 4. 검색 결과 페이지가 나타날 때까지 잠시 기다리기
		time.sleep(3) # 웹 페이지가 로딩될 시간을 3초 정도 줘요. (인터넷 속도에 따라 조절)

		# 5. 검색 결과 페이지의 제목 확인
		print(f"검색 결과 페이지 제목: {driver.title}")

		# 6. 첫 번째 검색 결과 제목 가져오기 (예시)
		# 검색 결과는 보통 <h2> 태그에 제목이 있어요.
		first_result_title = driver.find_element(By.CSS_SELECTOR, 'h2')
		print(f"첫 번째 검색 결과 제목: {first_result_title.text}")

	except Exception as e:
		print(f"웹 요소를 찾거나 상호작용 중 오류가 발생했습니다: {e}")

	driver.quit()


```

## **5. By 역할**
`By`의 역할은 **Selenium WebDriver에서 요소를 찾을 때 사용하는 선택자 전략(또는 위치 지정 방법)을 정의**하는 것입니다.

### **5.1 `By`의 사용 예시**
아래는 `By`를 사용하여 웹 요소를 찾는 예제입니다.

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time


driver = webdriver.Chrome()
driver.get("http://quotes.toscrape.com/")
print(f"현재 페이지 제목: {driver.title}\n")
time.sleep(2)

# 1. By.CLASS_NAME으로 요소 찾기 (예: 모든 인용구 텍스트)
print("--- By.CLASS_NAME 예시 ---")
quote_elements = driver.find_elements(By.CLASS_NAME, "text")
print(f"페이지에 있는 인용구 텍스트 개수: {len(quote_elements)}")
if quote_elements:
    print(f"첫 번째 인용구 텍스트: {quote_elements[0].text}\n")


# 2. By.CSS_SELECTOR로 요소 찾기 (예: 첫 번째 인용구의 작가)
print("--- By.CSS_SELECTOR 예시 ---")
# 'quote' 클래스를 가진 div 아래에 있는 'small' 태그를 찾음
author_element = driver.find_element(By.CSS_SELECTOR, ".quote small.author")
print(f"첫 번째 인용구의 작가: {author_element.text}\n")


# 3. By.XPATH로 요소 찾기 (예: 'love' 태그를 가진 모든 인용구)
print("--- By.XPATH 예시 ---")
# 'quote' 클래스를 가진 div 아래에, 'tag' 클래스를 가진 div가 있고
# 그 div 안에 'love' 텍스트를 가진 'a' 태그가 있는 인용구를 찾음
love_quotes = driver.find_elements(By.XPATH, "//div[@class='quote'][.//a[@class='tag' and text()='love']]")
print(f"'love' 태그를 가진 인용구 개수: {len(love_quotes)}")
if love_quotes:
    print(f"첫 번째 'love' 인용구 텍스트: {love_quotes[0].find_element(By.CLASS_NAME, 'text').text}\n")


# 4. By.LINK_TEXT로 요소 찾기 (예: 'Next' 버튼)
print("--- By.LINK_TEXT 예시 ---")
try:
    next_button = driver.find_element(By.LINK_TEXT, "Next »")
    print(f"'Next »' 버튼을 찾았습니다. 클릭합니다.")
    next_button.click()
    time.sleep(3)
    print(f"다음 페이지 제목: {driver.title}\n")
except Exception as e:
    print(f"'Next »' 버튼을 찾거나 클릭하는 데 실패했습니다: {e}\n")


# 5. By.TAG_NAME으로 요소 찾기 (예: 모든 a 태그)
print("--- By.TAG_NAME 예시 ---")
all_links = driver.find_elements(By.TAG_NAME, "a")
print(f"페이지에 있는 총 링크 개수: {len(all_links)}\n")


driver.quit()
print("브라우저 종료.")
```

## 6. 웹 요소 찾기 심화: XPath (가장 강력한 길 찾기)

`find_element(By.NAME, "q")`처럼 이름으로 찾을 수도 있지만, 웹 페이지의 모든 요소는 마치 주소처럼 고유한 **XPath**라는 경로를 가지고 있어요. XPath는 가장 강력하게 요소를 찾아낼 수 있는 방법이에요.

  * **XPath는 주소 같은 거예요:**

      * `/html/body/div/div[2]/h1` 처럼 웹 페이지의 가장 위부터 순서대로 내려가면서 '어떤 태그의 몇 번째 자식'이라는 식으로 요소를 찾아가는 경로예요.
      * `//div[@id='container']/h3` 처럼 `//`를 사용하면 웹 페이지 어디에 있든 'ID가 container인 div 아래의 h3 태그'를 바로 찾아갈 수도 있어요. `[@속성='값']`은 특정 속성과 값을 가진 요소를 의미해요.
      * `//a[text()='클릭할 링크']` 처럼 '텍스트 내용이 특정 값인 링크'를 찾을 수도 있어요.

  * **예시: 특정 링크 클릭하기**

    ```python
    # (위의 초기 설정 코드 driver = webdriver.Chrome(...)는 실행되어 있다고 가정)
    driver.get("https://www.neural9.com")
    time.sleep(2)

    # 'Books'라는 텍스트를 가진 링크 찾기
    # XPath: //a[contains(text(), 'Books')]
    # 'a' 태그 중에서 'Books' 텍스트를 포함하는 링크를 찾아요.
    try:
        books_link = driver.find_element(By.XPATH, "//a[contains(text(), 'Books')]")
        print(f"'Books' 링크를 찾았습니다: {books_link.text}")
        books_link.click() # 'Books' 링크 클릭!
        print(" 'Books' 링크를 클릭했습니다. 페이지 로딩 대기...")
        time.sleep(3)
        print(f"새 페이지 제목: {driver.title}")
    except Exception as e:
        print(f"'Books' 링크를 찾거나 클릭하는 데 실패했습니다: {e}")

    # 작업 완료 후 브라우저 닫기
    driver.quit()
    ```
