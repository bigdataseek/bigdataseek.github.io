---
title: 27차시 1:GenAI-5Days
layout: single
classes: wide
categories:
  - GenAI-5Days
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 1. 대형 언어 모델 학습 및 활용
- 출처: [Foundational Large Language Models & Text Generation](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)

### 1.1 퀴즈
1. 대형 언어 모델(LLM)이란 무엇이며, 이러한 모델의 주요 기능 두 가지를 설명하세요.
> LLM은 인간과 유사한 텍스트를 처리, 이해 및 생성하는 데 특화된 고급 인공 지능 시스템입니다. 주요 기능으로는 방대한 텍스트 데이터를 기반으로 언어 패턴을 학습하는 능력과 이를 활용하여 다양한 자연어 처리 작업을 수행하는 능력이 있습니다.

2. 트랜스포머 아키텍처에서 자기 주의(self-attention) 메커니즘의 중요성은 무엇이며, 쿼리(Query), 키(Key), 값(Value) 벡터는 이 과정에서 어떤 역할을 하나요?
> 자기 주의 메커니즘은 트랜스포머가 입력 시퀀스 내의 각 단어가 다른 단어와 어떤 관계를 맺고 있는지 파악하여 문맥을 이해하는 데 핵심적인 역할을 합니다. 쿼리 벡터는 모델이 관련 정보를 찾도록 돕고, 키 벡터는 단어가 어떻게 관련될 수 있는지 식별하는 데 사용되며, 값 벡터는 실제 단어 내용을 담고 있습니다.

3. LLM의 입력 준비 과정에서 토큰화(Tokenization)의 목적은 무엇이며, 언급된 토큰화 기법 두 가지를 간략하게 설명하세요.
> 토큰화는 문장을 단어나 서브워드 단위로 나누고 이를 어휘집에 있는 정수 토큰 ID에 매핑하는 과정입니다. 이 과정의 목적은 텍스트 데이터를 모델이 처리할 수 있는 숫자 형식으로 변환하는 것입니다. 언급된 기법으로는 바이트 쌍 인코딩(Byte-Pair Encoding)과 유니그램 토큰화(Unigram tokenization)가 있습니다.

4. GPT와 BERT 모델 아키텍처의 주요 차이점은 무엇이며, 각 모델이 어떤 유형의 자연어 처리 작업에 더 적합한지 설명하세요.
> GPT는 주로 디코더 전용 아키텍처로, 이전 단어를 기반으로 다음 단어를 예측하는 데 중점을 두어 텍스트 생성 작업에 강점을 가집니다. 반면, BERT는 인코더 전용 아키텍처로, 문맥 속에서 단어의 의미를 깊이 이해하는 데 중점을 두어 텍스트 이해 작업(질의 응답, 감성 분석 등)에 더 적합합니다.

5. Mixture of Experts (MoE) 아키텍처의 핵심 아이디어는 무엇이며, 이 접근 방식이 LLM의 효율성에 어떻게 기여하나요?
> MoE 아키텍처는 여러 개의 작은 하위 모델(전문가)을 두고, 각 입력에 대해 일부 전문가만 활성화시켜 계산 효율성을 높이는 아이디어입니다. 게이팅 네트워크(라우터)는 입력을 적절한 전문가에게 할당하는 역할을 수행합니다. 이를 통해 파라미터 수가 많은 모델의 계산 비용을 줄일 수 있습니다.

6. LLM을 처음부터 학습시키는 것과 비교했을 때, 파인튜닝(Fine-tuning)의 주요 장점 두 가지는 무엇인가요?
> 파인튜닝의 주요 장점 중 하나는 처음부터 LLM을 학습시키는 데 필요한 막대한 양의 데이터와 컴퓨팅 자원보다 훨씬 적은 자원으로 특정 도메인이나 작업에 맞게 모델을 조정할 수 있다는 점입니다. 또 다른 장점은 사전 학습된 모델이 이미 보유한 일반적인 언어 이해 능력을 활용하여 더 빠르게 높은 성능을 달성할 수 있다는 것입니다.

7. 프롬프트 엔지니어링(Prompt Engineering)이란 무엇이며, 제로샷(Zero-shot) 프롬프팅과 퓨샷(Few-shot) 프롬프팅의 차이점을 설명하세요.
> 프롬프트 엔지니어링은 LLM에 원하는 출력을 얻기 위해 입력 텍스트(프롬프트)를 설계하고 개선하는 과정입니다. 제로샷 프롬프팅은 추가적인 예시 없이 지침만 제공하는 반면, 퓨샷 프롬프팅은 모델이 응답하는 방식을 안내하기 위해 몇 가지 신중하게 선택된 예시를 함께 제공합니다.

8. LLM 추론(Inference) 속도를 높이기 위한 주요 기술 두 가지를 설명하고, 각 기술이 어떻게 작동하는지 간략하게 언급하세요.
> LLM 추론 속도를 높이기 위한 주요 기술 중 하나는 양자화(Quantization)로, 모델 가중치와 활성화 함수의 숫자 정밀도를 낮추어 메모리 사용량과 계산량을 줄입니다. 또 다른 기술은 스펙ulative decoding(추측 디코딩)으로, 작은 보조 모델을 사용하여 다음 토큰을 예측하고 메인 모델이 이를 병렬로 검증하여 디코딩 속도를 향상시킵니다.

9. 지식 증류(Knowledge Distillation)는 무엇이며, 이 기술이 작은 모델의 성능 향상에 어떻게 도움이 될 수 있나요?
> 지식 증류는 더 크고 강력한 "교사" 모델의 지식을 더 작고 효율적인 "학생" 모델로 전달하는 기술입니다. 이를 통해 학생 모델은 교사 모델의 추론 패턴을 학습하여 유사한 성능을 달성하면서도 더 적은 컴퓨팅 자원을 사용할 수 있게 됩니다.

10. Gemini 모델의 주요 특징과 이전 모델과 비교했을 때의 혁신적인 측면을 설명하세요.
> Gemini는 텍스트, 이미지, 오디오, 비디오 등 다양한 형태의 입력을 처리할 수 있는 최첨단 멀티모달 언어 모델입니다. 이전 모델과 비교했을 때의 혁신적인 측면으로는 멀티모달 입력 처리 능력, 매우 긴 문맥 창(context window) 지원, 효율적인 추론을 위한 아키텍처 개선 및 Mixture of Experts 아키텍처 활용 등을 들 수 있습니다.

### 1.3 에세이 형식 질문
1. 대형 언어 모델의 발전이 인공지능 분야에 가져온 근본적인 변화는 무엇이며, 이러한 변화가 미래 기술 발전에 미치는 잠재적 영향에 대해 논하세요.
> 대형 언어 모델(LLM)의 발전은 인공지능 분야에서 텍스트 이해, 생성, 번역 등 자연어 처리 능력의 혁신적인 향상을 가져왔으며, 이는 인간-컴퓨터 상호작용 방식의 변화와 더불어 다양한 산업 분야에 걸쳐 새로운 응용 가능성을 제시합니다. 이러한 변화는 미래 기술 발전에 있어 더욱 정교하고 맥락을 이해하는 인공지능 시스템 구축을 가속화하고, 개인 맞춤형 서비스, 자동화된 콘텐츠 생성, 지능형 정보 검색 등 혁신적인 기술 발전을 촉진할 잠재력을 지닙니다.

2. 트랜스포머 아키텍처의 핵심 혁신인 자기 주의 메커니즘이 기존 순환 신경망(RNN) 기반 모델의 한계를 어떻게 극복했으며, 다양한 자연어 처리 작업에서 트랜스포머가 우위를 점하게 된 이유를 분석하세요.
> 트랜스포머 아키텍처의 핵심 혁신인 자기 주의(Self-Attention) 메커니즘은 입력 시퀀스 내의 모든 단어 간의 관계를 직접적으로 파악하여 장거리 의존성 문제를 효과적으로 해결하고, 순차적인 처리가 아닌 병렬 처리를 가능하게 함으로써 기존 RNN 기반 모델의 고질적인 한계를 극복했습니다. 이러한 능력 덕분에 트랜스포머는 문맥 이해도가 중요한 다양한 자연어 처리 작업에서 RNN 기반 모델 대비 뛰어난 성능을 보이며 우위를 점하게 되었습니다.

3. 효율적인 LLM 학습 및 추론을 위한 다양한 기술(예: 파인튜닝, 양자화, 지식 증류, 스펙ulative decoding)을 비교 분석하고, 특정 사용 사례에서 어떤 기술을 선택하는 것이 적절한지 설명하세요.
> 효율적인 LLM 학습을 위한 파인튜닝은 특정 작업에 모델을 최적화하며, 양자화는 모델 크기와 연산량을 줄여 추론 속도를 향상시킵니다. 지식 증류는 큰 모델의 지식을 작은 모델로 이전하여 효율성을 높이고, 스펙ulative decoding은 작은 모델로 초안을 생성하고 큰 모델로 검증하여 추론 속도를 빠르게 합니다. 따라서, 높은 정확도가 중요한 작업에는 파인튜닝을, 자원 제약적인 환경에서는 양자화나 지식 증류를, 빠른 응답 속도가 요구되는 경우에는 스펙ulative decoding을 고려하는 것이 적절합니다.

4. 오픈 소스 LLM 생태계의 성장과 발전이 인공지능 연구 및 산업에 미치는 영향에 대해 논하고, 주목할 만한 오픈 소스 모델(예: LLaMA, Gemma, Mixtral)의 특징과 기여를 평가하세요.
> 오픈 소스 LLM 생태계의 성장은 인공지능 연구 및 산업 전반에 걸쳐 혁신과 접근성을 증진시키며, 폐쇄형 모델에 대한 의존도를 낮추고 다양한 활용 사례를 창출하는 데 기여합니다. LLaMA는 뛰어난 성능과 오픈 라이선스로 LLM 연구의 저변을 확대했으며, Gemma는 Gemini의 경량화 모델로 온디바이스 AI 가능성을 제시하고 효율성을 강조합니다. Mixtral은 전문가 혼합(MoE) 아키텍처를 통해 높은 성능과 효율성을 동시에 달성하며 다국어 및 코드 생성 능력에서 강점을 보입니다.

5. LLM의 윤리적 문제(예: 편향성, 허위 정보 생성, 악용 가능성)를 해결하기 위한 노력과 과제를 분석하고, 책임감 있는 LLM 개발 및 활용을 위한 잠재적인 해결책을 제시하세요.
> 대형 언어 모델(LLM)의 윤리적 문제 해결을 위한 노력은 편향된 데이터셋 개선, 유해 콘텐츠 필터링 기술 개발, 설명 가능한 AI(XAI) 연구 등을 포함하며, 책임감 있는 개발 및 활용을 위해서는 다학제적 협력을 통한 규제 마련과 윤리적 가이드라인 정립이 중요합니다. 하지만, LLM의 복잡성과 지속적인 발전으로 인해 완벽한 해결책을 찾기는 어려운 과제이며, 기술적, 사회적, 정책적 측면에서의 꾸준한 관심과 노력이 필요합니다.

### 1.4 용어집
1. 대형 언어 모델 (Large Language Model, LLM): 
    - 방대한 양의 텍스트 데이터를 학습하여 인간과 유사한 텍스트를 생성, 이해 및 처리할 수 있는 깊은 신경망 기반 모델.
2. 트랜스포머 (Transformer): 
    - 자기 주의 메커니즘을 기반으로 하는 신경망 아키텍처로, 병렬 처리가 가능하여 긴 시퀀스 데이터의 종속성을 효과적으로 모델링하고 학습 속도가 빠름.
3. 자기 주의 (Self-Attention): 
    - 트랜스포머 아키텍처의 핵심 메커니즘으로, 입력 시퀀스 내의 각 위치가 다른 모든 위치에 얼마나 집중해야 하는지를 계산하여 문맥적 관계를 파악함.
4. 임베딩 (Embedding): 
    - 단어나 토큰을 의미론적 유사성을 반영하는 고차원 벡터로 변환하는 과정 또는 그 결과로 생성된 벡터.
5. 토큰화 (Tokenization): 
    - 텍스트를 더 작은 단위(토큰)로 나누는 과정. 단어, 서브워드, 문자 등이 토큰이 될 수 있음.
6. 파인튜닝 (Fine-tuning): 
    - 사전 학습된 대형 모델을 특정 작업 또는 도메인의 데이터셋으로 추가 학습시켜 해당 작업에서의 성능을 향상시키는 과정.
7. 프롬프트 엔지니어링 (Prompt Engineering): 
    - 원하는 출력을 얻기 위해 LLM에 제공하는 입력 텍스트(프롬프트)를 설계하고 최적화하는 기술.
8. 제로샷 프롬프팅 (Zero-shot Prompting): 
    - 추가적인 예시 없이 작업 설명만으로 LLM에게 응답을 요청하는 방식.
9. 퓨샷 프롬프팅 (Few-shot Prompting): 
    - 작업 설명과 함께 몇 가지 예시를 제공하여 LLM의 응답 방식을 안내하는 방식.
10. 혼합 전문가 (Mixture of Experts, MoE): 
    - 입력에 따라 활성화되는 여러 개의 하위 모델(전문가)로 구성된 아키텍처로, 모델 용량을 늘리면서 계산 효율성을 높임.
11. 양자화 (Quantization): 
    - 신경망 모델의 가중치와 활성화 함수의 숫자 정밀도를 낮추어 모델 크기를 줄이고 추론 속도를 높이는 기술.
12. 지식 증류 (Knowledge Distillation): 
    - 큰 "교사" 모델의 지식을 작은 "학생" 모델로 전달하여 학생 모델의 성능을 향상시키는 학습 기법.
13. 스펙ulative decoding (추측 디코딩): 
    - 작은 모델을 사용하여 다음 토큰을 빠르게 예측하고, 큰 모델이 이를 병렬로 검증하여 LLM의 디코딩 속도를 향상시키는 기술.
14. 멀티모달 (Multimodal): 
    - 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 함께 처리할 수 있는 능력.



## 2. 프롬프트 엔지니어링
- 출처: [Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)

### 2.1 퀴즈 (짧은 답변)
1. 프롬프트 엔지니어링이란 무엇이며, 왜 중요한가요? 
> 프롬프트 엔지니어링은 LLM이 정확하고 의미 있는 출력을 생성하도록 안내하는 고품질 프롬프트를 설계하는 프로세스입니다. 이는 LLM의 성능에 큰 영향을 미치므로 모호하거나 부정확한 응답을 방지하고 모델의 잠재력을 최대한 활용하는 데 중요합니다.

2. LLM 출력 구성에서 '온도(Temperature)' 설정은 어떤 역할을 하며, 어떻게 LLM 출력의 무작위성에 영향을 미치나요? 
> 온도는 LLM이 다음 토큰을 선택할 때 무작위성의 정도를 제어합니다. 낮은 온도는 더 결정적인 응답을 유도하며, 높은 온도는 더 다양하고 예상치 못한 결과를 생성할 수 있습니다.

3. '제로 샷(Zero-shot)' 프롬프팅과 '퓨 샷(Few-shot)' 프롬프팅의 주요 차이점은 무엇인가요? 각각 어떤 상황에서 유용할까요? 
> 제로 샷 프롬프팅은 작업에 대한 설명만 제공하고 예시를 제공하지 않는 반면, 퓨 샷 프롬프팅은 몇 가지 예시를 포함하여 모델이 원하는 출력 형식을 학습하도록 돕습니다. 제로 샷은 간단한 작업에 유용하며, 퓨 샷은 더 복잡하거나 특정 형식의 출력이 필요한 작업에 효과적입니다.

4. '시스템 프롬프트(System Prompt)', '맥락 프롬프트(Contextual Prompt)', '역할 프롬프트(Role Prompt)'의 목적은 각각 무엇이며, 서로 어떻게 관련될 수 있나요? 
> 시스템 프롬프트는 LLM의 전반적인 맥락과 목적을 설정하고, 맥락 프롬프트는 현재 대화나 작업과 관련된 구체적인 배경 정보를 제공하며, 역할 프롬프트는 LLM에 특정 캐릭터나 정체성을 부여하여 응답 스타일과 목소리를 형성합니다. 이들은 서로 중첩될 수 있으며, 명확한 의도를 가진 프롬프트를 설계하는 데 도움을 줍니다.

5. 'CoT(Chain of Thought)' 프롬프팅은 LLM이 복잡한 문제를 해결하는 데 어떻게 도움이 되나요? 이 기법의 핵심 아이디어는 무엇인가요? 
> CoT 프롬프팅은 LLM이 최종 답변을 도출하기 전에 중간 추론 단계를 명시적으로 생성하도록 지시하여 복잡한 문제 해결 능력을 향상시킵니다. 핵심 아이디어는 문제를 더 작은 단계로 나누어 모델이 논리적인 사고 과정을 따르도록 유도하는 것입니다.

6. '자기 일관성(Self-consistency)' 프롬프팅은 LLM 응답의 정확성과 일관성을 어떻게 향상시키나요? 어떤 단계를 거쳐 작동하나요? 
> 자기 일관성은 동일한 프롬프트를 여러 번 LLM에 제공하여 다양한 추론 경로를 생성하고, 생성된 응답에서 가장 빈번하게 나타나는 답변을 선택하여 응답의 정확성과 일관성을 높입니다. 이는 다양한 관점을 고려하고 가장 일관된 답을 선택하는 방식으로 작동합니다.

7. 'ReAct(Reason & Act)' 프롬프팅의 주요 특징은 무엇이며, 기존의 프롬프팅 방식과 어떻게 다른가요? 어떤 종류의 작업을 해결하는 데 적합할까요? 
> ReAct 프롬프팅은 자연어 추론과 외부 도구 사용(예: 검색, 코드 인터프리터)을 결합하여 LLM이 복잡한 작업을 해결할 수 있도록 하는 패러다임입니다. 인간이 추론하고 필요한 정보를 얻기 위해 행동하는 방식을 모방하며, 정보 검색이 필요한 다양한 영역에서 뛰어난 성능을 보입니다.

8. '자동 프롬프트 엔지니어링(Automatic Prompt Engineering, APE)'의 기본 아이디어는 무엇이며, 프롬프트 작성 과정을 어떻게 자동화할 수 있나요? 
> 자동 프롬프트 엔지니어링은 또 다른 LLM을 사용하여 주어진 작업에 대한 효과적인 프롬프트 후보를 자동으로 생성하는 방법입니다. 생성된 프롬프트는 평가 및 개선 과정을 거쳐 최종적으로 사용됩니다.

9. 코드 관련 프롬프트 엔지니어링은 어떤 다양한 작업에 적용될 수 있나요? 
> 코드 관련 프롬프트 엔지니어링은 코드 생성, 코드 설명, 코드 번역, 코드 디버깅 및 검토 등 다양한 작업에 적용될 수 있습니다.

10. 효과적인 프롬프트를 설계하기 위한 주요 모범 사례 중 세 가지를 설명해 주세요.
> 효과적인 프롬프트 설계를 위한 주요 모범 사례에는 간결하고 명확하게 작성하기, 원하는 출력에 대해 구체적으로 명시하기, 그리고 다양한 프롬프트 형식과 작성 스타일을 실험해 보는 것이 포함됩니다.

### 2.3 에세이 형식 질문
1. 프롬프트 엔지니어링의 다양한 기법(예: 제로 샷, 퓨 샷, CoT, ReAct)을 비교 분석하고, 각 기법의 강점과 약점을 논의해 보세요. 특정 유형의 문제나 작업에 어떤 기법이 더 적합한지 예시와 함께 설명하세요.
> 제로 샷은 별도의 예시 없이 프롬프트만으로 답변을 유도하지만, 복잡한 추론이나 맥락 이해가 부족할 수 있습니다. 퓨 샷은 소수의 예시를 제공하여 모델의 이해도를 높이지만, 예시의 품질에 따라 성능이 크게 좌우될 수 있습니다. CoT는 사고 과정을 단계별로 제시하여 복잡한 문제 해결에 효과적이지만, 프롬프트가 길어지고 모델의 토큰 제한에 영향을 줄 수 있습니다. 반면 ReAct는 추론과 행동을 반복하며 외부 정보를 활용하여 사실 기반 답변에 강점을 보이지만, 잘못된 외부 정보 접근 시 오류가 발생할 수 있습니다. 예를 들어, 간단한 질문에는 제로 샷이 적합하지만, 수학 문제 풀이에는 CoT, 외부 지식 기반 질의응답에는 ReAct, 새로운 개념 학습에는 퓨 샷이 유리할 수 있습니다.

2. LLM의 출력 구성을 제어하는 요소(예: 온도, Top-K, Top-P, 토큰 제한)가 프롬프트 엔지니어링 과정에서 갖는 중요성을 설명하고, 이러한 설정을 조정하는 것이 LLM 출력의 품질과 다양성에 어떻게 영향을 미치는지 구체적인 사례를 들어 논하세요.
> LLM의 출력 구성을 제어하는 온도, Top-K, Top-P, 토큰 제한 등의 요소는 프롬프트 엔지니어링 과정에서 모델의 응답 방식과 품질을 결정하는 핵심적인 역할을 합니다. 온도는 출력의 무작위성을 조절하여 창의적이거나 일관된 답변을 유도하고, Top-K와 Top-P는 다음 단어 선택 범위를 제한하여 관련성 높은 출력을 생성하는 데 기여합니다. 예를 들어, 낮은 온도는 사실적인 답변에 유리하지만, 높은 온도는 소설 창작과 같은 творческий 작업에 적합하며, 토큰 제한은 생성될 수 있는 텍스트의 길이를 제어하여 간결하거나 상세한 답변을 얻도록 합니다.

3. 시스템 프롬프트, 맥락 프롬프트, 역할 프롬프트의 개념을 통합하여 설명하고, 실제 시나리오를 예로 들어 이러한 다양한 유형의 프롬프트를 결합하여 LLM의 응답을 효과적으로 유도하는 방법을 상세히 논하세요.
> 시스템 프롬프트는 LLM의 전반적인 행동 양식과 목표를 설정하는 최상위 지침이며, 맥락 프롬프트는 특정 질의에 필요한 배경 정보나 예시를 제공하여 답변의 관련성과 정확성을 높입니다. 역할 프롬프트는 LLM에게 특정 페르소나를 부여하여 응답의 스타일과 관점을 조정합니다. 예를 들어, "당신은 한국사 전문가입니다. 조선 시대 왕들의 업적을 설명하되, 각 왕의 주요 정책과 그 시대적 의의를 중심으로 간결하게 요약해 주세요."라는 프롬프트에서 "당신은 한국사 전문가입니다."는 역할 프롬프트, "조선 시대 왕들의 업적을 설명하되, 각 왕의 주요 정책과 그 시대적 의의를 중심으로"는 시스템 프롬프트, 그리고 이전 대화 내용이나 특정 왕에 대한 정보는 맥락 프롬프트로 작용하여 LLM이 전문적이면서도 맥락에 맞는 답변을 생성하도록 유도할 수 있습니다.

4. 자동 프롬프트 엔지니어링(APE)의 잠재적인 이점과 과제를 분석하고, 이 방법이 미래의 프롬프트 엔지니어링 분야에 어떤 영향을 미칠 수 있을지 예측해 보세요. APE가 인간 프롬프트 엔지니어의 역할을 어떻게 변화시킬 수 있을지도 함께 고려해 보세요.
> 자동 프롬프트 엔지니어링(APE)은 인간의 개입 없이 최적의 프롬프트를 자동으로 탐색하고 생성함으로써 프롬프트 엔지니어링의 효율성을 극대화하고, 인간이 놓칠 수 있는 창의적인 프롬프트를 발견할 잠재력을 지닙니다. 하지만 APE 시스템의 복잡성과 생성된 프롬프트의 해석 및 검증의 어려움, 그리고 여전히 인간의 직관과 전문성이 필요한 영역이 존재한다는 과제를 안고 있습니다. 미래에는 APE가 인간 프롬프트 엔지니어의 생산성을 높이는 강력한 도구가 될 것이며, 인간은 더욱 고차원적인 프롬프트 설계 및 결과 분석에 집중하게 될 것입니다.

5. 프롬프트 엔지니어링 과정에서 발생할 수 있는 윤리적 고려 사항(예: 편향된 응답, 허위 정보 생성)을 논하고, 책임감 있는 프롬프트 엔지니어링을 위해 어떤 노력이 필요하며, 이러한 위험을 완화하기 위한 전략에는 어떤 것들이 있는지 심층적으로 분석하세요.
> 프롬프트 엔지니어링 과정에서 편향된 데이터 학습으로 인한 차별적인 응답이나 악의적인 프롬프트에 의해 허위 정보가 생성 및 확산될 수 있다는 윤리적 문제가 발생할 수 있습니다. 책임감 있는 프롬프트 엔지니어링을 위해서는 다양한 관점을 고려한 프롬프트 설계, 생성된 응답에 대한 비판적 평가 및 검증, 그리고 잠재적 위험을 최소화하기 위한 기술적·정책적 노력이 필요합니다. 이러한 위험을 완화하기 위한 전략으로는 학습 데이터의 편향성 완화, 명확하고 안전한 프롬프트 설계 가이드라인 마련, 생성된 콘텐츠의 사실성 검증 시스템 구축, 그리고 윤리적 문제 발생 시 책임 소재 및 해결 절차 규정 등이 있습니다.


### 2.4 주요 용어 해설
1. 프롬프트 (Prompt): 
    - 대규모 언어 모델(LLM)에 제공되는 입력 텍스트로, 특정 출력 또는 예측을 생성하도록 모델을 안내합니다.
2. 프롬프트 엔지니어링 (Prompt Engineering): 
    - LLM이 정확하고 바람직한 출력을 생성하도록 고품질의 효과적인 프롬프트를 설계하고 최적화하는 프로세스입니다.
3. 제로 샷 프롬프팅 (Zero-shot Prompting): 
    - LLM에 작업에 대한 설명만 제공하고, 원하는 출력에 대한 예시를 제공하지 않는 프롬프팅 기법입니다.
4. 퓨 샷 프롬프팅 (Few-shot Prompting): 
    - LLM에 작업 설명과 함께 몇 가지 예시를 제공하여 모델이 원하는 출력 형식을 학습하도록 돕는 프롬프팅 기법입니다.
5. 온도 (Temperature): 
    - LLM 출력 생성 시 무작위성의 정도를 제어하는 파라미터입니다. 낮은 온도는 더 결정적인 출력을, 높은 온도는 더 다양하고 창의적인 출력을 유도합니다.
6. Top-K: 
    - LLM이 다음 토큰을 예측할 때 확률이 가장 높은 상위 K개의 토큰으로 후보를 제한하는 샘플링 전략입니다.
7. Top-P (Nucleus Sampling): 
    - LLM이 다음 토큰을 예측할 때 누적 확률이 특정 임계값 P를 넘지 않는 상위 토큰 집합에서 후보를 선택하는 샘플링 전략입니다.
8. 시스템 프롬프트 (System Prompt): 
    - LLM의 전반적인 행동 방식, 목표, 스타일 등을 정의하는 지침으로, 대화의 큰 그림을 설정합니다.
9. 맥락 프롬프트 (Contextual Prompt): 
    - 현재 작업 또는 대화에 관련된 구체적인 배경 정보나 세부 사항을 제공하여 LLM이 응답을 맞춤화하도록 돕는 프롬프트입니다.
10. 역할 프롬프트 (Role Prompt): 
    - LLM에 특정 인물, 직업 또는 성격을 부여하여 해당 역할에 맞는 어조, 스타일, 지식을 사용하여 응답하도록 유도하는 프롬프트입니다.
11. CoT (Chain of Thought) 프롬프팅: 
    - LLM이 복잡한 문제에 대한 답을 도출하기 전에 일련의 중간 추론 단계를 생성하도록 유도하는 프롬프팅 기법입니다.
12. 자기 일관성 (Self-consistency): 
    - 동일한 프롬프트를 여러 번 실행하여 다양한 추론 경로를 얻고, 가장 자주 나타나는 최종 답변을 선택하여 LLM 응답의 정확성과 일관성을 향상시키는 방법입니다.
13. ToT (Tree of Thoughts): 
    - CoT 프롬프팅을 일반화한 개념으로, LLM이 여러 개의 다른 추론 경로를 동시에 탐색할 수 있도록 하여 복잡한 문제 해결에 효과적입니다.
14. ReAct (Reason & Act): 
    - LLM이 자연어 추론과 외부 도구(예: 검색 엔진, 코드 실행기) 사용을 결합하여 복잡한 작업을 해결할 수 있도록 하는 프롬프팅 패러다임입니다.
15. 자동 프롬프트 엔지니어링 (Automatic Prompt Engineering, APE): 
    - 또 다른 LLM을 사용하여 특정 작업에 대한 효과적인 프롬프트 후보를 자동으로 생성하는 방법입니다.
16. 다중 모달 프롬프팅 (Multimodal Prompting): 
    - 텍스트뿐만 아니라 이미지, 오디오, 코드 등 여러 입력 형식을 결합하여 LLM을 안내하는 기술입니다.

## 3. 임베딩 및 벡터 스토어
- 출처: [Embeddings & Vector Stores](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)

### 3.1 퀴즈
1. 임베딩이란 무엇이며, 왜 중요한가요? 
> 임베딩은 텍스트, 이미지, 오디오 등 다양한 유형의 실제 데이터를 저차원 벡터 공간의 숫자 표현으로 변환하는 것입니다. 이를 통해 서로 다른 유형의 데이터를 통합적으로 처리하고, 데이터 객체 간의 의미적 유사성을 효율적으로 비교할 수 있으며, 대규모 데이터의 압축 및 검색 속도 향상에 기여합니다.

2. 임베딩 모델의 품질을 평가하는 주요 지표는 무엇이며, 각각 어떻게 정의되나요? 
> 주요 평가지표는 정밀도(Precision)와 재현율(Recall)입니다. 정밀도는 검색된 문서 중 관련 문서의 비율을 나타내며, 재현율은 전체 관련 문서 중 검색된 관련 문서의 비율을 나타냅니다. 일반적으로 특정 개수의 검색된 문서에 대해 정밀도@K, 재현율@K와 같이 표현됩니다.

3. 검색 예시에서 RAG (Retrieval Augmented Generation) 접근 방식은 어떻게 작동하며, 임베딩은 이 과정에서 어떤 역할을 하나요? 
> RAG는 사용자 쿼리에 대해 관련된 문서를 검색한 후, 이를 LLM (Large Language Model)의 프롬프트에 삽입하여 답변을 생성하는 방식입니다. 임베딩은 문서와 쿼리를 동일한 벡터 공간에 매핑하여 의미적으로 유사한 문서를 효율적으로 검색하는 데 사용됩니다.

4. 텍스트를 임베딩으로 변환하는 일반적인 과정은 무엇인가요? 
> 일반적으로 텍스트는 먼저 의미 있는 작은 단위인 토큰으로 분할되는 토큰화 과정을 거칩니다. 각 토큰에는 고유한 정수 ID가 할당되며, 이후 이 토큰 ID를 사용하여 희소 벡터 또는 원-핫 인코딩된 밀집 벡터로 표현될 수 있습니다. 최종적으로 이러한 표현은 임베딩 모델을 통해 저차원 의미 벡터로 변환됩니다.

5. Word2Vec의 CBOW와 Skip-gram 방식의 주요 차이점은 무엇인가요? 
> CBOW (Continuous Bag of Words)는 주변 단어들의 임베딩을 사용하여 중간 단어의 임베딩을 예측하는 방식이며, Skip-gram은 반대로 중간 단어의 임베딩을 사용하여 주변 단어들의 임베딩을 예측하는 방식입니다. CBOW는 학습 속도가 빠르고 빈번한 단어에 대해 더 나은 성능을 보이며, Skip-gram은 학습 속도는 느리지만 적은 데이터와 희귀 단어에 대해 더 나은 성능을 보입니다.

6. 문서 임베딩의 주요 발전 단계를 shallow BoW 모델과 deeper pretrained LLM으로 나누어 설명해주세요. 
> 초기 문서 임베딩은 단어 순서를 고려하지 않는 BoW (Bag-of-Words) 패러다임을 따랐으며, LSA, LDA, TF-IDF 등이 대표적입니다. 이후 심층 신경망의 발전과 함께 대규모 코퍼스로 사전 학습된 LLM을 활용한 문서 임베딩 모델들이 등장하여 의미적 표현 능력이 크게 향상되었습니다. BERT와 같은 모델이 대표적입니다.

7. 벡터 검색의 기본적인 개념과 전통적인 키워드 검색과의 주요 차이점은 무엇인가요? 
> 벡터 검색은 데이터의 의미적 내용을 벡터 임베딩으로 표현하고, 쿼리 임베딩과 유사한 벡터를 검색하는 방식입니다. 반면, 전통적인 키워드 검색은 쿼리에 포함된 정확한 키워드와 일치하는 항목을 찾습니다. 벡터 검색은 의미 기반 검색이 가능하여 표현이 다르더라도 의미가 유사한 결과를 찾을 수 있습니다.

8. 효율적인 벡터 검색을 위해 사용되는 주요 알고리즘 두 가지를 설명해주세요. 
> 두 가지 주요 알고리즘은 LSH (Locality Sensitive Hashing)와 HNSW (Hierarchical Navigable Small Worlds)입니다. LSH는 유사한 항목들을 동일한 해시 버킷에 매핑하는 해시 함수를 사용하여 검색 공간을 줄입니다. HNSW는 계층적 그래프 구조를 활용하여 쿼리와 가장 유사한 벡터를 효율적으로 탐색합니다.

9. 벡터 데이터베이스의 주요 역할과 이점은 무엇인가요? 
> 벡터 데이터베이스는 벡터 임베딩을 효율적으로 저장, 관리, 검색하기 위해 특화된 시스템입니다. 대규모 임베딩 데이터에 대한 빠른 유사성 검색을 지원하며, 메타데이터 관리, 필터링, 하이브리드 검색 등 다양한 기능을 제공하여 프로덕션 환경에서 임베딩을 효과적으로 활용할 수 있도록 돕습니다.

10. 임베딩과 벡터 스토어가 결합되어 활용될 수 있는 주요 애플리케이션 세 가지를 예시와 함께 설명해주세요. 
> 세 가지 주요 애플리케이션은 검색 (의미적으로 관련된 문서 검색), 추천 시스템 (사용자와 유사한 아이템 추천), 그리고 RAG (LLM의 답변 생성 시 관련 정보 검색 및 활용)입니다.

### 3.2 에세이 형식 질문
1. 다양한 유형의 데이터 (텍스트, 이미지, 구조화된 데이터 등)에 대한 임베딩을 생성하는 다양한 방법을 비교하고, 각 방법의 장단점과 적용 분야를 논의하세요.
> 다양한 데이터 유형에 대한 임베딩 생성 방법은 텍스트에는 단어 임베딩(Word2Vec, GloVe, FastText), 문장 임베딩(BERT, Sentence-BERT), 이미지에는 CNN 기반 특징 추출, Transformer 모델 등이 사용됩니다. 구조화된 데이터는 Entity Embedding, Neural Network 기반 방법 등을 활용하며, 각 방법은 데이터 특성, 차원 축소 효과, 의미론적 정보 보존 능력 등에서 장단점을 가지며 적용 분야도 상이합니다. 따라서 데이터 유형과 분석 목표에 따라 적절한 임베딩 방법을 선택하는 것이 중요합니다.

2. 임베딩 모델의 품질을 평가하는 데 사용되는 다양한 지표 (정밀도, 재현율, nDCG 등)를 심층적으로 설명하고, 특정 애플리케이션에서 어떤 지표를 우선적으로 고려해야 하는지 논하세요.
> 임베딩 모델의 품질 평가는 검색, 추천 등 다양한 애플리케이션의 성능에 직결되므로 정밀도(Precision), 재현율(Recall), nDCG(Normalized Discounted Cumulative Gain)와 같은 지표들이 활용됩니다. 정밀도는 모델이 검색한 결과 중 실제 관련 있는 항목의 비율을 나타내고, 재현율은 전체 관련 항목 중 모델이 얼마나 많이 검색했는지를 측정합니다. 특히 순위가 중요한 검색 시스템에서는 관련성이 높은 항목이 상위에 랭크되도록 평가하는 nDCG를 우선적으로 고려해야 하며, 모든 관련 항목을 찾는 것이 중요한 추천 시스템에서는 재현율을 높게 평가할 수 있습니다.

3. 대규모 데이터셋에서 효율적인 벡터 검색을 수행하기 위한 다양한 ANN (Approximate Nearest Neighbor) 알고리즘 (LSH, HNSW, ScaNN 등)의 작동 방식, 장단점, 그리고 실제 사용 사례를 비교 분석하세요.
> 대규모 데이터셋에서 효율적인 벡터 검색을 위한 ANN 알고리즘들은 정확도를 일부 희생하는 대신 검색 속도를 크게 향상시키는 것을 목표로 합니다. LSH(Locality Sensitive Hashing)는 유사한 벡터들이 같은 해시 버킷에 속할 확률을 높이는 해시 함수를 사용하여 검색 공간을 줄이는 반면, HNSW(Hierarchical Navigable Small World)는 계층적인 그래프 구조를 구축하여 탐색 경로를 최적화합니다. ScaNN(Scalable Nearest Neighbors)은 벡터 양자화와 비대칭 거리 계산 방식을 통해 메모리 효율성과 검색 속도를 동시에 높이는 특징을 가지며, 각 알고리즘은 데이터 분포와 검색 요구 사항에 따라 장단점을 가지므로 실제 사용 사례에 맞춰 선택됩니다.

4. 벡터 데이터베이스의 아키텍처와 주요 기능 (인덱싱, 쿼리 처리, 스케일링, 보안 등)을 설명하고, 특정 사용 사례에 적합한 벡터 데이터베이스를 선택할 때 고려해야 할 요소들을 논하세요.
> 벡터 데이터베이스는 고차원 벡터 데이터를 효율적으로 저장, 인덱싱, 검색하기 위한 특화된 시스템으로, 유사성 검색을 빠르게 수행하기 위해 다양한 인덱싱(HNSW, IVF 등) 알고리즘을 활용합니다. 쿼리 처리 시에는 벡터 간의 거리 또는 유사도를 측정하여 가장 근접한 벡터들을 반환하며, 대규모 데이터 처리를 위한 스케일링(샤딩, 복제 등)과 데이터 보호를 위한 보안(접근 제어, 암호화 등) 기능을 제공합니다. 특정 사용 사례에 적합한 벡터 데이터베이스를 선택할 때는 데이터 규모, 쿼리 성능 요구 사항, 비용, 보안 요구 사항, 그리고 기존 시스템과의 호환성 등을 종합적으로 고려해야 합니다.

5. 임베딩과 벡터 스토어 기술이 RAG (Retrieval Augmented Generation) 파이프라인에서 어떻게 활용되어 LLM의 성능을 향상시키고, 환각 현상을 줄이며, 답변의 신뢰성을 높이는지 구체적인 예시와 함께 설명하세요.
> 임베딩 기술은 텍스트 데이터를 의미론적 유사성을 반영하는 벡터 형태로 변환하여 벡터 스토어에 저장하고, 사용자 질문 또한 동일한 방식으로 임베딩하여 벡터 스토어 내 관련 정보를 효율적으로 검색합니다. 예를 들어, "최신 스마트폰 비교"라는 질문은 스마트폰 관련 문서들의 임베딩과 비교되어 가장 유사한 정보를 담은 문서들을 RAG 파이프라인으로 전달, LLM이 이 정보를 바탕으로 답변을 생성함으로써 환각 현상을 줄이고 답변의 신뢰성을 높입니다.

### 3.3 용어집
1. 임베딩 (Embedding): 
    - 텍스트, 이미지, 오디오 등 고차원 데이터를 저차원 벡터 공간의 숫자 표현으로 변환하는 것. 의미적으로 유사한 데이터는 벡터 공간에서 가까운 거리에 위치하도록 학습됨.

2. 벡터 스토어 (Vector Store): 
    - 벡터 임베딩을 효율적으로 저장, 관리, 검색하기 위해 특화된 데이터베이스. 유사성 검색 (Nearest Neighbor Search) 기능을 제공하여 쿼리 벡터와 가장 유사한 임베딩 벡터를 빠르게 찾을 수 있도록 지원함.

3. ANN (Approximate Nearest Neighbor): 
    - 대규모 데이터셋에서 쿼리 벡터와 가장 가까운 이웃 벡터를 정확도가 약간 떨어지더라도 매우 빠른 속도로 검색하는 기술. LSH, HNSW, ScaNN 등이 대표적인 알고리즘임.

4. RAG (Retrieval Augmented Generation): 
    - 질문 응답, 텍스트 생성 등에서 LLM이 답변을 생성하기 전에 관련된 외부 문서를 검색하고, 검색된 정보를 활용하여 답변의 정확성과 관련성을 높이는 방법.

5. LLM (Large Language Model): 
    - 방대한 텍스트 데이터로 학습된 수억 개 이상의 파라미터를 가진 신경망 기반 언어 모델. 텍스트 생성, 번역, 질의응답 등 다양한 자연어 처리 task를 수행할 수 있음.

6. 토큰화 (Tokenization): 
    - 텍스트를 의미 있는 최소 단위 (토큰)로 분리하는 과정. 단어, 단어 조각 (subword), 문자 등이 토큰이 될 수 있음.

7. Word2Vec: 
    - 단어의 의미를 벡터 공간에 표현하는 널리 사용되는 word embedding 모델. CBOW와 Skip-gram 두 가지 주요 학습 방식을 가짐.

8. GloVe (Global Vectors for Word Representation): 
    - 단어-단어 동시 발생 통계 정보를 활용하여 word embedding을 학습하는 방법.

9. BERT (Bidirectional Encoder Representations from Transformers): 
    - Transformer 아키텍처 기반의 사전 학습된 언어 모델. 문맥 정보를 양방향으로 이해하여 문장 및 문서 임베딩에 널리 사용됨.

10. 정밀도 (Precision): 
    - 검색 결과 중 실제 관련 문서의 비율.

11. 재현율 (Recall): 
    - 전체 관련 문서 중 검색된 관련 문서의 비율.

12. nDCG (Normalized Discounted Cumulative Gain): 
    - 검색 결과의 순위를 고려하여 관련성 점수를 평가하는 지표. 높은 순위에 관련 문서가 위치할수록 높은 점수를 얻음.

13. 코사인 유사도 (Cosine Similarity): 
    - 두 벡터 사이의 각도의 코사인 값을 이용하여 벡터 간의 유사도를 측정하는 방법. 벡터의 크기가 아닌 방향에 초점을 맞춤.

14. 유클리드 거리 (Euclidean Distance): 
    - 두 벡터 사이의 직선 거리.

15. 내적 (Dot Product): 
    - 두 벡터를 성분별로 곱한 후 합한 값. 벡터의 유사성을 측정하는 데 사용될 수 있으며, 벡터의 크기도 고려함.

16. LSH (Locality Sensitive Hashing): 
    - 유사한 데이터 포인트를 높은 확률로 동일한 해시 버킷에 매핑하는 해싱 기술. 근사 최근접 이웃 검색에 사용됨.

17. HNSW (Hierarchical Navigable Small Worlds): 
    - 계층적인 그래프 구조를 이용하여 효율적인 근사 최근접 이웃 검색을 수행하는 알고리즘.

18. ScaNN (Scalable Nearest Neighbors): 
    - Google에서 개발한 대규모 데이터셋에 대한 효율적인 근사 최근접 이웃 검색 알고리즘. 양자화 및 파티셔닝 기술을 활용하여 속도와 정확도 간의 균형을 맞춤.


## 4. 생성형 AI 에이전트
- 출처: [Agents](https://www.kaggle.com/whitepaper-agents)
 
### 4.1 퀴즈
1. 생성형 AI 에이전트의 기본적인 정의는 무엇이며, 주요 특징 두 가지를 설명하세요.
> 생성형 AI 에이전트는 목표를 달성하기 위해 주변 환경을 관찰하고 사용 가능한 도구를 활용하여 행동하는 애플리케이션입니다. 주요 특징으로는 자율성(인간의 개입 없이 독립적으로 행동 가능)과 능동성(명시적인 지시 없이도 목표 달성을 위해 추론하고 다음 행동을 결정)이 있습니다.

2. 에이전트의 인지 아키텍처에서 모델의 역할은 무엇이며, 어떤 종류의 언어 모델이 활용될 수 있는지 예시를 들어 설명하세요.
> 에이전트의 인지 아키텍처에서 모델은 에이전트 프로세스의 중앙 의사 결정자 역할을 수행합니다. 활용 가능한 언어 모델은 일반 목적 모델, 멀티모달 모델, 특정 에이전트 아키텍처의 요구에 따라 미세 조정된 모델 등이 있습니다.

3. 도구가 에이전트의 기능에 어떻게 기여하는지 설명하고, 주요 도구 유형 세 가지를 간략하게 요약하세요.
> 도구는 에이전트가 외부 데이터 및 서비스와 상호 작용할 수 있도록 하여 기본 모델의 단독 능력 이상의 광범위한 작업을 수행할 수 있도록 지원합니다. 주요 도구 유형으로는 확장 프로그램(표준화된 방식으로 API와 에이전트 연결), 함수(클라이언트 측에서 실행되는 코드 모듈), 데이터 저장소(최신 정보를 제공하고 모델 응답의 사실성과 관련성을 보장)가 있습니다.

4. 에이전트와 모델의 주요 차이점 세 가지를 비교하여 설명하세요.
> 모델은 학습 데이터에 제한된 지식을 가지는 반면, 에이전트는 도구를 통해 외부 시스템과 연결하여 지식을 확장합니다. 모델은 일반적으로 단일 추론 또는 예측을 수행하지만, 에이전트는 세션 기록을 관리하여 다중 턴 상호 작용을 지원합니다. 또한, 모델은 기본적으로 도구를 구현하지 않지만, 에이전트 아키텍처에는 도구가 기본적으로 구현되어 있습니다.

5. ReAct 프레임워크의 기본적인 작동 방식과 주요 단계를 간략하게 설명하세요.
> ReAct 프레임워크는 언어 모델이 사용자 쿼리에 대해 추론(Reason)하고 행동(Act)할 수 있도록 하는 프롬프트 엔지니어링 기법입니다. 주요 단계는 질문(Question), 생각(Thought), 행동(Action), 행동 입력(Action input), 관찰(Observation), 최종 답변(Final answer)의 순환으로 이루어집니다.

6. 확장 프로그램(Extensions)이 에이전트와 외부 API 간의 상호 작용을 어떻게 단순화하는지 설명하고, 사용자 쿼리에 따라 적절한 확장 프로그램을 선택하는 방식을 설명하세요.
> 확장 프로그램은 API와 에이전트 사이의 간극을 표준화된 방식으로 메워 API의 기본 구현에 관계없이 에이전트가 원활하게 API를 실행할 수 있도록 합니다. 에이전트는 런타임 시 모델과 확장 프로그램에 포함된 예시를 사용하여 사용자 쿼리를 해결하는 데 가장 적합한 확장 프로그램을 동적으로 선택합니다.

7. 함수 호출(Function Calling)이 확장 프로그램과 어떻게 다른지 주요 차이점 두 가지를 설명하고, 함수 호출의 일반적인 사용 사례 두 가지를 제시하세요.
> 함수 호출은 모델이 함수와 그 인수를 출력하지만 실제 API 호출을 수행하지 않는다는 점, 그리고 함수가 클라이언트 측에서 실행되는 반면 확장 프로그램은 에이전트 측에서 실행된다는 점에서 확장 프로그램과 다릅니다. 일반적인 사용 사례로는 API 호출을 에이전트 아키텍처 외부의 다른 애플리케이션 계층에서 수행해야 하는 경우, 보안 또는 인증 제약으로 인해 에이전트가 직접 API를 호출할 수 없는 경우 등이 있습니다.

8. 데이터 저장소(Data Stores)가 에이전트의 지식 범위를 어떻게 확장하는지 설명하고, RAG 기반 애플리케이션의 기본적인 프로세스를 요약하세요.
> 데이터 저장소는 에이전트가 다양한 형식의 최신 정보에 접근할 수 있도록 하여 기본 학습 데이터 이상의 지식을 제공합니다. RAG 기반 애플리케이션은 사용자 쿼리 임베딩 생성, 벡터 데이터베이스 검색, 관련 콘텐츠 검색, 에이전트에 검색된 콘텐츠 제공, 최종 응답 생성의 단계를 거칩니다.

9. 모델 성능 향상을 위한 세 가지 주요 학습 방법(in-context learning, retrieval-based in-context learning, fine-tuning)을 각각의 요리와 비유하여 설명하세요.
> In-context learning은 특정 레시피(프롬프트), 몇 가지 주요 재료(도구), 예시 요리(few-shot examples)를 제공받은 요리사가 제한된 정보와 일반적인 요리 지식을 바탕으로 즉석에서 요리를 만드는 것에 비유할 수 있습니다. Retrieval-based in-context learning은 재료와 요리책(외부 데이터 저장소)이 잘 갖춰진 주방에서 요리사가 고객의 레시피와 선호도에 맞춰 재료와 요리책을 동적으로 선택하는 것에 해당합니다. Fine-tuning은 요리사가 특정 요리(지식 도메인)를 배우기 위해 요리 학교에 다시 다니는 것에 비유할 수 있습니다.

10. LangChain과 같은 라이브러리가 에이전트 구축을 어떻게 용이하게 하는지 간략하게 설명하고, 제시된 예시에서 사용된 도구 두 가지를 언급하세요.
> LangChain과 같은 라이브러리는 논리, 추론 및 도구 호출 시퀀스를 "연결"하여 사용자 정의 에이전트를 구축할 수 있는 프레임워크를 제공함으로써 에이전트 구축을 용이하게 합니다. 제시된 예시에서는 SerpAPI (Google 검색용)와 Google Places API가 사용되었습니다.

### 4.2 에세이 형식 질문
1. 생성형 AI 에이전트의 개념과 주요 구성 요소(모델, 도구, 오케스트레이션 계층)를 설명하고, 각 구성 요소가 에이전트의 전반적인 기능에 어떻게 기여하는지 논하세요.
> 생성형 AI 에이전트는 대형 언어 모델을 기반으로 자율적으로 작업을 수행하는 지능형 시스템으로, 모델은 텍스트 이해 및 생성을 담당하고, 도구는 외부 세계와의 상호작용 및 특정 기능 수행을 지원하며, 오케스트레이션 계층은 모델과 도구의 활용을 계획하고 관리하여 복잡한 작업을 효과적으로 처리하도록 합니다. 이러한 구성 요소들의 유기적인 협력을 통해 생성형 AI 에이전트는 인간의 개입을 최소화하면서 다양한 문제를 해결하고 새로운 콘텐츠를 창조하는 능력을 갖추게 됩니다.

2. 에이전트의 인지 아키텍처에서 다양한 추론 프레임워크(예: ReAct, Chain-of-Thought, Tree-of-Thoughts)의 역할과 중요성을 비교 분석하고, 특정 유형의 작업에 어떤 프레임워크가 더 적합한지 설명하세요.
> 에이전트의 인지 아키텍처에서 ReAct는 관찰과 행동을 번갈아 수행하며 외부 환경과의 상호작용에 특화되어 실시간 피드백이 중요한 작업에 적합합니다. 반면 Chain-of-Thought는 복잡한 추론 과정을 단계별로 명시하여 답변의 논리적 근거를 확보하는 데 유리하며, Tree-of-Thoughts는 다양한 추론 경로를 탐색하고 평가하여 최적의 해결책을 찾는 데 효과적이므로 고난도의 문제 해결 작업에 적합합니다. 따라서 작업의 복잡성, 필요한 추론 깊이, 외부 환경과의 상호작용 필요성 등을 고려하여 적절한 추론 프레임워크를 선택하는 것이 중요합니다.

3. 에이전트가 외부 세계와 상호 작용하는 데 사용되는 다양한 유형의 도구(확장 프로그램, 함수 호출, 데이터 저장소)의 장단점을 비교하고, 특정 사용 사례에서 어떤 유형의 도구가 가장 효과적인지 논하세요.
> 에이전트가 외부 세계와 상호 작용하는 데 사용되는 도구들은 각각 장단점을 지닙니다. **확장 프로그램**은 특정 기능을 용이하게 통합하지만, 유연성이 제한적일 수 있고 보안 위험을 초래할 수도 있습니다. **함수 호출**은 명확하고 효율적인 상호 작용을 가능하게 하지만, 복잡한 작업 흐름을 관리하기 어려울 수 있습니다. **데이터 저장소**는 정보를 지속적으로 활용할 수 있게 하지만, 데이터 관리 및 접근 방식에 따라 성능과 비용 효율성이 달라질 수 있습니다.
>
> 특정 사용 사례에서 가장 효과적인 도구는 요구 사항에 따라 달라집니다. 간단한 API 호출이나 특정 기능 통합에는 함수 호출이나 확장 프로그램이 적합할 수 있으며, 장기적인 정보 활용 및 복잡한 의사 결정에는 데이터 저장소와 이를 활용하는 함수 호출 또는 확장 프로그램의 조합이 효과적일 수 있습니다. 궁극적으로는 에이전트의 목표, 필요한 상호 작용의 복잡성, 데이터 관리 요구 사항, 보안 고려 사항 등을 종합적으로 고려하여 최적의 도구를 선택해야 합니다.

4. 모델의 기본 능력과 에이전트의 확장된 능력을 비교하여 설명하고, 에이전트 아키텍처가 생성형 AI의 잠재력을 어떻게 확장하고 새로운 애플리케이션 가능성을 여는지 논하세요.
> 모델의 기본 능력은 학습된 데이터 패턴을 기반으로 텍스트 생성, 번역, 요약 등 특정 작업을 수행하는 데 국한되지만, 에이전트는 이러한 기본 모델에 계획, 도구 활용, 기억, 자기 개선 등의 능력을 통합하여 복잡한 작업을 자율적으로 수행할 수 있습니다. 에이전트 아키텍처는 생성형 AI가 단순한 콘텐츠 생성을 넘어 실제 세계와 상호작용하고 문제를 해결하는 지능적인 시스템으로 발전할 수 있도록 확장하며, 개인 비서, 자동화된 워크플로우, 로봇 제어 등 이전에는 상상하기 어려웠던 새로운 애플리케이션 가능성을 열어줍니다.

5. 실제 시나리오에서 생성형 AI 에이전트의 잠재적인 응용 분야를 다양하게 제시하고, 이러한 에이전트가 다양한 산업과 개인의 삶에 미칠 수 있는 영향에 대해 논하세요.
> 생성형 AI 에이전트는 고객 서비스, 콘텐츠 제작, 개인 비서, 교육, 의료 진단 등 다양한 실제 시나리오에서 활용될 잠재력을 지닙니다. 이러한 에이전트들은 반복적인 작업을 자동화하고, 개인 맞춤형 경험을 제공하며, 새로운 아이디어를 창출하는 데 도움을 주어 산업 전반의 생산성을 향상시키고 개인의 삶을 더욱 편리하고 풍요롭게 만들 수 있습니다. 다만, 일자리 감소 및 윤리적 문제에 대한 신중한 고려와 대비가 필요합니다.

### 4.3 용어 해설
1. 에이전트 (Agent): 
    - 목표를 달성하기 위해 주변 환경을 관찰하고 사용 가능한 도구를 사용하여 행동하는 애플리케이션 또는 프로그램.

2. 모델 (Model): 
    - 에이전트 프로세스의 의사 결정을 담당하는 언어 모델(LM). 다양한 크기와 유형(일반 목적, 멀티모달, 미세 조정)이 가능함.

3. 도구 (Tools): 
    - 에이전트가 외부 데이터 및 서비스와 상호 작용할 수 있도록 하는 메커니즘. 확장 프로그램, 함수, 데이터 저장소 등이 포함됨.

4. 오케스트레이션 계층 (Orchestration Layer): 
    - 에이전트가 정보를 받아들이고, 내부 추론을 수행하며, 다음 행동이나 결정을 내리는 방식을 관리하는 순환 프로세스.

5. 인지 아키텍처 (Cognitive Architecture): 
    - 에이전트의 행동, 행동 및 의사 결정을 주도하는 구성 요소의 조합.

6. 확장 프로그램 (Extensions): 
    - API와 에이전트 사이의 간극을 표준화된 방식으로 연결하여 에이전트가 API를 원활하게 실행할 수 있도록 하는 도구.

7. 함수 (Functions): 
    - 특정 작업을 수행하고 필요에 따라 재사용할 수 있는 독립적인 코드 모듈. 에이전트 아키텍처에서 모델이 호출할 수 있음.

8. 데이터 저장소 (Data Stores): 
    - 에이전트가 최신 정보에 접근하고 활용할 수 있도록 하는 저장소. 벡터 데이터베이스 형태로 구현되어 RAG 등에 활용됨.

9. ReAct: 
    - 언어 모델이 추론(Reason)과 행동(Act)을 번갈아 수행하며 사용자 쿼리에 응답하도록 유도하는 프롬프트 엔지니어링 프레임워크.

10. Chain-of-Thought (CoT): 
    - 언어 모델이 중간 추론 단계를 거쳐 복잡한 질문에 답하도록 유도하는 프롬프트 엔지니어링 프레임워크.

11. Tree-of-Thoughts (ToT): 
    - 언어 모델이 다양한 사고 체인을 탐색하여 문제 해결 능력을 향상시키는 프롬프트 엔지니어링 프레임워크.

12. RAG (Retrieval Augmented Generation): 
    - 외부 데이터 저장소에서 관련 정보를 검색하여 언어 모델의 답변 생성 능력을 향상시키는 기술.

13. In-context learning: 
    - 모델에게 프롬프트, 도구 및 몇 가지 예시를 제공하여 추론 시간에 특정 작업을 수행하는 방법을 학습시키는 방법.

14. Retrieval-based in-context learning: 
    - 외부 메모리에서 가장 관련성 높은 정보, 도구 및 예시를 검색하여 모델 프롬프트에 동적으로 채우는 기술.

15. Fine-tuning: 
    - 추론 전에 특정 예시 데이터셋을 사용하여 모델을 학습시켜 특정 도구를 적용하는 시점과 방법을 이해하도록 돕는 방법.

16. LangChain: 
    - 사용자 정의 에이전트를 구축하기 위해 논리, 추론 및 도구 호출 시퀀스를 연결할 수 있는 오픈 소스 라이브러리.

## 5. 에이전트 동반자
- 출처: [Agents Companion](https://www.kaggle.com/whitepaper-agent-companion)

### 5.1 퀴즈
1. 에이전트의 세 가지 필수 요소는 무엇이며 각각의 주요 기능은 무엇입니까? 
> 에이전트의 세 가지 필수 요소는 모델(언어 모델로서 의사 결정의 핵심), 도구(외부 데이터 및 서비스와의 상호 작용 촉진), 오케스트레이션 계층(정보 흡수, 추론, 후속 행동 결정의 순환 프로세스)입니다. 모델은 에이전트의 특정 요구 사항에 따라 다양한 형태를 가질 수 있으며, 도구는 에이전트의 내부 역량과 외부 세계를 연결하며, 오케스트레이션 계층은 에이전트의 기억, 상태, 추론 및 계획을 관리합니다.

2. AgentOps는 GenAIOps의 하위 범주로서 기존의 "Ops" 접근 방식과 구별되는 주요 추가 구성 요소는 무엇입니까? 
> AgentOps는 기존의 DevOps 및 MLOps 위에 구축되지만, 내부 및 외부 도구 관리, 에이전트 브레인 프롬프트(목표, 프로필, 지침) 및 오케스트레이션, 기억, 작업 분해와 같은 에이전트별 요소를 추가적으로 포함합니다. 이러한 구성 요소는 에이전트의 효율적인 운영 및 관리를 가능하게 합니다.

3. 에이전트 성공 지표를 설정할 때 비즈니스 지표와 에이전트 평가 지표의 관계를 설명하고 주요 에이전트 성공 지표의 예를 두 가지 제시하십시오. 
> 비즈니스 지표는 에이전트의 전반적인 성공을 측정하는 "북극성" 역할을 하며, 수익이나 사용자 참여와 같은 높은 수준의 목표를 나타냅니다. 에이전트 평가 지표는 목표 완료율이나 중요한 작업 완료율과 같이 에이전트의 특정 성능을 측정하는 데 사용됩니다. 예를 들어, 목표 완료율과 특정 사용자 상호 작용 성공률은 중요한 에이전트 성공 지표가 될 수 있습니다.

4. 에이전트 평가의 세 가지 주요 구성 요소는 무엇이며, 각 구성 요소의 평가 초점을 간략하게 설명하십시오. 
> 에이전트 평가의 세 가지 주요 구성 요소는 에이전트 역량 평가(명령 이해 및 논리적 추론 능력 평가), 궤적 및 도구 사용 평가(솔루션 도달 과정 분석), 최종 응답 평가(결과물의 품질, 관련성, 정확성 평가)입니다. 각 구성 요소는 에이전트의 성능을 다양한 각도에서 분석하는 데 중점을 둡니다.

5. 자동화된 궤적 평가 방법 중 "정확히 일치(Exact match)"와 "순서 무관 일치(Any-order match)"의 차이점을 설명하십시오. 
> "정확히 일치"는 AI 에이전트가 이상적인 솔루션과 완전히 동일한 행동 순서(궤적)를 생성해야 하는 가장 엄격한 메트릭입니다. 반면, "순서 무관 일치"는 에이전트가 필요한 모든 행동을 포함했는지 여부를 평가하지만, 행동의 순서는 고려하지 않으며 불필요한 추가 행동도 허용합니다.

6. 최종 응답 평가를 자동화하는 데 사용되는 "자동 평가기(autorater)"의 개념을 설명하고, 이 방법의 주요 고려 사항을 한 가지 언급하십시오. 
> 자동 평가기는 LLM을 심판관으로 활용하여 입력 프롬프트와 생성된 응답을 기반으로 사용자 정의 평가 기준에 따라 응답을 평가하는 메커니즘입니다. 이 방법을 사용할 때 중요한 고려 사항은 ground-truth가 없는 상황에서 평가 기준을 매우 정확하게 정의해야 한다는 것입니다.

7. 단일 에이전트 시스템과 비교하여 다중 에이전트 시스템이 제공하는 세 가지 주요 장점은 무엇입니까? 
> 다중 에이전트 시스템은 단일 에이전트 시스템에 비해 향상된 정확성(상호 검증), 향상된 효율성(병렬 작업), 복잡한 작업 처리 능력 향상(작업 분할)과 같은 여러 가지 주요 장점을 제공합니다. 또한 확장성, 오류 내성, 환각 및 편향 감소에도 기여합니다.

8. 다중 에이전트 아키텍처 내에서 "플래너 에이전트(Planner Agent)"와 "실행 에이전트(Execution Agent)"의 주요 역할을 설명하십시오. 
> 다중 에이전트 아키텍처에서 플래너 에이전트는 높은 수준의 목표를 구조화된 하위 작업으로 분해하는 역할을 담당합니다. 반면, 실행 에이전트는 실제 계산을 수행하고, 응답을 생성하거나, API와 상호 작용하는 등의 구체적인 작업을 실행합니다.

9. 전통적인 RAG 파이프라인과 비교하여 에이전트 기반 RAG가 검색 정확성과 적응성을 향상시키는 주요 방법 두 가지를 설명하십시오. 
> 에이전트 기반 RAG는 상황 인식 쿼리 확장(단일 검색 대신 여러 쿼리 개선)과 다단계 추론(복잡한 쿼리를 작은 단계로 분해하여 순차적으로 정보 검색)을 통해 전통적인 RAG에 비해 검색 정확성과 적응성을 크게 향상시킵니다. 또한, 적응형 소스 선택 및 검증 및 수정 기능도 활용합니다.

10. 자동차 AI 분야에서 다중 에이전트 아키텍처를 사용할 때 얻을 수 있는 세 가지 주요 이점은 무엇입니까? 
> 자동차 AI를 위한 다중 에이전트 아키텍처는 복잡한 작업을 전문화된 역할로 분담하여 효율성을 높이고, 각 에이전트가 특정 영역에 집중하여 더 깊은 역량을 개발할 수 있도록 합니다. 또한, 중요 기능에 대한 빠른 응답을 보장하고, 연결이 끊긴 상황에서도 기본적인 기능을 유지하는 등 복원력을 향상시킵니다.

### 5.2 에세이 형식 질문
1. AgentOps의 원칙을 설명하고, AI 에이전트의 성공적인 개발 및 배포에 AgentOps가 어떻게 기여하는지 구체적인 예를 들어 논하십시오.
> 생성형 AI 에이전트는 고객 서비스, 콘텐츠 제작, 개인 비서, 교육, 의료 진단 등 다양한 실제 시나리오에서 활용될 잠재력을 지닙니다. 이러한 에이전트들은 반복적인 작업을 자동화하고, 개인 맞춤형 경험을 제공하며, 새로운 아이디어를 창출하는 데 도움을 주어 산업 전반의 생산성을 향상시키고 개인의 삶을 더욱 편리하고 풍요롭게 만들 수 있습니다. 다만, 일자리 감소 및 윤리적 문제에 대한 신중한 고려와 대비가 필요합니다.

2. 에이전트 평가 프레임워크를 설계할 때 고려해야 할 주요 요소들을 설명하고, 자동화된 평가 방법과 인간 기반 평가 방법의 장단점을 비교 분석하십시오.
> 에이전트 평가 프레임워크 설계 시 주요 고려 요소는 목표 정확성, 일반화 능력, 효율성, 공정성, 확장성 등이다. 자동화된 평가는 빠른 처리와 객관성이 장점이지만, 복잡한 맥락 이해의 한계가 있으며, 인간 기반 평가는 세밀한 판단과 유연성이 우수하지만 시간과 비용이 많이 소요된다는 단점이 있다. 두 방법을 혼용하여 상호 보완적인 평가 체계를 구축하는 것이 효과적이다.

3. 다양한 다중 에이전트 아키텍처 패턴(예: 계층형, 다이아몬드형, 피어-투-피어, 협업형)을 비교하고, 각 패턴이 특정 유형의 문제 해결에 어떻게 적합한지 사례를 들어 설명하십시오.
> 다중 에이전트 아키텍처 패턴은 에이전트 간의 조직 구조와 상호작용 방식에 따라 다양하게 분류되며, 계층형은 중앙 집중식 제어가 필요한 복잡한 작업 분할에, 다이아몬드형은 정보 집약적인 작업의 효율적인 분배 및 통합에 적합합니다. 반면, 피어-투-피어형은 분산된 환경에서 자율적인 협업을, 협업형은 공동의 목표 달성을 위한 전문 지식 공유 및 조율에 효과적이며, 예를 들어 계층형은 제조 공정 제어, 다이아몬드형은 센서 데이터 분석, 피어-투-피어형은 분산 컴퓨팅, 협업형은 재난 구조 작업 등에 활용될 수 있습니다.

4. Agentic RAG의 개념과 중요성을 설명하고, 전통적인 RAG와 비교하여 지식 검색 및 활용 방식을 어떻게 혁신하는지 심층적으로 논하십시오.
> Agentic RAG는 자율적인 에이전트의 능력과 검색 증강 생성(RAG)을 결합하여, 복잡한 질문에 대해 능동적으로 정보를 탐색, 추론, 통합하여 답변하는 혁신적인 접근 방식입니다. 전통적인 RAG가 단순한 검색 후 생성을 수행하는 반면, Agentic RAG는 다단계 추론, 외부 도구 활용, 자기 개선 등의 에이전트 기능을 통해 지식 검색의 정확성과 답변의 맥락 적합성을 크게 향상시키고, 더욱 심층적인 수준의 질문 해결을 가능하게 합니다. 이러한 발전은 정보 접근 및 활용 방식을 혁신하여, 보다 지능적이고 사용자 맞춤형의 정보 서비스를 제공할 수 있는 잠재력을 지닙니다.

5. 자동차 산업에서 다중 에이전트 시스템의 실제 사용 사례(예: 대화형 내비게이션, 미디어 검색, 차량 매뉴얼 에이전트)를 분석하고, 이러한 아키텍처가 사용자 경험과 차량 기능에 어떤 이점을 제공하는지 평가하십시오.
> 자동차 산업에서 다중 에이전트 시스템은 대화형 내비게이션, 미디어 검색, 차량 매뉴얼 에이전트 등 다양한 실제 사용 사례를 통해 사용자에게 맞춤형 정보와 편리한 기능을 제공합니다. 이러한 아키텍처는 각 에이전트가 특정 작업을 전문적으로 수행하고 협력하여 복잡한 사용자 요구를 효율적으로 처리함으로써 사용자 경험을 향상시키고 차량 기능을 확장합니다. 결과적으로 운전자는 더욱 안전하고 편리하며 풍부한 차량 내 경험을 누릴 수 있게 됩니다.


### 5.3 용어집
1. 에이전트 (Agent): 
    - 특정 목표를 달성하기 위해 환경을 인식하고, 사용 가능한 도구를 사용하여 전략적으로 행동하는 애플리케이션.

2. 언어 모델 (Language Model, LM): 
    - 텍스트 데이터를 기반으로 학습하여 인간과 유사한 텍스트를 이해하고 생성할 수 있는 AI 모델.

3. 도구 (Tools): 
    - 에이전트가 외부 데이터 및 서비스와 상호 작용할 수 있도록 지원하는 확장, 함수, 데이터 저장소 등의 메커니즘.

4. 오케스트레이션 계층 (Orchestration Layer): 
    - 에이전트가 정보를 흡수하고, 추론을 수행하며, 후속 행동을 결정하는 순환적 프로세스를 관리하는 구성 요소.

5. AgentOps: 
    - AI 에이전트의 효율적인 운영 및 관리에 중점을 두는 GenAIOps의 하위 범주.

6. GenAIOps: 
    - 생성형 AI 모델 및 애플리케이션의 운영화를 위한 원칙과 사례.

7. RAG (Retrieval-Augmented Generation): 
    - 외부 지식 소스를 검색하여 언어 모델의 응답을 강화하는 기술.

8. Agentic RAG: 
    - 자율적인 검색 에이전트를 활용하여 검색 프로세스를 능동적으로 개선하고 평가하는 고급 RAG 접근 방식.

9. 다중 에이전트 시스템 (Multi-Agent System): 
    - 복잡한 목표를 달성하기 위해 협력하는 여러 전문화된 에이전트로 구성된 시스템.

10. 에이전트 벤치마크 (Agent Benchmark): 
    - 에이전트의 핵심 역량 및 전반적인 성능을 평가하기 위한 표준화된 테스트 및 지표.

11. 궤적 (Trajectory): 
    - 에이전트가 목표를 달성하기 위해 취하는 일련의 행동 또는 단계.

12. 자동 평가기 (Autorater): 
    - LLM을 활용하여 사용자 정의 기준에 따라 에이전트의 응답을 자동으로 평가하는 메커니즘.

13. 계층형 패턴 (Hierarchical Pattern): 
    - 중앙 오케스트레이터 에이전트가 쿼리를 분류하고 전문화된 에이전트로 라우팅하는 다중 에이전트 아키텍처 패턴.

14. 다이아몬드 패턴 (Diamond Pattern): 
    - 전문화된 에이전트의 응답이 사용자에게 전달되기 전에 중앙 중재 에이전트를 거치는 계층형 패턴의 변형.

15. 피어-투-피어 패턴 (Peer-to-Peer Pattern): 
    - 에이전트가 라우팅 오류를 감지하면 서로에게 쿼리를 핸드오프할 수 있는 다중 에이전트 아키텍처 패턴.

16. 협업형 패턴 (Collaborative Pattern): 
    - 여러 에이전트가 동일한 작업의 상호 보완적인 측면에서 작업하고, 응답 믹서 에이전트가 결과를 결합하여 포괄적인 답변을 생성하는 패턴.

17. 응답 믹서 에이전트 (Response Mixer Agent): 
    - 여러 에이전트의 응답 중에서 최적의 부분을 선택하고 병합하여 사용자에게 가장 유용한 답변을 제공하는 전문 에이전트.

18. 적응형 루프 패턴 (Adaptive Loop Pattern): 
    - 원하는 기준을 충족할 때까지 반복적인 시도를 통해 결과를 점진적으로 개선하는 패턴.

19. 계약 (Contract): 
    - 요청자와 에이전트 간의 합의를 명시하여 결과 정의, 협상 가능성, 하위 계약 생성을 표준화하는 개념.

## 6. 도메인 특화 LLM을 활용한 문제 해결
- 출처: [Solving Domain-Specific Problems Using LLMs](https://www.kaggle.com/whitepaper-solving-domains-specific-problems-using-llms)

### 6.1 퀴즈

1. 이 백서에서 주로 다루는 두 가지 특정 도메인은 무엇이며, 각 도메인에서 LLM이 제시하는 주요 과제는 무엇인가요? 
> 이 백서에서 다루는 두 가지 주요 도메인은 사이버 보안과 의료입니다. 사이버 보안에서 주요 과제는 공개적으로 사용 가능한 데이터의 부족, 매우 기술적인 개념의 다양성, 그리고 끊임없이 변화하는 위협 정보입니다. 의료 분야에서는 방대하고 끊임없이 진화하는 의학 지식과 상황에 따른 정확한 적용의 필요성이 주요 과제입니다.

2. SecLM API의 주요 목표는 무엇이며, 보안 전문가가 복잡한 보안 질문에 대한 답변을 얻는 방식을 어떻게 간소화하려고 하나요? 
> SecLM API의 주요 목표는 보안 질문에 대한 '원스톱 샵'을 제공하는 것입니다. 이는 엔지어나 분석가가 자연어로 질문하고 데이터 소스를 참조하면 필요한 정보를 자동으로 통합한 답변을 얻을 수 있도록 함으로써 복잡한 보안 문제 해결 방식을 간소화하려고 합니다.

3. 사이버 보안 분야에서 일반 목적 LLM보다 특화된 LLM이 필요한 세 가지 주요 이유는 무엇인가요? 
> 일반 목적 LLM보다 사이버 보안에 특화된 LLM이 필요한 세 가지 주요 이유는 공개적으로 사용 가능한 보안 데이터의 부족, 보안 콘텐츠의 제한된 깊이, 그리고 악성 코드 분석과 같은 민감한 사용 사례를 일반 모델이 설계상 제대로 처리하지 못하기 때문입니다.

4. SecLM 모델을 훈련하는 데 사용되는 주요 단계는 무엇이며, 각 단계에서 어떤 종류의 데이터를 활용하여 성능, 일반화 및 데이터 보안을 달성하려고 하나요? 
> SecLM 모델 훈련의 주요 단계는 광범위한 일반 텍스트 및 코드 데이터에 대한 사전 훈련, 보안 관련 콘텐츠에 대한 지속적인 사전 훈련, 그리고 악성 스크립트 분석 및 위협 인텔리전스 요약과 같은 특정 보안 작업에 대한 지도 학습 미세 조정입니다. 각 단계는 성능 향상, 새로운 작업 및 데이터에 대한 일반화 보장, 그리고 민감한 사용자 데이터의 분리를 목표로 합니다.

5. SecLM의 유연한 계획 및 추론 프레임워크는 광범위하고 높은 수준의 질문에 어떻게 대처하여 분석가에게 실행 가능한 통찰력을 제공할 수 있나요? 
> SecLM의 유연한 계획 및 추론 프레임워크는 보안 전문가의 지침 또는 고급 LLM을 사용하여 복잡한 질문을 개별 작업으로 분해하는 다단계 계획을 생성합니다. 그런 다음 위협 인텔리전스 검색, 정보 추출, SIEM 쿼리와 같은 작업을 조정하여 분석가의 질문에 대한 포괄적인 답변을 제공하고 실행 가능한 통찰력을 제공합니다.

6. MedLM 제품군의 핵심 모델인 Med-PaLM이 의료 질의응답에서 전문가 수준의 성능을 달성하는 데 기여한 주요 발전 사항은 무엇인가요? 
> Med-PaLM이 의료 질의응답에서 전문가 수준의 성능을 달성하는 데 기여한 주요 발전 사항은 대규모 의료 데이터 세트에 대한 모델의 미세 조정, USMLE 스타일 질문에 대한 정확도 향상을 위한 Chain-of-Thought 및 Self-Consistency와 같은 고급 프롬프트 전략의 사용, 그리고 앙상블 정제와 같은 기술을 통한 답변 개선입니다.

7. 의료 분야에서 GenAI가 제공하는 몇 가지 잠재적인 기회는 무엇이며, 이러한 기술이 환자와 임상의 상호 작용 방식을 어떻게 혁신할 수 있나요? 
> 의료 분야에서 GenAI가 제공하는 몇 가지 잠재적인 기회는 환자 기록의 맥락에서 질문할 수 있도록 지원, 환자 메시지의 긴급성을 이해하고 분류하여 임상의에게 메시지 우선순위 지정, 환자 응답에 따라 적응적인 환자 정보 수집 프로세스 개선, 환자-임상의 대화 모니터링 및 실행 가능한 피드백 제공, 그리고 임상의가 익숙하지 않은 시나리오를 처리할 수 있도록 온디맨드 컨설팅 제공 등이 있습니다.

8. Med-PaLM 프레임워크에서 제안하는 평가 방법은 의료 질의응답 성능을 어떻게 종합적으로 평가하며, 단순 정확도 외에 어떤 측면을 고려하나요? 
> Med-PaLM 프레임워크의 평가 방법은 USMLE 스타일 질문에 대한 정확도뿐만 아니라 사실성, 추론 시 전문가 지식 활용, 유용성, 건강 형평성 및 잠재적 위해성과 같은 장문 답변의 질적 평가를 포함합니다. 전문 임상의는 상세한 평가 루브릭을 사용하여 이러한 측면을 체계적으로 평가합니다.

9. 새로운 AI 기반 의료 기술을 실제 임상 환경에 통합할 때 권장되는 과학적 단계는 무엇이며, 이러한 단계가 중요한 이유는 무엇인가요? 
> 새로운 AI 기반 의료 기술을 실제 임상 환경에 통합할 때 권장되는 과학적 단계는 과거 데이터에 대한 후향적 평가, 새로운 실제 데이터에 대한 전향적 관찰 평가 (기술 결과가 환자 치료에 영향을 미치지 않음), 그리고 동의한 환자와 실제 임상 환경에서 기술을 배포하고 환자 치료 및 건강 결과에 영향을 미치는 전향적 중재 평가입니다. 이러한 단계는 모델 성능과 실제 워크플로 통합 시 시스템의 전반적인 효과를 검증하는 데 중요합니다.

10. 작업 특화 모델과 도메인 특화 모델의 주요 차이점은 무엇이며, 특정 의료 도메인 작업에서 뛰어난 성능을 보이는 것이 다른 의료 도메인 작업의 성공을 보장하지 못하는 이유는 무엇인가요? 
> 작업 특화 모델은 특정 작업 (예: 의료 이미지 분류)에 대해 훈련되는 반면, 도메인 특화 모델 (예: Med-PaLM)은 더 넓은 도메인 내의 다양한 작업에 대한 일반적인 이해를 목표로 합니다. 특정 의료 도메인 작업에서 뛰어난 성능을 보이는 것이 다른 의료 도메인 작업의 성공을 보장하지 못하는 이유는 각 작업이 고유한 기술, 지식 및 검증 요구 사항을 가질 수 있기 때문입니다.

### 6.2 에세이 형식 질문

1. 사이버 보안 및 의료 분야에서 대규모 언어 모델 (LLM)을 사용하여 도메인별 문제를 해결할 때의 주요 과제와 기회를 논의하고, 이러한 과제를 해결하고 기회를 활용하기 위한 전략을 분석하십시오.
> 자동차 산업에서 다중 에이전트 시스템은 대화형 내비게이션, 미디어 검색, 차량 매뉴얼 에이전트 등 다양한 실제 사용 사례를 통해 사용자에게 맞춤형 정보와 편리한 기능을 제공합니다. 이러한 아키텍처는 각 에이전트가 특정 작업을 전문적으로 수행하고 협력하여 복잡한 사용자 요구를 효율적으로 처리함으로써 사용자 경험을 향상시키고 차량 기능을 확장합니다. 결과적으로 운전자는 더욱 안전하고 편리하며 풍부한 차량 내 경험을 누릴 수 있게 됩니다.

2. SecLM API의 설계 및 훈련 철학을 설명하고, 보안 전문가의 작업 흐름을 개선하고 현대 사이버 보안 시스템의 주요 과제 (위협, 업무 부담, 인력 부족)를 해결할 수 있는 잠재력을 평가하십시오.
> SecLM API는 보안 전문가의 작업을 지원하기 위해 자연어 처리와 사이버 보안 지식을 결합하여 설계되었으며, 대규모 언어 모델이 보안 관련 데이터를 학습해 정확하고 신뢰할 수 있는 결과를 제공하는 것을 목표로 합니다. 이를 통해 위협 탐지 및 분석 자동화, 업무 효율성 향상, 인력 부족 문제 완화 등 현대 사이버 보안 시스템의 주요 과제를 해결할 잠재력을 가지고 있습니다. 특히 복잡한 보안 로그 분석이나 실시간 위협 대응에서 인간 전문가의 부담을 줄이고 더 나은 의사결정을 지원할 수 있습니다.

3. MedLM 제품군의 개발 및 평가 프로세스를 비판적으로 분석하고, 의료 질의응답에서 전문가 수준의 성능을 달성하는 데 기여한 주요 방법론적 혁신을 강조하십시오. 또한 실제 임상 환경에서 이러한 모델을 책임감 있게 배포하기 위한 윤리적 및 실질적인 고려 사항을 논의하십시오.
> MedLM 제품군의 개발 및 평가 프로세스는 의료 데이터의 민감성과 복잡성을 고려하여, 대규모 의료 데이터셋을 활용한 사전 학습과 의료 전문가의 피드백을 통합한 반복적 미세 조정을 특징으로 합니다. 특히, 질의응답 성능 향상을 위해 지식 그래프와 연계된 멀티모달 학습, 그리고 불확실성 추정 기법 도입이 주요 방법론적 혁신으로 작용했습니다. 실제 임상 환경에서 책임감 있는 배포를 위해서는 모델의 투명성 확보, 의사 결정의 설명 가능성 제공, 그리고 환자 데이터의 개인정보 보호를 위한 강력한 암호화 및 접근 제어 정책이 필수적이며, 윤리적으로는 잘못된 진단이나 치료 권고로 인한 위험을 최소화하기 위해 인간 전문가의 감독 하에 점진적 적용이 필요합니다.

4. 작업 특화 모델과 도메인 특화 모델의 개념을 비교 및 대조하고, 특정 애플리케이션에 대한 LLM을 훈련하고 평가할 때의 장단점을 탐구하십시오. 또한 의료 분야에서 다양한 임상 및 과학적 사용 사례를 위해 MedLM과 같은 도메인 특화 모델을 개발하는 미래 방향에 대해 추측하십시오.
> 작업 특화 모델은 특정 작업(예: 번역, 요약)에 최적화된 모델로, 일반적으로 넓은 범위의 데이터에서 학습된 LLM을 해당 작업에 맞게 미세 조정합니다. 반면, 도메인 특화 모델은 특정 분야(예: 의료, 법률)의 데이터를 중심으로 사전 학습되어 해당 분야의 전문 지식을 내포합니다. 특정 애플리케이션에 대한 LLM을 훈련할 때 작업 특화 모델은 빠른 적용과 적은 데이터 요구라는 장점이 있지만, 도메인 특화 모델은 깊이 있는 전문성을 제공하는 대신 더 많은 도메인별 데이터와 리소스가 필요합니다.
>
> 의료 분야에서는 MedLM과 같은 도메인 특화 모델이 임상 의사 결정 지원, 의학 연구 자동화, 환자 데이터 분석 등 다양한 사용 사례에서 활용될 수 있습니다. 미래에는 이러한 모델이 더욱 정교해지며, 다중 모달 데이터(텍스트, 이미지, 유전체 데이터 등)를 통합하고 실시간으로 진단 및 치료 옵션을 제안하는 방향으로 발전할 가능성이 큽니다. 이를 통해 의료 서비스의 효율성과 정확성을 크게 향상시킬 수 있을 것입니다.

5. 이 백서에서 제시된 사례 연구 (SecLM 및 MedLM)를 기반으로 다양한 도메인에서 도메인 특화 LLM을 성공적으로 개발하고 배포하기 위한 주요 성공 요인을 식별하고, 이러한 요인이 의료 또는 사이버 보안 이외의 새로운 도메인에 어떻게 적용될 수 있는지 논의하십시오.
> 주요 성공 요인으로는 도메인별 데이터의 품질과 양, 도메인 전문가와의 긴밀한 협업, 그리고 특정 도메인에 맞춘 모델 튜닝 및 최적화를 들 수 있습니다. 이러한 요인은 의료나 사이버 보안 외에도 금융, 법률, 교육 등 새로운 도메인에 적용될 수 있으며, 각 도메인의 고유한 요구사항과 규제를 반영한 데이터 수집 및 모델 개발 프로세스를 통해 해당 분야에서 높은 성능과 신뢰성을 확보할 수 있습니다. 특히 적절한 윤리적 기준과 규정 준수를 고려한 접근이 필수적입니다. 


### 6.3 용어집 
1. LLM (Large Language Model): 
    - 방대한 양의 텍스트 데이터에 대해 훈련되어 텍스트를 이해하고 생성할 수 있는 심층 학습 알고리즘입니다.

2. GenAI (Generative AI): 
    - 기존 데이터에서 학습하여 새로운 콘텐츠 (텍스트, 이미지, 오디오 등)를 생성할 수 있는 인공 지능의 한 유형입니다.

3. SecLM: 
    - 사이버 보안 작업을 위해 특별히 설계되고 훈련된 도메인 특화 대규모 언어 모델입니다.

4. MedLM: 
    - 의료 및 건강 관리 애플리케이션을 위해 미세 조정된 대규모 언어 모델 제품군입니다.

5. Med-PaLM: 
    - 의료 관련 질문에 고품질의 권위 있는 답변을 제공하기 위해 설계된 Google의 LLM으로 MedLM 제품군의 핵심 모델입니다.

6. Fine-tuning (미세 조정): 
    - 특정 작업이나 도메인에서 성능을 향상시키기 위해 사전 훈련된 모델을 추가 데이터로 훈련하는 프로세스입니다.

7. Retrieval-Augmented Generation (RAG): 
    - LLM이 답변을 생성하기 전에 외부 지식 소스를 검색하여 답변의 정확성과 관련성을 향상시키는 기술입니다.

8. Zero-shot learning (제로샷 학습): 
    - 모델이 이전에 본 적 없는 작업이나 클래스에 대해 직접 수행할 수 있는 능력입니다.

9. Few-shot prompting (퓨샷 프롬프트): 
    - 모델에 작업 수행 방법을 보여주는 몇 가지 예시를 제공하여 더 나은 출력을 유도하는 기술입니다.

10. Chain-of-Thought (CoT) prompting (연쇄적 사고 프롬프트): 
    - 모델이 최종 답변에 도달하기 위한 추론 단계를 설명하도록 유도하는 기술입니다.

11. Self-consistency (자기 일관성): 
    - 모델에서 여러 개의 가능한 답변을 샘플링하고 가장 일관된 답변을 선택하여 다중 선택 질문에 대한 성능을 향상시키는 기술입니다.

12. Ensemble Refinement (ER) (앙상블 정제): 
    - LLM이 생성한 여러 추론 경로를 조건으로 하여 답변을 개선하고 정제하는 기술입니다.

13. USMLE (United States Medical Licensing Examination): 
    - 미국에서 의사가 되기 위해 합격해야 하는 3단계 시험입니다. 의료 지식 및 임상 기술을 평가하는 데 사용되는 벤치마크입니다.

14. TTPs (Tactics, Techniques, and Procedures) (전술, 기술 및 절차): 
    - 공격자가 공격을 수행하는 데 사용하는 패턴입니다.

15. APT (Advanced Persistent Threat) (지능형 지속 위협): 
    - 장기간에 걸쳐 네트워크에 은밀히 침투하여 민감한 정보를 훔치는 것을 목표로 하는 고도로 숙련된 공격 그룹입니다.

16. SIEM (Security Information and Event Management) (보안 정보 및 이벤트 관리):
    - 보안 경고 및 이벤트를 중앙 집중식으로 수집 및 분석하여 위협을 식별하고 대응하는 데 사용되는 시스템입니다.

17. Malware (악성 코드): 
    - 컴퓨터 시스템에 손상을 주거나 무단 액세스를 얻도록 설계된 소프트웨어입니다.

18. Phishing (피싱): 
    - 신뢰할 수 있는 개체로 위장하여 민감한 정보를 얻으려는 사기성 시도입니다.

19. Operational toil (운영 부담): 
    - 자동화하거나 지원할 수 있는 반복적이고 수동적인 작업에 소비되는 시간과 노력입니다.

20. Principle of least privilege (최소 권한 원칙): 
    - 사용자 또는 프로세스에 작업을 수행하는 데 필요한 최소한의 권한만 부여해야 한다는 보안 원칙입니다.

21. Fuzz-testing (퍼즈 테스트): 
    - 소프트웨어에 유효하지 않거나 예상치 못한 입력을 제공하여 결함 및 취약점을 찾는 테스트 기술입니다.

22. Threat intelligence (위협 인텔리전스): 
    - 알려진 또는 잠재적인 위협에 대한 정보입니다.

23. Indicators of compromise (IOCs) (침해 지표): 
    - 시스템이나 네트워크가 보안 사고를 당했음을 나타내는 증거입니다.

24. De-obfuscation (난독화 해제): 
    - 코드를 이해하기 어렵게 만드는 기술을 되돌려 코드를 읽기 쉽도록 만드는 프로세스입니다.

25. Decompilation (역컴파일): 
    - 실행 가능한 코드를 인간이 읽을 수 있는 소스 코드로 변환하는 프로세스입니다.

26. Pre-training (사전 훈련): 
    - 다운스트림 작업에 사용할 수 있는 일반적인 언어 이해 및 생성 능력을 학습하기 위해 대규모 데이터 세트에 대해 모델을 훈련하는 초기 단계입니다.

27. Parameter-efficient tuning (PET) (매개변수 효율적 튜닝): 
    - 사전 훈련된 모델의 모든 매개변수를 업데이트하는 대신 소수의 추가 매개변수만 훈련하여 미세 조정의 계산 비용을 줄이는 기술입니다.

28. In-context learning (문맥 내 학습): 
    - 명시적인 기울기 업데이트 없이 프롬프트 내의 예시를 기반으로 작업을 수행하는 LLM의 능력입니다.

29. Multi-modal (다중 모드): 
    - 텍스트, 이미지, 오디오 등과 같은 여러 가지 유형의 데이터를 처리하고 통합할 수 있는 시스템입니다.

30. Instruction fine-tuning (명령어 미세 조정): 
    - 모델이 자연어 지침을 따르도록 훈련하는 데 사용되는 미세 조정의 한 유형입니다.

31. MultiMedQA: 
    - 의료 도메인에서 LLM을 평가하기 위한 다양한 질의응답 데이터 세트의 모음입니다.

32. Ensemble learning (앙상블 학습): 
    - 여러 모델의 예측을 결합하여 단일 모델의 성능보다 더 나은 예측을 얻는 기술입니다.

33. Temperature sampling (온도 샘플링): 
    - LLM에서 텍스트를 생성할 때 무작위성을 제어하는 데 사용되는 매개변수입니다. 높은 온도는 더 무작위적인 출력을 생성하고, 낮은 온도는 더 결정적인 출력을 생성합니다.

34. IRB (Institutional Review Board) (기관 검토 위원회): 
    - 인간 연구의 윤리적 측면을 감독하는 위원회입니다.

35. Retrospective evaluation (후향적 평가): 
    - 과거에 수집된 실제 데이터에 대해 기술을 평가하는 것입니다.

36. Prospective evaluation (전향적 평가): 
    - 새롭게 수집된 실제 데이터에 대해 기술을 평가하는 것입니다. 이는 관찰적 (환자 치료에 영향을 미치지 않음) 또는 중재적 (환자 치료에 영향을 미침)일 수 있습니다.

## 7. 생성형 AI 운영 및 MLOps 
- 출처: [Operationalizing Generative AI on Vertex AI using MLOps](https://www.kaggle.com/whitepaper-operationalizing-generative-ai-on-vertex-ai-using-mlops)

### 7.1 퀴즈
1. DevOps와 MLOps의 주요 목표는 무엇이며, Gen AI 시스템의 맥락에서 MLOps의 특별한 고려 사항은 무엇입니까?
> DevOps는 개발과 운영 간의 간극을 해소하여 소프트웨어 개발 라이프사이클을 간소화하는 것을 목표로 합니다. MLOps는 머신러닝 시스템에 동일한 원칙을 적용합니다. Gen AI 시스템의 경우 모델 선택, 데이터 큐레이션, 프롬프트 엔지니어링, 모델 튜닝 및 평가와 관련된 새로운 과제가 발생하므로 MLOps 관행을 조정해야 합니다.

2. Gen AI 시스템 개발 수명 주기의 "발견" 단계에서 중요한 요소는 무엇이며, Vertex AI Model Garden은 이 단계에서 어떻게 도움이 됩니까?
> "발견" 단계에서는 다양한 파운데이션 모델의 가용성, 기능, 비용, 성능 및 규정 준수를 이해하는 것이 중요합니다. Vertex AI Model Garden은 Google 및 기타 제공업체의 사전 학습된 다양한 모델을 탐색, 테스트 및 배포할 수 있는 중앙 집중식 플랫폼을 제공하여 모델 검색 프로세스를 지원합니다.

3. Gen AI 실험 주기의 핵심은 무엇이며, 프롬프트 엔지니어링은 이 과정에서 어떤 역할을 합니까? "데이터로서의 프롬프트"와 "코드로서의 프롬프트"의 차이점을 설명하십시오.
> Gen AI 실험 주기는 데이터 개선, 파운데이션 모델 선택 및 적응, 그리고 프롬프트 엔지니어링 간의 반복적인 상호 작용을 포함합니다. 프롬프트 엔지니어링은 모델의 출력을 안내하기 위해 프롬프트를 설계하고 최적화하는 과정입니다. "데이터로서의 프롬프트"는 퓨샷 예제와 같이 데이터 중심 MLOps 관행이 필요한 부분을 나타내고, "코드로서의 프롬프트"는 템플릿과 같이 코드 중심 관행이 필요한 구조적 요소를 나타냅니다.

4. Gen AI 모델이 직면한 고유한 과제(예: 환각)를 해결하기 위해 "체인 및 증강" 기술이 어떻게 사용됩니까? RAG와 에이전트의 개념을 간략하게 설명하십시오.
> "체인 및 증강" 기술은 여러 개의 프롬프트 모델 구성 요소를 연결하고 외부 API 및 코드를 통합하여 최신 정보를 유지하고 환각을 줄이며 복잡한 작업을 해결하는 데 사용됩니다. RAG(Retrieval-Augmented Generation)는 외부 데이터를 검색하여 프롬프트를 보강하는 반면, 에이전트는 LLM을 사용하여 도구와 상호 작용하고 복잡한 작업을 수행합니다.

5. Gen AI 모델을 튜닝하고 최적화하는 데 사용되는 주요 기술은 무엇이며, 각 기술의 장점은 무엇입니까? Vertex AI는 이러한 프로세스를 어떻게 지원합니까?
> Gen AI 모델을 튜닝하는 기술에는 프롬프트 엔지니어링, 지도 학습 미세 조정(SFT), 강화 학습(RLHF) 및 증류가 포함됩니다. 각 기술은 특정 요구 사항과 트레이드오프를 제공합니다. Vertex AI는 모델 튜닝 및 실험을 위한 다양한 도구를 제공하며, Vertex AI Studio에서 프롬프트 엔지니어링을 지원하고 Vertex AI Training을 통해 SFT 및 기타 튜닝 방법을 지원합니다.

6. Gen AI 애플리케이션에서 다양한 유형의 입력 데이터(예: 컨디셔닝 프롬프트, 퓨샷 예제, 그라운딩 데이터)를 관리하는 데 필요한 주요 데이터 관리 방식은 무엇입니까?
> Gen AI 애플리케이션은 다양한 소스의 다양한 데이터 유형을 활용하므로 데이터 관리 방식에는 버전 관리, 데이터 유효성 검사, 드리프트 감지 및 라이프사이클 관리가 포함되어야 합니다. 컨디셔닝 프롬프트, 퓨샷 예제 및 그라운딩/증강 데이터는 모델 동작에 영향을 미치는 고유한 특성을 가지므로 적절하게 관리해야 합니다.

7. Gen AI 시스템의 성능을 평가하는 데 따르는 몇 가지 어려움은 무엇이며, Vertex AI는 이러한 과제를 해결하기 위해 어떤 도구를 제공합니까? 자동 평가와 인간 평가의 역할을 논의하십시오.
> Gen AI 시스템을 평가하는 데 따르는 어려움에는 적절한 메트릭 정의의 주관성, 인간 판단과의 메트릭 상관 관계 보장, 그리고 생성된 콘텐츠의 다면적인 품질 평가 등이 있습니다. Vertex AI Experiments, Tensorboard 및 평가 파이프라인은 실험을 추적하고 시각화하며 자동 및 LLM 기반 평가를 수행하는 데 도움이 됩니다. 자동 평가는 확장성을 제공하는 반면, 인간 평가는 주관적인 품질 측면에서 통찰력을 제공합니다.

8. Gen AI 시스템과 파운데이션 모델의 배포의 주요 차이점은 무엇입니까? Gen AI 시스템의 지속적 통합 및 지속적 배포(CI/CD)를 위한 중요한 고려 사항은 무엇입니까?
> Gen AI 시스템 배포에는 특정 사용 사례를 위한 전체 애플리케이션 스택 배포가 포함되는 반면, 파운데이션 모델 배포는 모델 자체를 광범위한 잠재적 사용 사례에 사용할 수 있도록 만드는 데 중점을 둡니다. Gen AI 시스템의 CI/CD에는 코드 변경 사항에 대한 자동 테스트, 모델 버전 관리, 프롬프트 및 체인 정의 버전 관리, 그리고 데이터 파이프라인 관리가 포함되어야 합니다.

9. Gen AI 시스템의 로깅 및 모니터링의 중요한 측면은 무엇입니까? 특히 편향 및 드리프트 감지에 대한 Gen AI의 고유한 고려 사항을 설명하십시오.
> Gen AI 시스템의 로깅 및 모니터링은 애플리케이션 성능, 리소스 사용률 및 오류를 추적하는 데 중요합니다. Gen AI의 경우 훈련-서빙 편향 외에도 입력 및 출력 데이터의 편향 및 드리프트를 감지하는 것이 중요합니다. 텍스트 데이터의 경우 임베딩 거리, 토큰 수 및 어휘 변화를 모니터링할 수 있습니다. 멀티모달 모델의 경우 프롬프트 및 조직 정책과의 정렬을 모니터링해야 합니다.

10. Gen AI 시스템의 거버넌스의 주요 목표는 무엇이며, Vertex AI는 데이터, 모델 및 코드 자산의 거버넌스를 어떻게 용이하게 합니까? 에이전트 라이프사이클의 핵심 구성 요소는 무엇입니까?
> Gen AI 시스템 거버넌스의 목표는 개발, 배포 및 지속적인 관리에 대한 제어, 책임 및 투명성을 확립하는 것입니다. Vertex AI Feature Store는 기능 및 임베딩 계보를 관리하고 드리프트를 모니터링하는 데 도움이 되며, Model Registry는 모델 수명 주기를 관리하고, Dataplex는 데이터 거버넌스를 중앙 집중화합니다. 에이전트 라이프사이클의 핵심 구성 요소는 파운데이션 모델, 지침 및 도구입니다.

### 7.3 에세이 형식 질문
1. MLOps 원칙은 Gen AI 시스템의 고유한 과제를 어떻게 해결하기 위해 조정되어야 합니까? 구체적인 예와 Vertex AI 도구를 사용하여 설명을 뒷받침하십시오.
> MLOps 원칙은 Gen AI 시스템의 고유한 과제, 특히 대규모 데이터 처리와 복잡한 모델 관리를 해결하기 위해 확장성과 자동화를 강화해야 합니다. 예를 들어, Vertex AI의 Vertex Pipelines는 모델 학습 및 배포 과정을 자동화하여 Gen AI 모델의 지속적인 업데이트와 성능 모니터링을 지원하며, Vertex Model Monitoring은 데이터 드리프트나 성능 저하를 감지하여 신뢰성을 유지합니다. 이를 통해 Gen AI는 높은 수준의 품질과 안정성을 보장하면서도 빠르게 진화하는 요구사항에 적응할 수 있습니다. 

2. Gen AI 애플리케이션 개발에서 프롬프트 엔지니어링의 중요성이 커지고 있습니다. 효과적인 프롬프트 엔지니어링의 주요 측면과 Gen AI 시스템의 성능 및 거버넌스에 미치는 영향을 논의하십시오.
> 효과적인 프롬프트 엔지니어링은 Gen AI 시스템의 출력 품질과 관련성에 직접적인 영향을 미칩니다. 명확하고 구조화된 프롬프트를 설계하면 원하는 결과를 보다 정확하게 도출할 수 있으며, 이는 AI의 성능 최적화와 윤리적 사용 및 거버넌스 준수에도 기여합니다. 특히, 잘못된 프롬프트는 부정확하거나 편향된 결과를 초래할 수 있어, 신중한 설계가 필수적입니다.

3. RAG와 에이전트 기반 아키텍처는 Gen AI 모델의 기능과 신뢰성을 어떻게 향상시킵니까? 이러한 접근 방식의 장단점을 비교하고 실제 사용 사례를 설명하십시오.
> RAG(Retrieval-Augmented Generation)는 외부 데이터 소스를 활용하여 모델의 답변을 사실적으로 보강하므로, 정확성과 신뢰성을 높이고 환각 문제를 줄입니다. 에이전트 기반 아키텍처는 여러 도구와 상호 작용하며 복잡한 작업을 단계적으로 해결할 수 있어 유연성과 문제 해결 능력을 강화합니다. 예를 들어, RAG는 고객 지원 챗봇에서 최신 문서를 기반으로 답변을 제공하고, 에이전트 기반 시스템은 여행 계획처럼 여러 단계를 거쳐 다양한 API(예: 항공편 검색, 호텔 예약)를 조율하는 데 적합합니다. 

4. Gen AI 모델을 평가하고 모니터링하는 데 따르는 주요 과제는 무엇이며, 이러한 과제를 해결하기 위해 어떤 새로운 메트릭과 방법론이 개발되고 있습니까? Vertex AI는 Gen AI 평가 및 모니터링을 어떻게 지원합니까?
> Gen AI 모델을 평가하고 모니터링하는 주요 과제로는 모델의 편향성, 일관성 부족, 그리고 상황에 맞는 적절한 응답 생성 등이 있습니다. 또한 실제 운영 환경에서 발생하는 데이터 드리프트(data drift)나 성능 저하를 실시간으로 감지하고 대응하는 것도 어려운 문제입니다. 이를 해결하기 위해 새로운 메트릭과 방법론으로 ROUGE, BLEU 같은 기존 언어 평가 지표 외에도 사실성(Factuality), 안전성(Safety), 다양성(Diversity) 등을 측정하는 지표가 개발되고 있으며, 인간 평가(Human Evaluation)와 결합된 하이브리드 접근법도 활용되고 있습니다.
>
> Vertex AI는 Gen AI 모델의 평가 및 모니터링을 위해 자동화된 파이프라인과 모니터링 도구를 제공하여 모델의 입력/출력 패턴을 분석하고 이상 징후를 탐지합니다. 또한 Vertex AI의 Model Monitoring 기능은 데이터 드리프트를 감지하고, 사용자 정의 지표를 설정하여 모델의 성능을 지속적으로 추적할 수 있도록 지원합니다. 이를 통해 신뢰성 있는 AI 운영을 가능하게 합니다. 

5. Gen AI 기술이 발전함에 따라 Gen AI 시스템의 거버넌스 및 윤리적 고려 사항이 점점 더 중요해지고 있습니다. Gen AI의 책임감 있는 개발 및 배포를 보장하기 위해 조직이 채택해야 하는 주요 거버넌스 관행 및 기술은 무엇입니까?
> Gen AI의 책임감 있는 개발 및 배포를 위해서는 투명성, 공정성, 그리고 설명 가능성을 보장하는 거버넌스 체계가 필요합니다. 이를 위해 AI 윤리 규정 수립, 데이터 편향 최소화를 위한 기술적 도구 활용, 지속적인 모니터링 및 검증 프로세스 구축이 중요하며, 이해관계자와의 협력을 통해 사회적 영향을 고려한 의사결정을 수행해야 합니다. 또한, AI 시스템의 오용을 방지하기 위한 접근 제어와 보안 강화도 필수적입니다.

### 7.4 용어집
1. Gen AI (Generative AI): 
    - 텍스트, 이미지, 오디오 또는 기타 데이터를 포함한 새로운 콘텐츠를 생성할 수 있는 인공 지능 모델입니다.

2. Foundation Model: 
    - 광범위한 데이터 세트에 대해 사전 학습된 대규모 머신 러닝 모델로, 다양한 다운스트림 작업에 맞게 미세 조정하거나 프롬프트할 수 있습니다.

3. LLM (Large Language Model): 
    - 텍스트를 이해하고 생성하도록 설계된 심층 신경망을 사용하는 일종의 파운데이션 모델입니다.

4. MLOps (Machine Learning Operations): 
    - 머신 러닝 시스템의 개발, 배포 및 유지 관리를 간소화하고 자동화하는 것을 목표로 하는 일련의 관행입니다.

5. DevOps (Development and Operations): 
    - 개발 및 IT 운영 간의 협업, 자동화 및 지속적인 개선을 강조하는 소프트웨어 개발 방법론입니다.

6. Prompt Engineering: 
    - 원하는 출력을 유도하기 위해 대규모 언어 모델에 제공되는 입력을 설계하고 최적화하는 프로세스입니다.

7. RAG (Retrieval-Augmented Generation): 
    - 외부 지식 소스에서 검색된 관련 정보를 사용하여 LLM이 생성하는 응답을 보강하는 기술입니다.

8. Agent: 
    - 환경을 인식하고 목표를 달성하기 위해 행동을 취할 수 있는 자율 시스템으로, 종종 LLM을 기반으로 합니다.

9. Tool Registry: 
    - 에이전트가 사용할 수 있는 모든 도구에 대한 중앙 집중식 카탈로그입니다.

10. Vertex AI: 
    - Google Cloud의 엔드투엔드 머신 러닝 플랫폼으로, Gen AI 애플리케이션을 포함한 ML 모델을 구축, 배포 및 관리하기 위한 다양한 도구를 제공합니다.

11. Vertex Model Garden: 
    - Google 및 파트너의 사전 학습된 다양한 ML 및 Gen AI 모델을 탐색하고 배포할 수 있는 플랫폼입니다.

12. Vertex AI Studio: 
    - Gen AI 모델 및 프롬프트를 실험하고 프로토타입을 제작할 수 있는 웹 기반 인터페이스입니다.

13. Vertex AI Training: 
    - ML 모델을 훈련하고 미세 조정하기 위한 서비스입니다.

14. Vertex AI Endpoints: 
    - 훈련된 ML 모델을 온라인 예측을 위해 배포하고 관리하는 데 사용됩니다.

15. Vertex AI Experiments: 
    - ML 실험을 추적하고 비교하기 위한 도구입니다.

16. Vertex AI TensorBoard: 
    - ML 모델 훈련 및 평가 메트릭을 시각화하기 위한 도구입니다.

17. Vertex AI Feature Store: 
    - ML 특징 및 임베딩을 저장, 공유 및 관리하기 위한 중앙 집중식 저장소입니다.

18. Vertex AI Model Registry: 
    - ML 모델의 수명 주기를 관리하기 위한 중앙 집중식 저장소입니다.

19. Dataplex: 
    - 데이터 거버넌스 및 관리를 위한 지능형 데이터 패브릭입니다.

20. Model Quantization: 
    - 모델 크기 및 계산 요구 사항을 줄이기 위해 모델 가중치 및 활성화를 낮은 정밀도로 변환하는 기술입니다.

21. Model Pruning: 
    - 모델 정확도를 유지하면서 불필요한 가중치를 제거하여 모델 크기를 줄이는 기술입니다.

22. Knowledge Distillation: 
    - 더 큰 "교사" 모델의 지식을 더 작은 "학생" 모델로 전송하는 기술입니다.

23. Continuous Integration (CI): 
    - 코드 변경 사항이 자동으로 테스트되고 공유 리포지토리에 병합되는 소프트웨어 개발 관행입니다.

24. Continuous Delivery (CD): 
    - 코드 변경 사항이 자동으로 프로덕션 환경에 릴리스될 준비가 되는 소프트웨어 개발 관행입니다.

25. Drift Detection: 
    - 프로덕션 데이터의 통계적 속성이 훈련 데이터와 어떻게 다른지 감지하는 프로세스입니다.

26. Skew Detection: 
    - 훈련 데이터와 서빙 데이터 간의 불일치를 감지하는 프로세스입니다.

27. Hallucination: 
    - LLM이 사실적으로 부정확하거나 근거 없는 정보를 생성하는 경향입니다.
