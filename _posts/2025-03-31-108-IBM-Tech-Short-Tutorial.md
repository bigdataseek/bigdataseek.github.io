---
title: 25차시 7:IBM TECH(종합 내용)
layout: single
classes: wide
categories:
  - IBM TECH(종합 내용)
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 61. 순환 신경망 (RNN)
- 출처: [The Power of Recurrent Neural Networks (RNN)](https://www.youtube.com/watch?v=Gafjk7_w1i8)

### **61.1 RNN 이란?**

*   **정의:** 순차 데이터를 처리하도록 설계된 신경망  
    - 순차 데이터란 시간에 따라 순서가 있는 데이터를 의미하며, 예를 들어 문장, 음성, 주식 가격 변화 등이 이에 해당합니다. RNN은 이러한 데이터의 순서를 고려해 학습하도록 설계되었습니다.
*   **특징:**
    *   **메모리:** 과거 정보를 기억하여 문맥 분석 가능  
        - RNN은 이전 단계의 정보를 활용해 현재 데이터를 이해하므로, 문맥이 중요한 작업(예: "I am" 다음에 올 단어 예측)에 적합합니다.
    *   **Hidden State (ht):** 이전 단계의 정보를 담는 루프 역할  
        - Hidden State는 RNN의 핵심으로, 과거 데이터를 요약한 정보를 저장하며 이를 다음 단계로 전달해 연속성을 유지합니다.

### **61.2 RNN 작동 방식**

*   **기본 구조:** 입력 (xt), 출력 (yt), Hidden State (ht)  
    - 입력(xt)은 현재 시점의 데이터, 출력(yt)은 해당 시점의 결과물, Hidden State(ht)는 과거와 현재를 연결하는 기억 장치로 작동합니다.
*   **Hidden State 계산:** 현재 입력 (xt)과 이전 Hidden State (ht-1)을 기반으로 계산  
    - 이 과정에서 현재 데이터와 과거 정보를 결합해 새로운 Hidden State를 생성하며, 이를 통해 시퀀스의 흐름을 학습합니다.
    *   **수식:** ht = activation(Wx \* xt + Wh \* ht-1 + b)  
        - Wx는 입력에 곱해지는 가중치 행렬로 입력의 중요도를 조정하고, Wh는 이전 Hidden State에 곱해지는 가중치 행렬로 과거 정보의 영향을 조절합니다.  
        - b는 편향(bias)으로, 모델이 데이터에 더 잘 맞도록 조정하는 상수입니다.  
        - activation은 활성화 함수(예: tanh, ReLU 등)로, 비선형성을 추가해 복잡한 패턴을 학습하게 합니다.
*   **Hidden State 역할:** 과거 입력 정보를 현재 단계로 전달하여 순차적인 데이터 처리  
    - 예를 들어, "The cat is"라는 문장에서 "is"를 처리할 때 "The cat"의 정보를 Hidden State로 전달해 문맥을 유지합니다.

### **61.3 RNN 활용 형태**

*   **Sequence-to-Sequence:** 입력 시퀀스 -> 출력 시퀀스 (ex: 주가 예측)  
    - 입력으로 일정 기간 주가 데이터를 받아 다음 기간의 주가를 예측하는 시계열 분석에 활용됩니다.
*   **Sequence-to-Vector:** 입력 시퀀스 -> 단일 벡터 출력 (ex: 영화 리뷰 감정 분석)  
    - 영화 리뷰 문장을 입력받아 긍정/부정과 같은 단일 감정 점수를 출력하며, 시퀀스 전체를 하나의 벡터로 요약합니다.
*   **Vector-to-Sequence:** 단일 입력 -> 출력 시퀀스 (ex: 이미지 캡셔닝)  
    - 이미지 한 장을 입력으로 받아 이를 설명하는 문장(시퀀스)을 생성하는 작업에 사용됩니다.
*   **Encoder-Decoder:** 입력 시퀀스 (Encoder) -> 벡터 -> 출력 시퀀스 (Decoder) (ex: 기계 번역)  
    - 영어 문장을 Encoder로 압축해 벡터로 만든 뒤, Decoder가 이를 한국어 문장으로 변환하는 방식으로 동작합니다.

#### **61.4 RNN 주요 문제점**

*   **Vanishing/Exploding Gradients (기울기 소실/폭주):**  
    - RNN은 역전파 시 기울기를 계산하는데, 시퀀스가 길어질수록 문제가 발생합니다.
    *   **Vanishing Gradients:** 기울기가 너무 작아 학습이 어려움 (과거 정보 활용 불가)  
        - 기울기가 0에 가까워지면 과거 정보가 제대로 반영되지 않아 장기 의존성(long-term dependency)을 학습하기 어렵습니다.
    *   **Exploding Gradients:** 기울기가 너무 커 학습 불안정  
        - 반대로 기울기가 폭발적으로 커지면 가중치 업데이트가 불안정해져 모델이 수렴하지 못할 수 있습니다.
*   **학습 복잡성:** 순차적 데이터 처리로 인해 계산 비용 및 시간 증가  
    - 병렬 처리가 어려워 GPU 활용이 제한되고, 긴 시퀀스를 다룰수록 계산량이 기하급수적으로 늘어납니다.

### **61.5 문제 해결을 위한 발전**

*   **LSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit):**  
    - RNN의 단점을 보완한 변형 모델로, 장기 의존성을 효과적으로 학습할 수 있습니다.
    *   **게이트(Gate) 사용:** 정보 흐름을 제어하여 기울기 안정화  
        - LSTM은 Forget, Input, Output 게이트를, GRU는 Update, Reset 게이트를 사용해 불필요한 정보를 버리고 중요한 정보만 유지합니다.  
        - 이를 통해 기울기 소실/폭주 문제를 완화하고 안정적인 학습을 가능하게 합니다.
    *   장기 의존성 문제 해결 및 다양한 응용 분야 적용 가능  
        - 예를 들어, 긴 문장에서 앞부분과 뒷부분의 관계를 파악하거나, 음성 인식에서 문맥을 유지하는 데 유용합니다.

## 62. 증강 현실 (AR)
- 출처: [What is Augmented Reality (AR)?](https://www.youtube.com/watch?v=QpbJwad6v_s)

### **62.1 정의**

*   디지털 콘텐츠를 사용자 주변의 실제 환경에 실시간으로 통합하는 기술.  
    - 예를 들어, 스마트폰이나 AR 안경을 통해 가상의 이미지나 정보를 현실 공간 위에 덧붙여 보여줌.
*   실제 세계 경험을 대체하는 것이 아니라, 덧붙여 확장하는 개념.  
    - 사용자의 현실 인식을 유지한 채, 그 위에 정보나 그래픽을 추가하여 경험을 풍부하게 만듦.

#### **62.2 AR vs VR vs 혼합 현실 (MR)**

*   **AR:** 실제 세계 + 디지털 콘텐츠 오버레이 (예: 빈 거실에 가상 소파 배치).  
    - 현실 공간은 그대로 유지되고, 사용자는 자신의 환경을 인식하면서 그 위에 가상의 정보를 확인함.
*   **VR:** 사용자가 가상 세계에 완전히 몰입 (VR 헤드셋 착용).  
    - 현실과의 단절, 시각 및 청각 등 모든 감각 자극이 가상으로 대체됨. 게임, 시뮬레이션 훈련 등 사용.
*   **MR:** 현실 세계와 가상 세계가 상호 작용하는 하이브리드 형태 (예: 스타트렉 홀로덱).  
    - 가상 객체가 현실 공간 내에서 물리적 요소와 반응하거나, 사용자의 동작에 따라 실시간 반응함.

### **62.3 AR의 종류**

*   **마커 기반:**
    *   특정 마커 (QR 코드 등)를 통해 AR 경험 시작.  
        - 카메라가 마커를 인식하면 그 위치에 맞춰 가상 객체를 배치.
    *   유연하고 비용 효율적.  
        - 간단한 이미지 또는 패턴만으로도 작동 가능하여 개발 및 운영 부담이 적음.
*   **마커리스:**
    *   GPS, 센서, 컴퓨터 비전 등을 사용하여 사용자 환경을 실시간으로 매핑.  
        - 특정 마커 없이도 위치나 환경 정보를 기반으로 AR 콘텐츠를 배치 가능.
    *   역동적인 콘텐츠 제공.  
        - 사용자의 이동 경로나 위치에 따라 실시간으로 변화하는 콘텐츠 제공이 가능함.

### **62.4 AR 활용 사례**

*   **향상된 제품 시각화:** 집에서 가구 배치, 옷이나 화장품 가상으로 착용해보기.  
    - IKEA나 Sephora 등의 앱에서 제공하며, 구매 전 경험을 통해 소비자 만족도 향상.
*   **향상된 매장 내 네비게이션:** 매장 내 제품 위치, 할인 정보, 개인 맞춤 추천 등을 실시간으로 제공.  
    - 대형 매장에서 고객의 쇼핑 편의성을 높이고, 구매 유도에 기여.
*   **원활한 옴니채널 통합:** 웹사이트, 앱, 매장 등 모든 채널에서 일관된 고객 경험 제공.  
    - 예: 온라인에서 본 제품을 오프라인 매장에서 AR로 미리 배치해보고 구매 결정.

### **62.5 AR의 다양한 활용 분야**

*   커머스 외에도 의료, 제조, 교육, 게임 등 다양한 분야에서 활용 가능 (예: 포켓몬 고).  
    - 의료: 수술 시 AR로 해부학 정보 시각화  
    - 제조: 정비 매뉴얼을 AR로 실시간 안내  
    - 교육: 교과 내용에 대한 몰입형 시각 자료 제공  
    - 게임: 현실 배경과 상호작용하는 몰입형 게임 환경 제공


## 63. IBM Bee 프레임워크를 사용한 LLM 기반 에이전트 구축
- 출처: [Building LLM Agent with IBM Bee Agent Framework](https://www.youtube.com/watch?v=C-pZXA6Te_o)

### **63.1 IBM Bee 프레임워크**

* ReAct(추론/액션) 기반의 에이전트 프레임워크로, "Reasoning and Acting" 패러다임을 따라 생각하고 행동하는 AI 에이전트 구축을 지원합니다
* 다양한 도구(웹 검색, 날씨 API, 코드 실행 등), 여러 LLM 서비스, 대화 메모리 관리, 상세 로깅 기능을 포괄적으로 지원합니다
* 실제 사용을 위한 다양한 기능 제공: 상태 관리, 이벤트 기반 아키텍처, 플러그인 시스템, 오류 처리 메커니즘, 스트리밍 응답 등 프로덕션급 애플리케이션에 필요한 요소들을 포함합니다
* TypeScript로 작성되어 타입 안전성과 개발 생산성을 보장하며, 견고한 코드베이스를 구축할 수 있습니다
* Langchain의 대안으로 사용 가능하며, IBM 제품에 국한되지 않고 OpenAI, Ollama 등 다양한 오픈 소스 LLM을 지원합니다

### **63.2 3단계 에이전트 구축**

**1단계: 문자열을 사용한 응답 생성**

1. `flow.ts` 파일 생성 - 에이전트의 기본 워크플로우를 정의하는 시작점입니다
2. LLM 어댑터 선택 (Grok, Langchain, Ollama, OpenAI, Watsonx.ai 중 Watsonx.ai 사용) - 각 어댑터는 해당 LLM 서비스의 API와 통신하는 인터페이스를 제공합니다
3. API 키 및 프로젝트 ID 설정 (.env.config 사용) - 환경 변수를 통해 민감한 인증 정보를 안전하게 관리
4. Watson Chat LLM 클래스 가져오기 - IBM의 Watsonx.ai 서비스와 연결하는 클라이언트 라이브러리
5. `Llama 3.1 70b instruct` 프리셋 및 파라미터 설정 - 모델의 동작을 제어하는 온도, 토큰 제한 등의 하이퍼파라미터를 구성합니다
6. `LLM.stream` 메서드를 사용하여 프롬프트에 대한 응답 생성
   * 프롬프트 작성을 위해 `base message` 및 `role primitive` import 필요 - 대화 형식의 메시지 구조를 정의합니다
   * 비동기 함수 생성 후 LLM.stream 메서드 호출 - 스트리밍 방식으로 응답을 실시간 처리합니다

**필수 설정:**

* Node 프로젝트 초기화 (`yarn init`) - 프로젝트의 기본 구조와 의존성 관리를 위한 package.json 파일을 생성합니다
* 필요한 패키지 설치: `TSX`(TypeScript 실행기), `dotenv`(환경 변수 관리), `Bee agent framework`(핵심 프레임워크), `IBM generative A.I. Node SDK`(IBM AI 서비스 연동)
* `packages.json` 파일에 `flow` 스크립트 추가 (TSX를 사용하여 `flow.ts` 파일 실행) - 명령어 단축키를 제공하여 개발 워크플로우를 간소화합니다

**2단계: 함수 호출을 사용한 에이전트 구축**

1. Bee 에이전트 프레임워크에서 `Bee agent` 가져오기 - 에이전트의 핵심 클래스로 전체 기능을 조율
2. LLM 에이전트 인스턴스 생성 (LLM 전달) - 1단계에서 구성한 LLM을 에이전트에 연결합니다
3. 메모리 추가 (Token Memory 클래스 사용) - 대화 컨텍스트를 유지하고 토큰 한도를 관리하는 메모리 시스템입니다
4. 도구 추가 (DuckDuckGoSearchTool, OpenMeteoTool 등) - 에이전트가 외부 서비스와 상호작용할 수 있게 하는 인터페이스입니다
5. `agent.run` 및 `agent.observe` 메서드 사용
   * `run` 메서드에 프롬프트 및 실행 파라미터 전달 - 에이전트의 실행을 시작하고 필요한 설정을 지정
   * `observe` 메서드를 통해 에이전트 워크플로우의 각 단계별 상태 확인 (`update` 액션 관찰) - 에이전트의 실행 과정을 모니터링하고 디버깅할 수 있습니다

**3단계: Python 코드 인터프리터 추가**

1. Python 도구 및 로컬 Python 스토리지 클래스 가져오기 - 파이썬 코드 실행과 결과 관리를 위한 컴포넌트
2. Python 도구 구성 (코드 인터프리터 URL 및 스토리지 위치 설정) - 인터프리터의 접근 경로와 저장소 지정
3. Bee 에이전트 프레임워크에서 제공하는 독립 실행형 코드 인터프리터 실행 (Docker 사용)
   * Bee 에이전트 GitHub 리포지토리에서 Docker 파일 clone 및 종속성 설치 - 격리된 환경에서 안전하게 코드를 실행하기 위한 컨테이너 설정입니다
   * `yarn run infra:start-code-interpreter` 사용하여 컨테이너 실행 - 미리 정의된 스크립트로 인터프리터 환경을 쉽게 시작할 수 있습니다

### **63.3 부가 설명**

* 에이전트는 웹 검색, API 호출, 코드 실행 등 다양한 작업을 수행할 수 있어 복잡한 질문에도 응답 가능
* 데모에서는 IBM이 창립된 시기(역사적 정보 검색)와 뉴욕의 날씨(실시간 API 호출)를 묻는 예시를 보여주어 다양한 데이터 소스 활용 능력을 입증합니다
* 코드 인터프리터를 통해 에이전트는 파이썬 코드를 실행하고 결과를 얻을 수 있어 데이터 분석, 시각화, 계산 등의 프로그래밍 작업을 자동화할 수 있습니다


## 64. 텍스트 분류
- 출처: [Text Classification: AI Techniques and Real-World Applications](https://www.youtube.com/watch?v=hHiPs_wICsE)

### **64.1 텍스트 분류란?**

*   **정의:**  
    - 원시 텍스트 데이터를 입력받아 사전에 정의된 카테고리(레이블)에 자동 할당하는 머신러닝/자연어 처리 작업입니다.  
    - 예를 들어, "이 제품 정말 좋아요!"라는 텍스트는 "긍정" 감성 레이블로 분류됩니다.
    - **핵심 목적**은 대량의 텍스트를 체계적으로 조직화하여 정보 검색, 의사 결정, 업무 자동화 등을 효율화

*   **예시:**  
    - **이메일 필터링:** Gmail은 메일을 "스팸", "프로모션", "중요" 등으로 자동 분류합니다.  
    - **콘텐츠 추천:** 넷플릭스는 영화 설명 텍스트를 분석해 "코미디", "스릴러" 등 장르 태그를 부여합니다.  
    - **고객 지원:** 챗봇이 "결제 오류", "배송 문의" 등 고객 문의 유형을 분류해 담당 팀으로 연결합니다.

*   **중요성:**  
    - 디지털 환경에서 생성되는 텍스트 데이터는 기하급수적으로 증가합니다.  
    - 예: 하루 3000억 건 이상의 이메일이 전송되며, 이 중 45%는 스팸입니다.
    - 수동 분류는 비현실적이므로 자동화된 텍스트 분류 시스템이 필수적입니다.

### **64.2 텍스트 분류의 유형** (유형별 상세 비교)

*   **이진 분류(Binary Classification):**  
    - **특징:** 가장 단순한 형태로, 두 개의 상호 배타적인 클래스로 구분합니다.  
    - **도전 과제:** 클래스 불균형이 발생하기 쉽습니다.  
        - 예: 스팸 메일(5%) vs 일반 메일(95%)인 경우, 모델이 항상 "일반"으로 예측해도 95% 정확도가 나올 수 있습니다.
    - **해결책:** F1-score, AUC-ROC 등 불균형 데이터에 강건한 지표로 평가해야 합니다.

*   **다중 클래스 분류(Multi-class Classification):**  
    - **특징:** N개의 클래스 중 하나를 선택하는 문제입니다.  
    - **활용 예:** 뉴스 기사를 "정치", "경제", "스포츠" 등으로 분류합니다.  
    - **도전 과제:** 클래스 간 경계가 모호한 경우(예: "경제" vs "금융") 분류 성능이 저하될 수 있습니다.  
    - **해결책:** 계층적 분류(Hierarchical Classification)를 적용해 대분류 → 소분류로 단계적으로 분류

*   **다중 레이블 분류(Multi-label Classification):**  
    - **특징:** 하나의 텍스트가 여러 클래스에 동시 속할 수 있습니다.  
        - 예: 영화 "가디언즈 오브 갤럭시"는 "액션", "코미디", "SF" 모두 해당됩니다.
    - **기술적 복잡성:** 각 레이블 조합에 대한 충분한 학습 데이터 필요합니다.  
    - **해결책:** Label Powerset 또는 Binary Relevance와 같은 다중 레이블 전용 알고리즘을 사용

### **64.3 텍스트 분류의 핵심 기술** (단계별 심화 분석)

1.  **텍스트 전처리(Text Preprocessing):**  
    - **토큰화(Tokenization):**  
        - 문장을 단어/서브워드 단위로 분할합니다.  
        - 예: "I'm happy" → ["I", "'", "m", "happy"] (공백 기준) 또는 ["I'm", "happy"] (의미 단위)
    - **정규화(Normalization):**  
        - **소문자 통일:** "Apple"과 "apple"을 동일하게 처리  
        - **불용어 제거(Stopword Removal):** "a", "the" 등 의미 없는 단어 필터링  
        - **표제어 추출(Lemmatization):** "running" → "run"으로 환원  
    - **중요성:** 전처리 품질이 최종 모델 성능에 30% 이상 영향을 미칩니다.

2.  **특징 추출(Feature Extraction):**  
    - **전통적 방법:**  
        - **Bag-of-Words(BoW):** 단어 출현 빈도 기반 벡터화  
        - **TF-IDF:** 자주 등장하지만 특정 문서에서만 집중되는 단어에 가중치 부여  
    - **최신 기법:**  
        - **Word2Vec/GloVe:** 단어를 100~300차원의 밀집 벡터로 표현  
        - **BERT Embeddings:** 문맥을 반영한 동적 임베딩 생성  
            - 예: "은행" → "금융 기관" 의미 vs "강가" 의미를 문장별로 다르게 인코딩

3.  **모델 선택(Model Selection):**  
    - **전통 모델:**  
        - **Naive Bayes:** 간단하지만 특징 간 독립성 가정이 비현실적  
        - **SVM:** 고차원 공간에서 최적의 결정 경계 탐색  
    - **딥러닝 모델:**  
        - **CNN:** 지역적인 단어 패턴(예: 부정 표현) 감지에 효과적  
        - **LSTM:** 장기 의존성(예: "별로 좋지 않았다" 같은 부정 문장) 학습  
    - **초대형 모델:**  
        - **BERT/GPT-3:** 사전 학습된 지식을 활용해 소량의 데이터로도 높은 성능 달성  
        - **도메인 적응:** 의료/법률 등 특수 분야는 BioBERT, LegalBERT 등 도메인 특화 모델 필요

4.  **결과 조정(Result Refinement):**  
    - **오류 분석:**  
        - 분류 실패 사례를 유형화(예: 반어적 표현 오분류)해 전처리/모델 개선  
    - **Active Learning:**  
        - 모델이 불확실한 샘플을 전문가에게 질의해 레이블링 효율화  
    - **Ensemble:**  
        - 여러 모델의 예측을 결합해 Robustness 향상  

### **64.4. 텍스트 분류의 실제 활용 사례** (산업별 적용 예시)

*   **금융:**  
    - **신용 평가:** 고객의 SNS 텍스트를 분석해 신용 위험 예측  
    - **자동 보고서 생성:** 뉴스 기사를 "긍정/부정"으로 분류해 주가 영향 분석  

*   **의료:**  
    - **진단 보조:** 환자 증상 설명을 "질병 코드(ICD)"에 매핑  
    - **논문 분류:** 연구 논문을 "치료법", "병인론" 등 태그별로 조직화  

*   **소매:**  
    - **리뷰 분석:** 제품 리뷰에서 "배송", "품질" 등 불만 유형 자동 분류  
    - **추천 시스템:** 고객 문의 내용을 기반으로 관련 상품 추천  

### **64.5 텍스트 분류의 과제 및 해결책** (실무적 관점)

*   **불균형 데이터 문제:**  
    - **기술적 해결책:**  
        - **샘플링:** 언더샘플링(다수 클래스 감소) 또는 오버샘플링(소수 클래스 증강)  
        - **가중치 조정:** 소수 클래스 오분류 시 큰 페널티 부여  
    - **비즈니스 전략:**  
        - 예: 스팸 메일 분류에서 "스팸을 일반으로 오분류(FN)는 일반을 스팸으로 오분류(FP)보다 더 위험하므로, 비대칭 비용 함수를 설계합니다.

*   **모호성 해석:**  
    - **다중 모달 접근:** 텍스트 + 이미지/메타데이터를 함께 분석  
        - 예: "은행"이 포함된 텍스트에 금융 관련 이미지가 동반되면 금융 기관 의미로 해석
    - **도메인 지식 통합:** 금융/의료 등 전문 분야는 용어 사전 구축 필요  

*   **윤리적 고려사항:**  
    - **편향 감지:** 모델이 특정 인종/성별에 편향되지 않도록 fairness 지표 모니터링  
    - **설명 가능성:** 의료/법률 분야는 분류 근거를 설명할 수 있는 XAI(Explainable AI) 기법 적용  

*   **실시간 처리:**  
    - **경량화:** DistilBERT, TinyBERT 등 모델 경량화 기술로 모바일 환경 배포  
    - **점진적 학습:** 새로운 데이터가 도입될 때마다 전체 재학습 없이 업데이트  


## 65. Agentic RAG 구현 
- 출처: [Create Advanced AI Agents with LangChain and RAG Techniques](https://www.youtube.com/watch?v=Y1PaM3edYoI)

### **65.1 개요**  
- Agentic RAG (Agentic Retrieval Augmented Generation)는 기존의 RAG(Retrieval Augmented Generation) 모델을 확장하여, 에이전트(Agent)가 특정 질문에 대한 답변을 생성할 때 필요한 정보를 자동으로 검색하고 활용하는 프레임워크입니다. 
- 이 가이드에서는 Agentic RAG를 단계별로 구현하는 방법을 설명하며, LangChain과 IBM watsonx.ai를 주로 사용합니다. 
- 이를 통해 최신 정보를 포함한 정확한 답변을 생성하는 시스템을 구축할 수 있습니다.

### **65.2 필요 패키지**  
- Agentic RAG 구현을 위해 다음 패키지를 설치해야 합니다. 각 패키지는 특정 역할을 수행하며, 전체 워크플로우에서 중요한 구성 요소입니다.  
    - **LangChain**: 체인(Chain) 및 에이전트(Agent) 구조를 위한 핵심 라이브러리  
    - **Watsonx.ai**: LLM(Large Language Model) 및 임베딩 모델 제공  
    - **Chroma DB**: 벡터 스토어(Vector Store) 구축을 위한 오픈 소스 데이터베이스  
    - **dotenv**: 환경 변수 관리를 위한 라이브러리 (API 키 보안 저장용)  

- 설치 명령어 예시:  
```bash
pip install langchain ibm-watsonxai chromadb python-dotenv
```

### **65.3 import**  

- 구현에 필요한 패키지를 Python 코드에서 import합니다.  
예시:  
```python
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory
from ibm_watsonxai import WatsonxaiLLM, WatsonxaiEmbeddings
from chromadb import Client as ChromaClient
import os
from dotenv import load_dotenv
```


### **65.4 설정**  

1. **API 키 및 프로젝트 ID 입력 (.env 파일 사용 권장):**  
   - 외부 서비스(예: IBM watsonx.ai, Chroma DB)와의 통신을 위해 API 키와 프로젝트 ID가 필요합니다. `.env` 파일에 민감한 정보를 저장하여 보안성을 유지하세요.  
   ```bash
   # .env 파일 예시
   WATSONX_API_KEY=your_api_key_here
   WATSONX_PROJECT_ID=your_project_id_here
   ```

   Python 코드에서 `.env` 파일을 로드합니다.  
   ```python
   load_dotenv()
   api_key = os.getenv("WATSONX_API_KEY")
   project_id = os.getenv("WATSONX_PROJECT_ID")
   ```

2. **LLM 모델 선택:**  
   - 본 튜토리얼에서는 IBM granite 3.08b instruct 모델을 기본 LLM으로 사용합니다. 이 모델은 질문에 대한 답변을 생성하거나 행동 결정 엔진 역할을 수행합니다. 다른 LLM(예: GPT, PaLM 등)도 사용 가능합니다.     
   ```python
   llm = WatsonxaiLLM(api_key=api_key, project_id=project_id, model="granite-3.08b-instruct")
   ```


### **65.5 기본적인 RAG 구현**  

1. **프롬프트 템플릿 설정:**  
   - 질문을 여러 개 할 수 있도록 프롬프트 템플릿을 설계합니다. 예를 들어, "US Open에서 하는 스포츠는?"이라는 질문에 대한 템플릿을 작성합니다.  
   ```python
   prompt_template = ChatPromptTemplate.from_template(
       "질문: {question}\n답변:"
   )
   ```

2. **체인 설정:**  
   - 프롬프트와 LLM을 연결하여 응답을 생성하는 체인을 구성합니다.  
   ```python
   chain = LLMChain(llm=llm, prompt=prompt_template)
   ```

3. **테스트:**  
   - 기본적인 질문으로 응답을 확인합니다.  
   ```python
   response = chain.run(question="US Open에서 하는 스포츠는?")
   print(response)
   ```

### **65.6 문제점**  

1. **LLM의 한계:**  
   LLM은 학습 데이터 이후의 정보에 접근할 수 없습니다. 예를 들어, 2024 US Open의 장소는 학습 데이터에 포함되지 않았을 수 있습니다.  
   
2. **최신 정보 부족:**  
   적절한 도구가 없으면 최신 정보에 대한 질문에 답할 수 없습니다. 이를 해결하기 위해 지식 베이스를 구축하고 RAG 도구를 활용합니다.

### **65.7 지식 베이스 구축**  

1. **URL 목록:**  
   - 관련 정보를 가져올 URL 리스트를 생성합니다. 예를 들어, IBM의 2024 US Open 참여 관련 URL을 수집합니다.  
   ```python
   urls = [
       "https://www.ibm.com/us-open-2024",
       "https://www.usopen.org/news/2024"
   ]
   ```

2. **URL 로딩:**  
   - LangChain의 웹 기반 로더를 사용하여 URL의 내용을 문서로 로딩합니다.  
   ```python
   from langchain.document_loaders import WebBaseLoader
   loader = WebBaseLoader(urls)
   documents = loader.load()
   ```

3. **데이터 분할:**  
   - 텍스트 스플리터를 사용하여 문서를 작은 덩어리(chunk)로 분할합니다.  
   ```python
   from langchain.text_splitter import RecursiveCharacterTextSplitter
   splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
   chunks = splitter.split_documents(documents)
   ```

4. **임베딩 모델 초기화:**  
   - Watsonx.ai 임베딩 서비스를 통해 IBM slate 모델을 사용하여 텍스트를 벡터로 변환합니다.  
   ```python
   embeddings = WatsonxaiEmbeddings(api_key=api_key, project_id=project_id, model="slate")
   ```

5. **벡터 스토어 구축:**  
   - Chroma DB를 사용하여 임베딩된 문서를 저장합니다.  
   ```python
   chroma_client = ChromaClient()
   collection = chroma_client.create_collection(name="us_open_2024")
   collection.add(documents=chunks, embeddings=embeddings)
   ```

6. **Retriever 설정:**  
   - 벡터 스토어에 접근하기 위한 retriever를 설정합니다.  
   ```python
   from langchain.retrievers import VectorStoreRetriever
   retriever = VectorStoreRetriever(vectorstore=collection)
   ```


### 65.8 **도구 정의**  

- **`get IBM US Open context` 함수 및 도구 정의:**  
  - 이 함수는 에이전트에게 언제 도구를 호출해야 하는지 알려주는 역할을 합니다. 질문이 IBM의 2024 US Open 참여와 관련된 경우 벡터 스토어로 질문을 라우팅합니다.  
  ```python
  def get_ibm_us_open_context(question):
      if "IBM" in question and "US Open" in question:
          return retriever.get_relevant_documents(question)
      return None
  ```


### **65.9 고급 프롬프트 템플릿**  

1. **시스템 프롬프트:**  
   - 에이전트의 사고 과정, 사용된 도구, 최종 결과 출력을 지시합니다.  
   ```python
   system_prompt = "에이전트는 질문에 대한 답변을 생성하며, 필요한 경우 도구를 사용합니다."
   ```

2. **인간 프롬프트:**  
   - 사용자 입력 및 에이전트의 중간 단계를 표시합니다.  
   ```python
   human_prompt = "{question}\n중간 단계: {intermediate_steps}"
   ```

3. **부분 프롬프트 템플릿:**  
   - 도구 이름, 설명, 인수를 추가하여 프롬프트 템플릿을 완성합니다.  
   ```python
   full_prompt = ChatPromptTemplate.from_messages([
       ("system", system_prompt),
       ("human", human_prompt)
   ])
   ```


### **65.10 메모리 설정**  

- **LangChain ConversationBufferMemory:**  
  - 과거 대화 및 정보를 저장하여 응답의 정확성과 관련성을 향상시킵니다.  
  ```python
  memory = ConversationBufferMemory()
  ```


### **65.11 체인 및 에이전트 실행**  

1. **체인 설정:**  
   - 에이전트의 스크래치패드 메모리 프롬프트와 LLM을 연결합니다.  
   ```python
   agent_chain = LLMChain(llm=llm, prompt=full_prompt, memory=memory)
   ```

2. **Agent Executor:**  
   - 에이전트 실행을 담당합니다.  
   ```python
   from langchain.agents import AgentExecutor
   agent_executor = AgentExecutor(agent=agent_chain, tools=[get_ibm_us_open_context])
   ```

### **65.12 테스트 및 검증**  

1. **질문 재시도:**  
   - 이전에 답변할 수 없었던 질문(예: 2024 US Open 장소?)을 다시 시도합니다.  
   ```python
   response = agent_executor.run("2024 US Open의 장소는?")
   print(response)
   ```

2. **결과 확인:**  
   - 에이전트가 RAG 도구를 사용하여 관련 정보를 검색했는지 확인합니다.  

3. **불필요한 도구 호출 방지:**  
   - US Open과 관련 없는 질문(예: "프랑스의 수도는?")으로 테스트하여, 에이전트가 불필요한 도구 호출을 피하는지 확인합니다.

### **65.13 결론**  

- **핵심 기능:**  
  LangChain과 watsonx.ai를 사용하여 RAG 에이전트를 생성하고, IBM granite 3.08b Instruct 모델을 활용했습니다.  
- **성공 사례:**  
  RAG 도구를 통해 관련 정보 검색, 메모리 업데이트, 응답 출력에 성공했습니다.  
- **판단 능력:**  
  에이전트는 질문에 필요한 정보가 이미 있는 경우 도구를 사용하지 않고 답변할 수 있어야 합니다.  


## 66. 추천 엔진
- 출처: [What is an AI Recommendation Engine?](https://www.youtube.com/watch?v=gEdePRsDACc)

### **66.1 추천 엔진이란?**

* **핵심:** 추천 엔진은 인공지능(AI) 기술을 기반으로 작동하는 지능형 시스템으로, 방대한 양의 사용자 데이터와 아이템 정보를 분석하여 각 사용자에게 맞춤화된 콘텐츠(제품, 서비스, 정보 등)를 제안함으로써 개인화된 경험을 제공합니다.
* **개인화 효과:** McKinsey의 연구에 따르면, 효과적인 개인화 전략은 기업의 매출을 상당 수준(5~15%)까지 끌어올리는 강력한 동력이 됩니다. 이는 사용자 만족도 향상과 구매 전환율 증가에 직접적인 영향을 미치기 때문입니다.
* **시장 전망:** 현재 약 68억 8천만 달러 규모의 추천 엔진 시장은 디지털 전환 가속화와 개인화된 경험에 대한 수요 증가에 힘입어 향후 5년 안에 약 3배 성장할 것으로 예측됩니다. 이는 추천 엔진 기술이 다양한 산업 분야에서 핵심적인 역할을 수행하게 될 것이라는 전망을 뒷받침합니다.

### **66.2 추천 엔진 작동 방식 (5단계): 데이터에서 개인화된 추천까지**

1.  **데이터 수집 (Data Gathering): 추천 엔진의 연료 확보**
    * **핵심:** 사용자에게 최적의 아이템을 추천하기 위한 첫 단계는 양질의 사용자 데이터를 확보하는 것입니다. 이 데이터는 추천 엔진의 성능을 결정짓는 중요한 기반이 됩니다.
    * **명시적 데이터 (Explicit Data): 사용자의 직접적인 표현:** 사용자가 직접적으로 표현한 선호도 정보입니다. 예를 들어, 온라인 쇼핑몰에서 남긴 상품 리뷰, 영화에 대한 별점 평가, 특정 콘텐츠에 대한 댓글 등이 이에 해당합니다. 이러한 데이터는 사용자의 명확한 의도를 파악하는 데 유용합니다.
    * **암묵적 데이터 (Implicit Data): 사용자의 행동 패턴:** 사용자의 웹사이트 클릭 기록, 구매 내역, 검색어, 콘텐츠 시청 시간 등 서비스 이용 과정에서 자연스럽게 발생하는 행동 데이터입니다. 이러한 데이터는 사용자의 숨겨진 선호도나 관심을 파악하는 데 중요한 역할을 합니다.
    * **추가 데이터 활용:** 사용자의 나이, 성별과 같은 인구 통계학적 정보뿐만 아니라, 관심사, 라이프스타일, 가치관 등 심리 통계학적 데이터를 통합하여 사용자 프로필을 더욱 풍부하게 만들고, 추천의 정확도를 높일 수 있습니다.
2.  **저장 (Storage): 데이터 자산 관리**
    * **핵심:** 수집된 방대한 양의 데이터는 효율적인 분석 및 활용을 위해 체계적으로 저장되어야 합니다.
    * **다양한 저장소:** 데이터의 특성과 활용 목적에 따라 데이터 웨어하우스(정형 데이터 분석), 데이터 레이크(비정형 데이터 포함 다양한 형태의 데이터 저장), 데이터 레이크하우스(데이터 웨어하우스와 데이터 레이크의 장점을 결합) 등 다양한 유형의 데이터 저장소를 활용합니다.
3.  **분석 (Analysis): 숨겨진 패턴 발견**
    * **핵심:** 저장된 데이터는 머신러닝 알고리즘을 통해 심층적으로 분석됩니다. 이 과정에서 사용자들의 행동 패턴, 아이템 간의 연관성, 사용자 그룹 간의 유사성 등이 발견됩니다.
    * **머신러닝의 역할:** 다양한 머신러닝 기법(예: 회귀 분석, 분류, 클러스터링, 연관 규칙 학습 등)이 적용되어 데이터 세트 내의 숨겨진 패턴을 찾고, 사용자-아이템 간의 상관 관계를 식별하며, 이러한 패턴과 상관 관계의 강도를 측정합니다.
4.  **필터링 (Filtering): 맞춤형 추천 생성**
    * **핵심:** 분석 결과를 바탕으로 각 사용자에게 가장 관련성이 높을 것으로 예측되는 아이템들을 선별하여 추천 목록을 생성합니다. 다양한 필터링 방법이 사용되며, 각 방법은 고유한 장단점을 가집니다.
    * **협업 필터링 (Collaborative Filtering): 함께 좋아할 가능성:**
        * **기본 원리:** 특정 사용자와 유사한 선호도를 가진 다른 사용자들의 행동 데이터를 기반으로 추천합니다. 즉, 비슷한 취향의 사람들은 유사한 아이템에 관심을 가질 것이라는 가정에 기반합니다.
        * **메모리 기반 (Memory-based): 사용자-아이템 행렬 활용:**
            * 사용자와 아이템 간의 상호 작용(예: 평점, 구매) 데이터를 행렬 형태로 구성하고, K-최근접 이웃(KNN) 알고리즘과 같은 통계적 기법을 활용하여 유사한 사용자 또는 아이템을 찾습니다.
            * **아이템 기반 (Item-based):** 사용자가 특정 아이템과 상호 작용한 기록을 바탕으로, 해당 아이템과 유사한 다른 아이템을 추천합니다.
            * **사용자 기반 (User-based):** 특정 사용자와 유사한 행동 패턴이나 선호도를 가진 다른 사용자들이 좋아했던 아이템을 추천합니다.
        * **모델 기반 (Model-based): 예측 모델 학습:**
            * 머신러닝 알고리즘을 사용하여 사용자 행동 패턴을 학습하고, 이를 기반으로 각 사용자의 선호도를 예측합니다. 행렬 분해(Matrix Factorization)와 같은 기법이 주로 사용됩니다.
    * **콘텐츠 기반 (Content-based): 아이템 속성 기반 추천:**
        * **기본 원리:** 아이템 자체의 특징(예: 영화의 장르, 배우, 감독, 줄거리, 제품의 사양, 키워드 설명 등)을 분석하여 사용자가 이전에 좋아했던 아이템과 유사한 속성을 가진 아이템을 추천합니다.
        * **특징 분석:** 아이템의 텍스트 정보(설명, 리뷰 등)에서 키워드를 추출하거나, 이미지, 비디오 등의 멀티미디어 정보를 분석하여 아이템의 특징을 벡터 형태로 표현합니다.
    * **하이브리드 필터링 (Hybrid Filtering): 최적의 조합:**
        * **기본 원리:** 협업 필터링과 콘텐츠 기반 필터링을 포함한 두 가지 이상의 필터링 방법을 결합하여 각 방법의 단점을 보완하고 장점을 극대화합니다.
        * **넷플릭스 사례:** 넷플릭스의 추천 엔진은 사용자의 시청 기록 및 평가를 기반으로 하는 협업 필터링과 영화의 장르, 배우, 감독 등의 메타 정보를 활용하는 콘텐츠 기반 필터링을 결합하여 높은 정확도의 추천을 제공하는 대표적인 예시입니다.
5.  **피드백 루프 (Feedback Loop): 지속적인 개선**
    * **핵심:** 추천 시스템의 성능은 한 번 구축으로 끝나는 것이 아니라, 사용자의 반응을 지속적으로 모니터링하고 분석하여 개선해 나가야 합니다.
    * **사용자 반응 분석:** 사용자가 추천된 아이템을 클릭, 구매, 평가하는 등의 행동 데이터를 수집하고 분석하여 추천의 효과를 측정합니다.
    * **모델 최적화:** 분석 결과를 바탕으로 추천 알고리즘을 재조정하거나 새로운 데이터를 학습시켜 추천의 정확성과 품질을 지속적으로 향상시킵니다.

### **66.3 추천 엔진의 장점 및 과제: 빛과 그림자**

* **장점:**
    * **향상된 사용자 경험:** 사용자가 원하는 제품이나 서비스를 쉽고 빠르게 찾을 수 있도록 도와 불필요한 탐색 시간을 줄여주고 만족도를 높입니다.
    * **높은 고객 유지율:** 개인화된 콘텐츠 제공을 통해 사용자의 서비스 이용 만족도를 높이고, 이는 충성도 향상 및 이탈 방지로 이어집니다.
    * **매출 증가:** 사용자의 관심사에 맞는 제품을 효과적으로 추천함으로써 구매를 유도하고, 숨겨진 니즈를 발굴하여 추가적인 매출 기회를 창출합니다.
* **과제:**
    * **비용 및 복잡성 증가:** 대규모 데이터를 처리하고 정교한 추천 알고리즘을 운영하기 위해서는 고성능 컴퓨팅 인프라 구축 및 유지 보수 비용, 데이터 분석 및 모델 개발을 위한 전문 인력 확보 등에 상당한 투자가 필요합니다.
    * **잘못된 추천:** 알고리즘이 최적화된 평가 지표가 실제 사용자 만족도와 괴리가 있거나, 데이터의 품질 문제 등으로 인해 사용자의 기대와 다른 부적절한 아이템을 추천할 수 있습니다.
    * **편향:** 학습 데이터에 내재된 편향 또는 모델을 개발하고 평가하는 과정에서의 주관적인 편향이 추천 결과에 반영되어 특정 아이템이나 사용자 그룹에 불리한 추천이 발생할 수 있습니다. 이는 공정성 문제를 야기할 수 있습니다.

### **66.4 활용 분야: 경계를 넘나드는 추천 엔진**

* **전자 상거래:** 상품 추천, 개인화된 광고, 쇼핑 경험 최적화
* **미디어 및 엔터테인먼트:** 영화, 드라마, 음악, 뉴스 추천
* **여행 및 숙박:** 호텔, 항공권, 여행 상품 추천
* **소셜 미디어:** 친구 추천, 관심사 기반 콘텐츠 추천
* **교육:** 맞춤형 학습 콘텐츠 추천
* **금융:** 맞춤형 금융 상품 추천

## 67. Retrieval Augmented Generation (RAG) & Agentic RAG
- 출처: [What is Agentic RAG?](https://www.youtube.com/watch?v=0z9_MhcYvcY)

### **67.1 RAG (Retrieval Augmented Generation)란?**

*   LLM(Large Language Model)의 응답 품질과 신뢰도를 높이기 위한 파이프라인.  
    *   LLM은 방대한 데이터를 학습하지만, 최신 정보나 특정 도메인 지식에서 한계가 있을 수 있음. RAG는 이를 보완하기 위해 설계됨.
*   벡터 데이터베이스에서 관련 데이터를 검색하여 프롬프트에 컨텍스트로 추가, LLM으로 전달, 답변 생성.  
    *   예: "2023년 기후 변화 정책"에 대한 질문이 들어오면, 벡터 DB에서 최신 문서를 찾아 LLM에 제공.
*   LLM이 정확한 정보에 기반하여 응답할 수 있도록 함.  
    *   단순히 학습된 데이터에 의존하지 않고, 실시간으로 검색된 신뢰할 수 있는 데이터를 활용해 hallucination(허구 생성)을 줄임.

### **67.2 기존 RAG 파이프라인**

*   사용자 쿼리 -> 프롬프트 구성 -> LLM -> 응답 생성  
    *   기본적인 LLM 작동 방식으로, 사용자가 입력한 질문에 대해 학습된 지식만으로 답변을 생성.
*   벡터 DB 추가: 사용자 쿼리 -> 벡터 DB -> (검색된 정보) 프롬프트 구성 -> LLM -> 응답 생성  
    *   벡터 DB는 텍스트를 수치화한 벡터 형태로 저장해 유사성을 빠르게 검색하며, 이를 프롬프트에 추가해 LLM의 응답을 보강.
*   LLM은 응답 생성에만 활용됨.  
    *   즉, 검색된 데이터를 해석하거나 추가 작업을 수행하지 않고, 주어진 컨텍스트를 기반으로 텍스트를 생성하는 역할에 국한됨.

### **67.3 Agentic RAG 파이프라인**

*   LLM을 '에이전트'로 활용하여 단순히 응답 생성 외에 추가적인 의사 결정 수행.  
    *   LLM이 단순한 생성 도구가 아닌, 쿼리 처리 과정에서 주도적 판단을 내리는 지능형 에이전트로 진화.
*   예: 쿼리 유형에 따라 어떤 벡터 DB를 쿼리할지 결정, 응답 형식을 결정 (텍스트, 차트, 코드 스니펫 등)  
    *   사용자의 의도를 분석해 최적의 데이터 소스를 선택하거나, "코드로 보여줘" 같은 요청에 맞춰 출력 형식을 조정.

### **67.4 Agentic RAG 작동 방식 예시**

*   **다중 데이터 소스:** 내부 문서 (정책, 절차) + 외부 지식 (업계 표준, 모범 사례)  
    *   예: 회사 내부 규정과 외부 법률 자료를 동시에 활용 가능.
*   **에이전트 역할:** 사용자 쿼리 이해, 컨텍스트 파악, 최적의 벡터 DB 선택  
    *   LLM이 질문의 맥락을 분석해 적절한 데이터 소스를 동적으로 연결.  
    *   예: "휴가 중 원격 근무 정책" -> 내부 문서 DB로 연결  
        *   회사의 구체적인 휴가 정책 문서를 검색해 답변 생성.  
    *   예: "기술 회사 원격 근무 산업 표준" -> 외부 지식 DB로 연결  
        *   업계 보고서나 통계 데이터를 찾아 제공.  
    *   예: "2015년 월드 시리즈 우승팀" -> 관련 정보 없음 -> "정보 없음" 응답  
        *   시스템에 해당 데이터가 없으면 솔직히 "모른다"고 답변하거나, 외부 검색을 제안.

### **67.5 Agentic RAG의 장점**

*   더욱 관련성 높고 정확한 데이터 검색  
    *   쿼리에 맞는 최적의 소스를 찾아 불필요한 정보를 걸러냄.  
*   더욱 능동적인 의사 결정  
    *   LLM이 단순히 답변을 생성하는 데 그치지 않고, 검색 전략을 스스로 조정.  
*   실시간 데이터 또는 외부 서비스 통합 가능  
    *   예: API를 통해 최신 뉴스나 날씨 데이터를 가져와 답변에 반영.  
*   더욱 반응성, 정확성, 적응성 향상  
    *   사용자의 요구 변화에 유연하게 대응하며, 도메인별 특화된 응답 제공 가능.

### **67.6 Agentic RAG 활용 분야:**

*   고객 지원 시스템  
    *   예: 고객 문의에 따라 FAQ DB나 실시간 채팅 기록을 참조해 답변.  
*   법률 기술 (내부 브리핑 + 공개 사건 데이터베이스)  
    *   변호사가 과거 판례와 회사 내부 자료를 동시에 활용해 조언 생성.  
*   헬스케어  
    *   환자 기록과 최신 의학 논문을 결합해 의사에게 진단 보조 제공.  
*   기타 다양한 분야  
    *   교육(학습 자료 검색), 금융(시장 데이터 분석) 등 무궁무진한 응용 가능성.


## 68. LangChain vs. LangGraph
- 출처: [LangChain vs LangGraph: A Tale of Two Frameworks](https://www.youtube.com/watch?v=qAF1NjEVHhY)

### **68.1 LangChain**

*   **정의:**  
    LLM 기반 애플리케이션을 구축하기 위해 다양한 컴포넌트(문서 로딩, 프롬프트 생성, 메모리 등)를 연결하여 실행하는 프레임워크  
    - "기능 단위의 블록들을 순차적으로 조합해 하나의 애플리케이션을 구성하는 방식"

*   **구조:**  
    *   Chain 구조 (Directed Acyclic Graph, DAG)  
        - "한 번 지나간 경로는 다시 가지 않는 일방향 구조로, 명확한 순서를 따름"
    *   작업들이 특정 순서로 진행 (순차적)  
        - "예: 문서 로딩 → 텍스트 분할 → 요약 → 출력"
    *   정해진 단계가 명확한 작업에 적합  
        - "워크플로우가 단순하고 변하지 않는 경우에 효과적"

*   **구성 요소:**  
    *   Document Loader (데이터 로딩)  
        - "웹, 로컬 파일 등 다양한 소스로부터 문서 불러오기"
    *   Text Splitter (텍스트 분할)  
        - "긴 텍스트를 LLM이 처리하기 쉬운 단위로 나누기"
    *   Chain (작업 흐름 오케스트레이션)  
        - "작업들을 연결하고 실행 순서를 제어"
    *   Prompt (LLM 지시)  
        - "LLM에게 어떤 작업을 수행할지 지시하는 입력 템플릿"
    *   LLM (대규모 언어 모델)  
        - "텍스트 생성, 요약, 추론 등 핵심 처리 담당"
    *   Memory (대화 기록 및 맥락 저장)  
        - "사용자와의 이전 대화를 기억해 맥락 반영"
    *   Agent (구성 요소 연결)  
        - "조건에 따라 여러 Chain 또는 도구들을 동적으로 호출"

*   **상태 관리:**  
    *   제한적인 상태 관리 능력  
        - "Chain 자체는 상태 저장 기능이 약함"
    *   Chain을 통해 정보 전달은 가능하지만, 여러 실행에 걸쳐 지속적인 상태 유지가 어려움  
        - "하나의 요청/응답 내에서는 맥락 유지 가능, 그러나 긴 세션이나 복잡한 흐름은 어려움"
    *   Memory 컴포넌트를 통해 일부 상태 유지 가능  
        - "대화 기록을 통해 간단한 맥락 유지가 가능하지만 복잡한 데이터는 어려움"

*   **주요 사용 사례:**  
    *   데이터 검색, 처리, 결과 출력과 같은 순차적 작업에 적합  
        - "예: 문서 요약 시스템, 질의응답 챗봇"
    *   어느 정도 비순차적인 작업도 에이전트 기능을 통해 가능  
        - "단, 복잡한 조건 분기나 반복에는 한계"

### **68.2 LangGraph**

*   **정의:**  
    복잡한 비선형 워크플로우를 처리할 수 있는 상태 저장(Stateful) 멀티 에이전트 시스템 구축에 특화된 라이브러리  
    - "다양한 상황에 따라 유연하게 흐름이 바뀌는 시스템을 구축할 수 있음"

*   **구조:**  
    *   Graph 구조 (루프 및 이전 상태 재방문 가능)  
        - "순환 구조를 지원하여, 동일 노드를 여러 번 방문하거나 이전 상태로 돌아갈 수 있음"
    *   상태, 사용자 입력에 따라 다음 단계가 결정되는 상호작용 시스템에 적합  
        - "동적인 의사결정 및 복잡한 사용자 흐름을 표현 가능"

*   **구성 요소:**  
    *   Node (작업 단위)  
        - "하나의 작업 또는 기능을 수행하는 단위 (예: 요약, 분류 등)"
    *   Edge (노드 간 전환)  
        - "조건에 따라 노드 간 이동을 정의"
    *   State (작업 목록 유지)  
        - "시스템의 현재 상태 및 전체 흐름을 저장하고 관리"

*   **상태 관리:**  
    *   강력한 상태 관리  
        - "상호작용 흐름을 기억하고 조절 가능"
    *   모든 노드가 State에 접근하고 수정 가능  
        - "각 단계에서 정보를 추가하거나 수정하여 전체 맥락 관리 가능"
    *   맥락을 인식하는 복잡한 동작 가능  
        - "예: 대화 이력 기반 조건 분기, 사용자 맞춤형 응답"

*   **주요 사용 사례:**  
    *   지속적인 상호 작용과 적응이 필요한 복잡한 시스템  
        - "예: 고객센터 챗봇, 복잡한 업무 플로우 자동화"
    *   긴 대화에 대한 맥락을 유지하고 다양한 유형의 요청을 처리해야 하는 가상 비서  
        - "다양한 역할을 수행하며 장기적인 맥락을 기억하는 시스템 구축에 적합"

### **68.3 핵심 차이점**

| 구분         | LangChain                                                    | LangGraph                                                               |
| ------------ | ------------------------------------------------------------ | ----------------------------------------------------------------------- |
| 주요 목표     | LLM 작업을 연결하여 LLM 기반 애플리케이션 구축                        | 상태 저장 멀티 에이전트 시스템 및 워크플로우 생성 및 관리                         |
| 구조         | Chain (DAG)                                                  | Graph (루프 가능)                                                        |
| 상태 관리     | 제한적 (Memory 컴포넌트 사용)                                          | 강력함 (State 컴포넌트 사용)                                                   |
| 주요 사용 사례 | 순차적 작업 (데이터 처리, 결과 출력 등)                                  | 복잡한 시스템, 지속적인 상호 작용 및 적응이 필요한 시스템 (가상 비서 등)                  |


### **68.4 어떤 것을 선택해야 할까?**

*   **LangChain:**  
    순차적인 작업 흐름이 명확하고, 비교적 간단한 LLM 애플리케이션을 구축하는 경우  
    - "처리 순서가 고정되어 있고, 상태 관리가 단순한 프로젝트에 적합"

*   **LangGraph:**  
    복잡하고 비선형적인 작업 흐름, 지속적인 상태 관리, 다중 에이전트 시스템이 필요한 경우  
    - "사용자의 입력이나 조건에 따라 흐름이 유동적으로 바뀌는 복잡한 시스템에 적합"


## 69. Llama 모델
- 출처: [Llama: The Open-Source AI Model that's Changing How We Think About AI](https://www.youtube.com/watch?v=8c2LnKNoSmg)

### **69.1 Llama란?**

*   오픈 소스 모델
    *   개방형 데이터로 구축되었으며, 소스 코드가 공개되어 누구나 접근하고 수정할 수 있음
    *   Meta(구 Facebook)에서 개발한 대규모 언어 모델로, AI 커뮤니티의 접근성을 높이기 위해 공개됨
*   장점
    *   투명성: 모델 구축 방식과 장단점을 명확하게 파악할 수 있어 신뢰성이 높음
    *   커스터마이징: 모델 분석, 소형화, 미세 조정이 용이하여 특정 사용 사례나 산업 분야에 최적화 가능
    *   정확성: 더 작은 크기로도 우수한 성능을 발휘하는 모델 구축이 가능하여 컴퓨팅 비용 및 개발 시간 절감 효과가 있음
*   타 모델과의 차별점
    *   크기: GPT-4, Claude 등 상용 모델보다 훨씬 작은 크기로 설계되어 자원 효율성이 높고 배포가 용이
    *   커스터마이징: 범용성보다는 특정 도메인 및 사용 사례에 맞춤형 모델 구축에 초점을 두어 특화된 성능 발휘 가능

### **69.2 Llama의 역사**

*   **Llama 1 (2023년 2월)**
    *   자기회귀적 방식으로 단어 및 단어 시퀀스를 학습하여 이전 단어를 기반으로 다음 단어를 예측하는 기본 구조 채택
    *   70억, 130억, 330억, 650억 파라미터 규모의 다양한 모델 버전을 출시하여 사용 환경에 따른 선택권
    *   출시 당시 시장의 다른 상용 모델보다 훨씬 작은 크기로 설계되어 접근성을 높인 혁신적 시도였음

*   **Llama 2 (2023년 7월)**
    *   전반적인 성능 업데이트와 학습 데이터 확장으로 이전 버전 대비 성능 향상
    *   70억, 130억, 700억 파라미터 규모의 모델을 제공하며 상업적 사용도 허용하는 라이선스 변경
    *   모델 크기 대비 벤치마크 테스트에서 뛰어난 성능을 보여 효율성 측면에서 주목받음

*   **Code Llama (2023년 8월)**
    *   프로그래밍 언어에 특화된 도메인 특화 모델로 코드 생성 및 이해에 최적화
    *   일반 코드 생성 모델과 함께 Python에 특화된 특수 모델도 함께 출시하여 개발자 지원 강화
    *   코드 완성, 버그 수정, 알고리즘 제안 등 개발 생산성 향상을 위한 기능 제공

*   **Llama 3 (2024년 4월)**
    *   70억, 80억, 700억 파라미터 모델 및 다양한 크기의 모델을 출시하여 선택의 폭 확장
    *   이전 버전 대비 추론 속도와 정확도가 크게 향상되었으며 특히 다중 언어 지원 기능 강화
    *   대화형 응답에서의 품질이 향상되어 ChatGPT 등 상용 서비스와의 격차 축소

*   **Llama 3.1 (2024년 7월)**
    *   영어 외 다양한 언어 지원이 대폭 강화되어 글로벌 활용성 증대
    *   컨텍스트 윈도우 확장으로 모델이 더 많은 텍스트를 처리하고 생성할 수 있게 되어 장문 분석 및 생성 능력 향상
    *   Llama Guard와 같은 보안 기술을 도입하여 프롬프트 인젝션 공격 방지 및 유해 콘텐츠 필터링 강화
    *   8억, 70억, 405억 파라미터 크기의 다양한 모델을 제공하며, 특히 405억 파라미터 모델은 GPT-4와 견줄 만한 경쟁력 있는 성능 보유

### **69.3 Llama 3.1 활용법**

*   데이터 생성: 실제 데이터와 유사한 합성 데이터를 대량으로 생성하여 데이터 접근성 문제 해결 및 ML 모델 학습 데이터 확보
*   지식 증류: 대형 모델의 지식을 소형 모델로 전달하여 특정 도메인에 최적화된 경량 모델 개발 및 실용적 사용 사례 발굴
*   LLM 평가: 다양한 언어 모델의 성능을 객관적으로 비교하고 특정 태스크에 가장 적합한 모델을 선별하는 벤치마킹 도구로 활용

## 70. GPT (Generative Pre-trained Transformer)
- 출처: [Transforming Language with Generative Pre-trained Transformers (GPT)](https://www.youtube.com/watch?v=bdICz_sBI34)

### **70.1 GPT란?**

*   **정의:**  
    GPT는 인간과 유사한 자연어 텍스트를 생성하는 딥러닝 기반의 대규모 언어 모델(LLM)입니다.  
    *   "대규모"라는 표현은 수십억에서 수조 개에 이르는 파라미터(모델의 학습 가능한 변수)를 가진다
    *   "언어 모델"은 단어 시퀀스의 확률 분포를 학습하여 다음에 올 단어를 예측하는 모델을 말합니다.  

*   **작동 방식:**  
    GPT는 입력 시퀀스(예: 질문, 명령, 대화 맥락)를 분석하고, 통계적으로 가장 가능성 높은 출력을 단어 단위로 예측하여 생성합니다.  
    *   이 과정은 "자기회귀적(Autoregressive)"으로 이루어지며, 이전에 생성된 단어가 다음 단어 생성에 영향을 줍니다.  

*   **구성 요소:**  

    *   **Generative (생성적):**  
        *   GPT는 방대한 텍스트 데이터(책, 기사, 코드 등)에서 언어 패턴(문법, 의미, 스타일)을 학습
        *   학습된 패턴을 바탕으로 새로운 입력에 대해 창의적이고 맥락에 맞는 텍스트를 생성합니다.  
        *   **비지도 학습(Unsupervised Learning):**  
            *   레이블(정답)이 없는 데이터를 스스로 분석하여 패턴을 추출합니다.  
            *   예를 들어, "고양이는 [마스크]을 좋아한다"에서 [마스크] 위치의 단어를 예측하는 방식으로 학습합니다.  

    *   **Pre-trained (사전 학습):**  
        *   GPT는 특정 작업(예: 챗봇, 번역)을 수행하기 전에 일반적인 언어 이해 능력을 갖추기 위해 대규모 데이터로 미리 학습됩니다.  
        *   사전 학습 후 특정 작업에 맞춰 미세 조정(Fine-tuning)될 수 있습니다.  

    *   **Transformer (트랜스포머):**  
        *   자연어 처리(NLP)를 위해 특화된 신경망 아키텍처입니다.  
        *   **핵심 특징:**  
            *   **토큰화(Tokenization):**  
                *   텍스트를 단어 또는 하위 단위(서브워드)로 분할하여 처리합니다.  
                *   예: "unhappiness" → "un", "happiness"  
            *   **인코더-디코더 구조:**  
                *   **인코더:** 입력 텍스트의 의미를 압축하여 표현합니다.  
                *   **디코더:** 압축된 표현을 바탕으로 출력 텍스트를 생성합니다.  
                *   (참고: GPT는 디코더만 사용하는 "디코더 전용" 모델입니다.)  
            *   **Self-Attention (자기 주의):**  
                *   입력 시퀀스 내에서 단어 간의 관계를 동적으로 파악합니다.  
                *   예: "The animal didn't cross the street because it was too tired."에서 "it"이 "animal"을 가리킨다는 것을 이해합니다.  

### **70.2 트랜스포머 (Transformer) 주요 특징 (심화)**

*   **Self-Attention 메커니즘의 작동 원리:**  
    1.  **쿼리(Query), 키(Key), 값(Value) 벡터 생성:** 각 단어에 대해 세 가지 벡터를 생성합니다.  
    2.  **유사도 계산:** 쿼리와 키 벡터의 내적(Dot Product)을 통해 단어 간 유사도를 계산합니다.  
    3.  **Attention 가중치:** 유사도를 소프트맥스(Softmax) 함수에 통과시켜 각 단어의 중요도(가중치)를 결정합니다.  
    4.  **가중 합계:** 가중치와 값 벡터를 곱하여 최종 표현을 생성합니다.  

*   **인코더(Encoder)의 상세 과정:**  
    1.  **임베딩(Embedding):**  
        *   단어를 고차원 벡터 공간에 매핑하여 의미적 유사성을 반영합니다.  
        *   예: "왕" - "남자" + "여자" = "여왕"  
    2.  **위치 인코딩(Positional Encoding):**  
        *   단어의 순서 정보를 추가합니다. RNN과 달리 트랜스포머는 순차적 처리가 없기 때문에 필요
    3.  **멀티-헤드 어텐션(Multi-Head Attention):**  
        *   여러 개의 Attention 헤드를 사용하여 다양한 관점에서 단어 관계를 분석합니다.  
    4.  **피드포워드 네트워크(Feedforward Network):**  
        *   Attention 출력을 변환하여 더 복잡한 패턴을 학습합니다.  

*   **디코더(Decoder)의 상세 과정:**  
    1.  **마스크드 어텐션(Masked Attention):**  
        *   현재 위치 이후의 단어를 보지 못하도록 마스킹하여 미래 정보를 활용하지 않습니다.  
    2.  **인코더-디코더 어텐션:**  
        *   인코더의 출력을 참조하여 디코딩합니다.  
    3.  **출력 생성:**  
        *   최종적으로 다음 단어의 확률 분포를 예측합니다.  

### **70.3 GPT 모델 역사 (추가 정보)**

*   **GPT-3 (2020):**  
    *   1750억 개의 파라미터를 가진 초대규모 모델입니다.  
    *   Few-shot Learning 능력을 보여준다.
*   **GPT-4 (2023):**  
    *   멀티모달(이미지 이해) 기능이 추가되었습니다.  
    *   추론 능력과 정확도가 크게 향상되었습니다.  
*   **ChatGPT의 발전:**  
    *   RLHF(Reinforcement Learning from Human Feedback)를 통해 인간의 피드백으로 학습
    *   대화 형식에 최적화되고, 유해한 응답을 필터링하는 기능이 강화되었습니다.  
