---
title: 32차시 4:ByteByteGo
layout: single
classes: wide
categories:
  - ByteByteGo
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 46. 아마존 프라임 비디오의 아키텍처 전환 사례
- 출처: [Amazon Prime Video Ditches AWS Serverless, Saves 90%](https://www.youtube.com/watch?v=JTp0TY_2hXM)

### 46.1 **배경**

* 아마존 프라임 비디오는 실시간 스트리밍 품질 모니터링 서비스의 아키텍처를 서버리스에서 모놀리식으로 변경하여 비용을 90% 절감했습니다. 이는 클라우드 최적화 관점에서 매우 중요한 사례로, 확장성과 비용 효율성 사이의 균형을 보여줍니다.
* 기존 서비스는 미디어 변환, 결함 감지, 실시간 알림의 3단계로 구성되었습니다. 각 단계는 독립적인 마이크로서비스로 운영되어 개별적으로 확장 가능했지만, 서비스 간 통신과 오케스트레이션에 추가 비용이 발생했습니다.

### **46.2 기존 서버리스 아키텍처의 문제점**

* AWS Step Functions을 사용한 오케스트레이션 워크플로우에서 상태 전환 비용이 높았습니다. 각 상태 전환마다 요금이 발생하는 구조로, 대규모 처리 시 비용이 기하급수적으로 증가했습니다.
* 분산 컴포넌트 간 데이터 전송에 Amazon S3를 사용하여 데이터 전송 비용이 많이 발생했습니다. 특히 미디어 파일과 같은 대용량 데이터를 여러 서비스 간에 주고받으며 S3 비용(PUT, GET 요청 및 데이터 저장)이 크게 증가했습니다.

### **46.3 모놀리식 아키텍처로의 전환**

* 미디어 변환기와 결함 감지기를 동일한 프로세스에 배포했습니다. 두 핵심 기능을 단일 컨테이너 내에서 실행함으로써 서비스 간 통신 오버헤드를 제거했습니다.
* S3 버킷을 통한 중간 데이터 저장 단계를 제거하여 데이터 전송 비용을 절감했습니다. 이제 데이터는 메모리 내에서 직접 전달되어 스토리지 및 네트워크 비용을 크게 줄였습니다.
* 오케스트레이션 로직을 단순화했습니다. 복잡한 Step Functions 워크플로우 대신 내부 프로세스 흐름을 사용하여 상태 전환 비용을 없앴습니다.

### **46.4 결과**

* 90%의 비용 절감 효과를 달성했습니다. 이는 연간 수백만 달러에 해당하는 상당한 절감 효과로, 동일한 기능을 제공하면서도 운영 비용을 크게 줄였습니다.

### **46.5 핵심 메시지**

* "Serverless First" 접근 방식을 통해 빠르게 프로토타입을 구축하고 필요에 따라 확장할 수 있습니다. 서버리스는 초기 개발 속도와 유연성 측면에서 큰 장점을 제공하며, 시스템의 초기 검증에 이상적입니다.
* 소프트웨어 시스템은 진화해야 하며, 아키텍처를 재검토할 때 열린 마음을 유지하는 것이 중요합니다. 기술 부채, 비용, 성능 등 다양한 측면을 지속적으로 평가하고 필요시 대담한 변화를 시도해야 합니다.
* 마이크로서비스가 항상 최선의 선택은 아니며, 특정 사용 사례에 따라 아키텍처를 발전시켜야 합니다. 특히 워크로드 특성과 데이터 흐름 패턴에 따라 최적의 아키텍처 모델이 달라질 수 있습니다.
* 분산된 마이크로서비스로 컴포넌트를 분해하는 데는 비용이 따를 수 있으므로 장단점을 신중하게 고려해야 합니다. 서비스 경계를 넘나드는 데이터 전송과 오케스트레이션은 눈에 보이지 않는 비용을 발생시킬 수 있습니다.
* 소프트웨어 아키텍처에는 만능 해결책이 없으며, 각 시나리오의 고유성을 고려해야 합니다. 현재의 트렌드나 패턴을 맹목적으로 따르기보다 비즈니스 요구사항, 팀 역량, 비용 구조에 맞는 최적의 솔루션을 찾는 것이 중요합니다.

## 47. API 아키텍처
- 출처: [Top 6 Most Popular API Architecture Styles](https://www.youtube.com/watch?v=4vLxWqE94l4)


- API(Application Programming Interface)는 현대 소프트웨어 개발에서 핵심적인 역할을 수행하며, 서로 다른 소프트웨어 컴포넌트 간의 통신 및 상호 작용을 가능하게 하는 다리 역할을 합니다. API는 개발자가 복잡한 기능을 손쉽게 구현할 수 있도록 추상화 계층을 제공하며, 코드 재사용성과 모듈화를 촉진합니다. 다양한 API 아키텍처 스타일이 존재하며, 각각 고유한 디자인 철학과 사용 사례를 가지고 있어 개발자는 프로젝트 요구사항에 맞는 최적의 방식을 선택할 수 있습니다.

### **47.1 SOAP (Simple Object Access Protocol)**

* **특징:** 성숙하고 포괄적인 XML 기반의 프로토콜로, 엄격한 표준과 규칙을 따르며 메시지 구조에 대한 명확한 정의를 제공합니다. WSDL(Web Services Description Language)을 통해 서비스를 명시적으로 기술합니다.
* **장점:** 높은 보안 및 안정성을 제공하며, WS-Security와 같은 내장 표준을 통해 엔터프라이즈급 보안 기능을 지원합니다. 트랜잭션 처리와 오류 처리에 강점이 있습니다.
* **단점:** 복잡성 및 과도한 코드 양으로 인한 개발 부담이 크고, XML 처리로 인한 성능 저하가 발생할 수 있어 경량 앱에는 부적합합니다.
* **주요 사용 분야:** 금융 서비스, 결제 게이트웨이, 기업 내부 시스템 통합과 같이 높은 보안과 신뢰성이 요구되는 환경에서 주로 사용됩니다.

### **47.2 RESTful API**

* **특징:** 인터넷의 중추 역할을 하며, 자원 중심 아키텍처와 상태 비저장(stateless) 원칙을 따릅니다. HTTP 메서드(GET, POST, PUT, DELETE 등)를 활용해 직관적인 CRUD 작업을 수행하며 URI를 통해 리소스를 식별합니다.
* **장점:** 널리 사용되고 이해하기 쉬운 표준으로, 간편한 구현이 가능합니다. 캐싱 지원이 우수하고 확장성이 뛰어나며 다양한 클라이언트 플랫폼과의 호환성이 좋습니다.
* **단점:** 실시간 데이터 처리에 한계가 있으며, 복잡한 데이터 모델이나 관계를 표현하기 어렵습니다. 또한 오버페칭(over-fetching)이나 언더페칭(under-fetching) 문제가 발생할 수 있습니다.
* **주요 사용 분야:** Twitter, YouTube, Google Maps API 등 대부분의 웹 서비스와 모바일 앱 백엔드에서 널리 채택되고 있습니다.

### **47.3 GraphQL**

* **특징:** 아키텍처 스타일이자 쿼리 언어로, 클라이언트가 필요한 데이터만 정확히 요청할 수 있는 유연성을 제공합니다. 단일 엔드포인트를 통해 다양한 리소스에 접근할 수 있으며, 강력한 타입 시스템을 갖추고 있습니다.
* **장점:** 효율적인 네트워크 통신으로 대역폭 사용을 최적화하고, 빠른 응답 속도를 제공합니다. REST의 주요 문제점인 데이터 과잉/부족 문제를 효과적으로 해결하며, 버전 관리 없이 API를 진화시킬 수 있습니다.
* **단점:** 높은 학습 곡선이 존재하며, 단순 앱에는 과도한 복잡성을 초래할 수 있습니다. 또한 서버 측 처리 부담이 증가하고 캐싱 구현이 더 복잡해질 수 있습니다.
* **주요 사용 분야:** Facebook, GitHub, Shopify 등 복잡한 데이터 요구 사항이 있는 애플리케이션과 다양한 클라이언트 플랫폼을 지원해야 하는 서비스에서 활용됩니다.

### **47.4 gRPC (gRPC Remote Procedure Calls)**

* **특징:** Google이 개발한 최신 기술로, 고성능 RPC(원격 프로시저 호출) 프레임워크입니다. Protocol Buffers를 사용해 데이터를 직렬화하며, HTTP/2를 기반으로 하여 다중화된 스트림과 헤더 압축을 지원합니다.
* **장점:** 마이크로서비스 아키텍처에 적합하며, 언어 중립적인 인터페이스 정의를 제공합니다. 바이너리 프로토콜로 인한 뛰어난 성능과 효율적인 코드 생성 기능을 갖추고 있습니다.
* **단점:** 제한적인 브라우저 지원으로 웹 클라이언트에서의 직접 사용이 어려우며, REST에 비해 상대적으로 진입 장벽이 높습니다. 디버깅이 복잡할 수 있습니다.
* **주요 사용 분야:** Netflix, Square, Lyft 등 대규모 마이크로서비스 간 통신이 필요한 시스템과 저지연, 고효율 통신이 중요한 분산 시스템에서 사용됩니다.

### **47.5 WebSocket**

* **특징:** 실시간, 양방향, 지속적인 연결을 제공하는 프로토콜로, HTTP 핸드셰이크를 통해 연결을 설정한 후 TCP 연결을 유지합니다. 서버와 클라이언트 간에 실시간 데이터 스트림을 가능하게 합니다.
* **장점:** 낮은 지연 시간과 빠른 데이터 교환으로 실시간 애플리케이션에 이상적입니다. HTTP와 달리 연결을 유지함으로써 통신 오버헤드를 줄이고 이벤트 기반 아키텍처를 효과적으로 지원합니다.
* **단점:** 실시간 데이터가 필요 없는 앱에는 불필요한 오버헤드가 발생할 수 있으며, 연결 유지 관리와 재연결 로직이 복잡할 수 있습니다. 일부 프록시와 방화벽에서 문제가 발생할 수 있습니다.
* **주요 사용 분야:** 실시간 채팅 애플리케이션, 실시간 협업 도구, 금융 거래 플랫폼, 온라인 게임, 실시간 모니터링 시스템에서 널리 활용됩니다.

### **47.6 Webhook**

* **특징:** 이벤트 기반 아키텍처를 구현하는 HTTP 콜백 메커니즘으로, 특정 이벤트가 발생했을 때 지정된 URL로 HTTP 요청을 보냅니다. 서버 간 비동기 통신을 가능하게 하며 "역방향 API" 또는 "발행-구독" 패턴의 일종으로 볼 수 있습니다.
* **장점:** 시스템 간 실시간 알림 기능을 제공하며, 폴링(polling) 방식에 비해 자원을 효율적으로 사용합니다. 느슨한 결합(loose coupling)을 통해 시스템 확장성을 향상시킵니다.
* **단점:** 동기 통신이나 즉각적인 응답이 필요한 상황에는 부적합하며, 전송 실패 시 재시도 메커니즘이 별도로 필요합니다. 보안 측면에서 URL 노출 위험이 있을 수 있습니다.
* **주요 사용 분야:** GitHub의 새로운 커밋 알림, 결제 처리 시스템의 상태 업데이트, CRM 시스템의 고객 활동 트래킹, IoT 장치의 이벤트 알림 등에 활용됩니다.

## 48. 코드 배포 전략
- 출처: [Top 5 Most-Used Deployment Strategies](https://www.youtube.com/watch?v=AWVTKBUnoIg)

### **48.1 Big Bang Deployment (일괄 배포)**

*   **방식:** 
    - 모든 변경 사항을 한 번에 적용 (반창고 떼는 방식) 
    - 마치 반창고를 한 번에 떼듯이 모든 업데이트를 순간적으로 시스템에 적용하는 방법으로, 기존 시스템을 완전히 중단하고 새 버전으로 대체함
*   **장점:** 
    - 단순함, 데이터베이스 업그레이드 등에 유일한 선택일 수 있음 
    - 구현이 간단하고 직관적이며, 데이터베이스 스키마 변경과 같이 부분적 적용이 불가능한 경우 필수적인 방법
*   **단점:** 
    - 시스템 중단 발생, 문제 발생 시 롤백 어려움, 데이터 손실 가능성
    - 서비스 운영 중단으로 인한 사용자 불편과 비즈니스 손실이 발생하며, 오류 발견 시 기존 시스템으로 복원하는 과정이 복잡함
*   **주의사항:** 
    - 철저한 준비 및 테스트, 견고한 롤백 계획 필수 
    - 배포 전 철저한 통합 테스트와 시뮬레이션을 통해 위험을 최소화하고, 문제 발생 시 신속하게 대응할 수 있는 상세한 롤백 절차를 마련해야 함

### **48.2 Rolling Deployment (점진적 배포)**

*   **방식:** 
    - 시스템의 각 부분을 점진적으로 업데이트 (마라톤) 
    - 마라톤처럼 서버 인스턴스를 하나씩 순차적으로 업데이트하여 전체 시스템을 점진적으로 새 버전으로 전환하는 방식
*   **장점:** 
    - 다운타임 최소화, 문제 조기 발견 및 완화 가능 
    - 서비스 중단 없이 배포가 가능하며, 일부 서버에서만 문제가 발생할 경우 초기에 발견하여 전체 시스템으로 확산되기 전 조치 가능
*   **단점:** 
    - 배포 속도 느림, 시스템 전체 문제 가능성 존재, 특정 사용자 대상 배포 불가 
    - 완전한 배포까지 시간이 오래 걸리고, 신/구 버전 공존 시 호환성 문제가 발생할 수 있으며, 타겟팅된 사용자 그룹에만 선별적 배포가 어려움
*   **특징:** 
    - 위험과 사용자 영향 간 균형을 맞춤 
    - 시스템 안정성을 유지하면서도 새로운 기능을 점진적으로 도입하여 리스크와 사용자 경험 사이의 최적점을 찾는 방식

### **48.3 Blue-Green Deployment (블루-그린 배포)**

*   **방식:** 
    - 두 개의 동일한 프로덕션 환경 (Blue: 현재 버전, Green: 새 버전) 유지, 로드 밸런서로 트래픽 전환 
    - 기존 환경(Blue)과 동일한 새 환경(Green)을 구축한 후, 트래픽을 순간적으로 전환함으로써 배포 리스크를 최소화
*   **장점:** 
    - 다운타임 없는 전환, 간편한 롤백 
    - 사용자 서비스 중단 없이 새 버전으로 즉시 전환 가능하며, 문제 발생 시 로드 밸런서 설정만 변경하여 원래 환경으로 신속하게 복귀 가능
*   **단점:** 
    - 특정 사용자 대상 배포 불가, 자원 소모 큼, 복잡한 인프라 관리 필요 
    - 모든 사용자가 동시에 새 버전을 경험하게 되며, 두 개의 완전한 환경을 유지하는 데 비용과 자원이 많이 소모되고, 두 환경의 동기화와 일관성 유지가 복잡함
*   **특징:** 
    - 원활한 사용자 경험과 안정적인 롤백 제공 
    - 배포 과정에서 사용자 경험을 끊김 없이 유지하면서도 문제 발생 시 빠르고 안전하게 이전 상태로 되돌릴 수 있는 안전망 제공

### **48.4 Canary Deployment (카나리아 배포)**

*   **방식:** 
    - 소규모 사용자 그룹(카나리아)에게 먼저 배포하여 테스트 후 전체 배포 여부 결정 
    - 옛날 광부들이 유독가스 감지를 위해 카나리아를 사용했듯이, 소수의 사용자 그룹으로 새 버전의 안정성을 먼저 검증하는 방식
*   **장점:** 
    - 안전성 및 제어력 확보, 특정 사용자 대상 배포 가능 
    - 제한된 영향 범위 내에서 실제 사용 환경에서의 테스트가 가능하며, 특정 지역이나 사용자 그룹을 선택하여 새 버전을 경험하게 할 수 있음
*   **단점:** 
    - 복잡한 모니터링 및 자동화된 테스트 필요, 구현 및 관리 복잡 
    - 정교한 모니터링 시스템과 자동화된 피드백 메커니즘이 필요하며, 트래픽 분배와 사용자 그룹 관리에 추가적인 인프라와 로직이 요구됨
*   **활용:** 
    - 롤링 배포와 함께 사용하여 장점 극대화 
    - 카나리아 배포로 안전성을 검증한 후 롤링 배포로 확대함으로써 리스크 관리와 효율적인 배포를 동시에 달성 가능

### **48.5 Feature Toggle (기능 토글)**

*   **방식:** 
    - 코드 내에 새로운 기능에 대한 스위치(토글)를 만들어 특정 사용자 또는 조건에 따라 기능 활성화/비활성화 
    - 코드 레벨에서 기능의 ON/OFF를 제어할 수 있는 논리적 스위치를 구현하여 배포와 기능 공개를 분리
*   **장점:** 
    - 새로운 기능에 대한 제어력 향상, 특정 사용자 대상 테스트 가능, A/B 테스트 용이
    - 코드 배포와 기능 릴리스를 분리하여 더 세밀한 통제가 가능하며, 특정 사용자 그룹에게만 기능을 공개하거나 비교 테스트를 쉽게 수행 가능
*   **단점:** 
    - 코드 복잡성 증가, 테스트 어려움, 불필요한 토글 관리 필요 (토글 부채) 
    - 코드베이스에 조건부 논리가 추가되어 복잡도가 증가하고, 모든 토글 상태에 대한 테스트가 필요하며, 사용되지 않는 오래된 토글이 쌓여 기술 부채가 됨
*   **활용:** 
    - 다른 배포 전략과 함께 사용 가능 (e.g., 카나리아 배포 + 기능 토글) 
    - 카나리아 배포로 시스템 안정성을 검증하면서 기능 토글로 새 기능의 점진적 출시를 제어하는 등 다양한 배포 전략과 조합하여 최적의 배포 프로세스 구성 가능

## 49. Discord는 Cassandra에서 ScyllaDB로의 메시지 데이터베이스 이전
- 출처: [How Discord Stores TRILLIONS of Messages](https://www.youtube.com/watch?v=O3PwuzCvAjI)

### **49.1 배경**

*   Discord는 Cassandra 데이터베이스에서 ScyllaDB로 수조 개의 메시지를 이전하는 대규모 작업을 수행했습니다.  
    - 플랫폼의 핵심 기능인 메시징 시스템이 안정적으로 동작하기 위해, 데이터베이스의 성능과 신뢰성이 매우 중요했습니다.

*   Cassandra는 플랫폼 성장으로 인해 성능 문제(예: 예측 불가능한 지연 시간, 빈번한 장애 대응)를 겪고 있었습니다.  
    - 사용자 수와 메시지 수가 폭발적으로 증가하면서 기존 아키텍처의 한계가 뚜렷해졌고, 운영팀의 대응 부담도 가중되었습니다.

*   2022년, Cassandra 클러스터는 177개 노드에 걸쳐 수조 개의 메시지를 저장하고 있었습니다.  
    - 이처럼 대규모 데이터셋은 단순한 이전이 아닌, 안정성과 속도를 모두 고려한 세심한 전략이 필요했습니다.

### **49.2 해결책**

1.  **ScyllaDB 선택:** Cassandra와 호환되면서도 더 강력한 C++ 기반 엔진을 가진 ScyllaDB를 선택했습니다.  
    - ScyllaDB는 JVM 기반인 Cassandra보다 더 낮은 지연 시간과 예측 가능한 성능을 제공하며, 하드웨어 자원을 더 효율적으로 사용할 수 있습니다.

2.  **점진적 접근 방식:** 가장 큰 데이터베이스로 바로 뛰어드는 대신, 작은 데이터베이스부터 이전하여 문제점을 파악하고 해결했습니다.  
    - 이 방식은 리스크를 최소화하면서 이전 중 발생할 수 있는 예외 상황을 조기에 발견하고 대응할 수 있게 해주었습니다.

3.  **데이터 서비스 레이어:** API와 데이터베이스 클러스터 사이에 Rust로 작성된 중간 레이어를 구축하여 요청 병합을 통해 핫 파티션 발생 가능성을 줄였습니다.  
    - 이 계층은 다수의 유사 요청을 하나로 묶고, 읽기/쓰기 분산을 통해 데이터베이스에 집중되는 부하를 완화했습니다.

4.  **Super-Disk:** 로컬 SSD와 Google Cloud Persistent Disk의 장점을 결합한 2계층 RAID 솔루션을 개발하여 낮은 읽기 지연 시간과 높은 쓰기 내구성을 확보했습니다.  
    - ScyllaDB의 고성능을 뒷받침하기 위한 맞춤형 스토리지 시스템으로, 하드웨어 병목을 줄이고 안정성을 확보했습니다.

    *   RAID0으로 여러 로컬 SSD를 결합하여 낮은 지연 시간의 가상 디스크를 생성  
        - 데이터 접근 속도를 극대화하여 빠른 읽기 성능을 보장합니다.
    *   RAID1으로 RAID0 배열을 Persistent Disk와 미러링  
        - 장애 발생 시 데이터 손실을 방지하고 복구 시간을 최소화합니다.
    *   Linux 커널 설정을 통해 쓰기는 Persistent Disk로, 읽기는 로컬 SSD로 라우팅  
        - 읽기/쓰기 경로를 최적화하여 입출력 효율성과 안정성을 동시에 달성했습니다.

5.  **데이터 마이그레이터:** Rust로 작성된 새로운 데이터 마이그레이터를 사용하여 9일 만에 수조 개의 메시지를 다운타임 없이 이전했습니다.  
    - 고속 스트리밍 처리와 오류 복구 기능을 갖춘 도구로, 실시간 서비스를 중단하지 않고 안전하게 이전할 수 있었습니다.

### **49.3 결과**

*   Cassandra 노드 177개에서 ScyllaDB 노드 72개로 감소  
    - 더 적은 자원으로 더 높은 성능을 낼 수 있어 인프라 비용과 관리 부담이 크게 줄었습니다.
*   지연 시간 대폭 감소  
    - 사용자 체감 성능이 향상되어 메시지 전송과 수신의 반응성이 개선되었습니다.
*   장애 대응 인력의 업무 부담 감소  
    - 시스템 안정성이 향상되어 운영팀의 수동 개입 빈도가 줄어들고, 유지보수 효율성이 증가했습니다.

## 50. Stack Overflow 시스템 아키텍처
- 출처: [Uncovering Stack Overflow's Shocking Architecture](https://www.youtube.com/watch?v=fKc050dvNIE)


### **50.1 핵심 내용**

- Stack Overflow는 월 20억 페이지 뷰를 처리하는 대규모 플랫폼이지만, 일반적인 빅테크 기업의 시스템 아키텍처와는 매우 다른 방식을 사용합니다.  
- 전형적인 빅테크 기업들이 채택하는 분산형, 클라우드 기반 인프라 대신, Stack Overflow는 단순하고 일관된 구조를 유지하면서도 고성능을 달성합니다.

### **50.2 일반적인 예상 vs. Stack Overflow**

*   **일반적인 예상:** 마이크로서비스, 쿠버네티스, 클라우드 기반 솔루션, 캐싱, 샤딩, 메시지 큐, Event Sourcing, CQRS, 분산 시스템 개념 활용 (eventual consistency, CAP theorem)  
    - 대부분의 대규모 트래픽 시스템은 확장성과 유연성을 확보하기 위해 복잡한 인프라와 아키텍처를 도입하는 경향이 있습니다

*   **Stack Overflow:** 온프레미스 서버, 모놀리식 애플리케이션  
    - 단일 애플리케이션과 자체 서버 인프라로 복잡한 아키텍처 없이도 놀라운 성능을 유지하고 있습니다

### **50.3 Stack Overflow의 실제 아키텍처**

*   **기본:** 
    - 9개의 온프레미스 웹 서버에서 실행되는 단일 모놀리식 애플리케이션으로 Q&A 사이트 운영  
    - 웹 애플리케이션과 API가 하나의 코드베이스에 통합되어 있으며, 네트워크 오버헤드 없이 빠르게 동작

*   **클라우드 미사용:** 
    - 클라우드 기반 솔루션에 의존하지 않음  
    - 자체 데이터센터를 운영함으로써 성능 제어와 비용 예측성을 확보

*   **마이크로서비스 미사용:** 
    - 애플리케이션을 마이크로서비스로 분할하지 않음  
    - 서비스 간의 통신 지연이나 복잡한 배포 파이프라인 없이 일관된 개발 및 운영이 가능

*   **성능:** 
    - 낮은 지연 시간 및 메모리 할당에 최적화된 시스템 설계  
    - 핵심 로직이 매우 빠르게 실행되도록 정교하게 튜닝되어 있으며, 하드웨어 리소스를 최대한 활용

*   **서버 용량:** 
    - 서버는 5~10%의 낮은 용량으로 실행되어 확장 여유 충분  
    - 현재 서버가 과도한 부하 없이 운영되고 있어 트래픽 급증 시에도 여유롭게 대응 가능

*   **익명 트래픽:** 
    - 트래픽의 80%가 익명 사용자이지만 뛰어난 성능 유지  
    - 로그인 없이 검색을 통해 들어오는 트래픽이 대부분임에도, 초고속 응답을 제공

*   **캐싱:** 
    - 가장 많이 방문하는 질문 페이지조차 캐싱하지 않지만 20ms 내에 렌더링  
    - 캐시 없이도 데이터베이스와 애플리케이션의 성능 최적화 덕분에 빠른 페이지 로딩이 가능

*   **메모리:** 
    - SQL Server 인스턴스에 1.5TB의 RAM을 사용하여 데이터베이스의 1/3을 메모리에서 빠르게 액세스  
    - 자주 조회되는 데이터를 메모리에 유지함으로써 디스크 접근을 최소화하고, 응답 속도를 극대화

### **50.4 시사점**

*   최신 기술 트렌드를 무조건 따르는 것보다 특정 문제에 대한 깊은 이해가 중요  
    - 기술 선택은 '최신'보다 '적합성'이 우선입니다. 무엇이 문제를 가장 잘 해결할 수 있는가가 핵심

*   시스템 아키텍처는 비즈니스 및 기술적 요구 사항에 맞게 조정해야 함  
    - 모든 기업이 마이크로서비스나 클라우드로 가야 하는 것은 아니며, 환경에 맞는 구조가 중요

*   효율성, 실용성, 고정관념 탈피를 통해 성공적인 시스템 구축 가능  
    - Stack Overflow는 단순함과 실용성을 기반으로 놀라운 확장성과 성능을 달성한 사례

### **50.5 결론**

Stack Overflow는 기술이 만능이 아니며, 특정 상황에 맞는 최적의 아키텍처를 선택하는 것이 중요하다는 것을 보여주는 사례 연구입니다.  
- 복잡한 기술이 아닌, 문제 해결에 집중한 설계가 오히려 더 효과적일 수 있다는 점을 시사.


## 51. OAuth 2.0
- 출처: [OAuth 2 Explained In Simple Terms](https://www.youtube.com/watch?v=ZV5yTm4pT8g)

### **51.1 문제 상황**

*   과거 인터넷에서는 정보 공유 시 사용자 이름과 비밀번호를 직접 제공해야 했습니다.  
    - 예를 들어, 다른 서비스에서 내 이메일 목록에 접근하려면 Gmail ID와 비밀번호를 그대로 입력해야 

*   이는 위험하며, 특히 개인 금융 정보와 같은 민감한 데이터에 문제가 됩니다.  
    - 중간에 정보가 탈취될 경우, 계정 전체가 해킹되는 등 치명적인 보안 사고로 이어질 수 있습니다.

### **51.2 OAuth 2.0 이란?**

*   특정 정보에 접근할 수 있는 "특별한 키"를 제공하는 방식입니다.  
    - 사용자의 계정 정보를 그대로 노출하지 않고, 제한된 권한만 가진 토큰(token)을 발급합니다.

*   비밀번호를 공유하지 않고, 접근 권한을 제어하고 언제든지 취소할 수 있습니다.  
    - 사용자는 언제든지 설정에서 특정 앱의 권한을 해제, 만료 시간이 지난 토큰은 자동으로 무효화됩니다.

### **51.3 OAuth 2.0 예시**

*   **스냅 스토어(Snap Store):** 사진 저장 앱 (Resource Server)  
    - 사용자의 사진 데이터를 보관하는 서비스입니다.

*   **프린트 매직(Print Magic):** 사진 인쇄 서비스 (Client)  
    - 사용자의 사진을 인쇄해주기 위해 접근 권한이 필요한 제3자 앱입니다.

*   **사용자:** 스냅 스토어 사진의 소유자 (Resource Owner)  
    - 자신의 사진을 Print Magic에서 사용할 수 있도록 권한을 부여할 수 있는 주체입니다.


### **51.4 OAuth 2.0 작동 방식**

1.  사용자가 프린트 매직에 스냅 스토어 사진 접근을 요청합니다.  
    - 예: "이 사진들을 인쇄하고 싶어요!" 라고 요청.

2.  프린트 매직은 스냅 스토어의 인증 서버에 Client ID 와 Scope (접근 수준) 을 함께 요청합니다.  
    - 예: "이 사용자의 사진 파일만 읽을 수 있는 권한이 필요해요."

3.  사용자는 스냅 스토어에서 직접 인증하고, 프린트 매직에 사진 접근 권한을 부여합니다.  
    - 사용자는 자신의 ID로 로그인하고 권한 요청 내용을 확인한 뒤, 동의 버튼을 누릅니다.

4.  스냅 스토어의 인증 서버는 프린트 매직에 Authorization Code 를 전달합니다.  
    - 이 코드는 짧은 시간 동안만 유효한 일회용 코드입니다.

5.  프린트 매직은 Authorization Code, Client ID, Client Secret 을 인증 서버에 제시합니다.  
    - 자신이 진짜 등록된 클라이언트임을 증명합니다.

6.  인증 서버가 검증 후 프린트 매직에 Access Token 을 발급합니다.  
    - 이제 프린트 매직은 이 토큰을 사용해서 사진에 접근할 수 있습니다.

7.  프린트 매직은 Access Token 을 사용하여 스냅 스토어의 리소스 서버 (사진) 에 접근합니다.  
    - 프린트 매직은 토큰을 API 호출 시 포함시켜 요청합니다.


### **51.5 핵심 개념**

*   **Resource Owner:** 정보 소유자 (사용자)  
    - 자신의 데이터에 대한 접근 권한을 가지고 있는 주체입니다.

*   **Resource Server:** 정보 저장 서버 (스냅 스토어)  
    - 보호된 리소스를 저장하고 있으며, Access Token을 검증하여 데이터 접근을 허용합니다.

*   **Client:** 정보 접근을 원하는 서비스 (프린트 매직)  
    - 직접 데이터를 갖고 있진 않지만, 사용자의 동의를 받아 제한된 접근을 시도하는 앱입니다.

*   **Authorization Server:** 인증 및 권한 부여 담당 (스냅 스토어 내부 또는 외부)  
    - 사용자 인증과 권한 부여 토큰 발급을 담당하는 중간 관리자입니다.

*   **Client ID:** 클라이언트를 식별하는 ID  
    - 등록된 앱임을 식별하는 공개된 고유값입니다.

*   **Client Secret:** 클라이언트와 인증 서버만 아는 비밀 키  
    - 토큰 요청 시 인증 서버에게 "진짜 나야!"라고 증명할 때 사용하는 비밀값입니다.

*   **Scope:** 접근 권한 범위  
    - 예: 사진만 보기(Read-only), 연락처 수정 등. 얼마나 깊이 데이터를 사용할 수 있는지를 정의합니다.

*   **Authorization Code:** 클라이언트에 대한 권한 부여를 나타내는 임시 코드  
    - 짧은 시간 동안만 유효하며, Access Token을 얻기 위한 중간 단계입니다.

*   **Access Token:** 리소스 서버에 접근하기 위한 키 (만료 시간 설정 가능, 취소 가능)  
    - API 호출 시 헤더에 포함되어 리소스를 요청할 수 있습니다.

*   **Refresh Token:** Access Token 이 만료되었을 때 새로운 Access Token 을 획득하는 데 사용  
    - 사용자가 다시 로그인하지 않고도 권한을 유지할 수 있게 해줍니다.

### **51.6 OAuth 2.0 장점**

*   보안성 강화 (비밀번호 공유 불필요)  
    - 사용자 계정을 직접적으로 노출하지 않아 위험을 크게 줄일 수 있습니다.

*   접근 권한 제어  
    - 어떤 정보에, 어느 정도의 권한으로 접근할지를 세밀하게 조정할 수 있습니다.

*   만료 및 취소 기능 제공  
    - 보안 이슈 발생 시 즉시 권한을 회수하거나 자동 만료 설정을 통해 위험을 줄입니다.

*   안전한 앱 상호 작용 지원  
    - 다양한 서비스 간 연동을 안전하고 유연하게 가능하게 해줍니다.


## 52. 넷플릭스 스튜디오 API 아키텍처 변천사
- 출처: [Demystifying the Unusual Evolution of the Netflix API Architecture](https://www.youtube.com/watch?v=Uu32ggF-DWg)


### **52.1 초기**

*   **모놀리식 아키텍처:** 모든 기능이 하나의 코드베이스에 통합된 시스템.  
    - 사용자 관리, 콘텐츠 제작, 승인, 릴리즈 관리 기능이 모두 하나의 애플리케이션 내부에서 동작.
*   **문제점:** 넷플릭스 성장 및 협업 스튜디오 증가로 인해 확장성 및 유지보수 어려움 발생.  
    - 기능이 늘어나고 코드베이스가 커지면서, 하나의 변경이 전체 시스템에 영향을 주는 상황이 빈번해짐.

### **52.2 마이크로서비스 전환**

*   **모놀리스 해체:** 시스템을 독립적인 마이크로서비스로 분할.  
    - 콘텐츠 제작, 승인 프로세스, 자산 관리 등 기능별로 별도 서비스로 분리하여 각각 배포 및 관리 가능.
*   **장점:** 효율성 및 자율성 향상.  
    - 각 팀이 독립적으로 개발 및 배포 가능해져 개발 속도와 유연성 증가.
*   **새로운 문제:** 스튜디오 앱과 수많은 마이크로서비스 간의 직접적인 인터페이스 복잡성 증가.  
    - 클라이언트 앱에서 여러 서비스에 대해 각각 호출을 해야 하며, 종속성과 네트워크 호출 복잡도가 급격히 상승.

### **52.3 API Gateway 도입**

*   **게이트웨이 통합 레이어:** 모든 서비스를 묶어 클라이언트에 통합된 인터페이스 제공.  
    - 클라이언트는 개별 서비스를 몰라도 게이트웨이 하나만 호출하면 필요한 데이터를 받을 수 있음.
*   **해결:** 여러 서비스에 걸친 요청 처리 간소화. (예: 영화, 제작, 배우 정보를 하나의 앱에서 통합 요청)  
    - 클라이언트는 하나의 API 호출로 다양한 데이터 응답을 받을 수 있어 개발 편의성 향상.
*   **새로운 문제:** 팀 규모 및 서비스 증가로 인해 게이트웨이 레이어가 새로운 모놀리스로 변질.  
    - 게이트웨이에 모든 로직이 집중되면서 다시 하나의 거대한 코드베이스가 되어버리는 문제 발생.

### **52.4 GraphQL & Federated Gateway 도입**

*   **GraphQL:** UI가 필요한 데이터만 정확하게 요청할 수 있는 강력한 쿼리 언어.  
    - 과도한 데이터 요청이나 불필요한 필드 응답 없이, 필요한 데이터만 선택적으로 받아올 수 있음.
*   **Federated Gateway:** 각 도메인 전문가가 자신의 '그래프'를 관리하고, 통합된 접근점 제공.  
    - 예를 들어 콘텐츠 팀은 콘텐츠 관련 스키마를, 인사 팀은 배우 정보 스키마를 관리하며, 중앙 게이트웨이가 이를 연결.
*   **해결:** 복잡한 비즈니스 로직을 적절한 서비스로 직접 라우팅 가능, 단일 GraphQL 게이트웨이를 통해 여러 API에서 데이터 가져오기 가능.  
    - 클라이언트는 하나의 쿼리로 여러 서비스를 연결해 데이터를 가져오고, 도메인별 분산 관리도 가능

### **52.5 핵심 메시지**

*   시스템 아키텍처는 성장하는 비즈니스 요구에 맞게 진화해야 함.  
    - 초기 구조가 이상적이더라도, 조직 규모와 요구사항 변화에 맞춰 지속적으로 재설계가 필요.
*   타사의 인프라를 무분별하게 모방하기보다는, 고유한 비즈니스 요구에 맞는 아키텍처를 구축해야 함.  
    - 넷플릭스만의 워크플로우, 협업 방식, 콘텐츠 제작 흐름에 최적화된 구조가 필요.
*   비즈니스 로직의 위치, 확장 필요성 등을 고려하여 아키텍처를 설계해야 함.  
    - 로직을 어디에 두는 것이 유지보수성과 확장성 측면에서 유리한지를 항상 고민해야 함.

## 53. DevOps, SRE, Platform Engineering 개념
- 출처: [DevOps vs SRE vs Platform Engineering \| Clear Big Misconceptions](https://www.youtube.com/watch?v=an8SrFtJBdM)

### **53.1 소개**

*   Netflix, Amazon과 같이 서비스를 제공하는 기업들이 어떻게 빠르고 안정적으로 서비스를 제공하는지 알아본다.  
    - 이들 기업은 수많은 사용자가 동시에 접속하는 상황에서도 높은 가용성과 성능을 유지하기 위해 체계적인 개발 및 운영 전략을 활용한다.
*   DevOps, SRE, Platform Engineering의 차이점, 유사점, 협력 관계를 이해한다.  
    - 이 세 가지는 모두 현대 소프트웨어 개발 환경에서 필수적인 역할을 하며, 함께 작동할 때 가장 큰 시너지를 발휘한다.

### **53.2 DevOps**

*   **정의:** 개발(Development)팀과 운영(Operations)팀 간의 간극을 줄이는 문화 및 방식. 소프트웨어 개발 라이프사이클 전반에 걸쳐 두 팀이 협력하는 것을 목표로 한다.  
    - 이는 조직 내 사일로(Silo)를 허물고, 전체 팀이 공동의 책임을 갖고 서비스를 개발하고 운영
*   **핵심:** "You build it, you run it" 원칙. 개발팀이 직접 소프트웨어 배포 및 유지보수를 담당하여 최종 사용자에게 더 빠르게 새로운 기능을 제공한다.  
    - 이를 통해 피드백 루프가 짧아지고, 제품 품질과 배포 속도가 모두 향상된다.
*   **특징:**
    *   클라우드 엔지니어가 Ansible로 가상 인스턴스를 구축하고 Kubernetes를 운영하는 경우 DevOps 전문가로 볼 수 있다.  
        - 인프라 자동화와 컨테이너 오케스트레이션을 통해 효율적인 배포 환경을 구성하는 역할을 수행
    *   시스템 관리자가 도구를 만들고 모니터링 시스템을 활용하는 경우 SRE로 볼 수 있다.  
        - 단순한 운영을 넘어서, 안정성 유지와 관련된 코드 기반의 접근을 실천한다.


### **53.3 SRE (Site Reliability Engineering)**

*   **정의:** Google에서 시작된 개념으로, 대규모 시스템의 안정성(resilience)을 구축하는 것을 목표로 한다.  
    - 서비스 중단이나 장애를 최소화하면서, 서비스 품질과 가용성을 일정 수준 이상으로 유지하는 것
*   **핵심:** 소프트웨어가 실제 환경의 요구 사항을 잘 처리할 수 있도록 보장한다. 운영 문제를 해결하기 위해 소프트웨어 엔지니어링 접근 방식을 사용한다.  
    - 코드로 운영 문제를 해결하는 "운영의 코드화"가 중요한 특징이다.
*   **특징:**
    *   Google의 Borg, Monarch 시스템과 같은 도구와 방식을 개발하여 시스템의 안정성을 높인다.  
        - 자체적인 모니터링 및 배포 시스템을 통해 문제를 사전에 탐지하고 자동으로 대응한다.
    *   개발자를 위한 도구를 만들어 Platform Engineer의 역할을 수행하기도 한다.  
        - 이처럼 SRE는 단순한 운영자 역할을 넘어, 개발팀이 효율적으로 일할 수 있도록 인프라 측면에서 지원하는 교차 역할을 한다.

### **53.4 Platform Engineering**

*   **정의:** 개발자가 고품질 소프트웨어를 빠르게 생산할 수 있도록 안정적인 플랫폼을 개발하는 것을 목표
    - 내부 개발자들이 공통 인프라를 반복적으로 구축할 필요 없이, 일관된 개발 환경을 활용하도록 도움
*   **핵심:** 제품 개발의 전체 라이프사이클을 비즈니스 목표에 맞게 조정한다.  
    - 개발 도구, 테스트 환경, 배포 파이프라인 등을 표준화하여 개발자의 생산성을 극대화한다.
*   **특징:**
    *   Netflix의 플랫폼 엔지니어링 팀이 좋은 예시이다.  
        - Netflix는 다양한 개발 팀들이 동일한 기준과 툴셋에서 작업할 수 있도록 내부 플랫폼을 운영하며, 이를 통해 효율성과 품질을 동시에 확보한다.
    *   소프트웨어 개발 및 운영의 다양한 구성 요소를 결합하여 응집력 있는 단위를 만든다.  
        - 예를 들어, CI/CD 파이프라인, 로깅 및 모니터링 시스템, 테스트 자동화 도구 등을 하나의 통합된 플랫폼으로 제공한다.

### **53.5 공통점 및 결론**

*   DevOps, SRE, Platform Engineering은 협업, 자동화, 효율성을 향상시키는 공통된 비전을 공유한다.  
    - 이들은 모두 ‘더 나은 개발 - 더 빠른 배포 - 더 안정적인 운영’이라는 선순환 구조를 목표로 한다.
*   각 역할은 고정된 직함에 얽매이기보다는 산업의 변화에 적응하고 진화하는 전문가를 의미한다.  
    - DevOps나 SRE는 하나의 직무라기보다는 조직 문화와 기술적 역량의 융합으로 보는 것이 적절하다.
*   각각의 역할은 공존하며, 더 강력하고 효율적인 기술 생태계를 조성하는 데 기여한다.  
    - 서로 다른 역할이지만, 협력 구조를 통해 더 나은 개발자 경험과 서비스 품질을 만들어낸다.


## 54. API 성능 향상을 위한 7가지 최적화 기법
- 출처: [Top 7 Ways to 10x Your API Performance](https://www.youtube.com/watch?v=zvWKqUiovAM)

### **54.1 핵심** 
- API 최적화는 섣불리 시작하면 불필요한 복잡성을 초래할 수 있으므로, **로드 테스트와 프로파일링을 통해 실제 병목 현상을 파악한 후** 진행해야 합니다.     
- 이는 New Relic, Datadog 같은 APM 도구를 활용해 요청 처리 시간, 데이터베이스 쿼리 성능, 네트워크 지연 등을 분석함으로써 최적화 우선순위를 명확히 설정하는 것을 의미합니다.

### **54.2 최적화 기법**

1. **캐싱 (Caching):**
    - **원리:** 동일한 요청에 대한 응답을 저장하여 재사용, 불필요한 연산 반복 방지.
    - **활용:** 자주 액세스되는 API 엔드포인트에 적용, Redis 또는 Memcached와 같은 인메모리 캐시 시스템 활용.
    - **효과:** 데이터베이스 부하 감소, 응답 속도 향상.
    - **주요설명:** 
        - 캐싱 전략으로는 TTL(Time-To-Live) 설정, LRU(Least Recently Used) 정책 등이 중요하며, 캐시 무효화(invalidation) 전략도 신중히 설계해야 합니다. 
        - 예를 들어, 전자상거래 플랫폼에서 제품 목록 API는 캐싱으로 초당 요청 처리량을 2~3배 향상시킬 수 있습니다. 
        - 다만, 캐시 일관성 문제(예: 데이터 갱신 지연)를 방지하기 위해 이벤트 기반 캐시 갱신(예: Kafka를 통한 변경 알림)을 고려해야 합니다.

2. **Connection Pooling:**
    - **원리:** 데이터베이스 연결을 미리 생성하여 풀(Pool)에 보관 후 재사용.
    - **활용:** API 호출마다 새로운 연결 생성하는 대신 풀에서 연결 재사용.
    - **효과:** 연결 설정에 소요되는 시간 절약, 전체 처리량 향상.
    - **서버리스 환경:** AWS RDS Proxy, Azure SQL Database serverless 등 연결 관리 솔루션 활용.
    - **주요설명:** 
        - 연결 풀 크기는 서버의 동시 요청 처리 능력과 데이터베이스 부하를 고려해 조정해야 합니다. 
        - 예를 들어, HikariCP(Java) 또는 pgBouncer(PostgreSQL)를 사용하면 연결 관리 오버헤드를 줄일 수 있습니다. 
        - 서버리스 환경에서는 연결이 자주 끊길 수 있으므로, 연결 풀 대신 프록시 서비스를 활용해 안정성을 높이는 것이 효과적입니다.

3. **N+1 쿼리 문제 해결:**
    - **문제:** 엔티티와 관련된 엔티티 데이터를 가져올 때 발생하는 비효율적인 쿼리 방식 (예: 게시글-댓글 관계).
    - **해결:** 데이터를 한 번의 쿼리 또는 최소한의 쿼리로 가져오도록 개선.
    - **효과:** 데이터베이스 왕복 횟수 감소, 성능 향상.
    - **주요설명:** 
        - ORM(Object-Relational Mapping) 프레임워크(예: Hibernate, Django ORM)에서 흔히 발생하는 N+1 문제를 해결하려면 Eager Loading 또는 JOIN 쿼리를 활용해야 합니다. 
        - 예를 들어, GraphQL API에서 DataLoader 패턴을 적용해 배치 처리로 쿼리 수를 줄일 수 있다. 
        - 실제 사례로, 소셜 미디어 플랫폼에서 게시글 목록 조회 시 N+1 문제를 해결해 응답 시간을 50% 이상 단축한 경우가 있습니다.

4. **페이지네이션 (Pagination):**
    - **원리:** API 응답 데이터를 작은 페이지 단위로 분할하여 전송.
    - **활용:** `limit` 및 `offset` 파라미터 사용.
    - **효과:** 데이터 전송 속도 향상, 클라이언트 측 부하 감소.
    - **주요설명:** 
        - 페이지네이션은 대량 데이터 처리 시 필수적이며, 오프셋 기반 페이지네이션 대신 커서 기반 페이지네이션(예: `after`, `before` 파라미터)을 사용하면 대규모 데이터셋에서 성능이 더 안정적. 
        - 예를 들어, 트위터의 타임라인 API는 커서 기반 페이지네이션을 통해 스크롤 성능을 최적화
        - 또한, 클라이언트 측에서 불필요한 데이터 요청을 줄이기 위해 적절한 페이지 크기(예: 20~50개 항목)를 설정하는 것이 중요합니다.

5. **경량 JSON Serializer 사용:**
    - **원리:** JSON 직렬화 속도가 빠른 라이브러리 사용.
    - **효과:** JSON 변환에 소요되는 시간 최소화, 응답 시간 단축.
    - **주요설명:** 
        - Python에서는 `ujson` 또는 `orjson`, Java에서는 `Jackson` 또는 `Gson` 같은 고성능 직렬화 라이브러리를 사용하는 것이 효과적입니다. 
        - 예를 들어, 대규모 JSON 페이로드를 다루는 API에서 `orjson`으로 전환해 직렬화 시간을 30% 단축한 사례가 있습니다. 
        - 또한, 불필요한 필드를 제외하거나 JSON 스키마를 최적화해 페이로드 크기를 줄이는 것도 병행해야 합니다.

6. **압축 (Compression):**
    - **원리:** API 응답 페이로드를 압축하여 네트워크 전송량 감소.
    - **활용:** Brotli 등 효율적인 압축 알고리즘 사용, CDN 활용.
    - **효과:** 데이터 전송 속도 향상, 대역폭 사용량 감소.
    - **주요설명:** 
        - Brotli는 Gzip보다 더 높은 압축률을 제공하며, 특히 텍스트 기반 데이터(예: JSON, XML)에 효과적입니다. 
        - CDN(예: Cloudflare, Akamai)을 활용하면 압축과 함께 캐싱, 엣지 최적화를 통해 추가적인 성능 향상을 기대할 수 있습니다.
        -  예를 들어, 글로벌 API 서비스에서 Brotli 압축을 적용해 데이터 전송량을 70% 줄이고 응답 시간을 20% 단축한 사례가 있습니다. 
        - 다만, 압축/해제 과정에서 CPU 사용량이 증가할 수 있으므로 서버 성능을 모니터링해야 합니다.

7. **비동기 로깅 (Asynchronous Logging):**
    - **원리:** 로그 기록 작업을 메인 스레드와 분리하여 백그라운드에서 처리.
    - **활용:** 메모리 버퍼를 이용하여 로그 엔트리 저장, 별도 스레드에서 로그 기록.
    - **효과:** 로그 기록으로 인한 성능 저하 방지.
    - **주의:** 애플리케이션 크래시 발생 시 로그 유실 가능성 존재.
    - **주요설명:** 
        - 비동기 로깅은 Log4j2(Async Logger), Fluentd, 또는 ELK 스택과 같은 도구를 통해 구현
        - 고속 트랜잭션 처리 시스템에서 비동기 로깅을 적용해 로그 기록 지연을 90% 줄인 사례가 있다. 
        - 로그 유실 문제를 완화하려면 메모리 버퍼 크기를 적절히 설정하고, 주기적으로 디스크에 플러시(flush)하거나, 크래시 복구 메커니즘(예: 로컬 파일 백업)을 마련해야 합니다.

### **54.3 추가 고려사항**  
- 각 최적화 기법은 시스템 아키텍처와 워크로드 패턴에 따라 효과가 달라질 수 있습니다. 예를 들어, 캐싱은 읽기 중심 워크로드에 효과적이며, 쓰기 중심 워크로드에서는 캐시 일관성 유지가 어려울 수 있습니다.  
- 최적화 전후로 성능 테스트(예: JMeter, Locust)를 통해 실제 개선 효과를 정량적으로 측정하는 것이 중요.  
- 클라우드 환경에서는 비용 효율성도 고려해야 합니다. 예를 들어, 캐싱이나 압축은 컴퓨팅 리소스를 추가로 사용하므로, 비용 대비 성능 향상을 분석해야 합니다.


## 55. Monorepo vs. Microrepo: 코드 관리 전략
- 출처: [Why Google and Meta Put Billion Lines of Code In 1 Repository?](https://www.youtube.com/watch?v=x3cANGNPyx0)

-  대규모 프로젝트 코드 관리를 위한 두 가지 주요 접근 방식인 모노레포(Monorepo)와 마이크로레포(Microrepo)를 비교 분석합니다. 이 문서에서는 두 전략의 정의, 장단점, 적합한 사용 사례, 그리고 실제 적용 사례를 통해 코드 관리 방식의 선택 기준을 탐구합니다.

### **55.1 Monorepo (모노레포)**

*   **정의:** 모든 프로젝트와 서비스의 코드를 하나의 중앙 저장소에 통합하여 관리하는 방식입니다. 예를 들어, 애플리케이션, 라이브러리, 인프라 코드 등이 단일 Git 저장소에 저장됩니다.
*   **장점:**
    *   **교차 프로젝트 변경 용이:** 
        - 여러 서비스에 걸친 변경을 한 번의 커밋으로 처리 가능합니다. 예를 들어, 공통 라이브러리의 업데이트가 필요한 경우, 모든 관련 프로젝트를 단일 PR(Pull Request)로 수정할 수 있습니다.
    *   **통합된 의존성 관리:** 
        - 모든 프로젝트가 동일한 의존성 버전을 사용하므로, 버전 충돌 문제가 최소화됩니다. 예를 들어, npm이나 Maven 같은 패키지 매니저에서 단일 lock 파일로 의존성을 관리할 수 있습니다.
    *   **일관성 유지:** 
        - 코드 리뷰 규칙, 포맷팅 도구(Prettier, ESLint 등), 빌드 시스템이 모든 프로젝트에 통일됩니다. 이는 팀 간 코드 품질의 일관성을 보장합니다.
    *   **코드 재사용 용이:** 
        - 공통 모듈이나 유틸리티 함수를 쉽게 공유할 수 있습니다. 예를 들어, Google의 내부 모노레포에서는 공통 UI 컴포넌트를 여러 제품에서 재사용합니다.
*   **단점:**
    *   **높은 초기 계획 및 도구 필요:** 
        - 대규모 모노레포를 효율적으로 관리하려면 Google의 Blaze(Bazel로 진화)나 Facebook의 Buck 같은 특화된 빌드 도구가 필요합니다. 이러한 도구는 설정과 학습 비용이 큽니다.
    *   **CI/CD 파이프라인 성능 저하 가능성:** 
        - 코드베이스가 커질수록 빌드, 테스트, 배포 시간이 길어질 수 있습니다. 예를 들어, 수십만 개의 파일이 포함된 저장소에서는 CI 파이프라인 최적화가 필수적입니다.
    *   **새로운 개발자의 부담:** 
        - 방대한 코드베이스는 신규 개발자에게 진입 장벽이 될 수 있습니다. 예를 들어, Windows 소스 코드처럼 수백만 줄의 코드가 있는 경우, 특정 모듈을 찾는 데 시간이 걸릴 수 있습니다.
    *   **제한적인 커스터마이징:** 
        - 팀별로 독립적인 도구나 라이브러리를 사용하는 것이 어렵습니다. 예를 들어, 한 팀이 TypeScript를 선호하더라도 조직이 JavaScript를 표준으로 정하면 이를 따라야 합니다.
*   **적합한 경우:** 
    - 대규모 팀이 상호 연결된 프로젝트를 개발하며, 코드 일관성과 협업이 중요한 경우 적합합니다. 
    - 예를 들어, Google은 Gmail, Google Maps 등 여러 제품을 단일 모노레포에서 관리하여 효율적인 협업을 구현합니다.
*   **사용 기업:** 
    - Google(전사 제품), Facebook(Meta의 소셜 플랫폼), Uber(마이크로서비스와 공통 코드), Linux 커널(오픈소스 커뮤니티), Microsoft Windows(운영체제 개발).

### **55.2 Microrepo (마이크로레포)**

*   **정의:** 각 컴포넌트, 서비스, 또는 모듈을 독립적인 저장소로 분리하여 관리하는 방식입니다. 예를 들어, 프론트엔드, 백엔드, 데이터베이스 스키마가 각각 별도의 Git 저장소에 저장됩니다.
*   **장점:**
    *   **팀 독립성:** 
        - 각 팀이 자신의 저장소를 독립적으로 관리하며, 빌드 시스템, 배포 주기, 기술 스택을 자유롭게 선택할 수 있습니다. 예를 들어, Netflix의 한 팀은 Node.js를, 다른 팀은 Python을 사용할 수 있다.
    *   **위험 격리:** 
        - 한 저장소의 버그나 장애가 다른 저장소에 영향을 미치지 않습니다. 예를 들어, 프론트엔드 저장소의 배포 실패가 백엔드 서비스에 영향을 주지 않습니다.
    *   **유연성:** 
        - 팀이 프로젝트 요구사항에 따라 최적의 도구를 선택할 수 있습니다. 예를 들어, 한 팀은 Jenkins로 CI/CD를 구성하고, 다른 팀은 GitHub Actions를 사용할 수 있습니다.
    *   **명확한 소유권:** 
        - 각 저장소는 특정 팀이 책임지므로, 코드 변경과 유지보수의 책임이 명확합니다. 이는 특히 대규모 조직에서 책임 소재를 명확히 하는 데 유용합니다.
*   **단점:**
    *   **교차 저장소 변경 조정의 어려움:** 
        - 여러 저장소에 걸친 변경은 복잡한 협업과 동기화가 필요합니다. 예를 들어, API와 클라이언트 코드가 별도 저장소에 있는 경우, 변경 사항을 조율하기 위해 추가적인 커뮤니케이션이 필요합니다.
    *   **의존성 관리의 복잡성:** 
        - 각 저장소가 독립적으로 의존성을 관리하므로, 버전 불일치 문제가 발생할 수 있습니다. 이를 해결하려면 Nexus나 Artifactory 같은 중앙화된 아티팩트 저장소가 필요합니다.
    *   **코드 표준의 편차:** 
        - 팀마다 코딩 스타일, 테스트 전략, 문서화 방식이 달라질 수 있습니다. 이를 통일하려면 조직 차원의 가이드라인과 정기적인 코드 리뷰가 필요합니다.
    *   **코드 중복:** 
        - 공통 기능을 공유하기 어렵기 때문에, 팀마다 유사한 유틸리티 코드를 작성할 가능성이 높습니다. 이를 방지하려면 내부 라이브러리 저장소를 별도로 구축해야 합니다.
*   **적합한 경우:** 
    - 팀 자율성과 독립성을 우선시하며, 개별 프로젝트가 느슨하게 연결된 경우 적합합니다. 
    - 예를 들어, Netflix는 각 마이크로서비스를 독립적인 저장소로 관리하여 빠른 개발과 배포를 구현.
*   **사용 기업:** 
    - Amazon(AWS 서비스별 독립 저장소), Netflix(마이크로서비스 아키텍처).


## 56. Git Merge, Rebase, Squash 정리
- 출처: [Git MERGE vs REBASE: Everything You Need to Know](https://www.youtube.com/watch?v=0chZFIZLR_0)


### **56.1 상황**

*   `main` 브랜치에서 새 `feature` 브랜치 생성 (`git checkout -b feature`).
*   `feature` 브랜치에 A, B, C 커밋 추가 (예: 새로운 기능 구현, 버그 수정 등).
*   `main` 브랜치에 D, E 커밋 추가 (예: 다른 팀원의 작업 반영).
*   이 상황에서 `feature` 브랜치를 `main` 브랜치에 통합하려고 할 때 사용할 수 있는 방법들을 비교.

### **56.2 `git merge`**

*   **기능:** `main` 브랜치의 최신 변경 사항을 `feature` 브랜치로 가져오거나, 반대로 `feature` 브랜치를 `main` 브랜치에 통합.
*   **방식:** `feature` 브랜치와 `main` 브랜치의 변경 사항을 결합하여 새로운 "merge commit"을 생성. 이 커밋은 두 브랜치의 히스토리를 연결하는 매듭 역할을 함.
*   **장점:** 
    *   모든 커밋 히스토리가 그대로 보존되어 브랜치의 작업 흐름과 컨텍스트를 명확히 파악 가능.
    *   팀 협업에서 안전하게 사용 가능 (히스토리 변경 없음).
*   **단점:** 
    *   빈번한 병합으로 merge commit이 쌓이면 히스토리가 복잡해지고 가독성이 떨어질 수 있음.
    *   커밋 그래프가 비선형으로 나타나 프로젝트의 전체 흐름을 파악하기 어려울 수 있음.
*   **활용:** 
    *   팀에서 모든 작업의 상세 히스토리를 유지하고 싶을 때.
    *   예: 오픈소스 프로젝트에서 다양한 기여자의 작업을 명확히 기록.
    *   명령어 예시: `git checkout feature; git merge main` (또는 `git checkout main; git merge feature`).

### **56.3 `git rebase`**

*   **기능:** `feature` 브랜치의 베이스를 `main` 브랜치의 최신 커밋으로 변경한 뒤, `feature` 브랜치의 커밋을 그 위에 재배치(replay).
*   **방식:** `feature` 브랜치의 커밋(A, B, C)을 `main` 브랜치의 최신 커밋(D, E) 뒤로 이동시켜 히스토리를 선형으로 만듦. 이후 `main` 브랜치로 fast-forward merge 수행.
*   **장점:** 
    *   히스토리가 깔끔하고 선형으로 유지되어 프로젝트의 변경 사항을 한눈에 파악 가능.
    *   불필요한 merge commit이 없어 로그가 간결.
*   **단점:** 
    *   히스토리를 재작성하므로 이미 공유된 브랜치에서 사용 시 팀원 간 충돌 가능성.
    *   충돌 해결이 merge보다 복잡할 수 있음 (각 커밋별로 충돌 해결 필요).
*   **활용:** 
    *   개인 작업 브랜치에서 히스토리를 정리한 뒤 `main` 브랜치에 병합하고 싶을 때.
    *   예: 풀 리퀘스트(PR)를 깔끔하게 유지하려는 개발자.
    *   명령어 예시: `git checkout feature; git rebase main; git checkout main; git merge feature` (fast-forward).

### **56.4 Squash Commits**

*   **기능:** `feature` 브랜치의 모든 커밋(A, B, C)을 하나의 커밋으로 압축하여 `main` 브랜치에 병합.
*   **방식:** `main` 브랜치에는 단일 커밋만 추가되며, `feature` 브랜치의 상세 커밋 기록은 별도로 유지 가능 (예: PR 내역에서 확인).
*   **장점:** 
    *   `main` 브랜치의 히스토리가 매우 간결하고 선형으로 유지.
    *   GitHub, GitLab 등의 풀 리퀘스트 워크플로우에서 선호됨 (PR 단위로 작업을 묶음).
    *   상세 커밋 기록은 `feature` 브랜치나 PR에서 확인 가능.
*   **단점:** 
    *   `main` 브랜치에서는 개별 커밋의 세부 변경 사항을 확인할 수 없음.
    *   squash 후 히스토리 추적이 어려울 수 있음 (예: 특정 커밋의 버그 추적).
*   **활용:** 
    *   메인 브랜치의 히스토리를 최소화하면서도 팀 내부에서 상세 작업 기록을 유지하고 싶을 때.
    *   예: 작은 기능 추가나 버그 수정 PR에서 작업 단위를 하나로 묶음.
    *   명령어 예시: `git checkout main; git merge --squash feature; git commit` 또는 GitHub PR의 "Squash and Merge" 버튼 사용.

### **56.5 선택 기준**

*   **커밋 히스토리 중요도:** 
    *   전체 히스토리 유지: `git merge`로 모든 작업의 맥락 보존.
    *   깔끔한 히스토리: `git rebase` 또는 squash로 간결한 로그 유지.
*   **팀 워크플로우:** 
    *   공유 브랜치 사용 시 `git merge`가 안전.
    *   개인 작업 브랜치나 PR 기반 워크플로우에서는 `rebase` 또는 squash 선호.
    *   팀의 히스토리 변경 정책(예: force push 허용 여부)에 따라 결정.
*   **프로젝트 규모:** 
    *   대규모 프로젝트에서는 히스토리 추적이 중요하므로 merge 선호.
    *   소규모 프로젝트나 빠른 개발 주기에서는 squash로 간결함 추구.

### **56.6 핵심**

*   **`git merge`:** 전체적인 히스토리와 작업 맥락을 보존하며 팀 협업에 적합.
*   **`git rebase`:** 선형 히스토리로 깔끔한 로그를 유지, 개인 작업 정리 시 유용.
*   **Squash Commits:** `main` 브랜치의 간결함과 `feature` 브랜치의 상세 기록을 절충, PR 기반 워크플로우에 최적.

## 57. 로드 밸런싱 알고리즘
- 출처: [Top 6 Load Balancing Algorithms Every Developer Should Know](https://www.youtube.com/watch?v=dBmxNsS3BGE)

### **57.1 개요**

- **로드 밸런싱**은 대규모 웹 애플리케이션의 **가용성**, **응답성**, 그리고 **확장성**을 보장하는 핵심 기술로, 트래픽을 효율적으로 관리하여 사용자 경험을 개선한다.
- 서버 간 워크로드를 분산함으로써 특정 서버의 **과부하**를 방지하고, 시스템 전체의 안정성을 높인다.
- 로드 밸런싱 알고리즘을 이해하는 것은 애플리케이션 설계, 문제 해결, 그리고 **성능 최적화** 과정에서 필수적이며, 시스템 아키텍처의 효율성을 결정짓는 중요한 요소이다.

### **57.2 알고리즘 분류**

1. **정적(Static) 알고리즘:** 서버의 실시간 상태나 성능 지표를 고려하지 않고, 사전에 정의된 규칙에 따라 요청을 분배한다.
    - **장점:** 구현이 간단하고, 예측 가능한 방식으로 동작하여 소규모 시스템에서 유용하다.
    - **단점:** 서버의 실제 부하나 상태 변화에 적응하지 못해, 효율성이 떨어질 수 있다.
    - **종류:**
        - **라운드 로빈(Round Robin):** 
            - 요청을 순차적으로 서버 A, B, C...로 균등하게 분배한다.
            - **장점:** 설정이 간단하고 이해하기 쉬워 초보자도 쉽게 구현 가능.
            - **단점:** 서버 성능 차이(예: 하드웨어 사양, 네트워크 상태)를 고려하지 않아, 특정 서버가 과부하 상태에 빠질 가능성이 있다.
            - **추가설명:** 이 방식은 모든 서버의 처리 능력이 동일하고 트래픽 패턴이 균일할 때 적합하다. 하지만 실제 환경에서는 서버 간 성능 차이가 존재하므로 주의가 필요하다.
        - **스티키 라운드 로빈(Sticky Round Robin):** 
            - 동일 사용자의 후속 요청을 동일한 서버로 보내도록 설계된다.
            - **목표:** 세션 데이터를 동일 서버에 유지하여 캐싱 효과를 극대화하고, 데이터 일관성을 보장해 성능을 향상시킨다.
            - **단점:** 새로운 사용자의 요청이 무작위로 할당되므로, 특정 서버에 부하가 집중될 가능성
            - **추가설명:** 이 방법은 세션 기반 애플리케이션(예: 로그인 세션)에서 유용하지만, 서버 간 부하 균형을 맞추는 데 한계가 있을 수 있다.
        - **가중 라운드 로빈(Weighted Round Robin):** 
            - 관리자가 서버마다 가중치를 부여하여, 더 높은 가중치를 가진 서버가 더 많은 요청을 처리하도록 설정한다.
            - **장점:** 서버의 처리 능력(예: CPU, 메모리)에 따라 요청을 분배하므로, 이기종(heterogeneous) 서버 환경에 적합하다.
            - **단점:** 가중치를 수동으로 설정해야 하며, 부정확한 가중치 설정은 비효율적 부하 분배 초래
            - **추가설명:** 이 방식은 서버 성능이 명확히 구분되는 환경에서 효과적이며, 주기적으로 가중치를 조정하여 최적화할 수 있다.
        - **해시 기반(Hash-based):** 
            - 클라이언트 IP, URL, 또는 기타 고유 식별자를 입력값으로 해시 함수를 적용해 요청을 특정 서버에 매핑한다.
            - **장점:** 적절한 해시 함수를 사용할 경우 요청이 균등하게 분배되며, 특정 클라이언트의 요청을 일관되게 동일 서버로 보낼 수 있다.
            - **단점:** 해시 함수의 품질에 따라 분배 균일도가 달라지며, 서버 추가/제거 시 재매핑이 필요해 복잡도가 증가한다.
            - **추가설명:** 이 방식은 캐싱 효율성을 높이는 데 유리하지만, 해시 충돌이나 서버 구성 변경 시 주의가 필요하다.

2. **동적(Dynamic) 알고리즘:** 서버의 실시간 상태(예: CPU 사용률, 메모리, 연결 수)와 성능 지표를 모니터링하여 요청을 분배한다.
    - **장점:** 변화하는 트래픽 패턴과 서버 상태에 실시간으로 적응하여 효율적인 부하 분배를 제공한다.
    - **단점:** 모니터링 및 계산 과정에서 시스템 자원을 소모하며, 구현이 복잡하다.
    - **종류:**
        - **최소 연결(Least Connections):** 
            - 현재 활성 연결 수가 가장 적은 서버에 새로운 요청을 전송
            - **장점:** 서버의 남은 용량을 고려하여 부하를 동적으로 분배하므로, 과부하를 방지하는 데 효과
            - **단점:** 연결 시간이 길거나, 특정 요청이 무거운 작업을 유발할 경우, 부하가 불균등하게 누적
            - **추가설명:** 이 방식은 트래픽이 불규칙하거나 서버 간 처리 시간이 크게 다른 환경에서 유리하다. 하지만 연결 수만 고려하므로, 실제 작업 부하를 정확히 반영하지 못할 수 있다.
        - **최소 응답 시간(Least Response Time):** 
            - 서버의 현재 응답 속도(지연 시간)를 기준으로 가장 빠른 서버에 요청을 전송한다.
            - **장점:** 사용자 경험(낮은 대기 시간)을 최우선으로 하며, 서버 성능에 따라 적응적으로 동작
            - **단점:** 지속적인 응답 시간 모니터링이 필요해 시스템 오버헤드가 증가하며, 기존 연결 수나 작업 부하는 고려하지 않는다.
            - **추가설명:** 이 방식은 응답 시간이 중요한 애플리케이션(예: 실시간 스트리밍, 온라인 게임)에 적합하지만, 모니터링 시스템의 정확도가 결과에 큰 영향을 미친다.

### **57.3 알고리즘 선택 시 고려 사항**

- **성능 목표**: 
    - 응답 시간 최소화, 처리량 최대화, 또는 가용성 보장이 목표인지 명확히 정의해야 한다.
- **시스템 역량**: 
    - 서버 하드웨어, 네트워크 대역폭, 모니터링 시스템의 성능 등 인프라 역량을 고려한다.
- **제약 조건**: 
    - 예산, 관리 인력, 구현 복잡도 등의 제약을 평가한다.
- **정적 알고리즘**: 
    - 설정이 간단하고, **stateless** 애플리케이션(예: 정적 웹사이트)에서 효과적이다.
- **동적 알고리즘**: 
    - 트래픽 변동이 크거나, 복잡한 워크로드를 처리하는 대규모 애플리케이션(예: 클라우드 기반 서비스)에서 응답 시간과 가용성을 최적화하는 데 적합하다.
- **추가설명:** 
    - 알고리즘 선택은 애플리케이션의 특성과 운영 환경에 따라 달라진다. 예를 들어, 소규모 웹사이트는 라운드 로빈으로 충분할 수 있지만, 대규모 전자상거래 플랫폼은 최소 연결이나 최소 응답 시간 알고리즘을 통해 더 나은 성능을 얻을 수 있다. 또한, 하이브리드 접근(정적+동적)도 상황에 따라 효과적


## 58. 소프트웨어 엔지니어를 위한 필수 알고리즘
- 출처: [Algorithms You Should Know Before System Design Interviews](https://www.youtube.com/watch?v=xbgzl2maQUU)

### **58.1 핵심**

* 시스템 설계 인터뷰뿐 아니라 실제 시스템 구축에도 유용한 알고리즘 소개
    - 이 요약은 소프트웨어 엔지니어가 분산 시스템, 데이터베이스, 검색 엔진 등 다양한 실무 환경에서 자주 활용되는 핵심 알고리즘을 이해하고 적용할 수 있도록 돕습니다.
* 구현 세부 사항보다는 알고리즘의 중요성과 활용 분야에 초점: 
    - 코드 레벨의 세부 구현보다는 각 알고리즘이 해결하는 문제와 그 적용 가능성을 강조하여, 엔지니어가 문제 해결에 필요한 개념적 이해를 우선시하도록 유도합니다.
* 코드 암기보다 높은 수준의 개념 이해 강조: 
    - 단순히 코드를 외우는 대신, 알고리즘의 작동 원리와 설계 철학을 깊이 이해함으로써 다양한 상황에 유연하게 대응할 수 있는 역량을 키우는 데 중점을 둡니다.

### **58.2 알고리즘 목록**

1. **Consistent Hashing (일관성 해싱)**

    * **목표:** 
        - 데이터를 여러 서버에 효율적으로 분산
    * **원리:** 
        - 데이터의 키를 해시 함수로 해싱하여 링(원형 구조)에 매핑하고, 각 서버에 링의 특정 범위를 할당합니다. 이를 통해 데이터가 서버 간에 고르게 분배됩니다.
    * **장점:** 
        - 서버가 추가되거나 제거될 때, 전체 키의 재매핑이 아닌 변경된 범위에 해당하는 키만 재매핑되므로 데이터 이동 비용이 최소화됩니다. 이는 시스템의 확장성과 안정성을 크게 향상시킵니다.
    * **활용:** 
        - 분산 캐싱 시스템(예: Memcached), NoSQL 데이터베이스(예: Apache Cassandra, DynamoDB)에서 데이터 파티셔닝 및 로드 밸런싱에 사용됩니다.
    * **고려 사항:** 
        - 기본 일관성 해싱은 데이터가 특정 서버에 치우치는 불균등 분산 문제를 야기할 수 있습니다. 이를 해결하기 위해 가상 노드(Virtual Nodes)를 도입하여 각 서버에 여러 지점을 할당함으로써 데이터 분포를 보다 균일하게 만듭니다.
    * **추가설명:** 
        - 일관성 해싱은 특히 클라우드 환경에서 서버의 동적 추가/제거가 빈번한 상황에서 유용합니다. 예를 들어, Amazon DynamoDB는 이 기법을 활용해 대규모 트래픽을 처리하며, 가상 노드를 통해 데이터 불균형 문제를 완화합니다.

2. **Quadtrees (쿼드 트리)**

    * **목표:** 
        - 공간 인덱싱을 통한 빠른 위치 기반 검색
    * **원리:** 
        - 2D 공간을 재귀적으로 네 개의 사분면으로 분할하여 계층적 트리 구조를 형성합니다. 각 노드는 특정 공간 영역을 나타내며, 객체가 해당 영역에 속하면 해당 노드에 저장됩니다.
    * **장점:** 
        - 특정 좌표나 반경 내의 객체를 빠르게 검색할 수 있어, 대규모 공간 데이터 처리에 효율적입니다. 검색 복잡도는 일반적으로 O(log N) 수준입니다.
    * **활용:** 
        - 지도 애플리케이션(예: Google Maps, Uber)에서 근처 장소 검색, 게임 엔진에서 충돌 감지, GIS(지리정보시스템)에서 공간 데이터 관리에 사용됩니다.
    * **참고:** 
        - R-tree는 동적 데이터 삽입에 더 적합하며, KD-tree는 고차원 데이터에 유리합니다. 쿼드 트리는 2D 공간에 특화된 간단한 구조로 이해하기 쉽습니다.
    * **추가설명:** 
        - 쿼드 트리는 특히 실시간 애플리케이션에서 유용합니다. 예를 들어, Uber는 쿼드 트리를 활용해 운전자와 승객의 위치를 빠르게 매핑하여 근처 차량을 효율적으로 찾습니다. 또한, 트리 깊이를 조절하여 검색 성능과 메모리 사용량 간 균형을 맞출 수 있습니다.

3. **Leaky Bucket Algorithm (누수 버킷 알고리즘)**

    * **목표:** 
        - 요청 속도 제한(Rate Limiting)을 통해 시스템 과부하를 방지
    * **원리:** 
        - 요청을 버킷에 담고, 일정한 속도로 요청을 처리(누수)합니다. 버킷이 가득 차면 새로운 요청은 거부되거나 대기열에 추가됩니다.
    * **장점:** 
        - 구현이 간단하며, 버킷 크기(용량)와 누수 속도(처리율)라는 두 개의 파라미터만으로 설정이 가능합니다. 예측 가능한 트래픽 제어를 제공합니다.
    * **활용:** 
        - API 엔드포인트의 속도 제한(예: Twitter API, Stripe API), 네트워크 트래픽 관리, DDoS 공격 방어에 사용됩니다.
    * **참고:** 
        - 토큰 버킷 알고리즘은 버킷에 토큰을 채우고 요청이 토큰을 소비하는 방식으로, 누수 버킷과 반대 접근법을 취합니다. 슬라이딩 윈도우 카운터는 시간 창 내 요청 수를 세밀하게 관리합니다.
    * **추가설명:** 
        - 누수 버킷은 특히 트래픽이 일정하게 유지되어야 하는 시스템에 적합합니다. 예를 들어, 클라우드 서비스 제공업체는 API 호출 제한을 위해 이 알고리즘을 사용하며, 버킷 크기를 조정하여 사용자별 트래픽 패턴에 맞춘 유연한 제어가 가능합니다.

4. **Tries (트라이)**

    * **목표:** 
        - 문자열 및 접두사 저장에 최적화된 트리 구조
    * **원리:** 
        - 각 노드가 문자열의 문자나 접두사를 나타내며, 공통 접두사를 공유하는 문자열은 동일한 서브트리를 사용합니다. 루트에서 리프까지의 경로는 하나의 문자열을 형성합니다.
    * **장점:** 
        - 접두사 기반 검색이 O(m) 시간 복잡도(m은 문자열 길이)로 매우 빠르며, 중복 접두사를 공유하여 메모리 효율성을 높일 수 있습니다.
    * **활용:** 
        - 검색 엔진의 자동 완성 기능, 텍스트 편집기의 단어 추천, IP 라우팅 테이블, 사전 구현에 사용됩니다.
    * **고려 사항:** 
        - 기본 트라이 구조는 메모리 사용량이 클 수 있습니다. 이를 개선하기 위해 Radix Tries(공통 접두사를 압축)나 Suffix Tries(문자열의 모든 접미사를 저장)를 사용할 수 있습니다.
    * **추가설명:** 
        - 트라이는 특히 검색 엔진에서 사용자 쿼리의 실시간 자동 완성에 필수적입니다. 예를 들어, Google 검색은 트라이 기반 구조를 활용해 사용자가 입력하는 동안 관련 검색어를 빠르게 제안합니다. Radix Tries는 메모리 효율성을 높여 대규모 데이터셋에 적합합니다.

5. **Bloom Filters (블룸 필터)**

    * **목표:** 
        - 집합 멤버십 검사(특정 요소가 집합에 속하는지 확인)를 위한 확률적 자료 구조
    * **원리:** 
        - 여러 해시 함수를 사용해 요소를 비트 배열에 매핑하고, 해당 비트를 1로 설정합니다. 검사 시 모든 관련 비트가 1인지 확인하여 멤버십을 판단합니다.
    * **특징:**
        * False Positive(없는 요소를 있다고 판단)는 가능하지만, False Negative(있는 요소를 없다고 판단)는 절대 발생하지 않습니다.
        * 한 번 추가된 요소는 제거할 수 없으며, 삭제를 지원하려면 Counting Bloom Filter와 같은 변형이 필요합니다.
    * **활용:** 
        - 캐싱 시스템에서 중복 요청 방지(예: Redis), 데이터베이스 쿼리 최적화, 네트워크 라우터의 패킷 필터링, 웹 크롤러의 URL 중복 제거에 사용됩니다.
    * **추가설명:** 
        - 블룸 필터는 메모리 효율성이 뛰어나 대규모 데이터셋에서 유용합니다. 예를 들어, Google Chrome은 블룸 필터를 사용해 악성 URL 데이터베이스를 빠르게 확인하며, False Positive 비율을 조정하여 정확도와 메모리 사용량 간 균형을 맞춥니다.

6. **Consensus Algorithms (합의 알고리즘)**

    * **목표:** 
        - 분산 시스템에서 모든 노드가 공유 상태(예: 데이터 복제본)에 대해 일관되게 합의하도록 보장
    * **문제:** 
        - 네트워크 지연, 노드 장애, 비잔틴 오류(악의적 노드) 등으로 인해 합의 도달이 복잡합니다.
    * **예시:** 
        - Paxos는 이론적으로 견고하지만 구현이 복잡합니다. Raft는 Paxos를 단순화한 대안으로, 이해와 구현이 더 쉽습니다.
    * **Raft:**
        * **장점:** 명확한 리더 기반 설계와 단계별 프로세스로 단순성과 효율성을 제공합니다.
        * **원리:** 클러스터에서 리더를 선출하고, 리더가 로그 복제와 상태 관리를 책임집니다. 장애 발생 시 새로운 리더를 선출하여 복구합니다.
        * **활용:** 분산 키-값 저장소(예: etcd), 메시지 브로커(예: Apache Kafka), 분산 데이터베이스에서 복제, 장애 조치, 리더 선출에 사용됩니다.
    * **추가설명:** 
        - Raft는 특히 컨테이너 오케스트레이션 시스템(예: Kubernetes)에서 etcd의 상태 관리에 활용됩니다. Raft의 로그 복제 메커니즘은 노드 간 데이터 일관성을 보장하며, 리더 선출 과정은 시스템의 고가용성을 유지하는 데 핵심적입니다.


## 59. 소프트웨어 아키텍처 패턴
- 출처: [Top 5 Most Used Architecture Patterns](https://www.youtube.com/watch?v=f6zXyq4VPP8)

### **59.1 계층형 아키텍처 (Layered Architecture): 역할 분담과 책임 명확화**

* **개념:** 
    - 마치 케이크처럼 시스템의 구성 요소를 명확하게 분리된 수평적 계층으로 구성하는 패턴입니다. 
    - 일반적으로 표현(presentation), 비즈니스 로직(business logic), 데이터 접근(data access) 계층으로 나뉘며, 각 계층은 특정 책임과 역할을 수행합니다.
* **예시:** 사용자 인터페이스 디자인에서 자주 활용되는 Model-View-Presenter (MVP) 패턴은 계층형 아키텍처의 한 종류입니다.
    * **Model:** 
        - 애플리케이션의 데이터와 비즈니스 규칙을 관리합니다. 데이터베이스와의 상호작용, 데이터 유효성 검사 등을 담당합니다.
    * **View:** 
        - 사용자에게 데이터를 표시하고 사용자로부터 입력을 받는 역할을 합니다. 일반적으로 UI 화면을 구성합니다.
    * **Presenter:** 
        - Model과 View 사이의 중개자 역할을 수행합니다. View로부터 사용자 액션을 전달받아 Model을 업데이트하고, Model의 변경 사항을 View에 반영합니다.
* **목표:** 각 계층 간의 명확한 분리를 통해 시스템의 복잡성을 줄이고, 변경 사항이 다른 계층에 미치는 영향을 최소화하여 유지보수성과 확장성을 높이는 데 있습니다. 또한, 각 계층을 독립적으로 개발하고 테스트하는 것이 용이해집니다.
* **장점:** 한 계층의 내부 구현이 변경되더라도 인터페이스가 유지되면 다른 계층에 거의 영향을 미치지 않아 시스템의 안정성을 높입니다. 각 계층은 독립적으로 개발 및 테스트가 가능하여 개발 효율성을 향상시킵니다.

### **59.2 이벤트 기반 아키텍처 (Event-Driven Architecture): 비동기적 상호작용과 높은 유연성**

* **개념:** 
    - 시스템 내의 느슨하게 결합된 구성 요소 또는 서비스들이 서로 이벤트를 생성하고 소비하는 방식으로 통신하는 아키텍처입니다. 
    - 각 구성 요소는 특정 이벤트가 발생했을 때만 반응하므로, 서로에 대한 의존성이 낮아집니다.
* **동작 방식:** 어떤 구성 요소가 특정 상태 변화나 액션이 발생하면 이벤트(message)를 발행(publish)하고, 다른 관심 있는 구성 요소들은 해당 이벤트를 구독(subscribe)하여 처리합니다.
* **예시:** Command Query Responsibility Segregation (CQRS) 패턴은 이벤트 기반 아키텍처의 중요한 개념을 활용합니다.
    * **데이터 쓰기(Commands)와 읽기(Queries) 분리:** 
        - 데이터의 변경(쓰기) 작업을 처리하는 모델과 데이터를 조회(읽기)하는 모델을 분리하여 각 목적에 최적화된 구조를 가질 수 있도록 합니다.
    * **이벤트로 변경 사항 전달:** 
        - 데이터 쓰기 모델에서 발생한 변경 사항은 이벤트 형태로 발행되어 읽기 모델에 전달되고, 읽기 모델은 이 이벤트를 기반으로 자신의 상태를 업데이트합니다.
* **특징:** 구성 요소들이 서로를 직접 호출하는 대신, 중앙 집중식 이벤트 버스 또는 메시지 큐를 통해 비동기적으로 통신합니다. 이는 시스템의 반응성을 높이고, 특정 서비스의 장애가 전체 시스템에 미치는 영향 감소.
* **장점:** 서비스 간의 결합도가 매우 낮아 각 서비스를 독립적으로 개발, 배포, 확장할 수 있습니다. 시스템의 유연성과 확장성이 뛰어나며, 대규모 트래픽 처리에도 유리합니다.

### **59.3 마이크로커널 아키텍처 (Microkernel Architecture): 핵심 기능과 확장성의 분리**

* **개념:** 
    - 시스템의 핵심 기능만을 작은 마이크로커널에 포함시키고, 부가적인 기능들은 플러그인(plug-in) 형태로 외부 컴포넌트로 분리하는 아키텍처입니다. 
    - 마이크로커널은 플러그인 간의 통신 및 기본적인 시스템 운영을 담당합니다.
* **예시:**
    * **운영체제:** 전통적인 운영체제와 달리, 마이크로커널 기반 운영체제는 프로세스 간 통신, 메모리 관리 등 최소한의 핵심 기능만을 커널에 포함하고, 장치 드라이버, 파일 시스템 등은 사용자 공간의 플러그인 형태로 제공합니다.
    * **Eclipse IDE:** 이 강력한 개발 환경은 코어 런타임이 플러그인 아키텍처를 관리하고, Java 개발 도구, Git 통합, 다양한 언어 지원 등은 개별 플러그인으로 제공되어 사용자가 필요한 기능만 선택하여 사용할 수 있습니다.
* **장점:** 새로운 기능을 플러그인 형태로 쉽게 추가할 수 있어 시스템의 확장성이 뛰어납니다. 각 플러그인은 독립적으로 개발 및 배포될 수 있어 유지보수성이 향상되고, 특정 플러그인의 오류가 전체 시스템에 미치는 영향을 최소화하여 코어 시스템의 안정성을 유지할 수 있습니다.

### **59.4 마이크로서비스 아키텍처 (Microservices Architecture): 독립적인 서비스들의 협업**

* **개념:** 
    - 하나의 거대한 애플리케이션을 작고 독립적으로 배포 가능한 서비스들의 집합으로 분해하는 아키텍처입니다. 
    - 각 마이크로서비스는 특정 비즈니스 기능을 수행하며, 자체적인 데이터 모델을 가지고 독립적인 프로세스로 실행됩니다. 
    - 서비스 간의 통신은 주로 경량화된 API(예: REST, gRPC)를 통해 이루어집니다.
* **특징:** 각 서비스는 서로 다른 기술 스택을 사용할 수 있으며, 독립적으로 개발, 배포, 확장될 수 있습니다. 이는 개발 속도를 높이고, 특정 기술에 대한 종속성을 줄이며, 장애 발생 시 전체 시스템으로의 확산을 방지하는 데 도움이 됩니다.
* **예시:** 대표적인 예시로 Netflix를 들 수 있습니다. 영화 추천, 사용자 인증, 결제 처리, 콘텐츠 스트리밍 등 다양한 기능들이 각각 독립적인 마이크로서비스로 구현되어 유기적으로 협력합니다.
* **장점:** 작은 단위로 모듈화되어 있어 개발 및 유지보수가 용이하고, 각 서비스를 독립적으로 확장할 수 있어 자원 효율성을 높일 수 있습니다. 또한, 새로운 기술 도입이 용이하고, 팀 조직 구조와 비즈니스 요구사항 변화에 유연하게 대응할 수 있습니다.
* **단점:** 서비스 간 통신을 관리하고, 분산된 환경에서의 데이터 일관성을 유지하는 것이 복잡해질 수 있습니다. 또한, 전체 시스템을 모니터링하고 디버깅하는 것이 모놀리식 아키텍처에 비해 더 어려울 수 있습니다.

### **59.5 모놀리식 아키텍처 (Monolithic Architecture): 하나의 거대한 통합체**

* **개념:** 
    - 애플리케이션의 모든 구성 요소(데이터 접근, 비즈니스 로직, 사용자 인터페이스)가 하나의 거대한 코드베이스로 통합되어 단일 실행 유닛으로 배포되는 전통적인 아키텍처입니다.
* **장점:** 개발 초기 단계에는 구조가 단순하여 개발 및 배포가 비교적 용이합니다. 작은 규모의 프로젝트에서는 빠르게 개발을 완료하고 배포할 수 있다는 장점이 있습니다.
* **변형:** 최근에는 모놀리식 아키텍처의 단점을 보완하기 위해 모듈형 모놀리스(modular monolith)라는 접근 방식이 주목받고 있습니다.
    * **모듈형 모놀리스:** 
        - 애플리케이션을 여전히 단일 배포 단위로 유지하면서도, 코드베이스 내부에 명확한 모듈 경계를 설정하여 각 모듈 간의 의존성을 줄이고 응집도를 높입니다. 
        - 이는 모놀리식 아키텍처의 장점을 유지하면서 유지보수성과 확장성을 어느 정도 개선 가능.
* **특징:** 많은 초기 단계의 플랫폼이나 비교적 단순한 애플리케이션들이 모놀리식 구조로 시작하는 경우가 많습니다. 그러나 애플리케이션의 규모가 커지고 복잡해짐에 따라 유지보수, 확장, 배포의 어려움에 직면하여 마이크로서비스와 같은 분산 아키텍처로 전환하는 사례가 늘고 있습니다.

## 60. Apache Kafka
- 출처: [System Design: Apache Kafka In 3 Minutes](https://www.youtube.com/watch?v=HZklgPkboro)

### **60.1 개요**

* **분산 스트리밍 플랫폼의 선두 주자:** 
    - Apache Kafka는 단순히 메시지를 전달하는 것을 넘어, **대규모의 실시간 데이터 파이프라인을 구축하고, 스트리밍 기반의 혁신적인 애플리케이션을 개발**하는 데 특화된 강력한 분산 스트리밍 플랫폼.
* **탄생 배경과 철학:** 
    - 초기 LinkedIn의 엔지니어들은 **폭발적으로 증가하는 사용자 활동 데이터를 낮은 지연 시간으로 안정적으로 수집하고 처리**하는 데 어려움을 겪었습니다. Kafka는 이러한 근본적인 문제를 해결하기 위해 탄생했으며, **높은 처리량, 확장성, 그리고 안정성**을 핵심 가치로 삼고 있습니다.
* **오픈소스 커뮤니티의 힘:** 
    - 2011년 Apache Software Foundation을 통해 오픈 소스 프로젝트로 전환된 이후, 전 세계 개발자들의 활발한 참여와 기여를 통해 **지속적으로 발전하고 성숙**해 왔습니다. 이는 Kafka 생태계의 확장과 안정적인 유지보수에 큰 동력이 되고 있습니다.
* **핵심 역량 요약:**
    * **압도적인 대용량 데이터 처리 능력:** 
        - Kafka는 **TB, PB 단위의 막대한 데이터를 실시간으로 안정적으로 처리**
    * **광범위한 호환성과 유연성:** 
        - 다양한 프로그래밍 언어와 시스템을 지원하여 **거의 모든 종류의 애플리케이션과 유연하게 통합**
    * **탁월한 결함 허용 (Fault Tolerance):** 
        - 여러 대의 Broker 서버에 데이터를 분산 저장하고 복제하는 메커니즘을 통해 **특정 서버에 장애가 발생해도 데이터 손실 없이 안정적인 서비스**를 제공

### **60.2 구조**

* **Topic과 Partition:** 
    - Event Stream은 **Topic**이라는 논리적인 채널로 구성되며, 
    - 각 Topic은 처리량과 병렬성을 높이기 위해 여러 개의 **Partition**으로 나뉩니다. 
    - 각 Partition은 Broker 서버에 분산되어 저장되고 순서대로 관리됩니다.
* **Broker:** 
    - Kafka 클러스터를 구성하는 서버들을 **Broker**라고 부릅니다. 
    - 각 Broker는 하나 이상의 Partition을 담당하며, 데이터의 저장, 복제, 그리고 Consumer의 요청 처리를 담당합니다.
* **Producer:** 
    - **Producer**는 Kafka Topic에 데이터를 발행(publish)하는 애플리케이션입니다. 
    - Producer는 어떤 Topic의 어떤 Partition으로 데이터를 보낼지 결정할 수 있습니다.
* **Consumer:** 
    - Kafka Topic으로부터 데이터를 구독(subscribe)하고 소비(consume)하는 애플리케이션입니다. 
    - Consumer Group이라는 개념을 통해 여러 Consumer가 하나의 Topic을 병렬로 처리하여 처리량을 높일 수 있습니다.

### **60.3 주요 사용 사례**

1.  **메시지 큐 (Message Queue):**
    * **비동기 통신의 핵심:** 
        - Kafka는 전통적인 메시지 큐 시스템처럼 **데이터 생산자와 소비자를 느슨히 결합**, 각 애플리케이션이 독립적으로 운영될 수 있도록 지원합니다. 이는 시스템의 안정성과 확장성을 크게 향상시킵니다.
2.  **활동 추적 (Activity Tracking):**
    * **실시간 사용자 행동 분석:** 
        - 웹사이트나 모바일 앱에서 발생하는 **클릭, 페이지 조회, 구매, 검색 등의 모든 사용자 활동 이벤트를 실시간으로 수집하고 저장**, 사용자 행동 분석, 개인화 추천, 이상 감지 등에 활용됩니다. (실제로 Uber는 사용자 이동 경로 추적, Netflix는 콘텐츠 시청 기록 분석에 Kafka를 활용합니다.)
3.  **데이터 통합 (Data Integration):**
    * **다양한 데이터 소스의 허브:** 
        - IoT 장치, 센서, 데이터베이스, 로그 시스템 등 **다양한 소스에서 발생하는 데이터를 중앙 집중식으로 통합**, 실시간 분석 및 데이터 웨어하우스 구축을 위한 파이프라인을 용이하게 만듭니다.
4.  **마이크로서비스 아키텍처 (Microservices Architecture):**
    * **서비스 간 실시간 통신:** 
        - 여러 개의 작은 서비스로 구성된 마이크로서비스 환경에서 **각 서비스 간의 실시간 데이터 교환을 위한 안정적이고 확장 가능한 메시지 버스** 역할을 수행합니다. 이를 통해 서비스 간의 의존성을 줄이고 유연성을 높일 수 있습니다.
5.  **모니터링 및 관찰 가능성 (Monitoring and Observability):**
    * **시스템 Health Check 및 성능 분석:** 
        - ELK 스택(Elasticsearch, Logstash, Kibana)과 같은 도구와 통합하여 **애플리케이션의 메트릭, 로그, 네트워크 데이터 등을 실시간으로 수집하고 분석**하여 시스템의 상태를 모니터링하고 잠재적인 문제를 사전에 감지할 수 있도록 지원합니다.
6.  **스트림 처리 (Stream Processing):**
    * **실시간 데이터 분석 및 액션:** 
        - Kafka Streams, Flink, Spark Streaming과 같은 스트림 처리 엔진과 연동하여 **대규모의 실시간 데이터 스트림에 대한 필터링, 변환, 집계, 조인 등의 복잡한 연산을 수행**하고, 이를 기반으로 실시간 제품 추천, 사기 탐지, 금융 거래 분석 등 다양한 실시간 액션을 수행할 수 있습니다.

### **60.4 제한 사항**

* **복잡한 구조와 높은 학습 곡선:** 
    - Kafka의 분산 시스템 구조는 매우 강력하지만, 동시에 **설치, 구성, 확장, 그리고 유지 관리에 상당한 전문 지식과 노력이 필요**합니다. 처음 접하는 개발자에게는 학습 곡선이 높을 수 있습니다.
* **상당한 리소스 요구 사항:** 
    - Kafka는 대규모 데이터를 처리하도록 설계되었기 때문에, **운영을 위해서는 충분한 성능의 하드웨어 자원(CPU, 메모리, 디스크)과 네트워크 대역폭이 필요**합니다. 이는 소규모 스타트업이나 개인 프로젝트에는 부담이 될 수 있습니다.
* **초저지연 (Ultra-low-latency)에는 부적합:** 
    - Kafka는 높은 처리량과 안정성에 최적화되어 있으며, 일반적으로 **밀리초 단위의 지연 시간**을 가집니다. 따라서 **극히 짧은 지연 시간(마이크로초 단위)을 요구하는 고빈도 거래 시스템 등에는 더 특화된 솔루션이 적합**할 수 있습니다.

### **60.5 결론**

* **실시간 데이터 스트리밍의 핵심 플랫폼:** 
    - Apache Kafka는 **높은 확장성, 안정성, 그리고 처리량을 바탕으로 실시간 데이터 스트리밍 분야에서 핵심적인 역할**을 수행하는 강력한 플랫폼입니다.
* **다양한 활용 가능성:** 
    - 메시지 큐에서부터 실시간 데이터 분석 및 스트림 처리까지, **다양한 유형의 애플리케이션과 워크로드를 지원하는 핵심 큐잉 및 메시징 기능**을 제공하며, 현대적인 데이터 중심 아키텍처에서 중요한 구성 요소로 자리매김하고 있습니다.

