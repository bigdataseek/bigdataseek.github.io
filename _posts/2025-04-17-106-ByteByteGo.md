---
title: 32차시 6:ByteByteGo
layout: single
classes: wide
categories:
  - ByteByteGo
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 76. Disney Hotstar, 크리켓 월드컵 경기 중 50억 개 이모지 반응 처리
- 출처: [How Disney Hotstar Captures One Billion Emojis!](https://www.youtube.com/watch?v=UN1kW5AHid4)

### **76.1 도전 과제**

*   크리켓 월드컵 경기 중 수백만 팬들의 실시간 이모지 반응 폭주 
    - 특히 인도와 파키스탄 간의 하이프로파일 경기에서는 초당 50만 건 이상의 이모지 반응이 발생
*   서버 과부하 방지 및 실시간 감정 변화 반영 
    - 기존 모놀리식 아키텍처는 이러한 트래픽 폭증을 처리하지 못하고 자주 다운되었습니다

### **76.2 해결 방안: 분리된 컴포넌트 기반의 비동기 처리 아키텍처**

1.  **데이터 수집:**

    *   **Kafka:** 오픈 소스 분산 이벤트 스트리밍 플랫폼
        *   토픽을 사용하여 데이터 스트림 구성 
            - 경기별 전용 토픽을 만들어 데이터 흐름 최적화
        *   컨슈머 그룹을 사용하여 병렬 처리 가능 
            - 수평적 확장을 통해 수천만 동시 시청자 처리
        *   대량의 이모지 데이터를 버퍼링하여 처리 
            - 네트워크 및 처리 지연 발생 시에도 데이터 손실 방지
2.  **API 서버:**

    *   **Golang:** Google에서 개발한 오픈 소스 프로그래밍 언어
        *   경량 Goroutine을 통해 대규모 동시성 지원 
            - 단일 서버에서 수백만 개의 동시 연결 처리 가능
        *   Go 채널을 통해 Goroutine 간 안전하게 데이터 교환 
            - 메모리 누수와 경쟁 조건 방지
        *   수백만 뷰어의 이모지 반응을 수집하고, 채널을 사용하여 일괄 처리 후 Kafka 토픽에 비동기적으로 기록 
            - 네트워크 I/O 작업 최소화로 처리량 향상
3.  **실시간 감정 분석:**

    *   **Spark:** JVM 기반 고속 통합 분석 엔진
        *   Kafka에서 이모지 스트림을 처리하여 2초마다 감정 점수 업데이트 
            - 이전에는 6초 소요됨
        *   인 메모리 처리를 통해 기존 Hadoop MapReduce 대비 처리 속도 향상 
            - 100배 이상 빠른 처리 가능
        *   **Spark Streaming:** 마이크로 배치 아키텍처를 사용하여 데이터를 작은 단위로 처리 
            - 2초 간격의 윈도우 적용
        *   배치된 스트리밍 데이터에 대한 집계 알고리즘을 실행하여 사용자 간 이모지 감정 분포 결정 
            - 감정 점수는 긍정/부정/중립으로 분류
4.  **감정 데이터 전달:**

    *   집계된 감정 데이터를 별도의 Kafka 토픽으로 전송하여 버퍼링 
        - 다운스트림 시스템의 부하 분산
    *   **Python 컨슈머:** Kafka 토픽에서 감정 데이터를 가져와 Hotstar의 PubSub 메시징 인프라에 게시 
        - 고효율 메모리 관리로 리소스 사용 최적화
5.  **PubSub 메시징:**

    *   **맞춤형 PubSub 시스템:** MQTT 기반으로 구축되어 대용량 콘텐츠 처리 및 지연 시간 최소화 
        - WebSocket 연결을 통한 효율적인 양방향 통신
    *   수백만 기기에 실시간 업데이트를 제공 
        - 네트워크 상태에 따라 자동으로 품질 조정

### **76.3 결과**

*   각 컴포넌트의 독립적인 확장을 통해 원활한 스트리밍 보장 
    - 핫스팟 발생 시 부분적 스케일링 가능
*   지연 시간 6초에서 2초로 단축 
    - 사용자 경험 및 참여도 크게 향상
*   시스템 장애 감소 
    - 이전 시즌 대비 99.99% 가용성 달성
*   비용 85% 절감 
    - 수직 확장 대신 효율적인 수평 확장 아키텍처 도입으로 인프라 비용 최적화

## 77. API를 설계하기 위한 7가지 주요 팁
- 출처: [Good APIs Vs Bad APIs: 7 Tips for API Design](https://www.youtube.com/watch?v=_gQaygjm_hg)


### **77.1 명확한 이름 사용**
- API를 구축할 때 직관적이고 논리적인 이름을 선택해야 합니다. 
- 예를 들어 쇼핑 앱에서 장바구니 항목을 가져오는 API 엔드포인트를 `get Cod123` 대신에 복수형을 사용하여 `cards`로 명명하고 특정 ID를 명시하는 `/123`과 같이 사용하는 것이 좋습니다. 
- 일관성 있고 직관적인 URL 구조를 따르면 개발자들이 API와 더 쉽게 상호 작용할 수 있습니다.

### **77.2 멱등성(Idempotency) 보장**
- 멱등성이란 동일한 API 호출을 여러 번 수행하더라도 그 결과가 한 번 호출했을 때와 동일해야 한다는 개념입니다. 이는 API의 안정성을 높이고 요청 재시도 시 발생할 수 있는 버그를 방지합니다.
    *   `GET` 요청은 데이터를 읽기만 하므로 기본적으로 멱등성을 가집니다.
    *   `PUT` 요청은 전체 리소스를 업데이트하므로 멱등성을 가질 수 있습니다.
    *   `DELETE` 요청은 한 번 삭제 후 여러 번 호출해도 결과적으로 리소스가 삭제된 상태를 유지하므로 멱등성을 가집니다.
    *   `POST` 요청은 리소스를 생성하므로 동일한 요청을 반복하면 중복된 리소스가 생성될 수 있습니다. 이를 방지하기 위해 클라이언트가 생성한 고유 ID를 요청 시 포함시켜 중복 생성을 방지하는 로직을 추가할 수 있습니다.
    *   `PATCH` 요청은 리소스의 특정 필드만 변경하므로 여러 번 호출 시 예기치 않은 결과(예: 배열에 중복된 요소 추가)를 초래하여 멱등성을 보장하기 어려울 수 있습니다.

### **77.3 버전 관리**
- API가 성장하고 업데이트가 필요함에 따라 기존 애플리케이션에 영향을 주지 않으면서 변경 사항을 적용할 수 있도록 버전 관리가 필요합니다. 
- URL에 버전 정보를 포함시키는 방법(`V1/cards/123`)을 통해 새로운 버전(`V2`)을 도입해도 기존 API 사용자는 영향을 받지 않고 자신의 일정에 맞춰 업그레이드할 수 있습니다. 
- 변경 사항은 자세한 릴리스 노트를 통해 개발자에게 알려야 합니다.

### **77.4 페이지네이션**
- API가 많은 양의 데이터를 반환할 경우 페이지네이션을 적용하여 API 소비자가 한 번에 받는 데이터 양을 제어해야 합니다. 
- 이는 성능을 향상시키고 사용자 경험을 개선합니다. 일반적인 페이지네이션 방법은 다음과 같습니다:
    *   **페이지 번호와 오프셋(Page plus offset)**: 페이지 번호와 페이지 크기를 사용하여 데이터를 가져옵니다 (예: 2페이지, 페이지 크기 10은 11번째부터 20번째 레코드를 의미합니다). 구현은 간단하지만 대규모 데이터셋에서 성능이 저하될 수 있습니다.
    *   **커서 기반 페이지네이션(Cursor based pagination)**: 다음 레코드 집합을 가져오기 위한 포인터를 사용합니다. 데이터 변경이 잦은 경우에도 정확하게 페이지를 추적할 수 있습니다.

### **77.5 명확한 쿼리 스트링 사용**
- API 데이터를 필터링하고 정렬하기 위해 명확한 쿼리 스트링을 사용해야 합니다. 예를 들어 가입 날짜별로 정렬하려면 `sort_by=registered`, 파란색 제품만 필터링하려면 `filter=color:blue`와 같은 방식을 사용할 수 있습니다. 이는 다음과 같은 이점을 제공합니다:
    *   응답 데이터를 쉽게 이해할 수 있습니다.
    *   기존 통합을 깨뜨리지 않고 새로운 정렬 및 필터링 조건을 쉽게 추가할 수 있습니다.
    *   필터링 및 정렬된 결과셋을 개별적으로 캐싱하여 속도를 향상시킬 수 있습니다.

### **77.6 보안을 나중에 생각하지 않기**
- API를 설계할 때 보안을 최우선으로 고려해야 합니다. 
- API 키와 같은 민감한 자격 증명은 URL 대신 HTTP 헤더를 통해 전달해야 서버 접근 로그에 노출되는 위험을 줄일 수 있습니다. 
- `Authorization`과 같은 헤더를 사용하는 것이 좋습니다. 헤더를 통한 전송도 유출될 수 있으므로 모든 트래픽에 대해 종단 간 TLS 암호화를 적용하여 전송 중인 데이터를 보호해야 합니다. 
- 모든 요청에 대해 키와 토큰을 확인하는 강력한 접근 제어를 구현해야 합니다. 

### **77.7 간단한 리소스 간 참조 유지**
- 연결된 리소스 간의 참조를 명확하고 간단하게 유지해야 합니다. 긴 쿼리 스트링으로 복잡하게 만드는 대신 명확한 경로를 사용하는 것이 좋습니다. 
- 예를 들어 카드 `123` 내의 항목 `321`을 참조할 때 `/cards/123/items/321`과 같은 직관적인 경로를 사용하는 것이 좋습니다. 이는 개발자가 API의 연관성을 더 쉽게 이해할 수 있도록 돕습니다.

### **77.8 추가 팁: 속도 제한(Rate Limiting) 계획**
- API를 과부하 및 남용으로부터 보호하기 위해 속도 제한을 설정해야 합니다. 
- 소스 IP 주소, 사용자 계정 또는 엔드포인트 카테고리와 같은 기준에 따라 요청 할당량을 설정할 수 있습니다. 
- 예를 들어 무료 티어 고객은 하루에 1000번의 요청만 허용하고, 특정 IP 주소는 분당 20번의 요청으로 제한할 수 있습니다. 
- 이는 인프라를 보호하고 모든 클라이언트에게 공정한 사용을 장려하며 DoS 공격의 위험을 줄입니다.


## 78. 코드에서 아키텍처 다이어그램으로 변환하는 도구
- 출처: [Top 6 Tools to Turn Code into Beautiful Diagrams](https://www.youtube.com/watch?v=jCd6XfWLZsg)

### 78.1 코드에서 아키텍처 다이어그램으로 변환하는 도구 정리

- 이 글에서는 코드에서 아키텍처 다이어그램을 생성하는 6가지 유용한 도구를 소개합니다. 이러한 도구는 개발자가 시스템을 문서화하거나 기술 리더가 지식을 공유하는 데 유용하며, 다이어그램 변경 사항을 버전 관리 시스템에서 추적할 수 있게 해줍니다. 코드로 다이어그램을 관리하면 문서와 실제 시스템 간의 불일치를 줄이고 팀 전체의 이해도를 높일 수 있다.

**1. Diagrams (Python 라이브러리):**

*   클라우드 시스템 아키텍처를 코드로 빠르게 프로토타입 제작
*   AWS, Azure, GCP, Kubernetes 등 주요 플랫폼 및 스택 지원
*   온프레미스 노드, SaaS 서비스, 주요 프로그래밍 프레임워크 및 언어 모델링 가능
*   광범위한 아이콘 카탈로그와 직관적인 구문 제공
*   Python의 강력한 생태계를 활용하여 기존 도구 및 워크플로우와 통합 가능
*   GraphViz를 기반으로 하여 전문적인 품질의 다이어그램 렌더링

**2. Go-Diagrams (Go):**

*   Diagrams와 동일한 아이디어
*   Go 언어로 작성 가능
*   Go의 강력한 타입 시스템과 동시성 기능을 활용
*   대규모 시스템 모델링에 적합한 성능 특성 제공
*   DevOps 및 인프라 팀에서 많이 사용하는 Go 기반 도구와 원활하게 통합

**3. Mermaid (JavaScript 라이브러리):**

*   텍스트를 사용하여 다이어그램 및 시각화 생성
*   Markdown 스타일의 텍스트 정의를 사용하여 복잡한 다이어그램 수정
*   "doc-rot" 문제 해결 목표
*   Mermaid Live Editor를 통해 비프로그래머도 상세한 시각 자료 제작 가능
*   GitHub, GitLab, Notion 등 많은 플랫폼에서 기본 지원
*   flowchart, sequenceDiagram, classDiagram, stateDiagram 등 다양한 다이어그램 타입 제공

**4. PlantUML:**

*   다양한 다이어그램 유형(시퀀스 다이어그램, 아키텍처 다이어그램, 네트워크 토폴로지, Gantt 차트 등) 생성
*   강력한 도메인 특화 언어 제공
*   코드와 함께 다이어그램을 포함하는 데 유용
*   대부분의 주요 IDE와 문서 도구에 플러그인 제공
*   대규모 기업 환경에서 널리 채택된 검증된 솔루션
*   표준 UML 다이어그램을 지원하여 전통적 소프트웨어 엔지니어링 접근법과 호환

**5. ASCII 다이어그램 편집기:**

*   다이어그램을 시각적으로 또는 텍스트로 그린 다음 ASCII 아트로 렌더링
*   텍스트 기반 다이어그램, 레이아웃, 순서도 등을 쉽게 작성
*   웹 기반 asciiflow 및 Mac 전용 Monodraw 등이 있음
*   특별한 도구 없이 모든 텍스트 편집기에서 볼 수 있어 접근성이 뛰어남
*   이메일, 코멘트, README 파일 등 리치 텍스트를 지원하지 않는 환경에서도 사용 가능
*   최소한의 의존성으로 콘솔 환경에서도 작업 가능

**6. Markmap:**

*   Markdown 문서에서 마인드 맵 생성 및 시각화
*   Markdown 콘텐츠를 파싱하여 마인드 맵으로 렌더링
*   아이디어와 관계 연결에 유용
*   다양한 플랫폼 지원
*   대화형 웹 기반 인터페이스로 확장/축소 및 재구성 가능
*   VS Code 확장 프로그램 제공으로 개발 워크플로우에 쉽게 통합
*   프로젝트 구조화, 브레인스토밍 및 시스템 의존성 문서화에 특히 유용

## 79. 웹훅(Webhooks) vs 폴링(Polling)
- 출처: [Top 3 Things You Should Know About Webhooks!](https://www.youtube.com/watch?v=x_jjhcDrISk)


- 온라인 쇼핑몰에서 결제 서비스(Stripe) 연동 시, 결제 완료 상태를 확인하는 방법으로 폴링과 웹훅을 비교 설명하고, 웹훅 사용 시 주의사항을 제시. 이러한 방식들은 현대 웹 애플리케이션에서 데이터 동기화와 이벤트 처리를 위한 핵심 아키텍처 패턴으로 활용됩니다.

### **79.1 기존 방식 (폴링)**

*   **Short Polling:**

    *   서버에 계속해서 "결제 완료?"를 묻는 방식.
    *   일정 간격(예: 2초마다)으로 클라이언트가 서버에 요청을 보내 상태 변화를 확인합니다.
    *   자원 낭비가 심함. 대부분의 요청이 "아직 완료되지 않음" 응답을 받게 되어 네트워크 트래픽과 서버 리소스를 불필요하게 소모합니다.
    *   구현이 간단하지만 규모가 커질수록 서버 부하가 기하급수적으로 증가하는 단점이 있습니다.

*   **Long Polling:**

    *   서버가 응답할 정보가 있을 때까지 연결을 유지하는 방식.
    *   클라이언트가 요청을 보내고, 서버는 데이터가 준비될 때까지 응답을 지연시키는 방식입니다(타임아웃 설정 있음).
    *   데이터가 준비되면 즉시 응답하고 연결을 종료하며, 클라이언트는 새로운 요청을 보냅니다.
    *   Short Polling보다 효율적이지만 서버 부담이 존재. 특히 많은 클라이언트가 동시에 연결을 유지할 경우 서버 리소스 소모가 증가합니다.
    *   연결 타임아웃 관리와 재연결 로직이 필요하여 구현이 더 복잡해집니다.

### **79.2 웹훅(Webhooks)**

*   서버(Stripe)가 특정 URL로 결제 상태 업데이트를 "push" 해주는 방식.
*   이벤트가 발생할 때만 서버가 클라이언트에 알려주므로 불필요한 요청이 없습니다.
*   자원 낭비가 적고 효율적. 결제가 완료된 시점에 즉시 알림을 받을 수 있어 사용자 경험도 향상됩니다.
*   "Reverse API" 또는 "Push API" 라고도 불림. 기존 API가 클라이언트에서 서버로 요청을 보내는 방식이라면, 웹훅은 반대로 서버에서 클라이언트로 데이터를 전송합니다.
*   구현을 위해 공개적으로 접근 가능한 엔드포인트가 필요하므로 개발 환경 설정이 더 복잡할 수 있습니다.

### **79.3 웹훅 사용 시 Best Practices**

*   **Fallback Polling:** 
    - 웹훅 전달 실패 시를 대비하여 주기적인 폴링 메커니즘을 마련 (Stripe가 호출을 잊은 경우 대비).
    *   네트워크 문제나 서버 장애로 웹훅이 유실될 수 있으므로, 마지막 업데이트 이후 일정 시간이 지나면 폴링으로 상태를 확인하는 보완책이 필요합니다.
    *   이중 안전장치(Double Safety Net)를 통해 데이터 동기화의 신뢰성을 높일 수 있습니다.

*   **보안:** 
    - 인증 토큰을 사용하여 웹훅 호출을 보호하고, signature를 검증하여 위조 방지.
    *   웹훅 URL에 비밀 토큰을 포함시키거나 HTTP 헤더에 인증 정보를 추가합니다.
    *   Stripe의 경우 요청 본문과 비밀키를 사용하여 생성된 서명을 제공하므로, 이를 검증하여 요청의 진위를 확인해야 합니다.
    *   TLS/SSL을 통한 암호화된 통신을 필수적으로 사용해야 합니다.

*   **멱등성(Idempotency):** 
    - 웹훅이 여러 번 전달되어도 문제가 발생하지 않도록 코드 작성 (중복 제거를 위해 unique identifier 사용).
    *   웹훅은 네트워크 문제로 재시도될 수 있어 동일한 이벤트가 여러 번 도착할 수 있습니다.
    *   이벤트 ID를 저장하고 중복 처리를 방지하는 로직이 필수적입니다.
    *   데이터베이스 트랜잭션과 조건부 업데이트를 활용하여 중복 처리를 방지합니다.

*   **트래픽 관리:** 
    - 웹훅 트래픽 급증에 대비하여 큐(Queue)를 사용하여 웹훅 이벤트 처리 분리.
    *   웹훅 수신과 처리를 분리하여, 수신은 빠르게 응답하고 처리는 비동기적으로 진행합니다.
    *   RabbitMQ, Amazon SQS 같은 메시지 큐를 사용하여 부하를 분산시키고 처리 속도를 조절.
    *   이벤트 우선순위를 설정하여 중요한 이벤트(예: 결제 완료)를 먼저 처리할 수 있습니다.

### **79.4 웹훅의 한계**

*   극도로 짧은 지연 시간(Microsecond latency)이 필요한 실시간 데이터에는 적합하지 않음.
    *   HTTP 기반 웹훅은 연결 설정 오버헤드가 있어 millisecond 수준의 지연이 발생합니다.
    *   고빈도 트레이딩이나 실시간 게임 같은 초저지연 애플리케이션에는 적합하지 않습니다.
*   이러한 경우에는 persistent socket 연결이 더 나은 성능을 제공하지만, 설정 및 확장성이 더 어려움.
    *   WebSocket, Socket.io, SignalR 같은 기술이 양방향 실시간 통신에 더 적합합니다.
    *   하지만 이러한 기술은 서버 자원 소모가 크고 확장 아키텍처가 복잡해지는 단점이 있습니다.
    *   로드 밸런싱과 연결 상태 관리의 복잡성이 증가합니다.

### **79.5 결론**

- 웹훅은 효율적인 업데이트 방식이지만, fallback 메커니즘, 보안, 멱등성, 트래픽 관리를 고려해야 함. 특히 결제 처리와 같은 중요한 비즈니스 로직에서는 데이터 일관성과 보안을 최우선으로 설계해야 합니다. 극단적인 실시간성이 요구되는 경우에는 persistent socket 연결을 고려하되, 대부분의 e-커머스 시나리오에서는 적절한 안전장치가 구현된 웹훅 방식이 균형 잡힌 선택이 될 수 있습니다.

## 80. 캐싱 문제점 및 해결 방안
- 출처: [Caching Pitfalls Every Developer Should Know](https://www.youtube.com/watch?v=wh98s0XhMmQ)

### **80.1 캐싱 기본 개념**

*   **정의:** 자주 사용되는 데이터의 복사본을 고속 메모리 계층에 저장하는 기술
*   **목적:** 
    *   데이터 접근 속도 향상 (디스크 I/O 대비 100~1000배 빠른 응답)
    *   백엔드 데이터베이스 부하 감소 (TPS 60% 이상 감소 효과)
    *   시스템 확장성 향상 (수직/수평 확장 비용 절감)

### **80.2 캐싱 문제점 및 심층 해결 방안**

*   **Cache Stampede (캐시 스탬피드):**
    *   **발생 메커니즘:** 
        *   Hot Key 캐시 만료 → 수천 QPS 요청이 DB 직접 호출
        *   동시성 갱신 경쟁으로 인한 DB CPU 100% 장애
    *   **고급 해결 전략:**
        *   **분산 락 (RedLock):** Redis 분산 락을 활용한 크리티컬 섹션 보호
        *   **Backoff & Retry:** Exponential Backoff 알고리즘 적용 (초기 100ms → 최대 2초 지연)
        *   **Stale-While-Revalidate:** 만료된 캐시를 임시 사용하면서 백그라운드 갱신
        *   **TTL 랜덤화:** 기본 TTL ±10% 변동 적용 (예: 300초 ± 30초)

*   **Cache Penetration (캐시 관통):**
    *   **시나리오 예시:** 
        *   유효하지 않은 userID(-1) 지속 요청 → 매번 DB Full Scan 발생
        *   악성 크롤러에 의한 공격 패턴
    *   **방어 체계:**
        *   **Negative Caching:** "NULL" 결과를 5~10분간 캐싱 (주의: 메모리 증발 문제)
        *   **Multi-layer Bloom Filter:** 
            *   L1: In-memory BF (10MB, 0.1% FP)
            *   L2: Redis-backed BF (100MB, 0.01% FP)
        *   **Query Pattern Blocking:** 비정상적 접근 패턴 차단 (예: 초당 100회 이상 NULL 요청)

*   **Cache Crash/Avalanche (캐시 장애/눈사태):**
    *   **재난 시뮬레이션:** 
        *   Redis Cluster 장애 → 50,000 RPS 직접 DB 전달
        *   캐시 Warm-up 시간 30분 소요 시 서비스 불능
    *   **생존 전략:**
        *   **Failover Architecture:** 
            *   Active-Active Redis Cluster (3 Region)
            *   Hot Backup Memcached Layer
        *   **Traffic Shaping:**
            *   Rate Limiter (5000 RPS 이상 차단)
            *   우선순위 큐 기반 요청 처리
        *   **Cold Start Protocol:** 
            *   Emergency Cache Dump 로드 (최근 24시간 Hot Key 80% 복구)
            *   Lazy Loading + Prefetch 병행

### **80.3 Cache Stampede vs. Cache Avalanche 심층 비교**

| 구분             | Cache Stampede                                  | Cache Avalanche                                 |
|------------------|-----------------------------------------------|-----------------------------------------------|
| **Trigger**      | 단일 Hot Item 만료 (예: 메인 배너 정보)          | 대규모 이벤트 (예: 새해 이벤트 시작 00:00)        |
| **Failure Mode** | Localized DB Overload                        | Cascading Failure Chain                     |
| **Detection**    | APM에서 특정 Key 초당 Timeout 500건 이상        | CloudWatch CPUUsage > 90% 지속 1분           |
| **Mitigation**   | - Lock Striping<br>- Soft Expiration         | - Global Rate Limit<br>- Degraded Mode      |
| **Recovery**     | 1~5분 내 자동 수복                           | 수동 개입 필요 (평균 47분 소요)               |

### **80.4 Emerging Solutions:**
*   **Adaptive Caching:** ML 기반 TTL 동적 조정 (사용 패턴 학습)
*   **Edge Caching:** Cloudflare Workers로 캐시 관통 차단
*   **Persistent Memory Cache:** Intel Optane을 활용한 장애 내성 향상

### **80.5 모니터링 지표**
- `cache_hit_ratio` > 0.85 (이상적 0.95)
- `stale_read_rate` < 0.01
- `penetration_attempt` 알람 (분당 100회 이상)


## 81. Reverse Proxy vs API Gateway vs Load Balancer
- 출처: [Reverse Proxy vs API Gateway vs Load Balancer](https://www.youtube.com/watch?v=RqfaTIWc3LQ)

- 이 비디오에서는 웹 아키텍처의 세 가지 핵심 구성 요소인 **리버스 프록시, API 게이트웨이, 로드 밸런서**를 심층 분석합니다. 각 구성 요소는 현대 웹 생태계에서 차별화된 기능을 수행하며, 상호 보완적으로 작동해 대규모 애플리케이션 인프라의 확장성과 안정성을 극대화합니다.

### 81.1 **리버스 프록시** 
- 클라이언트와 서버 간의 "지능적 중개자"로 작동합니다. 
- 클라우드플레어나 Nginx와 같은 솔루션은 실제 서버 위치를 은닉함으로써 DDoS 공격 방어(보안 강화), Gzip 압축을 통한 대역폭 절감(성능 최적화), 심지어 A/B 테스트를 위한 트래픽 분기(비즈니스 유연성)까지 가능하게 합니다. 
- 특히 Kubernetes 환경에서는 Ingress Controller가 리버스 프록시 기능을 구현해 파드 간 라우팅을 관리합니다. 

### 81.2 **API 게이트웨이**
- 마이크로서비스 아키텍처의 "교통 허브" 역할을 합니다. 
- Kong이나 AWS API Gateway는 JWT 검증(인증), Quota 관리(과금 제어), gRPC-HTTP 변환(프로토콜 브리징) 같은 고급 기능을 제공합니다. 
- Netflix의 경우 Zuul 게이트웨이가 초당 2백만 요청을 처리하며 서비스 디스커버리와 연동되는 동적 라우팅을 구현합니다.

### 81.3 **로드 밸런서**
- HAProxy나 AWS ALB에서 보듯, "트래픽 교통경찰"로서 L7(애플리케이션 계층)에서의 콘텐츠 기반 라우팅(예: /cart 경로는 카트 서버로)부터 L4(트랜스포트 계층)의 연결 추적에 이르기까지 다계층 작동이 가능합니다. 
- 클라우드 환경에서는 오토스케일링 그룹과 연동되어 CPU 사용률에 따라 인스턴스를 자동 증감하는 인프라 유연성을 제공합니다. 

### 81.4 **계층적 결합**
- 실제로 Istio 서비스 메시는 Envoy 프록시를 기반으로 API 게이트웨이 기능(외부 트래픽 제어)과 내부 로드 밸런싱(서비스 간 통신)을 통합합니다. 
- 반면 클라우드플레어는 리버스 프록시와 글로벌 로드 밸런싱을 결합해 200개 이상의 에지 위치에서 지연 시간 최적화를 실현합니다. 

### 81.5 **결론**
- 이 3요소는 클라우드 네이티브 아키텍처의 "불가분의 삼각형"으로, DevOps 팀이 선언적 설정(Infrastructure as Code)으로 관리하며, 점점 더 eBPF 같은 커널 수준 기술과 결합되어 초고성능 네트워킹을 구현하고 있습니다.

## 82. Apache Kafka 주요 활용 사례 5가지
- 출처: [System Design: Why is Kafka so Popular?](https://www.youtube.com/watch?v=yIAcHMJzqJc)


- Apache Kafka는 분산 이벤트 스트리밍 플랫폼으로서, 실시간 데이터 처리 방식에 혁신을 가져왔습니다.   대용량 데이터 스트림을 안정적으로 처리할 수 있는 설계로, **마이크로서비스 아키텍처, 데이터 레이크, IoT 시스템** 등 현대적 인프라의 핵심 컴포넌트로 자리잡았습니다.  

### **82.1 로그 처리 및 분석: 분산 시스템의 통합 관문**  
* **문제:**  
  - 복잡한 마이크로서비스 환경에서는 초당 수만 건의 로그가 분산되어 발생  
  - 파일 기반 로그 수집 방식은 확장성 부족 및 실시간성 결여  
* **Kafka 솔루션:**  
  - **중앙 집중식 로그 파이프라인** 구성 (예: Filebeat → Kafka → Logstash → Elasticsearch)  
  - **토픽 기반 파티셔닝**으로 서비스별/로그 유형별 분류 가능  
  - **Kafka Connect**를 이용해 S3, HDFS 등에 장기 저장 가능  
* **장점:**  
  - 초당 100만 메시지 이상 처리 가능 (수평 확장)  
  - ELK 스택과 결합 시 **실시간 오류 추적 및 대시보드** 구축 용이  


### **82.2 추천 시스템을 위한 데이터 스트리밍: 실시간 개인화의 핵심**  
* **목표:**  
  - Netflix, 쇼핑몰 등에서 사용자 행동(클릭, 검색, 머문 시간) 기반 **1초 이내 추천**  
* **Kafka 아키텍처:**  
  - **클릭스트림 데이터** → Kafka → **Flink/Spark Streaming** (실시간 집계) → **ML 모델** (TensorFlow Serving) → 추천 API  
  - **Kafka Streams**로 사용자 세션 윈도우 처리 가능 (예: 30분 내 조회 상품 패턴 분석)  
* **사례:**  
  - Spotify의 "Discover Weekly"는 Kafka로 5억+ 사용자 행동 데이터 처리  

### **82.3 시스템 모니터링 및 알림: 인프라 이상 감지의 첫 번째 방어선**  
* **필요성:**  
  - Kubernetes 클러스터, 클라우드 VM 등에서 **CPU Spike, 네트워크 지연** 등 즉시 감지 필요  
* **구현 방식:**  
  - **Prometheus + Kafka** 조합: 각 노드 메트릭 → Kafka → **Flink**로 이상 패턴 탐지 (예: 5분 평균 대비 300% CPU 사용)  
  - **다단계 알림 시스템:** 경고 → Kafka → Slack/이메일/PagerDuty 자동 발송  
* **장점:**  
  - **분산 트레이싱** 가능 (예: OpenTelemetry 데이터 수집)  

### **82.4 변경 데이터 캡처 (CDC): 데이터 동기화의 실시간 표준**  
* **과제:**  
  - 주문 DB(MySQL) → 분석 DB(Redshift) 동기화 시 **배치 작업**으로 인한 지연 (최대 24시간)  
* **Kafka 기반 CDC:**  
  - **Debezium 커넥터**로 MySQL Binlog → Kafka 토픽 → **Elasticsearch/Redis** 실시간 반영  
  - **스키마 레지스트리** 활용해 Avro/Protobuf 형식으로 데이터 일관성 보장  
* **사례:**  
  - Uber는 Kafka CDC로 100+ 데이터베이스 동기화  

### **82.5 시스템 마이그레이션: 제로 다운타임 전환의 키 플레이어**  
* **어려움:**  
  - 모놀리스 → MSA 전환 시 **데이터 일관성** 문제와 롤백 불가능 리스크  
* **Kafka 전략:**  
  - **Dual-Write 아키텍처:** 구 시스템 → Kafka → 신 시스템으로 **양방향 동기화**  
  - **카나리아 릴리스:** 특정 사용자 트래픽만 신 시스템으로 라우팅 테스트  
* **성공 요건:**  
  - **Exactly-Once Semantics**로 데이터 중복/유실 방지  
  - **Schema Evolution**으로 버전 간 호환성 관리  

### **82.6 결론: Kafka의 진화**  
- 이벤트 기반 아키텍처(EDA)의 확산으로, Kafka는 단순한 메시지 큐를 넘어 **데이터 인프라의 중추**로 진화했습니다.  
- **Kafka + Stream Processing + Connectors** 조합은 **실시간 데이터 파이프라인의 사실상 표준(de facto standard)** 이 되었으며, 향후 AIOps, 디지털 트윈 등에서도 핵심 역할을 할 것으로 전망됩니다.

## 83. ACID 속성
- 출처: [ACID Properties in Databases With Examples](https://www.youtube.com/watch?v=GAe5oB742dw)

- ACID는 데이터베이스 트랜잭션의 신뢰성을 보장하는 핵심 속성인 **Atomicity(원자성)**, **Consistency(일관성)**, **Isolation(격리성)**, **Durability(지속성)**의 약자입니다. 이 네 가지 속성은 데이터베이스 시스템에서 트랜잭션이 안정적이고 예측 가능한 방식으로 동작하도록 보장하며, 특히 금융, 전자상거래 등 데이터 정확성이 중요한 분야에서 필수적인 역할을 합니다.

### **83.1 Atomicity (원자성)**

*   **트랜잭션은 전부 실행되거나, 전혀 실행되지 않아야 합니다.**  
    - 트랜잭션은 "All-or-nothing" 원칙에 따라 처리됩니다. 즉, 트랜잭션 내의 모든 작업이 성공적으로 완료되어야만 최종 상태로 반영되며, 그렇지 않은 경우 초기 상태로 롤백됩니다.  
    - 예를 들어, 은행 앱에서 Alice에서 Bob에게 \\$100를 이체하는 경우, Alice의 계좌에서 \\$100를 빼고 Bob의 계좌에 \\$100를 더하는 두 작업이 모두 성공하거나 모두 실패해야 합니다.  
    - 만약 Alice의 계좌에서 돈을 뺀 후 시스템 장애로 인해 Bob의 계좌에 돈을 추가하지 못한다면, Alice의 계좌에서 돈이 사라지게 되어 데이터 일관성이 깨질 수 있습니다. 이를 방지하기 위해 트랜잭션은 원자적으로 처리되어야 합니다.

### **83.2 Consistency (일관성)**

*   **트랜잭션은 미리 정의된 규칙과 제약 조건을 따라야 합니다.**  
    - 데이터베이스는 항상 유효한 상태를 유지해야 하며, 트랜잭션은 이러한 상태를 위반하지 않도록 설계되어야 합니다.  
    - 예를 들어, 계좌 잔액이 음수가 될 수 없다는 규칙이 있는 경우, 잔액 부족으로 출금이 불가능해야.  
    - 일관성은 데이터베이스 스키마, 제약 조건(Constraints), 트리거(Triggers) 등을 통해 구현됩니다. 예를 들어, 외래 키(Foreign Key) 제약 조건은 참조 무결성을 보장하여 잘못된 데이터가 삽입되는 것을 방지합니다.


### **83.3 Isolation (격리성)**

*   **동시에 실행되는 트랜잭션들이 서로에게 영향을 주지 않도록 격리합니다.**  
    - 격리성은 여러 트랜잭션이 동시에 실행될 때 발생할 수 있는 문제를 방지하기 위한 속성입니다.  
    - 예를 들어, 가장 높은 격리 수준인 **Serializable (직렬화)**는 트랜잭션들이 순차적으로 실행되는 것처럼 보이게 하여 가장 강력한 일관성을 제공하지만, 이는 성능 저하를 유발할 수 있습니다.  
    - 낮은 격리 수준에서는 성능 향상을 위해 동시성을 높이지만, 아래와 같은 문제점이 발생할 수 있습니다.
    - **Dirty Read (더티 리드):** 
        - 아직 커밋되지 않은 트랜잭션의 데이터를 읽는 현상입니다. 예를 들어, 한 트랜잭션이 데이터를 수정한 후 커밋하기 전에 다른 트랜잭션이 해당 데이터를 읽어 사용할 경우, 이후 첫 번째 트랜잭션이 롤백되면 두 번째 트랜잭션의 데이터가 잘못된 값으로 처리될 수 있습니다.  
    - **Non-Repeatable Read (반복 불가능한 읽기):** 
        - 같은 트랜잭션 내에서 같은 데이터를 여러 번 읽을 때 다른 결과가 나오는 현상입니다. 예를 들어, 한 트랜잭션이 데이터를 읽은 후 다른 트랜잭션이 해당 데이터를 수정하고 커밋하면, 처음 트랜잭션이 다시 읽었을 때 다른 값을 얻게 됩니다.  
    - **Phantom Read (팬텀 리드):** 
        - 트랜잭션 재실행 시 다른 트랜잭션에 의해 추가/삭제된 레코드가 검색되어 결과가 달라지는 현상입니다. 예를 들어, 한 트랜잭션이 특정 조건을 만족하는 레코드를 조회한 후, 다른 트랜잭션이 해당 조건에 맞는 새로운 레코드를 추가하면, 처음 트랜잭션이 다시 조회했을 때 추가된 레코드가 포함됩니다.  

*   **격리 수준별 설명:**
    - **Read Committed (커밋된 읽기):** 
        - 커밋된 데이터만 읽을 수 있도록 하여 더티 리드를 방지합니다.  
    - **Repeatable Read (반복 가능한 읽기):** 
        - 트랜잭션 시작 시점의 데이터 스냅샷을 제공하여 반복 불가능한 읽기를 방지합니다.  
    - 적절한 격리 수준을 선택하여 성능과 데이터 일관성 간의 균형을 맞춰야 합니다. 예를 들어, 금융 거래와 같은 중요 데이터에는 높은 격리 수준(Serializable 또는 Repeatable Read)을 적용하고, 일반적인 조회 작업에는 낮은 격리 수준(Read Committed)을 적용할 수 있습니다.

### **83.4 Durability (지속성)**

*   **트랜잭션이 커밋되면 영구적으로 데이터베이스에 저장되어야 합니다.**  
    - 데이터베이스가 갑자기 중단되더라도 데이터가 손실되지 않도록 보장해야 합니다.  
    - 예를 들어, 트랜잭션 로그, WAL (Write-Ahead Logging)과 같은 기술을 사용하여 구현됩니다.  
    - WAL은 데이터 변경 사항을 디스크에 물리적으로 기록하기 전에 먼저 로그 파일에 기록하여 시스템 장애가 발생해도 복구가 가능하도록 합니다. 또한, 분산 데이터베이스에서는 데이터 복제(Replication)를 통해 지속성을 보장합니다. 
        - 예를 들어, 여러 서버에 데이터를 복제하여 하나의 서버가 장애를 일으켜도 다른 서버에서 데이터를 복구할 수 있습니다.

### **83.5 결론**
- ACID 속성은 데이터베이스의 신뢰성과 안정성을 보장하는 핵심 개념입니다. 각 속성은 상호 보완적으로 작용하며, 데이터베이스 시스템이 올바르게 설계되고 운영되기 위해서는 이 네 가지 속성을 적절히 구현하고 관리해야 합니다. 특히, 실제 환경에서는 성능과 일관성 간의 균형을 고려하여 최적의 설정을 선택하는 것이 중요합니다.

## 84. SQL 요약
- 출처: [Roadmap for Learning SQL](https://www.youtube.com/watch?v=yMqldbY2AAg)

### **84.1 SQL이란?**

*   **관계형 데이터베이스와 상호 작용하기 위한 표준 언어**  
    - SQL(Structured Query Language)은 데이터를 저장, 검색, 수정, 삭제하는 데 사용되
    - 데이터베이스의 구조를 정의하고 관리하며, 복잡한 데이터 조작 작업을 간단한 문법으로 처리할 수 있도록 설계되었습니다.  

*   **다양한 산업 분야에서 필수적인 도구**  
    - 금융, 전자상거래, 의료, 통신 등 다양한 산업에서 데이터 관리와 분석에 필수적으로 사용됩니다.  
    - 예를 들어, 온라인 쇼핑몰에서는 고객 정보, 주문 내역, 재고 현황 등을 관리하기 위해 SQL을 활용


### **84.2 주요 관계형 데이터베이스 관리 시스템 (RDBMS)**

*   MySQL, PostgreSQL, Oracle, SQL Server  
    - **MySQL**: 오픈소스 기반의 경량화된 데이터베이스로, 웹 애플리케이션 개발에서 널리 사용됩니다.  
    - **PostgreSQL**: 고급 기능과 확장성을 제공하는 오픈소스 데이터베이스로, 대규모 데이터 처리에 적합.  
    - **Oracle**: 엔터프라이즈급 데이터베이스로, 안정성과 성능이 뛰어나며 대용량 데이터 관리에 특화.  
    - **SQL Server**: 마이크로소프트의 데이터베이스로, 윈도우 환경에서 최적화된 성능을 제공합니다.  


### **84.3 데이터베이스 기본 구조**

*   **데이터베이스:** 데이터를 저장하고 구성하는 핵심  
    - 데이터베이스는 테이블, 인덱스, 뷰 등의 객체로 구성되며, 논리적이고 물리적인 데이터 관리를 지원.  

*   **테이블:** 데이터베이스 내 데이터 구조화 단위  
    - 데이터를 행과 열로 구성된 2차원 테이블 형태로 저장합니다.  
    - 예를 들어, "사원" 테이블에는 사원번호, 이름, 부서, 연봉 등의 컬럼이 포함될 수 있습니다.  

    *   **컬럼:** 데이터 필드 정의  
        - 각 컬럼은 특정 데이터 유형(예: 숫자, 문자열, 날짜)을 저장하도록 정의됩니다.  

    *   **로우:** 개별 레코드 표현  
        - 하나의 로우는 특정 데이터 항목(예: 한 명의 사원 정보)을 나타냅니다.  

*   **정규화:** 데이터 중복 및 종속성 최소화  
    - 데이터를 여러 테이블로 분리하여 중복을 줄이고, 데이터 일관성을 유지합니다.  
    - 예: 고객 정보와 주문 정보를 별도의 테이블로 분리하여 관리합니다.  

*   **제약 조건:** 데이터 무결성 유지  
    - 데이터의 정확성과 일관성을 보장하기 위해 설정된 규칙입니다.  

    *   **기본 키 (Primary Key):** 각 행을 고유하게 식별  
        - 예: 사원 테이블에서 "사원번호"는 중복되지 않는 값으로 설정됩니다.  

    *   **외래 키 (Foreign Key):** 테이블 간 관계 설정  
        - 예: 주문 테이블의 "사원번호"가 사원 테이블의 기본 키를 참조합니다.  

    *   **UNIQUE:** 중복 값 방지  
        - 예: 이메일 주소는 UNIQUE 제약 조건을 통해 중복 저장을 방지합니다.  

    *   **CHECK:** 데이터 조건 강제  
        - 예: 연봉 컬럼에 CHECK 제약 조건을 적용하여 음수 값을 입력하지 못하도록 합니다.  

    *   **DEFAULT:** 기본값 지정  
        - 예: 가입일 컬럼에 DEFAULT 값으로 현재 날짜를 설정합니다.  


### **84.4 SQL 연산**

*   **데이터 검색:**  
    - `SELECT`: 테이블에서 데이터를 검색하고, 필요한 조건으로 필터링하거나 정렬할 수 있습니다.  
        - 예: `SELECT * FROM customers WHERE country = 'USA';`  
    - `JOIN`: 관련된 테이블의 데이터를 결합하여 복잡한 질의를 수행합니다.  
        - INNER JOIN: 두 테이블 모두에 존재하는 데이터만 반환  
        - LEFT JOIN: 왼쪽 테이블의 모든 데이터와 오른쪽 테이블의 매칭 데이터를 반환  

*   **데이터 조작:**  
    - `INSERT`: 새 레코드를 추가합니다.  
        - 예: `INSERT INTO employees (name, department) VALUES ('John', 'Sales');`  
    - `UPDATE`: 기존 데이터를 수정합니다.  
        - 예: `UPDATE employees SET salary = 5000 WHERE id = 1;`  
    - `DELETE`: 특정 조건에 맞는 레코드를 삭제합니다.  
        - 예: `DELETE FROM employees WHERE id = 1;`  
    - **서브쿼리:** 다른 SQL 문 내에 중첩된 쿼리를 사용하여 복잡한 조건을 처리합니다.  
        - 예: `SELECT name FROM employees WHERE department_id IN (SELECT id FROM departments WHERE location = 'New York');`  

### **84.5 연산자 및 함수**

*   **논리 연산자:**  
    - AND, OR, NOT을 사용하여 복합 조건을 생성합니다.  
        - 예: `SELECT * FROM products WHERE price > 100 AND stock < 50;`  

*   **수치 연산자:**  
    - +, -, *, / 등의 연산자를 사용하여 산술 계산을 수행합니다.  

*   **문자열 연산자:**  
    - CONCAT, LIKE 등을 사용하여 문자열 연결 및 패턴 매칭을 수행합니다.  

*   **함수:**  
    - **수치 함수:** SUM, AVG, ROUND 등을 사용하여 데이터를 계산합니다.  
        - 예: `SELECT AVG(price) FROM products;`  
    - **문자열 함수:** CONCAT, SUBSTRING 등을 사용하여 문자열 데이터를 조작합니다.  
        - 예: `SELECT CONCAT(first_name, ' ', last_name) AS full_name FROM employees;`  
    - **날짜/시간 함수:** GETDATE, DATEADD 등을 사용하여 시간 데이터를 처리합니다.  
        - 예: `SELECT DATEADD(day, 7, order_date) AS delivery_date FROM orders;`  
    - **집계 함수:** COUNT, MIN, MAX 등을 사용하여 데이터를 요약합니다.  
        - `GROUP BY`: 특정 컬럼을 기준으로 데이터를 그룹화합니다.  
            - 예: `SELECT department, COUNT(*) FROM employees GROUP BY department;`  
        - `HAVING`: 그룹화된 결과에 대한 추가 필터링을 수행합니다.  
            - 예: `SELECT department, COUNT(*) FROM employees GROUP BY department HAVING COUNT(*) > 5;`  

### **84.6 데이터 타입 및 인덱스**

*   **데이터 타입:**  
    - INT, DECIMAL, VARCHAR, TEXT, DATE, TIMESTAMP, BIT 등 다양한 데이터 타입을 제공하여 데이터 저장 공간을 최적화하고 성능을 향상시킵니다.  

*   **인덱스:**  
    - 데이터 검색 속도를 빠르게 하기 위해 인덱스를 생성합니다.  
    - 하지만 INSERT, UPDATE, DELETE 작업 시 인덱스 유지에 따른 오버헤드가 발생할 수 있습니다.  

### **84.7 SQL 하위 언어**

*   **DDL (Data Definition Language):**  
    - CREATE TABLE, ALTER TABLE 등의 명령어를 사용하여 테이블 구조를 정의하고 변경합니다.  

*   **DCL (Data Control Language):**  
    - GRANT, REVOKE 등의 명령어를 사용하여 데이터베이스 접근 권한을 관리합니다.  

*   **TCL (Transaction Control Language):**  
    - COMMIT, ROLLBACK, SAVEPOINT 등의 명령어를 사용하여 트랜잭션을 관리하고 ACID(원자성, 일관성, 독립성, 지속성) 속성을 보장합니다.  


## 85. API 보안을 위한 12가지 주요 팁
- 출처: [Top 12 Tips For API Security](https://www.youtube.com/watch?v=6WZ6S-qmtqY)

### 85.1 안전한 API를 구축하기 위한 12가지 필수 팁 요약


1.   **HTTPS를 사용하여 API 통신 암호화:** 
- HTTPS는 클라이언트와 서버 간에 전송되는 데이터를 암호화하여 중간자 공격 및 도청을 방지합니다.  
- API 키, 세션 토큰, 사용자 데이터와 같은 민감한 정보를 보호하는 데 중요합니다.
2.  **OAuth 2.0을 사용하여 권한 부여:** 
- OAuth 2.0은 자격 증명을 직접 공유하지 않고 타사 애플리케이션에 제한된 리소스 접근 권한을 부여하는 산업 표준 프로토콜입니다. 
- 사용자가 Google 또는 Facebook으로 로그인하거나 클라우드 저장소에 접근하는 등의 시나리오에서 유용하며, 비밀번호를 저장할 필요 없이 안전하게 통합할 수 있습니다.
3.  **WebAuthn을 통한 강력한 사용자 인증:**     
- WebAuthn은 공개 키 암호화 및 생체 인식(지문, 얼굴 인식 등)을 활용하여 기존 비밀번호 기반 인증보다 안전하고 사용자 친화적인 인증 방식을 제공합니다. 
- 피싱 및 자격 증명 스터핑 공격으로부터 사용자 계정을 보호하는 데 효과적이며 주요 브라우저 및 플랫폼에서 지원됩니다.
4.  **다양한 접근 수준의 API 키 구현:** 
- 단일 API 키를 모든 서비스 및 작업에 사용하는 것은 위험합니다. 대신 각 키에 특정 권한과 범위를 정의하여 접근 수준을 다양화해야 합니다. 
- 예를 들어 읽기 전용 키, 쓰기 키, 관리자 키 등을 사용하여 하나의 키가 손상되더라도 공격 범위를 제한할 수 있습니다. API 키를 주기적으로 로테이션하고 손상된 키를 즉시 해지하는 것도 중요합니다.
5.  **역할 기반 접근 제어(RBAC)를 통한 권한 부여:** 
- 클라이언트에게 특정 권한을 가진 역할을 할당하여 접근 권한을 관리합니다. 
- 예를 들어 뷰어 역할은 데이터를 읽을 수만 있고, 편집자 역할은 데이터를 수정할 수도 있습니다. 최소 권한 원칙을 준수하여 잠재적인 공격 표면을 줄입니다.
6.  **요청률 제한(Rate Limiting) 구현:** 
- 클라이언트가 특정 시간 내에 만들 수 있는 요청 수를 제어하여 악의적인 공격이나 버그가 있는 클라이언트로 인한 API 과부하를 방지합니다. 
- IP 주소, 사용자 ID, API 키 등 다양한 요소를 기반으로 제한을 설정할 수 있으며, 요청 유형이나 리소스에 따라 다른 제한을 적용할 수도 있습니다.
7.  **API 버전 관리:** 
- API를 시간이 지남에 따라 발전시키면서 기존 클라이언트와의 호환성을 유지하기 위해 버전 관리가 필수적입니다. 
- URL에 버전 번호를 포함시키는 것이 일반적인 방법이며 (예: /v1/users/123), 각 버전별로 요구 사항 및 문서를 관리할 수 있습니다.
8.  **허용 목록(Allow Listing) 사용:** 
- 명시적으로 허용된 신뢰할 수 있는 엔터티(IP 주소, 사용자 ID, API 키 등)에만 접근을 허용하고 나머지는 기본적으로 거부하는 보안 방식입니다. 
- 이는 알려진 악의적인 행위자 몇 명을 차단하고 나머지는 허용하는 거부 목록(Deny Listing) 방식보다 더 안전한 "기본 거부(deny all)" 원칙을 따릅니다.
9.  **OWASP API 보안 Top 10 위험 검토 및 해결:** 
- OWASP(Open Web Application Security Project)는 API의 가장 중요한 보안 위험 목록을 제공합니다. 
- API 설계 및 개발 단계에서 이러한 위험(예: Broken Object Level Authorization, Security Misconfiguration 등)을 검토하고 적절한 대응책을 구현해야 합니다.
10.  **API 게이트웨이 활용:** 
- API 게이트웨이는 클라이언트가 백엔드 서비스 및 API에 접근하는 단일 진입점 역할을 합니다.
- 인증, 권한 부여, 요청률 제한과 같은 보안 정책을 중앙 집중식으로 적용하고 관리할 수 있으며, 트래픽 관리, 캐싱, 로깅, 모니터링과 같은 추가적인 이점도 제공합니다.
11.  **안전한 오류 처리:** 
- 오류 발생 시 클라이언트에게 유용한 정보를 제공하되, 민감한 내부 정보나 공격에 활용될 수 있는 세부 정보(예: SQL 쿼리 실패 메시지, 스택 트레이스 등)는 노출하지 않아야 합니다. 
- 오류를 클라이언트 오류와 서버 오류로 분류하고 적절한 HTTP 상태 코드를 반환하는 것이 좋습니다.
12. **강력한 입력 유효성 검사:** 
- 클라이언트로부터 수신하는 모든 데이터(요청 파라미터, 헤더, 페이로드 등)에 대해 유효성 검사를 철저히 수행해야 합니다. 
- 이는 SQL 인젝션, XSS(크로스 사이트 스크립팅) 등 다양한 취약점을 예방하는 데 중요하며, 클라이언트 측과 서버 측 모두에서 검증을 수행하고 서버 측에서는 유효성 검사 라이브러리나 프레임워크를 활용하는 것이 좋습니다.

## 86. 주요 엔지니어링 블로그
- 출처: [Top 9 Must-Read Blogs for Engineers](https://www.youtube.com/watch?v=UuT61kf292A)



### **86.1 소개**

*   주요 기술 기업들이 엔지니어링 문제 해결 방식을 엿볼 수 있는 최고의 엔지니어링 블로그 소개.  
    *   이 블로그들은 현대 소프트웨어 아키텍처, 클라우드 인프라, 데이터 처리, 머신러닝 등 다양한 분야에서의 최신 트렌드와 실질적인 사례를 제공합니다. 이를 통해 개발자와 엔지니어들은 실제 문제 해결 과정에서 얻은 통찰력을 학습하고 적용할 수 있습니다.

### **86.2 블로그 목록**

1.   [**Netflix Tech Blog:**](https://netflixtechblog.com/)
*   클라우드 컴퓨팅 활용 사례 소개 (마이크로서비스, 데이터 파이프라인 등).  
    *   Netflix는 AWS를 기반으로 한 마이크로서비스 아키텍처를 통해 초대규모 트래픽을 효율적으로 처리하며, 이를 통해 글로벌 스트리밍 서비스를 안정적으로 제공하고 있습니다.
*   "Chaos Monkey" 도구를 통한 시스템 복원력 강화 (고의적인 인스턴스 비활성화).  
    *   Chaos Monkey는 의도적으로 서버를 중단시키는 실험을 통해 시스템의 복원력을 테스트하는 도구로, 예상치 못한 장애 상황에서도 서비스가 지속적으로 운영되도록 보장합니다.

2.   [**Uber Blog:**](https://www.uber.com/en-KR/blog/seoul/)
*   머신러닝 (ML) 및 인공지능 (AI)을 활용한 수요 예측, 모델링, 동적 가격 책정 등 문제 해결 방식 소개.  
    *   Uber는 실시간 데이터 분석과 머신러닝을 결합하여 사용자의 수요 패턴을 예측하고, 이를 바탕으로 드라이버와 라이더를 최적화된 방식으로 매칭합니다.
*   실시간 Dispatch 시스템 최적화를 통한 라이더-드라이버 매칭 효율성 향상.  
    *   Uber의 Dispatch 시스템은 복잡한 알고리즘을 통해 최단 시간 내에 가장 적합한 드라이버를 할당하며, 이는 사용자 경험을 크게 개선합니다.

3.   [**Cloudflare Blog:**](https://blog.cloudflare.com/)
*   CDN 및 DDoS 방어 서비스 제공 업체의 웹사이트 속도 및 보안 유지 관련 심층적인 인사이트 제공.  
    *   Cloudflare는 전 세계적으로 분산된 네트워크를 통해 웹사이트의 로딩 속도를 극대화하고, 동시에 사이버 공격으로부터 웹사이트를 보호합니다.
*   "100만 패킷/초 수신 방법" 게시글: Linux 시스템에서 높은 패킷 처리 속도 달성 방법 (Multi-Queue NIC 활용).  
    *   이 게시물에서는 고성능 네트워크 환경에서 패킷 처리 성능을 극대화하기 위한 구체적인 기술적 접근법을 다룹니다.

4.   [**Engineering at Meta:**](https://engineering.fb.com/)
*   대규모 데이터베이스 확장 및 AI 기반 가짜 뉴스 탐지 등 엔지니어링 문제 해결 방식 소개.  
    *   Meta는 Facebook, Instagram 등 대규모 플랫폼에서 발생하는 데이터를 처리하기 위해 혁신적인 데이터베이스 기술을 개발하고 있습니다.
*   "RocksDB" 활용 사례: 대용량 데이터 처리 및 실시간 사용자 서비스 지원을 위한 Key-Value 스토어 활용.  
    *   RocksDB는 메모리와 디스크를 효율적으로 활용하여 대규모 데이터를 빠르게 처리할 수 있도록 설계된 오픈소스 데이터베이스입니다.

5.   [**LinkedIn Engineering:**](https://www.linkedin.com/blog/engineering)
*   Kafka 탄생 비화 및 분산 데이터 시스템에서의 로그 중요성 강조.  
    *   LinkedIn은 대규모 데이터 처리를 위해 Apache Kafka를 개발했으며, 이는 오늘날 실시간 데이터 스트리밍의 표준 도구로 자리 잡았습니다.
*   로그의 개념을 널리 알리는 데 기여.  
    *   로그는 분산 시스템에서 데이터의 일관성을 유지하고 오류를 추적하는 데 필수적인 역할을 합니다.

6.   [**Discord Blog:**](https://discord.com/blog)
*   Elixir를 활용한 고도의 동시성 시스템 구축 사례 소개.  
    *   Discord는 Elixir와 Erlang VM을 활용하여 수백만 명의 동시 접속자를 처리할 수 있는 안정적인 채팅 플랫폼을 구축했습니다.
*   Elixir 초기 도입 후 겪은 어려움 및 이를 해결하기 위한 라이브러리 개발 과정 공유.  
    *   초기에는 언어 생태계의 제한으로 인해 자체 라이브러리를 개발해야 했지만, 이를 통해 더욱 강력한 시스템을 구축할 수 있었습니다.

7.   [**AWS Architecture Blog:**](https://aws.amazon.com/ko/blogs/architecture/)
*   AWS 서비스 활용 사례 및 모범 사례 소개.  
    *   AWS는 다양한 산업의 고객들이 클라우드를 통해 비즈니스를 혁신할 수 있도록 구체적인 사례와 팁을 제공합니다.
*   "Well-Architected" 시리즈: 클라우드 아키텍처 모범 사례 및 다양한 아키텍처 패턴 소개.  
    *   Well-Architected Framework는 성능, 보안, 신뢰성, 비용 최적화 등을 고려한 클라우드 아키텍처 설계를 위한 가이드라인입니다.

8.   [**Slack Engineering:**](https://slack.engineering/)
*   대용량 데이터 및 사용자 트래픽 처리 플랫폼 구축 및 확장 방식 소개.  
    *   Slack은 실시간 메시징과 파일 공유를 지원하기 위해 고성능 데이터베이스와 캐싱 시스템을 활용합니다.
*   "Retest" 도구를 통한 MySQL 수평 확장 및 샤딩 관리 방식 소개.  
    *   Retest는 MySQL 데이터베이스의 샤딩 및 확장을 자동화하여 대규모 트래픽을 처리할 수 있도록 돕습니다.

9.   [**Stripe Blog:**](https://stripe.com/blog)
*   안정적이고 안전한 금융 시스템 구축 인사이트 제공.  
    *   Stripe는 전 세계적으로 사용되는 결제 시스템을 구축하며, 높은 수준의 보안과 신뢰성을 유지하는 데 집중합니다.
*   "Stripe Radar" 솔루션: 머신러닝 기반 실시간 사기 탐지 시스템 소개.  
    *   Stripe Radar는 거래 패턴을 분석하여 불법 거래를 실시간으로 탐지하고 차단합니다.


## 87. 좋은 코드를 작성하기 위한 10가지 코딩 원칙
- 출처: [10 Coding Principles Explained in 5 Minutes](https://www.youtube.com/watch?v=GmXPwRNIrAU)

### 87.1 좋은 코드를 작성하기 위한 10가지 코딩 원칙

**1. 코딩 스타일:**
*   **일관성 유지:**  
    - 팀 내 공유된 코딩 스타일 가이드 (예: Python의 PEP 8, Java의 Google Java Style Guide)를 준수하여 코드의 가독성을 높임.  
    - 일관된 스타일은 팀원 간 코드 리뷰와 협업을 용이하게 하며, 신규 개발자도 쉽게 코드베이스를 이해할 수 있게 합니다. 또한, 스타일 가이드를 문서화하고 공유하면 프로젝트의 장기적인 유지보수성을 높이는 데 기여합니다.

*   **자동 코드 포매터 활용:**  
    - Black, Prettier와 같은 도구를 사용하여 스타일 가이드를 자동으로 적용하고 코드 논리와 기능에 집중.  
    - 자동 포매터는 스타일 논쟁을 줄이고, 개발자가 중요한 문제에 집중할 수 있도록 도와줍니다. 특히 대규모 팀에서는 코드 스타일에 대한 불필요한 의견 충돌을 최소화하는 데 효과적입니다.

**2. 주석:**
*   **"코드는 어떻게, 주석은 왜":**  
    - 코드의 의도를 명확히 설명하고, 복잡한 알고리즘이나 설계 결정에 대한 배경 설명 제공.  
    - 주석은 단순히 "무엇을 하는지"가 아니라 "왜 이렇게 설계했는지"를 설명하는 데 초점을 맞춰야 합니다. 이를 통해 후속 개발자가 코드의 의도를 이해하고 수정 시 올바른 방향으로 나아갈 수 있습니다.

*   **참고할 만한 프로젝트:**  
    - Postgres, SQLite, Django 등의 오픈 소스 프로젝트의 주석 스타일 참고.  
    - 이러한 오픈 소스 프로젝트는 오랜 시간 동안 많은 사람들이 협력하여 개선해온 코드베이스를 가지고 있어, 주석 작성의 모범 사례를 제공합니다. 특히 주석이 너무 많거나 적지 않게 균형을 맞춘 점이 특징입니다.

**3. 견고성 (Robustness):**
*   **예외 처리:**  
    - 예상치 못한 상황에서도 코드의 작동을 보장하기 위해 적절한 오류 처리 추가.  
    - 예외 처리는 사용자 경험을 보호하고, 애플리케이션의 안정성을 높이는 데 필수적입니다. try-catch 블록이나 언어별 예외 처리 메커니즘을 적절히 활용하세요.

*   **자원 관리:**  
    - 메모리, 파일 핸들, 네트워크 연결과 같은 자원을 올바르게 사용하고 해제. (C++의 RAII, Go의 'defer' 활용)  
    - 자원 누수는 성능 저하와 시스템 장애를 유발할 수 있습니다. 언어별 자원 관리 패턴을 숙지하고, 자원을 열었으면 반드시 닫는 원칙을 지키세요.

*   **방어적 프로그래밍:**  
    - 발생 가능한 오류를 예측하고 대비. (입력값 검증, 빠른 실패를 위한 가드 절 사용, 철저한 오류 처리, 단언문 활용)  
    - 방어적 프로그래밍은 코드의 신뢰성을 높이고, 잠재적인 버그를 사전에 차단하는 데 도움이 됩니다. 특히 사용자 입력을 다룰 때는 항상 유효성을 검사해야 합니다.

**4. SOLID 원칙:**
*   **단일 책임 원칙 (Single Responsibility):**  
    - 클래스는 단 하나의 책임을 가져야 함.  
    - 이 원칙을 준수하면 클래스가 특정 역할에만 집중하게 되어 코드의 응집도가 높아지고 재사용성이 증가합니다.

*   **개방/폐쇄 원칙 (Open/Closed):**  
    - 확장에는 열려 있고, 수정에는 닫혀 있어야 함.  
    - 새로운 기능을 추가할 때 기존 코드를 수정하지 않고 확장할 수 있도록 설계하면 유지보수 비용을 줄일 수 있습니다.

*   **리스코프 치환 원칙 (Liskov Substitution):**  
    - 자식 클래스는 부모 클래스를 대체할 수 있어야 함.  
    - 이 원칙을 위반하면 상속 구조에서 예기치 않은 동작이 발생할 수 있습니다. 따라서 자식 클래스는 부모 클래스의 행동 규약을 항상 준수해야 합니다.

*   **인터페이스 분리 원칙 (Interface Segregation):**  
    - 클라이언트는 자신이 사용하지 않는 메서드에 의존하지 않아야 함.  
    - 큰 인터페이스를 작은 단위로 분리하면 필요한 기능만 선택적으로 구현할 수 있어 코드의 유연성이 높아집니다.

*   **의존성 역전 원칙 (Dependency Inversion):**  
    - 고수준 모듈은 저수준 모듈에 의존하지 않고, 둘 다 추상화에 의존해야 함.  
    - 이 원칙은 의존성 주입(DI)과 결합되어 테스트 가능성을 높이고, 코드 간 결합도를 낮추는 데 기여합니다.

*   **목적:**  
    - 이해, 변경, 확장이 쉬운 코드 작성. 코드 결합도를 낮추고 테스트 용이성을 높임.  
    - SOLID 원칙은 객체지향 설계의 핵심을 이루며, 이를 준수하면 코드베이스가 복잡해져도 유지보수가 용이해집니다.

**5. 쉬운 테스팅:**
*   **테스팅 용이성을 고려한 설계:**  
    - 컴포넌트를 단순하고 명확하게 유지하고 단일 책임 원칙을 준수.  
    - 테스트 가능한 코드는 독립적이어야 하며, 외부 의존성을 최소화하거나 모킹(Mocking)할 수 있어야 합니다.

*   **자동화된 테스팅:**  
    - 테스트 커버리지를 확보하여 코드 변경 및 기능 추가 시 안정성 확보.  
    - 단위 테스트, 통합 테스트, E2E 테스트를 조합하여 다양한 레벨에서 코드의 정확성을 검증하세요. CI/CD 파이프라인에 테스트를 통합하면 더욱 효과적입니다.

**6. 추상화:**
*   **적절한 추상화 수준 유지:**  
    - 복잡성을 숨기되, 과도한 추상화로 인해 불필요한 계층이 생기지 않도록 주의.  
    - 추상화는 코드의 복잡성을 줄이는 강력한 도구지만, 지나치면 오히려 이해하기 어려운 코드가 될 수 있습니다. 필요에 따라 적절한 수준을 찾아야 합니다.

*   **예시:**  
    - 다양한 데이터베이스 시스템을 사용하는 경우, 공통 작업을 위한 추상 'Database' 클래스를 만들고, 각 데이터베이스에 대한 구체적인 서브클래스 구현.  
    - 이는 전략 패턴(Strategy Pattern)의 한 예로, 특정 데이터베이스에 종속되지 않고 유연하게 확장할 수 있는 설계를 제공합니다.

**7. 디자인 패턴:**
*   **적절한 도구 선택:**  
    - 일반적인 문제에 대한 효과적인 해결책을 제공하지만, 모든 문제에 적용할 필요는 없음.  
    - 디자인 패턴은 문제 해결의 가이드라인이지, 무조건 따라야 할 규칙이 아닙니다. 문제의 맥락에 맞는 패턴을 선택하세요.

*   **MVC 패턴 예시:**  
    - 데이터, 표현, 사용자 상호 작용을 분리하는 데 유용.  
    - MVC(Model-View-Controller)는 웹 애플리케이션에서 널리 사용되는 패턴으로, 관심사를 분리하여 유지보수를 용이하게 합니다.

**8. 최소한의 전역 의존성:**
*   **지역 상태 및 파라미터 전달:**  
    - 전역 변수 및 인스턴스 사용을 최소화하여 코드의 조직성을 높이고 버그 추적을 용이하게 함.  
    - 전역 상태는 예측 불가능한 부작용(Side Effect)을 초래할 수 있습니다. 지역 상태를 사용하면 코드의 독립성이 높아지고 디버깅이 쉬워집니다.

*   **의존성 주입:**  
    모듈 내부에서 직접 서비스를 생성하는 대신 인터페이스를 정의하고 구체적인 구현을 주입. (테스트 용이성 향상)  
    - 의존성 주입은 테스트 환경에서 모의 객체(Mock Object)를 주입할 수 있어 단위 테스트를 쉽게 작성할 수 있게 합니다.

**9. 리팩토링:**
*   **코드 유지보수:**  
    - 코드 중복, 복잡성, 부적절한 이름과 같은 문제를 해결하여 기술 부채를 줄이고 코드 이해도 및 수정 용이성을 높임.  
    - 리팩토링은 코드의 내부 구조를 개선하면서 외부 동작을 변경하지 않는 작업입니다. 이를 통해 코드베이스의 건강성을 유지할 수 있습니다.

**10. 보안:**
*   **보안을 고려한 코딩:**  
    - SQL injection, XSS (Cross-site Scripting)과 같은 일반적인 보안 위협에 주의.  
    - 보안 취약점은 애플리케이션의 신뢰성을 손상시키고 심각한 피해를 초래할 수 있습니다. 항상 최신 보안 권고사항을 준수하세요.

*   **입력값 검증 및 소독:**  
    - 사용자 입력 유효성을 검사하고 안전한 쿼리 및 출력 인코딩 기술 사용.  
    - 사용자 입력은 언제나 신뢰할 수 없으므로, 입력값을 검증하고 필요한 경우 소독(Sanitization) 과정을 거쳐야 합니다.

*   **민감한 데이터 보호:**  
    - 필요한 개인 정보만 수집하고 안전하게 관리.  
    - GDPR, CCPA와 같은 개인정보 보호법을 준수하고, 민감한 데이터는 암호화하여 저장하세요. 데이터 유출 시 피해를 최소화할 수 있습니다.


## 88. 주요 API 프로토콜 비교
- 출처: [Top 9 Most Popular API Protocols](https://www.youtube.com/watch?v=zY2DMpCUfCg)

### 88.1 주요 API 프로토콜 비교
1.REST
*   정의: 
    *   HTTP 표준 메서드(GET, POST, PUT, DELETE 등)를 사용하며, Stateless 특성을 가지고 있어 서버가 클라이언트의 상태를 저장하지 않습니다. 웹 서비스의 표준으로 자리 잡았으며, 특히 간단한 CRUD(Create, Read, Update, Delete) 작업에 적합
*   장점:
    *   간단하고 직관적이어서 배우기 쉽고, RESTful 아키텍처는 확장성과 재사용성이 뛰어나며, 웹 서비스와의 호환성이 우수하여 널리 사용됩니다. 
*   단점:
    *   Over-fetching(필요 이상의 데이터를 받아오는 문제)과 Under-fetching(필요한 데이터를 충분히 받아오지 못하는 문제) 같은 문제가 발생할 수 있으며, 관련 데이터를 가져오기 위해 다중 요청이 필요할 경우 네트워크 지연이 증가할 수 있습니다. 
*   사용사례: 
    *   REST는 주로 웹 API, 모바일 애플리케이션 백엔드, 마이크로서비스 통신에 사용됩니다.

2.GraphQL
- 정의:
    - 단일 쿼리로 필요한 데이터만 선택적으로 요청할 수 있으며, Strongly typed schema를 제공하여 데이터 구조와 타입을 명확히 정의합니다. 
    - REST의 단점을 보완하기 위해 Facebook에서 개발
- 장점: 
    - 프론트엔드 개발자가 백엔드에서 어떤 데이터를 가져올지 직접 제어할 수 있고, Over-fetching과 Under-fetching 문제를 해결하여 네트워크 효율성을 향상시킬 수 있으며, 실시간 업데이트를 위한 Subscription 기능을 지원한다는 점입니다. 
- 단점: 
    - 복잡한 쿼리가 백엔드 서버에 과부하를 유발할 가능성이 있으며, 동적 특성으로 인해 전통적인 HTTP 캐싱 전략 적용이 어려운 점과 학습 곡선이 다소 가파르다는 단점이 있습니다. 
- 사용사례: 
    - 소셜 미디어 플랫폼, 데이터 집약적인 애플리케이션, 다중 데이터 소스 통합에 주로 사용.

3.Webhooks
- 정의:
    - 특정 이벤트가 발생했을 때 트리거되는 HTTP 콜백 메커니즘으로, 서버 간 비동기식 통신을 지원합니다. 
- 장점: 
    - 시스템 간 실시간 통신이 가능하여 응답 속도가 빠르고, 불필요한 폴링 없이 이벤트 기반으로 동작하여 컴퓨팅 파워 및 대역폭을 절약할 수 있으며, 분리된 아키텍처를 유지하면서도 유연한 통합이 가능하다는 것입니다. 
- 단점: 
    - 보안 취약점에 대한 대비가 필요하고, 신뢰할 수 없는 이벤트 소스로부터의 데이터 유효성 검증이 중요합니다. 
- 사용사례: 
    - 결제 시스템, 알림 서비스, CI/CD 파이프라인에 사용됩니다. 

4.SOAP
- 정의: 
    - XML 기반의 엄격한 표준을 준수하며, WSDL(Web Services Description Language)을 통해 서비스 계약을 정의하고 강력한 보안 기능(인증, 권한 부여, 암호화)을 포함합니다. 엔터프라이즈 환경에서 주로 사용
- 장점: 
    - 계약 준수 및 데이터 무결성이 중요한 환경에서 안정적이며, 다양한 프로그래밍 언어와 플랫폼 간 상호 운용성을 보장한다는 점입니다. 
- 단점:
    -  XML 형식으로 인해 메시지 크기가 커지고 처리 속도가 느릴 수 있으며, 복잡한 구조로 인해 학습 및 구현 난이도가 높고, REST에 비해 유연성이 떨어지는 단점이 있습니다.
- 사용사례: 금융 서비스, 의료 정보 시스템, 정부 기관, 엔터프라이즈급 시스템에 주로 사용.

5.WebSocket
- 정의:
    - 클라이언트와 서버 간 지속적인 양방향 연결을 지원하며, 낮은 지연 시간을 목표로 설계되었습니다. 실시간 데이터 전송이 필요한 애플리케이션에서 필수적
- 장점: 
    - WebSocket의 장점은 실시간 데이터 전송에 최적화되어 채팅, 게임, 거래 플랫폼 등에 적합하고, 연결이 유지되는 동안 데이터를 지속적으로 주고받을 수 있다는 것입니다. 
- 단점: 
    - 초기 연결 설정 시 추가 리소스가 필요하고, 방화벽 또는 프록시 서버와의 호환성 문제가 있을 수 있습니다. 
- 사용사례: 
    - 채팅 애플리케이션, 온라인 게임, 실시간 주식 거래 플랫폼, IoT 장치 통신에 사용.

6.gRPC
- 정의:
    - HTTP/2 기반으로 고성능 통신을 지원하며, Protocol Buffers(Protobuf)를 사용하여 데이터 직렬화 및 역직렬화를 수행합니다. 
- 장점: 
    - 저지연, 고처리량으로 분산 시스템에 적합하고, 다국어 지원으로 다양한 프로그래밍 언어 간 상호 운용성을 보장하며, 스트리밍 기능을 통해 지속적인 데이터 전송이 가능하다는 점입니다. 
- 단점: 
    - Protobuf 형식이 직관적이지 않아 디버깅이 어려울 수 있고, 브라우저에서 직접 사용하기 어려운 제약이 있습니다. 
- 사용사례: 
    - 마이크로서비스 아키텍처, 클라우드 네이티브 애플리케이션, 분산 시스템에 주로 사용.


## 89. 모바일 앱 출시 가이드 (iOS & Android)
- 출처: [Do You Know How Mobile Apps Are Released?](https://www.youtube.com/watch?v=RIX4ufelA58)

### **89.1 개발 준비**

*   **플랫폼 등록:**
    *   iOS: Apple Developer Program 가입 (연회비 발생)
        *   **Apple Developer Program은 연간 $99의 비용이 발생하며, 이 프로그램에 가입해야 앱을 App Store에 배포할 수 있습니다. 또한, push notification과 같은 고급 기능 사용이 가능해**
    *   Android: Google Play Console 개발자 등록 (일회성 등록비)
        *   **Google Play Console의 경우 일회성으로 $25의 등록비를 지불하면 됩니다. 이후 앱 배포 및 관리가 가능합니다.**
*   **개발 언어 선택:**
    *   iOS: Swift, Objective-C
        *   **Swift는 Apple에서 개발한 최신 언어로, 높은 성능과 간결한 문법이 특징입니다. Objective-C는 구형 프로젝트에서 주로 사용되며, 여전히 지원되지만 점차 Swift로 대체되고 있습니다.**
    *   Android: Java, Kotlin
        *   **Kotlin은 Google이 공식적으로 권장하는 언어로, Java보다 간결하고 안전한 코드 작성이 가능합니다. Java는 오랜 역사를 가진 언어로, 많은 기존 프로젝트에서 사용됩니다.**
*   **개발 도구 선택:**
    *   iOS: Xcode
        *   **Xcode는 Apple이 제공하는 통합 개발 환경(IDE)으로, iOS 앱 개발에 필수적입니다. 인터페이스 디자인, 디버깅, 시뮬레이션 등 다양한 기능을 제공합니다.**
    *   Android: Android Studio
        *   **Android Studio는 Google이 제공하는 Android 전용 IDE로, Gradle 기반 빌드 시스템, 실시간 레이아웃 미리보기, 강력한 디버깅 도구 등을 포함합니다.**
    *   **대안:** React Native, Flutter (크로스 플랫폼)
        *   장점: 개발 속도 향상, 비용 절감
            *   **React Native와 Flutter는 단일 코드베이스로 iOS와 Android 모두를 지원하는 크로스 플랫폼 프레임워크입니다. 이를 통해 개발 시간과 비용을 크게 절감할 수 있습니다.**
        *   단점: Native 앱 대비 성능, 기기 특정 기능 접근 제한 가능성
            *   **하지만 크로스 플랫폼의 경우 네이티브 앱에 비해 성능이 다소 떨어질 수 있으며, 특정 기기의 하드웨어나 API를 완벽히 활용하지 못할 수 있습니다.**

### **89.2 빌드 및 테스트**

*   앱 바이너리 컴파일
    *   **앱을 실행 가능한 형태로 변환하는 과정입니다.**
    *   iOS에서는 .ipa 파일, Android에서는 .apk 또는 .aab 파일로 패키징됩니다.
*   테스팅 도구 활용:
    *   iOS: XCTest
        *   **XCTest는 Apple이 제공하는 테스트 프레임워크로, 유닛 테스트, UI 테스트, 성능 테스트 등**
    *   Android: Espresso
        *   **Espresso는 Android용 UI 테스트 프레임워크로, 앱의 사용자 인터페이스를 자동화된 방식으로 테스트할 수 있습니다.**
*   **Device Farm 활용 (선택 사항):**
    *   AWS Device Farm, BrowserStack 등
        *   장점: 다양한 기기 및 OS 버전에서 자동 테스트 가능
            *   **Device Farm은 실제 기기에서 앱을 테스트할 수 있는 클라우드 서비스로, 다양한 기기와 운영 체제 조합에서 문제를 발견할 수 있습니다.**
        *   단점: 비용 발생
            *   **서비스 이용 시 시간당 또는 테스트 세션당 비용이 발생하므로 예산을 고려해야 합니다.**
*   CI/CD 파이프라인에 통합하여 빌드 및 테스트 프로세스 자동화
    *   **CI/CD(Continuous Integration/Continuous Deployment)를 통해 코드 변경이 있을 때마다 자동으로 빌드 및 테스트를 수행할 수 있습니다.**
    *   **Jenkins, GitHub Actions, Bitrise 등의 도구를 사용할 수 있습니다.**
*   **목표:** 최고 품질 및 성능 확보, 안정적인 릴리즈 후보 빌드 생성
    *   **최종 목표는 앱의 안정성을 보장하고, 사용자가 겪을 수 있는 문제를 사전에 방지하는 것입니다.**

### **89.3 품질 보증 (QA)**

*   **알파 테스트:** 내부 테스트를 통해 초기 버그 발견
    *   **알파 테스트는 개발팀 내부에서 수행되며, 앱의 핵심 기능이 정상적으로 작동하는지 확인합니다.**
*   **Dogfooding:** 팀 구성원이 앱을 광범위하게 사용
    *   **Dogfooding은 개발자 및 관련 팀원들이 실제로 앱을 사용해보는 과정으로, 사용자 경험을 직접 체험하고 문제점을 발견할 수 있습니다.**
*   **베타 테스트:** 사용자 그룹을 통해 피드백 수집
    *   iOS: Apple TestFlight (테스터 제한: 10,000명)
        *   **TestFlight는 Apple이 제공하는 베타 테스트 도구로, 최대 10,000명의 테스터에게 앱을 배포**
    *   Android: Google Play 베타 테스팅 (테스터 제한 존재)
        *   **Google Play Console에서도 베타 테스트를 진행할 수 있으며, 개발자는 테스트 그룹을 설정하고 피드백을 수집할 수 있습니다.**
*   실제 사용 환경에서 발생하는 문제점 파악
    *   **실제 사용자 환경에서 앱이 어떻게 동작하는지 확인하는 것은 중요합니다. 네트워크 상태, 기기 성능, 사용자 행동 패턴 등이 앱의 동작에 영향을 줄 수 있습니다.**

### **89.4 내부 승인 및 규정 준수**

*   주요 이해 관계자로부터 UX 일관성, 브랜드 일치, 기술 성능 지표 등 기준에 대한 승인 획득
    *   **UX 일관성은 사용자 경험을 균일하게 유지하는 것을 의미하며, 브랜드 일치는 앱이 회사의 이미지와 가치를 반영하도록 하는 것을 목표로 합니다.**
*   앱 스토어 가이드라인 및 보안, 개인 정보 보호 관련 산업 규정 준수 확인
    *   **Apple과 Google은 각각 엄격한 앱 스토어 가이드라인을 가지고 있으며, 이를 준수하지 않으면 앱이 거부될 수 있습니다. GDPR, CCPA와 같은 데이터 보호 법률도 반드시 고려해야 합니다.**

### **89.5 앱 스토어 최적화**

*   앱 검색 결과 상위 노출을 위한 최적화 작업
    *   제목, 설명, 키워드 등 메타데이터 최적화
        *   **사용자가 검색할 가능성이 높은 키워드를 포함한 제목과 설명을 작성하면 앱의 가시성이 향상.**
    *   다양한 지역 사용자 유치를 위한 콘텐츠 현지화
        *   **다양한 언어로 앱 설명과 메타데이터를 번역하거나 지역별로 맞춤형 콘텐츠를 제공하면 더 많은 사용자를 유치할 수 있습니다.**
    *   앱의 특징을 잘 보여주는 스크린샷 및 아이콘 디자인
        *   **첫인상을 결정짓는 중요한 요소로, 시각적으로 매력적인 스크린샷과 아이콘은 다운로드율을 높이는 데 기여합니다.**
    *   업데이트 내용, 개선 사항 등을 창의적으로 담은 릴리즈 노트 작성
        *   **릴리즈 노트는 사용자에게 앱의 새로운 기능이나 수정 사항을 알리는 창구로, 명확하고 흥미롭게 작성해야 합니다.**

### **89.6 앱 제출**

*   **iOS:** App Store Connect를 통해 Apple 가이드라인 준수하여 제출
    *   **App Store Connect는 앱을 제출하고 관리하는 포털로, 앱의 메타데이터, 스크린샷, 릴리즈 노트 등을 입력해야 합니다.**
*   **Android:** Google Play Console을 통해 Google 정책 준수하여 제출
    *   **Google Play Console에서는 앱의 내부 테스트 트랙, 베타 트랙, 프로덕션 트랙 중 하나를 선택하여 제출할 수 있습니다.**
*   앱 검토 지연에 대비하여 충분한 시간 확보
    *   **Apple의 경우 평균 24~48시간이 소요되며, Google은 대부분 즉시 검토가 완료됩니다. 하지만 예외적으로 더 오래 걸릴 수 있으니 여유를 두고 계획해야 합니다.**
*   검토 과정에서 변경 요청 또는 추가 정보 요청에 대응
    *   **검토 과정에서 문제가 발견되면 수정 요청이나 추가 정보 요청이 올 수 있습니다. 이에 신속하게 대응하는 것이 중요합니다.**

### **89.7 앱 출시**

*   가능하다면 iOS와 Android 플랫폼 동시 출시
    *   **두 플랫폼을 동시에 출시하면 사용자 기반을 극대화할 수 있으며, 마케팅 활동의 효율성을 제고.**
*   마케팅 활동을 통해 출시 전 기대감 고조 및 출시 후 바이럴 유도
    *   **소셜 미디어, 이메일 마케팅, 협업 프로모션 등을 통해 출시 전후로 사용자의 관심을 끌고 참여를 유도**

### **89.8 출시 후 관리**

*   사용자 피드백 및 분석 데이터 모니터링
    *   **사용자 리뷰, 앱 분석 도구(Google Analytics, Firebase 등)를 통해 사용자의 행동 패턴과 불편 사항을 파악합니다.**
*   버그 수정, 사용자 요구 기반 신규 기능 추가 등 앱 업데이트 지속
    *   **앱은 출시 이후에도 지속적으로 관리되어야 하며, 사용자 요구에 맞춘 업데이트를 통해 만족도를 향상.**
*   리뷰 및 소셜 미디어를 통한 사용자 소통 및 커뮤니티 형성
    *   **긍정적인 리뷰는 앱의 신뢰도를 높이고, 부정적인 리뷰는 개선의 기회로 활용할 수 있습니다. 소셜 미디어를 통해 사용자와 적극적으로 소통하면 충성 고객층을 형성할 수 있습니다.**


## 90. 시스템 설계 관련 주요 개념
- 출처: [KISS, SOLID, CAP, BASE: Important Terms You Might Not Know!](https://www.youtube.com/watch?v=cTyZ_hbmbDw)

### **90.1 CAP 정리**

*   **정의:** 분산 데이터 저장소에서 **일관성(Consistency), 가용성(Availability), 파티션 내성(Partition Tolerance)**의 세 가지 속성을 모두 만족할 수 없다는 정리  
    **분산 시스템에서는 네트워크 장애나 지연이 피할 수 없는 현실이므로, 파티션 내성(P)은 반드시 고려해야 합니다. 따라서 실질적으로는 일관성(C)과 가용성(A) 중 하나를 선택해야 합니다.**

*   **세 가지 속성:**
    *   **일관성 (Consistency):** 모든 읽기 작업은 가장 최근 쓰기 작업의 결과를 반환하거나 오류를 반환  
        **예를 들어, 사용자가 데이터를 업데이트한 후 다른 노드에서 해당 데이터를 읽으면 항상 최신 값이어야 합니다.**
    *   **가용성 (Availability):** 모든 요청에 대해 응답을 보장 (최신 데이터가 아닐 수도 있음)  
        **즉, 시스템은 항상 "응답 가능" 상태를 유지하지만, 응답 데이터가 최신이 아닐 수 있습니다. 이는 사용자 경험을 우선시하는 경우 유리합니다.**
    *   **파티션 내성 (Partition Tolerance):** 네트워크 장애 발생 시에도 시스템이 정상적으로 작동  
        **네트워크 파티션은 노드 간 통신이 끊어진 상태를 의미하며, 이를 견딜 수 있어야 안정적인 분산 시스템을 구축할 수 있습니다.**

*   **CAP 선택:**
    *   **CP (Consistency + Partition Tolerance):** 일관성 우선, 네트워크 문제 발생 시 오류 발생 가능  
        **예: 금융 시스템이나 전자상거래 결제 시스템처럼 데이터 정확성이 중요한 경우 CP를 선택합니다.**
    *   **AP (Availability + Partition Tolerance):** 가용성 우선, 네트워크 문제 발생 시 최신 데이터가 아닐 수 있음  
        **예: 소셜 미디어 플랫폼이나 콘텐츠 제공 서비스처럼 사용자 경험이 중요한 경우 AP를 선택합니다.**

### **90.2 PACELC 정리**

*   **정의:** CAP 정리를 확장하여 **지연시간(Latency)**까지 고려  
    **PACELC는 CAP 정리의 제한점을 보완하기 위해 만들어졌으며, 네트워크 파티션이 없는 상황에서도 시스템 설계에서 중요한 요소인 지연 시간을 포함합니다.**

*   **내용:**
    *   **파티션 발생 시 (P):** 가용성 (A) 또는 일관성 (C) 선택 (CAP 정리와 동일)  
        **네트워크 파티션이 발생하면 여전히 CAP 정리의 선택 기준이 적용됩니다.**
    *   **파티션 없을 시 (E):** 지연시간 (L) 또는 일관성 (C) 선택  
        **파티션 문제가 없는 경우에도 시스템은 응답 속도(L)와 데이터 일관성(C) 사이에서 균형을 맞춰야 합니다. 예를 들어, 캐싱을 활용하면 지연 시간을 줄일 수 있지만, 데이터 일관성이 약화될 수 있습니다.**


### **90.3 BASE**

*   **정의:** NoSQL 데이터베이스에서 많이 사용되는 개념으로, ACID의 엄격한 일관성 대신 유연성을 제공  
    **BASE는 특히 대규모 분산 시스템에서 확장성과 성능을 극대화하기 위해 설계된 접근 방식입니다.**

*   **구성 요소:**
    *   **Basically Available:** 시스템이 대부분 가용 상태를 유지 (일부 오류 발생 가능)  
        **사용자는 항상 시스템에 접근할 수 있지만, 일부 요청이 실패할 가능성도 감안해야 합니다.**
    *   **Soft State:** 데이터가 시간이 지남에 따라 변경될 수 있음 (일관성 보장 X)  
        **데이터는 복제 및 동기화 과정에서 일시적으로 불일치 상태가 될 수 있습니다.**
    *   **Eventual Consistency:** 모든 트랜잭션이 즉시 반영되지는 않지만, 결국 모든 읽기 작업은 최신 값을 반환  
        **예: 쇼핑몰 웹사이트에서 상품 재고 정보가 여러 서버에 걸쳐 점진적으로 동기화되는 경우입니다.**

### **90.4 ACID**

*   **정의:** 전통적인 관계형 데이터베이스의 트랜잭션 속성을 보장하는 원칙  
    **ACID는 데이터 무결성을 중요시하는 시스템에서 필수적인 특성입니다. 예를 들어, 은행 시스템에서 돈을 이체할 때 ACID 속성을 준수해야 합니다.**

*   **구성 요소:**
    *   **Atomicity (원자성):** 트랜잭션은 모두 실행되거나, 전혀 실행되지 않아야 함  
        **예: A 계좌에서 B 계좌로 100달러를 이체하려는데 중간에 실패하면, A 계좌의 돈이 차감되지 않도록 해야 합니다.**
    *   **Consistency (일관성):** 트랜잭션은 데이터베이스의 무결성 제약 조건을 위반하지 않아야 함  
        **예: 음수가 허용되지 않는 컬럼에 음수 값을 입력할 수 없도록 합니다.**
    *   **Isolation (고립성):** 동시에 실행되는 트랜잭션은 서로에게 영향을 주지 않아야 함  
        **예: 두 명의 사용자가 동시에 같은 데이터를 수정하더라도, 한 트랜잭션이 완료되기 전에는 다른 트랜잭션이 그 데이터를 볼 수 없습니다.**
    *   **Durability (지속성):** 커밋된 트랜잭션은 영구적으로 저장되어야 함  
        **예: 시스템이 다운되더라도 디스크에 기록된 데이터는 손실되지 않습니다.**

### **90.5 SOLID 원칙 (객체 지향 설계 원칙)**

*   **단일 책임 원칙 (Single Responsibility Principle):** 클래스는 단 하나의 변경 이유만 가져야 함  
    **예: 사용자 인증을 담당하는 클래스는 인증 로직만 처리하고, 데이터베이스 연결과 같은 다른 역할은 다른 클래스에서 처리해야 합니다.**

*   **개방-폐쇄 원칙 (Open/Closed Principle):** 확장에는 열려 있고, 수정에는 닫혀 있어야 함  
    **예: 새로운 기능을 추가할 때 기존 코드를 수정하지 않고, 새로운 클래스나 모듈을 추가하여 확장할 수 있어야 합니다.**

*   **리스코프 치환 원칙 (Liskov Substitution Principle):** 하위 클래스는 상위 클래스를 대체할 수 있어야
    **예: 새 클래스가 상속받았다면, 기존 코드에서 상위 클래스를 사용했던 부분을 하위 클래스로 교체해도 동작에 문제가 없어야 합니다.**

*   **인터페이스 분리 원칙 (Interface Segregation Principle):** 클라이언트는 자신이 사용하지 않는 인터페이스에 의존하지 않아야 함  
    **예: 큰 인터페이스를 작은 단위로 나누어 필요한 메서드만 구현하도록 설계합니다.**

*   **의존 역전 원칙 (Dependency Inversion Principle):** 고수준 모듈은 저수준 모듈에 의존하지 않아야 하며, 둘 다 추상화에 의존해야 함  
    **예: 비즈니스 로직(고수준)이 특정 데이터베이스(저수준)에 직접적으로 의존하지 않고, 데이터베이스 인터페이스를 통해 접근하도록 설계합니다.**

### **90.6 KISS 원칙 (Keep It Simple, Stupid)**

*   **정의:** 시스템은 설계 및 구현 모두에서 단순할수록 가장 잘 작동한다는 원칙  
    **복잡한 설계는 유지보수 비용을 증가시키고, 오류 발생 가능성을 높입니다. 따라서 가능한 한 단순한 해결책을 선택해야 합니다.**

*   **예시:** Google 검색 인터페이스 (로고, 검색창, 버튼)  
    **Google 검색 페이지는 사용자에게 직관적이고 간단한 인터페이스를 제공하여 복잡한 알고리즘을 숨기면서도 효율적으로 서비스를 제공합니다.**

### **90.7 핵심 요약**

*   **CAP/PACELC:** 분산 시스템에서 일관성, 가용성, 파티션 내성, 지연 시간 간의 trade-off 고려  
    **시스템 설계자는 요구사항에 따라 적절한 속성을 선택해야 합니다. 예를 들어, 실시간 데이터 분석 시스템은 일관성보다는 가용성을 우선시할 수 있습니다.**

*   **ACID/BASE:** 데이터베이스의 일관성 수준 선택 (ACID: 엄격, BASE: 유연)  
    **금융, 의료 등 민감한 데이터를 다루는 시스템은 ACID를, SNS나 IoT 데이터 수집 시스템은 BASE를 선호합니다.**

*   **SOLID:** 유지보수하기 쉽고 확장 가능한 코드 작성을 위한 객체 지향 설계 원칙  
    **SOLID는 특히 대규모 프로젝트에서 코드의 복잡성을 관리하고 협업을 원활하게 하는 데 도움을 줍니다.**

*   **KISS:** 단순함을 추구하는 설계 원칙  
    **단순한 설계는 개발 초기뿐만 아니라 시스템의 장기적인 성공을 보장하는 핵심 요소입니다.**

