---
title: 26차시 3:AI Research Papers
layout: single
classes: wide
categories:
  - AI Research Papers
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. LoRA(Low-Rank Adaptation)

### 1.1 **문제점**

*   자연어 처리(NLP) 분야에서 대규모 사전 학습 모델(Large-scale pre-trained language models)을 특정 작업이나 도메인에 맞게 적응시키는 것이 일반적인 패러다임입니다.
*   하지만 GPT-3 175B와 같이 모델이 점점 커지면서, 모델의 모든 매개변수를 업데이트하는 **"전체 미세 조정(Full fine-tuning)"**은 실행하기 어렵거나 (less feasible), 각 작업별 미세 조정 모델 인스턴스를 배포하고 저장하는 데 엄청난 비용이 발생합니다. GPT-3 175B의 경우 1750억 개의 매개변수를 가집니다.
*   기존의 매개변수 효율적인 적응 기술(Parameter-Efficient Adaptation)들은 **추론 지연 시간(inference latency)을 도입하거나** (예: 어댑터 레이어 - Adapter layers), 모델이 사용할 수 있는 **입력 시퀀스 길이를 줄이는** (예: 프리픽스 튜닝 - Prefix-tuning) 등의 단점이 있어 효율성과 모델 품질 간에 절충이 필요했습니다. 특히 온라인 추론과 같이 배치 크기가 작을 때 어댑터 레이어의 지연 시간은 상당할 수 있습니다.

### 1.2 **LoRA (Low-Rank Adaptation)의 제안**

*   LoRA는 사전 학습된 모델의 가중치(W0)는 **고정**하고 (freezes the pre-trained model weights), Transformer 아키텍처의 각 레이어에 **학습 가능한 저랭크 분해 행렬(trainable rank decomposition matrices) A와 B를 주입**하는 방식으로 작동합니다.
*   사전 학습된 가중치 행렬 W0 ∈ ℝᵈˣᵏ의 업데이트 ∆W를 저랭크 분해 ∆W = BA로 표현합니다. 여기서 B ∈ ℝᵈˣʳ, A ∈ ℝʳˣᵏ이고 랭크 r은 min(d, k)보다 훨씬 작습니다 (r ≪ min(d, k)).
*   학습 중에는 W0는 고정되고 기울기 업데이트를 받지 않으며, A와 B만 학습 가능한 매개변수를 포함합니다. 변형된 순방향 계산(forward pass)은 h = W0x + BAx 입니다.

### 1.3 **LoRA의 주요 장점**

1.  **매개변수 효율성 극대화:** 
    *   다운스트림 작업을 위한 학습 가능한 매개변수 수($\|Θ\|$)를 크게 줄입니다. GPT-3 175B 예시에서는 **최대 10,000배까지 매개변수를 줄일 수 있습니다** (r=4, Wq, Wv만 적응 시). 이는 전체 매개변수의 0.01%에 불과할 수 있습니다.
2.  **메모리 및 스토리지 절감:** 
    *   학습 시 GPU 메모리 요구량을 최대 3배 줄여 하드웨어 진입 장벽을 낮춥니다. 체크포인트 크기 또한 크게 줄어듭니다 (GPT-3 175B 예시에서 10,000배).
3.  **추론 지연 시간 없음:** 
    *   배포 시 학습된 행렬(BA)을 고정된 사전 학습 가중치(W0)에 명시적으로 합쳐서 W = W0 + BA를 계산하고 저장할 수 있습니다. 이렇게 구성하면 전체 미세 조정한 모델과 비교하여 **추가적인 추론 지연 시간이 전혀 발생하지 않습니다**.
4.  **효율적인 작업 전환:** 
    *   배포된 상태에서 작은 BA 행렬만 교체함으로써 작업 전환 비용이 매우 낮습니다. 이를 통해 사전 학습된 가중치를 VRAM에 저장한 상태로 여러 맞춤형 모델 간에 빠르게 전환할 수 있습니다.
5.  **더 빠른 학습 처리량:** 
    *   GPT-3 175B에서 전체 미세 조정 대비 학습 처리량이 25% 증가했습니다.
6.  **모델 품질 유지 또는 향상:** 
    *   RoBERTa, DeBERTa, GPT-2, GPT-3 등 다양한 모델과 작업에서 전체 미세 조정 또는 다른 매개변수 효율적인 방법들과 동등하거나 더 나은 성능을 보입니다. 특히 GPT-3 175B 실험에서 뛰어난 성능을 보여줍니다.
7.  **다른 방법과의 직교성:** 
    *   Prefix-tuning과 같은 다른 방법과 결합될 수 있습니다. 실제로 LoRA와 Prefix-embedding tuning을 결합한 실험에서 WikiSQL에서 더 나은 성능을 보이기도 했습니다.
8.  **샘플 효율성:** 
    *   적은 학습 데이터 환경(Low-data regime)에서도 Fine-Tuning보다 우수한 성능을 보여줍니다.

### 1.4 **LoRA가 작동하는 이유 (분석 결과)**

*   모델 적응 중 가중치 업데이트(∆W)에는 **낮은 "내재적 랭크(intrinsic rank)"**가 있다는 가설에서 출발했습니다.
*   실험 결과, 매우 작은 랭크 r (예: GPT-3의 경우 1-4)만으로도 경쟁력 있는 성능을 달성할 수 있으며, 이는 업데이트 행렬 ∆W가 매우 작은 "내재적 랭크"를 가질 수 있음을 시사합니다.
*   사전 학습된 W와 업데이트 ∆W 사이의 관계 분석 결과, ∆W는 W와 상관관계가 있지만, W에서 **크게 강조되지 않은 방향("task-specific" directions)**을 증폭시키는 경향이 있습니다. 이러한 방향은 특정 다운스트림 작업에 중요하지만 일반적인 사전 학습 모델에서는 덜 강조되었을 수 있습니다. 이 증폭 계수(amplification factor)가 클 수 있음을 보여줍니다.
*   Transformer의 셀프 어텐션 모듈 중 Q(Query) 및 V(Value) 프로젝션 행렬(Wq, Wv)에 LoRA를 적용하는 것이 전체적으로 가장 좋은 성능을 보였습니다. 작은 랭크로 하나의 가중치 타입만 적응하는 것보다 더 많은 가중치 행렬을 적응하는 것이 선호됩니다.

### 1.5 **결론**
LoRA는 대규모 언어 모델의 효율적인 적응을 위한 강력하고 효율적인 방법으로 제시됩니다. 추론 지연 시간을 도입하지 않으면서도 매개변수 수, 메모리 사용량, 스토리지 요구량을 획기적으로 줄이며, 전체 미세 조정에 필적하거나 그 이상의 성능을 달성합니다. 이는 거대한 LLM을 다양한 다운스트림 작업에 저비용으로 적용할 수 있는 실질적인 해결책을 제공합니다.


### 1.6 LoRA 학습 퀴즈

1. LoRA의 핵심 아이디어는 무엇이며, 왜 필요한가?
> LoRA의 핵심 아이디어는 사전 훈련된 모델 가중치를 고정하고 트랜스포머 아키텍처의 각 레이어에 학습 가능한 저랭크 분해 행렬을 주입하는 것이다. 이는 다운스트림 작업에 대해 학습 가능한 매개변수 수를 크게 줄여준다.

2. LoRA는 풀 미세 조절과 비교했을 때 어떤 주요 장점을 가지는가?
> LoRA는 학습 가능한 매개변수 수를 크게 줄이고 GPU 메모리 요구 사항을 낮추며, 어댑터와 달리 추가적인 추론 지연 시간을 도입하지 않는다. 또한 풀 미세 조절과 유사하거나 더 나은 모델 품질 성능을 보인다.

3. LoRA에서 학습되는 매개변수는 무엇인가?
> LoRA에서는 사전 훈련된 가중치 행렬 W0는 고정되고 학습되지 않으며, 주입된 저랭크 분해 행렬 A와 B만 학습 가능한 매개변수를 포함한다. 업데이트 ∆W는 BA로 표현된다.

4. 트랜스포머 아키텍처에서 LoRA는 일반적으로 어느 가중치 행렬에 적용되는가?
> 트랜스포머 아키텍처에서 LoRA는 주로 자체 주의 모듈의 쿼리(Wq) 및 값(Wv) 투영 가중치 행렬에 적용된다. MLP 모듈의 가중치는 단순성과 매개변수 효율성을 위해 동결되는 경우가 많다.

5. LoRA가 추론 지연 시간을 추가하지 않는 이유는 무엇인가?
> 배포 시 학습 가능한 저랭크 행렬 A와 B를 동결된 사전 훈련 가중치 W0와 명시적으로 연산하여 새로운 가중치 W = W0 + BA로 저장할 수 있기 때문에 LoRA는 추론 지연 시간을 추가하지 않는다. 이렇게 하면 풀 미세 조절된 모델과 동일한 방식으로 추론이 수행된다.

6. LoRA 연구에서 GPT-3 175B 모델을 사용하여 시연한 주요 이점은 무엇인가?
> LoRA는 GPT-3 175B에 대해 학습 가능한 매개변수 수를 10,000배, GPU 메모리 요구 사항을 3배 줄일 수 있음을 시연했다. 이는 대규모 모델의 배포 및 학습 효율성을 크게 향상시킨다.

7. 어댑터 계층 방식의 단점은 무엇인가?
> 어댑터 계층의 단점은 모델 깊이를 확장하거나 추가 연산을 요구하여 추론 지연 시간을 도입하는 경향이 있다는 것이다. 특히 온라인 추론 설정과 같이 배치 크기가 작은 시나리오에서 두드러진다.

8. 프롬프트 직접 최적화 방식의 한계는 무엇인가?
> 프롬프트 직접 최적화 방식의 한계는 최적화하기 어렵고, 학습 가능한 매개변수의 변화에 따라 성능이 단조롭지 않게 변하며, 적응을 위해 시퀀스 길이의 일부를 예약해야 하므로 다운스트림 작업 처리에 사용할 수 있는 시퀀스 길이가 줄어든다는 것이다.

9. 연구에서 WikiSQL, MNLI, SAMSum 데이터셋에 대한 GPT-3 175B 실험 결과를 통해 무엇을 알 수 있는가?
> GPT-3 175B 실험 결과는 LoRA가 WikiSQL, MNLI, SAMSum 데이터셋에서 풀 미세 조절 기준선과 일치하거나 이를 능가하는 성능을 보임을 보여준다. 이는 LoRA가 훨씬 적은 매개변수로 대규모 모델에 효과적으로 적용될 수 있음을 시사한다.

10. 학습된 LoRA 업데이트 행렬(∆W)과 사전 훈련된 가중치 행렬(W) 사이의 주요 관계는 무엇인가?
> ∆W는 W와 높은 상관 관계를 가지지만, W의 상위 특이 방향을 반복하기보다는 W에서 강조되지 않는 방향을 증폭시키는 경향이 있다. 이는 ∆W가 사전 훈련 모델에서 학습되었지만 강조되지 않은 특정 다운스트림 작업에 중요한 특징 방향을 증폭할 수 있음을 시사한다.


### 1.7 에세이 형식 질문
1. LoRA, 어댑터 계층, 프롬프트 직접 최적화와 같은 매개변수 효율적인 적응 방법 간의 주요 차이점을 비교하고 대조하십시오. 효율성, 모델 품질 및 배포 용이성 측면에서 각 방법의 장단점을 논의하십시오.
> LoRA, 어댑터 계층, 프롬프트 직접 최적화는 모두 사전학습된 언어 모델을 소수의 파라미터만 수정해 새로운 작업에 적응시키는 기법이다. LoRA는 기존 가중치에 소규모 저랭크 행렬을 추가하여 파라미터 효율성이 뛰어나고, 기존 모델의 구조를 그대로 유지할 수 있어 배포가 용이하다. 어댑터는 네트워크에 소형 모듈을 삽입하여 학습하지만 추론 시에도 어댑터를 유지해야 하므로 배포가 복잡해질 수 있다. 프롬프트 최적화는 모델 파라미터를 전혀 건드리지 않아 배포는 가장 간편하지만, 복잡한 작업에서는 성능이 낮을 수 있다. 전반적으로 효율성과 품질 간 균형 면에서 LoRA가 우수한 성능을 보인다.


2. LoRA는 어떻게 저랭크 구조를 활용하여 언어 모델 적응의 효율성을 향상시키는가? 이 연구에서 제공된 경험적 증거를 바탕으로 업데이트 행렬의 낮은 "내재적 랭크" 가설을 설명하고 평가하십시오.
> LoRA는 모델 가중치 행렬의 변화가 저랭크 구조로 근사 가능하다는 가정 하에 학습 가능한 저랭크 행렬 두 개를 삽입하여 적응을 수행한다. 연구에서는 다양한 자연어 처리 작업에서 고품질 성능을 유지하면서도 극히 적은 수의 파라미터만 학습 가능함을 보여주며, 이는 업데이트 행렬의 "내재적 랭크"가 낮다는 실증적 증거로 해석된다. 즉, 복잡한 고차원 행렬도 몇 개의 중요 방향(특잇값 방향)만으로 표현 가능하다는 것이다. 이로 인해 LoRA는 계산 자원과 메모리를 절약하면서도 효율적인 적응을 가능하게 한다. 이러한 저랭크 가정은 실제 실험에서도 매우 유효하게 작동함이 증명되었다.

3. 연구에서 LoRA를 트랜스포머 아키텍처의 다양한 가중치 행렬에 적용했을 때의 효과를 조사했다. 결과는 무엇이었으며, 왜 Wq 및 Wv 가중치 행렬만 적응하는 것이 종종 최상의 성능을 보이는가?
> 연구에서는 LoRA를 트랜스포머의 다양한 가중치 행렬(Wq, Wk, Wv, Wo 등)에 적용한 결과를 비교 분석했으며, 특히 쿼리(Wq)와 값(Wv) 행렬에만 적용했을 때 성능이 가장 뛰어난 것으로 나타났다. 이는 언어 모델에서 주로 주목(attention)의 핵심 역할을 하는 Wq와 Wv가 의미 있는 표현 학습에 가장 크게 기여하기 때문으로 해석된다. 반면 Wk와 Wo는 비교적 적응 효과가 제한적이며, 전체 모델을 지나치게 조정하면 오히려 성능이 저하될 수 있다. 따라서 적은 파라미터만 조정하면서도 최대 효과를 내려면 Wq와 Wv 중심의 적응이 전략적으로 유리하다.

4. 이 연구에서 제시된 결과에 따르면 LoRA의 랭크 r을 선택하는 것은 모델 성능에 어떤 영향을 미치는가? 랭크 r과 학습된 업데이트 행렬의 "내재적 랭크" 개념 사이의 관계를 논의하십시오.
> LoRA에서 랭크 r은 학습 가능한 저랭크 행렬의 차원을 의미하며, r 값은 모델의 유연성과 과적합 위험 사이의 균형을 결정한다. 연구 결과, 작은 r 값으로도 기존 모델 성능에 근접하거나 이를 초과할 수 있음이 입증되었으며, 이는 업데이트 행렬의 "내재적 랭크"가 실제로 낮다는 것을 시사한다. 즉, 모델 적응에 필요한 주요 정보는 소수의 랭크 방향에 집중되어 있다는 것이다. 너무 큰 r 값은 불필요한 계산 증가와 과적합 가능성을 초래할 수 있다. 적절한 r 선택은 성능과 자원 효율성 모두를 최적화하는 핵심 요소다.

5. LoRA와 사전 훈련된 가중치 행렬(W) 사이의 관계에 대한 연구 결과를 분석하고 해석하십시오. ∆W가 W의 특정 특징 방향과 어떻게 관련되고 증폭되는지에 대한 논의가 언어 모델 적응의 기본 원칙에 대해 시사하는 바를 설명하십시오.
> 연구에서는 LoRA의 업데이트 행렬 ∆W가 사전 훈련된 가중치 W의 특정 특잇값 방향(singular directions)과 정렬되어 있음을 관찰했다. 이는 ∆W가 W의 의미론적으로 중요한 방향을 증폭하거나 강조하는 방식으로 작용한다는 것을 의미한다. 이 결과는 언어 모델의 적응이 완전히 새로운 표현을 학습하는 것보다는, 기존 표현의 중요한 하위공간을 강화하는 방식으로 이루어진다는 기본 원칙을 지지한다. 따라서 LoRA는 기존 언어 모델의 의미 구조를 훼손하지 않으면서 필요한 작업 특화 정보를 효과적으로 주입하는 데 유리하다. 이는 파라미터 효율성과 해석 가능성 모두에서 LoRA의 강점을 설명해준다.

### 1.8 용어집
* 풀 미세 조절 (Full fine-tuning): 사전 훈련된 모델의 모든 매개변수를 특정 작업 또는 도메인에 적응시키기 위해 다시 학습시키는 과정.
* LoRA (Low-Rank Adaptation): 사전 훈련된 모델 가중치를 고정하고 트랜스포머 레이어에 학습 가능한 저랭크 분해 행렬을 주입하여 매개변수 수를 크게 줄이는 매개변수 효율적인 적응 방법.
* 저랭크 분해 (Low-rank decomposition): 원래 행렬을 두 개의 작은 행렬의 곱으로 표현하는 것으로, 원래 행렬의 랭크보다 작은 랭크를 가진다. LoRA에서는 ∆W = BA로 표현된다.
* 트랜스포머 (Transformer): 주로 주의 메커니즘에 기반한 시퀀스-투-시퀀스 아키텍처로, 자연어 처리 작업을 위한 대규모 언어 모델의 기반이 된다.
* 주의 (Attention): 트랜스포머 모델에서 입력 시퀀스의 다양한 부분에 대한 관련성을 계산하고 가중치를 부여하는 메커니즘.
* Wq, Wk, Wv, Wo: 트랜스포머의 자체 주의 모듈에서 쿼리, 키, 값, 출력 투영에 사용되는 가중치 행렬.
* ∆W: 적응 과정 중 가중치 행렬의 누적 그래디언트 업데이트 또는 변화.
* r: LoRA 모듈의 랭크를 나타내며, 학습 가능한 매개변수 수를 결정한다.
* dmodel: 트랜스포머 레이어의 입력 및 출력 차원 크기.
* 어댑터 계층 (Adapter layers): 매개변수 효율적인 적응을 위해 신경망의 기존 레이어 사이에 삽입되는 작은 신경망 모듈.
* 프롬프트 튜닝 (Prompt tuning): 사전 훈련된 언어 모델에 작업을 수행하도록 지시하는 입력 프롬프트의 일부를 최적화하는 매개변수 효율적인 방법. 여기에는 접두사 튜닝 및 접두사 임베딩 튜닝이 포함될 수 있다.
* 내재적 차원/랭크 (Intrinsic dimension/rank): 학습된 모델 또는 가중치 업데이트가 실제로 존재하는 더 낮은 차원 또는 랭크.
* Adam: 딥 러닝 모델 최적화에 일반적으로 사용되는 적응형 최적화 알고리즘.
* GLUE 벤치마크 (GLUE Benchmark): 자연어 이해(NLU) 작업을 평가하기 위한 다양한 데이터셋 모음.
* E2E NLG Challenge: 데이터-투-텍스트 생성을 평가하기 위한 데이터셋.
* WikiSQL: 자연어 질의에서 SQL 명령을 생성하는 작업을 위한 데이터셋.
* SAMSum: 대화 요약을 위한 데이터셋.
* 프로젝션 메트릭 (Projection Metric): 두 부분 공간 사이의 거리를 측정하는 방법. 연구에서는 이의 역방향 유사도 측정을 사용한다.
* 특이값 분해 (Singular Value Decomposition, SVD): 행렬을 세 개의 다른 행렬의 곱으로 분해하는 것으로, 행렬의 랭크와 중요한 방향을 분석하는 데 사용된다.

