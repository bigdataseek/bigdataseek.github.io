---
title: 8차시 2:Neuralnine 2
layout: single
classes: wide
categories:
  - NeuralNine
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 8. 파이썬 다중 프로세싱

- 출처: [Python Multiprocessing Explained in 7 Minutes](https://www.youtube.com/watch?v=EI1gLCvdX_U&t=3s)

파이썬에서 **다중 프로세싱(Multiprocessing)**은 여러 작업을 동시에 처리하여 프로그램 속도를 확 끌어올리는 기술입니다. 마치 여러 명이 동시에 일해서 작업 시간을 단축하는 것과 비슷하다고 생각하면 됩니다.

### 8.1 다중 스레딩 vs. 다중 프로세싱: 뭐가 다를까?

파이썬에는 **다중 스레딩(Multi-threading)**이라는 개념도 있습니다. 하지만 파이썬은 **GIL(Global Interpreter Lock)**이라는 특성 때문에 다중 스레딩으로는 CPU를 많이 쓰는 작업에서 **진정한 동시 처리(병렬 처리)**가 불가능해요. 마치 한 명의 일꾼이 여러 작업을 번갈아 하는 것과 같아서, 실제로는 동시에 처리되는 게 아닙니다.

반면, **다중 프로세싱**은 여러 개의 독립적인 **프로세스(Process)**를 만들어서 각각의 프로세스가 동시에 작업을 처리하게 합니다. 이는 마치 여러 명의 일꾼이 각자 맡은 일을 동시에 처리하는 것과 같아서, **진정한 동시 처리(병렬 처리)**가 가능하고, 그만큼 작업 속도도 빨라지는 거죠.

### 8.2 다중 프로세싱을 위한 파이썬 도구들

파이썬의 `multiprocessing` 모듈에는 다중 프로세싱을 효율적으로 사용할 수 있도록 도와주는 여러 가지 도구(클래스)들이 있습니다. 몇 가지 주요 도구들을 알아볼까요?

* **`Pool` (풀)**:
    * **언제 쓸까요?** 여러 개의 작업에 똑같은 계산을 동시에 적용할 때 유용해요. 예를 들어, 12,000개의 숫자에 복잡한 계산을 해야 한다면, 이 `Pool`을 사용하면 혼자 계산할 때보다 훨씬 빠르게 끝낼 수 있어요. 마치 여러 명의 전문가가 각자 할당된 숫자에 대해 동시에 계산하는 것과 같아요.
    * **예시**: 12,000개의 숫자에 팩토리얼(factorial) 계산을 할 때, 혼자 하면 9.1초 걸리던 작업을 5개의 `Pool` 프로세스를 사용하면 2.9초 만에 끝낼 수 있어요. 엄청 빠르죠!

* **`Process` (프로세스)**:
    * **언제 쓸까요?** 아주 특정한 한 가지 작업을 별도의 프로세스로 실행하고 싶을 때 사용해요.
    * **예시**: 컴퓨터가 복잡한 계산을 하는 동안에도, 동시에 다른 프로세스가 5초마다 "잘 작동하고 있어요!"라는 메시지를 계속 출력하게 할 수 있어요. 계산과 메시지 출력이 동시에 이루어지는 거죠.

* **`Queue` (큐, 대기열)**:
    * **언제 쓸까요?** 여러 프로세스가 서로 정보를 주고받을 때 사용해요. 특히 정보가 들어간 순서대로 정확하게 처리되어야 할 때 아주 유용합니다.
    * **예시**: 한 프로세스가 물건을 생산해서 큐에 넣어두면, 다른 프로세스들이 큐에 있는 물건들을 하나씩 가져다가 소비해요. 아무리 여러 프로세스가 동시에 가져가도 큐에 들어간 순서대로 정확하게 처리됩니다.

* **`Pipe` (파이프)**:
    * **언제 쓸까요?** 두 개의 프로세스가 직접적으로 대화할 수 있는 통로를 만들 때 사용해요.
    * **예시**: 한 프로세스가 다른 프로세스에게 메시지를 보내면, 다른 프로세스가 그 메시지를 바로 받아서 처리할 수 있어요. 필요하다면 양쪽에서 서로 메시지를 주고받을 수도 있습니다.

* **`Lock` (잠금)**:
    * **언제 쓸까요?** 여러 프로세스가 동시에 한 가지 중요한 데이터(자원)를 건드려서 문제가 생기는 것을 막을 때 사용해요. 마치 화장실 문에 잠금장치가 있어서 한 번에 한 명만 들어갈 수 있게 하는 것과 같아요.
    * **예시**: 네 개의 프로세스가 하나의 공유된 숫자 값을 100,000번씩 늘리려고 할 때, `Lock`을 사용하지 않으면 값이 엉망이 될 수 있어요. 하지만 `Lock`을 사용하면 한 번에 하나의 프로세스만 값을 변경할 수 있도록 보장해서, 우리가 원하는 정확한 최종 값(400,000)을 얻을 수 있습니다.

* **`Semaphore` (세마포어)**:
    * **언제 쓸까요?** `Lock`과 비슷하지만, 동시에 여러 프로세스가 특정 자원에 접근할 수 있도록 허용할 때 사용해요. 하지만 그 허용 개수는 우리가 정할 수 있습니다.
    * **예시**: 6개의 프로세스가 있는데, 동시에 2개의 프로세스만 특정 작업을 하도록 제한하고 싶을 때 `Semaphore`를 사용합니다. 마치 6명의 일꾼이 있지만, 2개의 작업대만 있어서 동시에 2명만 작업할 수 있는 것과 비슷해요.


### 8.3 `Pool` (풀) 예제

`Pool`을 사용하여 여러 숫자의 제곱을 병렬로 계산하는 예제입니다.

```python
import multiprocessing
import os
import time

def calculate_square(number):
    """주어진 숫자의 제곱을 계산합니다."""
    # print(f"Process ID: {os.getpid()} - Calculating square of {number}")
    return number * number

if __name__ == "__main__":
    numbers = range(10)  # 0부터 9까지의 숫자

    print("--- Pool 예제 시작 ---")
    start_time = time.time()

    # 4개의 프로세스 풀을 생성
    with multiprocessing.Pool(processes=4) as pool:
        # map 함수를 사용하여 각 숫자에 calculate_square 함수 적용
        results = pool.map(calculate_square, numbers)

    print(f"결과: {results}")
    end_time = time.time()
    print(f"총 실행 시간: {end_time - start_time:.4f} 초")
    print("--- Pool 예제 종료 ---")

```

**설명:**

  * `calculate_square` 함수는 주어진 숫자의 제곱을 계산합니다.
  * `multiprocessing.Pool(processes=4)`는 4개의 프로세스를 사용하는 풀을 만듭니다.
  * `pool.map(calculate_square, numbers)`는 `numbers` 리스트의 각 항목에 `calculate_square` 함수를 병렬로 적용하고 결과를 수집합니다.


### 8.4 `Process` (프로세스) 예제

두 개의 독립적인 프로세스를 생성하여 각각 다른 작업을 수행하는 예제입니다.

```python
import multiprocessing
import time
import os

def task1():
    """첫 번째 프로세스에서 실행될 작업입니다."""
    print(f"Process ID: {os.getpid()} - Task 1 시작")
    for i in range(3):
        time.sleep(1)
        print(f"Process ID: {os.getpid()} - Task 1 진행 중... ({i+1}/3)")
    print(f"Process ID: {os.getpid()} - Task 1 완료")

def task2():
    """두 번째 프로세스에서 실행될 작업입니다."""
    print(f"Process ID: {os.getpid()} - Task 2 시작")
    for i in range(2):
        time.sleep(1.5)
        print(f"Process ID: {os.getpid()} - Task 2 진행 중... ({i+1}/2)")
    print(f"Process ID: {os.getpid()} - Task 2 완료")

if __name__ == "__main__":
    print("--- Process 예제 시작 ---")
    
    # Process 객체 생성
    p1 = multiprocessing.Process(target=task1)
    p2 = multiprocessing.Process(target=task2)

    # 프로세스 시작
    p1.start()
    p2.start()

    # 모든 프로세스가 완료될 때까지 기다림
    p1.join()
    p2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Process 예제 종료 ---")
```

**설명:**

  * `task1`과 `task2`는 각각 다른 메시지를 출력하며 일정 시간 대기하는 함수입니다.
  * `multiprocessing.Process(target=함수명)`을 사용하여 각 함수를 실행할 새 프로세스를 생성합니다.
  * `p.start()`로 프로세스를 시작합니다.
  * `p.join()`은 해당 프로세스가 끝날 때까지 메인 프로세스가 기다리도록 합니다.


### 8.5 `Queue` (큐, 대기열) 예제

`Queue`를 사용하여 생산자 프로세스와 소비자 프로세스 간에 데이터를 주고받는 예제입니다.

```python
import multiprocessing
import time
import os

def producer(queue):
    """항목을 큐에 추가하는 생산자 함수입니다."""
    print(f"Process ID: {os.getpid()} - 생산자 시작")
    for i in range(5):
        item = f"아이템 {i+1}"
        queue.put(item)
        print(f"Process ID: {os.getpid()} - {item} 생산 및 큐에 추가")
        time.sleep(0.5)
    queue.put(None) # 소비자가 작업을 마쳤음을 알리는 신호
    print(f"Process ID: {os.getpid()} - 생산자 완료")

def consumer(queue, name):
    """큐에서 항목을 가져와 처리하는 소비자 함수입니다."""
    print(f"Process ID: {os.getpid()} - 소비자 {name} 시작")
    while True:
        item = queue.get()
        if item is None:
            # 생산자가 보낸 종료 신호를 받으면 다시 큐에 넣고 종료
            queue.put(None)
            break
        print(f"Process ID: {os.getpid()} - 소비자 {name} - {item} 소비")
        time.sleep(1)
    print(f"Process ID: {os.getpid()} - 소비자 {name} 완료")

if __name__ == "__main__":
    print("--- Queue 예제 시작 ---")
    
    q = multiprocessing.Queue() # 큐 생성

    # 생산자 프로세스 생성
    p_producer = multiprocessing.Process(target=producer, args=(q,))
    # 소비자 프로세스 생성
    p_consumer1 = multiprocessing.Process(target=consumer, args=(q, "A"))
    p_consumer2 = multiprocessing.Process(target=consumer, args=(q, "B"))

    # 프로세스 시작
    p_producer.start()
    p_consumer1.start()
    p_consumer2.start()

    # 모든 프로세스가 완료될 때까지 기다림
    p_producer.join()
    p_consumer1.join()
    p_consumer2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Queue 예제 종료 ---")
```

**설명:**

  * `producer` 함수는 `queue.put()`을 사용하여 큐에 데이터를 넣습니다.
  * `consumer` 함수는 `queue.get()`을 사용하여 큐에서 데이터를 가져옵니다.
  * `queue.put(None)`은 생산자가 더 이상 생산할 것이 없음을 소비자에게 알리는 "종료 신호"로 사용됩니다.


### 8.6 `Pipe` (파이프) 예제

두 프로세스 간에 단방향 및 양방향 통신을 설정하는 예제입니다.

```python
import multiprocessing
import time
import os

def sender(conn, messages):
    """메시지를 파이프를 통해 보내는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Sender 시작")
    for msg in messages:
        conn.send(msg)
        print(f"Process ID: {os.getpid()} - 메시지 보냄: {msg}")
        time.sleep(0.5)
    conn.close() # 통신 종료
    print(f"Process ID: {os.getpid()} - Sender 완료")

def receiver(conn):
    """파이프를 통해 메시지를 받는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Receiver 시작")
    while True:
        try:
            msg = conn.recv()
            print(f"Process ID: {os.getpid()} - 메시지 받음: {msg}")
        except EOFError: # 파이프가 닫히면 발생하는 오류
            break
        time.sleep(0.7)
    print(f"Process ID: {os.getpid()} - Receiver 완료")

if __name__ == "__main__":
    print("--- Pipe 예제 시작 (단방향) ---")
    
    # 단방향 파이프 생성 (부모-자식 연결)
    parent_conn, child_conn = multiprocessing.Pipe(duplex=False) # duplex=False는 단방향을 의미

    messages_to_send = ["안녕", "파이프", "예제", "데이터"]
    
    p_sender = multiprocessing.Process(target=sender, args=(child_conn, messages_to_send))
    p_receiver = multiprocessing.Process(target=receiver, args=(parent_conn,))

    p_sender.start()
    p_receiver.start()

    p_sender.join()
    p_receiver.join()

    print("\n--- Pipe 예제 시작 (양방향) ---")
    
    # 양방향 파이프 생성
    conn1, conn2 = multiprocessing.Pipe(duplex=True) # duplex=True는 양방향을 의미

    def worker1(conn):
        conn.send("Worker1 입니다. 안녕!")
        print(f"Process ID: {os.getpid()} - Worker1 받음: {conn.recv()}")
        conn.close()

    def worker2(conn):
        print(f"Process ID: {os.getpid()} - Worker2 받음: {conn.recv()}")
        conn.send("Worker2 입니다. 잘 가!")
        conn.close()

    p_worker1 = multiprocessing.Process(target=worker1, args=(conn1,))
    p_worker2 = multiprocessing.Process(target=worker2, args=(conn2,))

    p_worker1.start()
    p_worker2.start()

    p_worker1.join()
    p_worker2.join()

    print("모든 프로세스 완료. 메인 프로세스 종료.")
    print("--- Pipe 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Pipe()`를 호출하면 두 개의 연결 객체(`conn1`, `conn2`)가 반환됩니다. 이 두 객체는 파이프의 양쪽 끝을 나타냅니다.
  * `conn.send()`를 사용하여 데이터를 파이프를 통해 보냅니다.
  * `conn.recv()`를 사용하여 파이프에서 데이터를 받습니다.
  * `duplex=True`로 설정하면 양방향 통신이 가능하며, 기본값은 `False`로 단방향입니다.


### 8.7 `Lock` (잠금) 예제

`Lock`을 사용하여 여러 프로세스가 공유 자원(공유 숫자)을 안전하게 수정하는 예제입니다.

```python
import multiprocessing
import time
import os

def increment_shared_counter(counter, lock):
    """공유 카운터 값을 증가시키는 함수입니다."""
    print(f"Process ID: {os.getpid()} - 카운터 증가 시작")
    for _ in range(100000): # 10만 번 증가
        lock.acquire() # 락 획득 (다른 프로세스가 접근 못하게 잠금)
        try:
            counter.value += 1
        finally:
            lock.release() # 락 해제 (다른 프로세스가 접근 가능하게 풀어줌)
    print(f"Process ID: {os.getpid()} - 카운터 증가 완료")

if __name__ == "__main__":
    print("--- Lock 예제 시작 ---")
    
    # 공유할 숫자 변수 생성 (Value 객체는 여러 프로세스에서 공유 가능)
    shared_counter = multiprocessing.Value('i', 0) # 'i'는 정수형을 의미, 초기값 0
    lock = multiprocessing.Lock() # 락 객체 생성

    processes = []
    num_processes = 4

    for _ in range(num_processes):
        p = multiprocessing.Process(target=increment_shared_counter, args=(shared_counter, lock))
        processes.append(p)
        p.start()

    for p in processes:
        p.join()

    print(f"최종 카운터 값: {shared_counter.value}") # 예상 값: 400000
    print("--- Lock 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Value('i', 0)`는 여러 프로세스에서 공유할 수 있는 정수형 변수를 생성합니다.
  * `multiprocessing.Lock()`으로 락 객체를 생성합니다.
  * `lock.acquire()`는 락을 획득하여 다른 프로세스가 해당 코드 블록에 접근하지 못하도록 합니다.
  * `lock.release()`는 락을 해제하여 다른 프로세스가 접근할 수 있도록 합니다. `try...finally` 블록을 사용하여 락이 항상 해제되도록 보장하는 것이 중요합니다.


### 8.8 `Semaphore` (세마포어) 예제

`Semaphore`를 사용하여 동시에 특정 작업에 접근할 수 있는 프로세스의 수를 제한하는 예제입니다.

```python
import multiprocessing
import time
import os

def worker_with_semaphore(semaphore, worker_id):
    """세마포어를 사용하여 작업하는 함수입니다."""
    print(f"Process ID: {os.getpid()} - Worker {worker_id} 대기 중...")
    semaphore.acquire() # 세마포어 획득 (접근 허용 대기)
    try:
        print(f"Process ID: {os.getpid()} - Worker {worker_id} 작업 시작! (동시 실행 가능 수: 2)")
        time.sleep(2) # 작업 수행 시간
        print(f"Process ID: {os.getpid()} - Worker {worker_id} 작업 완료!")
    finally:
        semaphore.release() # 세마포어 해제 (다른 프로세스가 접근 가능하도록)

if __name__ == "__main__":
    print("--- Semaphore 예제 시작 ---")
    
    # 동시에 2개의 프로세스만 접근을 허용하는 세마포어 생성
    semaphore = multiprocessing.Semaphore(2) 

    processes = []
    num_workers = 6 # 총 6개의 워커 프로세스 생성

    for i in range(num_workers):
        p = multiprocessing.Process(target=worker_with_semaphore, args=(semaphore, i + 1))
        processes.append(p)
        p.start()

    for p in processes:
        p.join()

    print("모든 워커 프로세스 완료. 메인 프로세스 종료.")
    print("--- Semaphore 예제 종료 ---")
```

**설명:**

  * `multiprocessing.Semaphore(2)`는 동시에 2개의 프로세스만 `acquire()`를 성공적으로 호출할 수 있도록 제한합니다.
  * `semaphore.acquire()`는 세마포어를 획득하여 허용된 개수 내에서 작업을 시작합니다.
  * `semaphore.release()`는 세마포어를 해제하여 다른 프로세스가 접근할 수 있도록 합니다.


## 9. 파이썬으로 가우시안 나이브 베이즈 분류기 만들기 
- 출처: [Gaussian Naive Bayes From Scratch in Python (Mathematical)](https://www.youtube.com/watch?v=AqW3aPSPIhc)

직접 파이썬(Python)으로 **가우시안 나이브 베이즈(Gaussian Naive Bayes)**라는 인공지능 분류기를 만드는 방법을 알려줘요. 복잡한 머신러닝 도구(SciKit-learn 같은)를 사용하지 않고, 오직 **순수한 파이썬과 넘파이(NumPy)**만으로 핵심 수학 공식을 직접 구현하는 데 초점을 맞춰요.

### 9.1 가우시안 나이브 베이즈, 이게 무슨 뜻일까요?

* **가우시안(Gaussian):** 
    *   이 분류기는 데이터를 '**정규 분포(normal distribution)**' 또는 '**가우시안 분포(Gaussian distribution)**'라는 특별한 모양의 종(鐘)처럼 생긴 곡선으로 가정하고 사용해요. 통계에서 많이 쓰는 분포 모양이에요.
* **나이브(Naive):** 
    *   '순진하다'는 뜻인데, 여기서는 데이터의 여러 **특징(features)** (예: 키, 몸무게)들이 서로에게 아무 영향을 주지 않고 '**완전히 독립적**'이라고 가정한다는 의미예요. 실제로는 그렇지 않을 때가 많지만, 이렇게 가정하면 계산이 훨씬 쉬워져요.
* **베이즈(Bayes):** 
    *   **베이즈 정리(Bayes' Theorem)**라는 확률 이론에 기반을 두고 있어요. 이 정리는 어떤 사건이 일어날 확률을 새로운 정보를 바탕으로 업데이트하는 방법이에요.

이 알고리즘을 이해하려면 **확률, 통계, 정규 분포, 평균, 분산** 같은 기본적인 수학 지식이 필요하다고 해요. 특히 다음 용어들을 알아두면 좋아요:

* **베이즈 정리**
* **확률**
* **변수 독립성**
* **정규 분포**
* **표준 편차**
* **분산**
* **평균**

### 9.2 베이즈 정리와 '나이브'한 가정

우리가 궁금한 건 '어떤 데이터를 봤을 때, 이게 특정 종류(클래스)에 속할 확률'이에요. 이걸 수학적으로는 $P(Y=K\|X)$라고 써요. (X라는 데이터를 봤을 때 Y가 K일 확률)

* **기본 베이즈 정리:** 
    *   $$P(Y=K|X) = \frac{P(Y=K) \times P(X|Y=K)}{P(X)}$$
    여기서 $P(Y=K)$는 **사전 확률(prior probability)**이라고 하는데, '어떤 데이터를 보기 전에 Y가 K일 확률'을 의미해요.

* **$P(X)$ 무시:** 
    *   우리가 두 가지 종류(예: '암' 또는 '정상') 중에서 더 확률이 높은 쪽을 고를 때는, 이 분모인 $P(X)$는 항상 같기 때문에 계산에 넣지 않아도 괜찮아요. 결국 우리는 $P(Y=K) \times P(X\|Y=K)$ 값이 가장 큰 클래스를 찾으면 돼요.

* **나이브 가정의 마법:** 
    *   $P(X|Y=K)$ 부분이 복잡해지는 것을 피하기 위해, 모든 개별 특징($X_j$)이 클래스 $Y=K$일 때 **서로 독립적**이라고 가정해요. 이렇게 하면 $P(X|Y=K)$는 각 특징의 확률 $P(X_j|Y=K)$를 **모두 곱하는** 형태로 아주 간단해져요. $$P(X|Y=K) = P(X_1|Y=K) \times P(X_2|Y=K) \times \dots \times P(X_n|Y=K)$$
    또는 수학 기호로는 다음과 같이 나타낼 수 있어요.
    $$P(X|Y=K) = \prod_{j=1}^{n} P(X_j|Y=K)$$
    여기서 $\prod$는 모든 $P(X_j|Y=K)$를 곱하라는 의미예요.

### 9.3 가우시안 분포의 적용

각각의 특징 $X_j$가 특정 종류 $K$에 속할 확률 $P(X_j\|Y=K)$는 **가우시안 분포(정규 분포)**를 따른다고 봐요. 이 가우시안 분포는 그 종류 $K$에 속하는 특징 $J$들의 **평균($\mu_{KJ}$)**과 **분산($\sigma_{KJ}^2$)**을 가지고 정의돼요.

* **가우시안 분포의 확률 밀도 함수(PDF) 공식:**
    *   $$P(X_j|Y=K) = \frac{1}{\sqrt{2\pi \sigma_{KJ}^2}} e^{-\frac{(X_j - \mu_{KJ})^2}{2\sigma_{KJ}^2}}$$
    여기서 $X_j$는 우리가 관측한 특징 값이에요. 이 공식이 바로 가우시안 분포의 종 모양 곡선을 나타내는 식이에요.


### 9.4 모델 파라미터 계산 (학습 과정)

컴퓨터가 데이터를 보고 스스로 배우는 과정을 '학습(Fit)'이라고 해요. 

* **사전 확률 (Prior Probability):** 
    *   주어진 클래스 $K$의 데이터 개수를 전체 데이터 개수로 나누어 계산해요.
    $$P(Y=K) = \frac{\text{클래스 K의 인스턴스 수}}{\text{전체 인스턴스 수}}$$
* **평균 (Mean, $\mu_{KJ}$):** 
    *   각 클래스 $K$ 내에서 특정 특징 $J$에 대한 모든 샘플 값들을 더한 후, 해당 클래스 $K$의 인스턴스 수로 나누어 계산해요.
    $$\mu_{KJ} = \frac{1}{N_K} \sum_{i \in \text{클래스 K}} X_{i,j}$$
    여기서 $N_K$는 클래스 $K$의 데이터 개수예요.
* **분산 (Variance, $\sigma_{KJ}^2$):** 
    *   각 클래스 $K$ 내에서 특정 특징 $J$에 대한 샘플 값들의 제곱 편차 합을 해당 클래스 $K$의 인스턴스 수로 나누어 계산해요.
    $$\sigma_{KJ}^2 = \frac{1}{N_K} \sum_{i \in \text{클래스 K}} (X_{i,j} - \mu_{KJ})^2$$

이 모든 값들은 우리가 컴퓨터에게 제공하는 **학습 데이터(X, Y)**를 가지고 계산해요.


### 9.5 언더플로우 문제와 로그 확률

* **문제:** 
    *   확률 값들은 보통 0과 1 사이의 아주 작은 숫자예요. 이런 작은 숫자들을 계속 곱하면 컴퓨터가 너무 작아서 제대로 계산하지 못하고 '언더플로우(underflow)'라는 오류가 날 수 있어요. 이는 수치적으로 불안정하게 만들어요.
* **해결책:** 
    *   곱셈을 덧셈으로 바꿔서 이 문제를 해결해요. 어떻게 하냐고요? 확률 값에 **로그(log)**를 씌우면 곱셈이 덧셈으로 바뀌어요. (수학적으로 $log(A \times B) = log(A) + log(B)$)

    *   따라서, 우리가 비교하려는 최종 확률 $P(Y=K\|X) \propto P(Y=K) \times \prod_{j=1}^{n} P(X_j\|Y=K)$에 로그를 적용하면:

    $$\log(P(Y=K\|X)) \propto \log(P(Y=K)) + \sum_{j=1}^{n} \log(P(X_j\|Y=K))$$
    *   여기서 $\sum$는 모든 $\log(P(X_j\|Y=K))$를 더하라는 의미예요.

* **가우시안 분포의 로그:**
    *    $P(X_j|Y=K)$는 가우시안 분포 공식이었죠? 여기에 로그를 적용하면 다음과 같이 간단해져요.
    $$\log(P(X_j\|Y=K)) = -\frac{1}{2} \log(2\pi \sigma_{KJ}^2) - \frac{(X_j - \mu_{KJ})^2}{2\sigma_{KJ}^2}$$

* **최종 목표:** 
    *   결국 우리가 할 일은 이 **로그 확률 값**을 **가장 크게 만드는** 종류(클래스 $K$)를 찾는 거예요. (수학적으로는 $\text{argmax}_K$)

### 9.6 파이썬 구현 상세

* **환경 설정:**
    * **NumPy:** 효율적인 배열 작업과 선형 대수 계산에 필요한 라이브러리예요.
    * **scikit-learn:** 데이터셋을 불러오고, 데이터를 학습/테스트용으로 나누고, 모델 성능을 평가할 때 사용해요. (하지만 실제 머신러닝 모델 구현에는 사용하지 않아요!)
* **클래스 구조:** `GaussianNB`라는 이름의 파이썬 클래스를 만들고, 이 클래스 안에 `fit` (학습)과 `predict` (예측)이라는 함수를 넣어요.

    * `fit(self, X, y)` 메서드:
        * 입력 데이터를 넘파이(NumPy) 배열로 변환해요.
        * 데이터에 있는 고유한 클래스(정답 종류)들을 식별하고, 클래스 수와 특징 수를 결정해요.
        * 각 클래스와 특징에 대한 **평균, 분산, 사전 확률**을 저장할 빈 넘파이 배열을 초기화해요.
        * 모든 클래스를 하나씩 살펴보면서, 각 클래스에 해당하는 데이터($X_k$)를 필터링하고, **해당 클래스의 평균, 분산, 사전 확률을 계산하여 저장**해요.

    * `_log_gaussian(self, X)` 메서드:
        * 주어진 데이터 $X$에 대해 **가우시안 분포의 로그 확률 값**을 계산하는 내부 헬퍼 함수예요.
        * 위에서 설명한 로그 가우시안 분포 공식
            $$-\frac{1}{2} \log(2\pi \sigma_{KJ}^2) - \frac{(X_j - \mu_{KJ})^2}{2\sigma_{KJ}^2}$$
            을 넘파이(NumPy) 연산으로 직접 구현해요.
        * 계산된 로그 확률들을 모두 **더해서** 반환해요.

    * `predict(self, X)` 메서드:
        * 새로운 입력 데이터 $X$를 넘파이 배열로 변환해요.
        * `_log_gaussian` 메서드를 사용하여 각 클래스에 대한 **로그 우도(log likelihood)**를 계산해요.
        * 학습 단계에서 계산한 **사전 확률에 대한 로그 값($\log(P(Y=K))$)**을 가져와요.
        * 각 클래스에 대해 로그 우도와 로그 사전 확률을 더한 후 (위에서 설명한 합산 공식), **`np.argmax`를 사용하여 이 합을 최대화하는 클래스를 최종 예측으로 반환**해요. 즉, 이 데이터가 어떤 클래스에 속할 확률이 가장 높은지 찾아주는 거죠.

* **예제 및 평가:** 
    *   **유방암(breast cancer) 데이터셋**을 사용하여 모델을 학습하고 (데이터를 학습용과 테스트용으로 나누어 활용), 예측을 수행한 후 **정확도(accuracy score)**를 계산하여 모델의 성능을 평가해요. 직접 구현된 모델은 **90% 이상의 정확도**를 보여준다고 해요!
