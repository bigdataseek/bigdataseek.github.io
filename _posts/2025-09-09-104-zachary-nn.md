---
title: 10차시 4 :Zachary(Neural Network)
layout: single
classes: wide
categories:
  - Neural Network
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 1시간만에 신경망 학습하기

모든 현대 AI를 움직이는 핵심 엔진은 몇 가지 단순하고 매우 직관적인 아이디어 위에 구축되어 있습니다. 우리는 전체 과정을 해체하고 처음부터 함께 재구축할 것입니다.
*   짙은 안개 속에 갇혔을 때 계곡 바닥으로 가는 길을 어떻게 찾을까요?
*   팀 프로젝트가 잘못되었을 때 누구에게 "책임"을 물어야 할지 어떻게 알아낼까요?

이러한 간단한 아이디어를 이해하면 수학은 갑자기 완벽하게 말이 됩니다. 수학은 장벽이 아니라, 여러분이 이미 이해하고 있는 논리를 설명하는 언어일 뿐입니다.

우리는 단계별로 완전하고 투명한 수학적 설명을 진행할 것입니다. 건너뛰는 단계는 없습니다. 마법도 없습니다. 이 비디오가 끝날 무렵, 여러분은 기계가 진정으로 학습하는 방법에 대한 깊이 있는 기초 지식을 갖게 될 것입니다. 단순히 유행어를 아는 것을 넘어, 마침내 "아하!" 하는 순간을 맞이할 것입니다.

### 1.경사 하강법 - 최솟값 찾기

#### 1.1 **모든 AI 시스템의 공통 로직**
```bash
#의사코드
INPUT: function f(x)
OUTPUT: argmin_x f(x)

FOR 100 iterations:
  gradient = f'(x)
  x = x - η × gradient
RETURN x
```

이 알고리즘은 여러분이 들어본 모든 AI 시스템의 핵심입니다. ChatGPT, 이미지 인식, 자율주행 자동차 등 이 모든 것이 이 정확한 학습 루프를 사용합니다.

**핵심:** 모든 신경망은 "오류"를 최소화하여 학습하려고 합니다. 오류는 예측값과 실제 정답 사이의 차이입니다. 이 알고리즘은 오류를 체계적으로 줄여 네트워크를 완벽하게 안내하는 핵심 과정입니다.

**직관:** 짙은 안개 속 언덕에서 길을 잃고 계곡 바닥에 도달하려 한다고 상상해 보세요. 앞은 보이지 않지만, 발밑의 경사를 느낄 수 있습니다. 그래서 반복적으로: (1) 어느 방향이 가장 가파른지 느끼고, (2) 반대 방향으로 (내리막길로) 작은 발걸음을 내딛고, (3) 땅이 평평해질 때까지 반복합니다.

이것이 바로 우리 알고리즘이 수학적으로 하는 일입니다.

#### 1.2 **그 뒤에 숨겨진 수학**
함수 **f(x) = x²**로 구체화해 봅시다. 완벽한 U자형 계곡입니다.\\
**경사** (미분이라고도 함) f'(x)는 어떤 지점 x에서의 기울기를 알려줍니다. 우리 함수에서는: **f'(x) = 2x** 입니다.

이것은 다음을 의미합니다.
*   x=3일 때: 기울기 = 6 (오른쪽으로 가파른 오르막)
*   x=-2일 때: 기울기 = -4 (왼쪽으로 가파른 오르막)
*   x=0일 때: 기울기 = 0 (완전히 평평함 - 최솟값!)

우리의 업데이트 규칙인 x = x - η × f'(x)는 자동으로 기울기의 반대 방향, 즉 최솟값을 향해 우리를 움직입니다.

#### 1.3 단계별 예시
**우리가 최소화하는 것:** \\
f(x) = x² 여기서 x는 **독립 변수** (우리가 제어할 수 있음)이고 f(x)는 **종속 변수** (우리의 x 선택에 따라 달라짐)입니다. 학습률 η = 0.1로 x₀ = 3에서 시작하는 알고리즘을 추적해 봅시다.

| Iteration | Current x | f(x) = x² | Gradient f'(x) = 2x | Update: x - 0.1×f'(x) | New x |
|-----------|-----------|-----------|---------------------|----------------------|-------|
| 0 | 3.000 | **9.000** | 6.000 | 3.000 - 0.6 | **2.400** |
| 1 | 2.400 | **5.760** | 4.800 | 2.400 - 0.48 | **1.920** |
| 2 | 1.920 | **3.686** | 3.840 | 1.920 - 0.384 | **1.536** |
| 3 | 1.536 | **2.359** | 3.072 | 1.536 - 0.307 | **1.229** |
| 4 | 1.229 | **1.510** | 2.458 | 1.229 - 0.246 | **0.983** |
| ... | ... | ... | ... | ... | ... |
| 10 | 0.322 | **0.104** | 0.644 | 0.322 - 0.064 | **0.258** |

그래프에서 볼 수 있는 것:
*   **빨간 점**은 포물선 위 (3, 9)에서 시작합니다.
*   각 반복마다: 점은 곡선을 따라 왼쪽으로 미끄러져 내려갑니다.
*   각 점의 **파란색 접선**은 기울기를 보여줍니다.
*   점은 마침내 (0, 0) - 바닥에 정착합니다!
알고리즘은 순수하게 수학적 기울기를 따라 최솟값을 찾아냅니다. 

#### 1.4 큰 한계: 울퉁불퉁한 언덕은 어떨까요?
문제는 이것입니다: 경사 하강법은 시야가 좁습니다. 발밑의 경사만 볼 수 있습니다.

**예시: 함정이 있는 함수** \\
f(x) = x⁴ - 4x² + x + 1 함수로 이를 살펴보겠습니다. 이 함수는 두 개의 계곡이 있는 지형을 만듭니다. \\
**(두 개의 굴곡이 있는 곡선 – 왼쪽 x≈-1에 얕은 계곡, 오른쪽 x≈1.5에 더 깊은 계곡을 상상해 보세요.)**
*   x ≈ -1에서 **지역 최솟값** (얕은 계곡, f(x) ≈ -1)
*   x ≈ 1.5에서 **전역 최솟값** (깊은 계곡, f(x) ≈ -2.8)

**무슨 일이 일어날까요:**
*   x = -0.5에서 시작 → 경사 하강법은 x ≈ -1의 얕은 계곡에 갇힙니다.
*   x = 0.5에서 시작 → x ≈ 1.5에서 진짜 깊은 계곡을 찾습니다.
*   **부드러운 계곡에서는:** ✓ 바닥을 완벽하게 찾습니다. **울퉁불퉁한 지형에서는:** ✗ 시작 지점에 따라 갇힙니다. 같은 알고리즘이라도 시작 지점에 따라 결과가 다릅니다!

**신경망은 어떨까요?**
*   경사 하강법으로 훈련된 대규모 신경망은 실제로 지역 최솟값에 도달하지만, 나쁜 지역 최솟값에 갇히는 경우는 매우 드뭅니다.

**실제로 이것이 작동하는 이유:**
*   **고차원은 이상합니다:** 수백만 개의 매개변수를 사용하면 대부분의 "지역 최솟값"이 실제로는 좋은 해결책입니다.
*   **성공으로 가는 많은 경로:** 일반적으로 잘 작동하는 수백만 가지의 다른 가중치 조합이 있습니다.
*   **지역 최솟값의 군집:** "나쁜" 지역 최솟값은 "충분히 좋은" 최솟값에 비해 드문 경향이 있습니다.

**미스터리:** 
*   우리는 그 이유를 아직 완전히 이해하지 못하지만, 경험적으로 경사 하강법은 이론적인 함정 문제에도 불구하고 신경망에서 훌륭한 해결책을 찾습니다. 이는 AI에서 가장 운이 좋은 우연 중 하나입니다!
이것은 모든 머신러닝의 핵심 엔진입니다. 그 외의 모든 것은 복잡한 네트워크에 대해 f'(x)를 계산하는 것에 불과합니다.
다음으로, 우리 계곡이 한 개 이상의 차원을 가질 때 어떤 일이 일어나는지 알아볼 것입니다.

### 2. 편미분 - 다차원의 비밀
**돌파구:**
```
∂f/∂x = how steep in x-direction (treat y as constant)
∂f/∂y = how steep in y-direction (treat x as constant)
```

**도전:** 신경망은 수백만 개의 매개변수를 가집니다. 각 매개변수를 어느 방향으로 조정해야 할지 어떻게 알아낼까요? **편미분은 각 매개변수의 영향을 개별적으로 계산할 수 있게 해줍니다.**

**사운드보드를 조절하는 것과 같다고 생각하세요. 다른 모든 것을 고정해 두고 한 번에 하나의 노브에 집중하는 겁니다.**

#### 2.1 편미분이란 무엇인가요?
1부에서 경사를 기억하시나요? f(x)의 경우, 기울기를 얻기 위해 f'(x)라고 썼습니다. 하지만 우리 함수가 여러 변수에 의존한다면 어떨까요?

우리의 단순한 계곡을 업그레이드해 봅시다. f(x) = x² 대신 다음을 고려해 보세요:

**f(x1,x2) = x1² + 2x2²**

이것은 3차원 그릇 모양의 계곡을 만듭니다. 최솟값은 f(0,0) = 0인 (0,0)에 있습니다.
이제 우리는 두 개의 기울기가 필요합니다:
*   **∂f/∂x1:** x1 방향으로 움직인다면 기울기는 얼마나 가파를까요?
*   **∂f/∂x2:** x2 방향으로 움직인다면 기울기는 얼마나 가파를까요?

**마법의 규칙:** ∂f/∂x1을 찾기 위해 **x2를 상수처럼 취급하세요!!** (마치 5라는 숫자처럼), 그런 다음 x1에 대해 일반 미분을 취합니다.

**우리 함수 f(x1,x2) = x1² + 2x2²에 대해:**
*   ∂f/∂x1 = 2x1 (x2가 "상수"이므로 2x2² 항은 사라집니다)
*   ∂f/∂x2 = 4x2 (x1이 "상수"이므로 x1² 항은 사라집니다)

#### 2.2 이제 2D 알고리즘
편미분을 이해했으니, 여기 여러 변수에 대한 경사 하강법이 있습니다.

```
INPUT: function f(x1,x2), starting point (x1₀,x2₀)
OUTPUT: argmin_{x1,x2} f(x1,x2)

FOR 100 iterations:
  ∂f/∂x1 = calculate x1-gradient at current point
  ∂f/∂x2 = calculate x2-gradient at current point
  x1 = x1 - η × ∂f/∂x1
  x2 = x2 - η × ∂f/∂x2
RETURN (x1,x2)
```

각 변수는 자체 업데이트 규칙을 가지지만, 우리는 이들을 모두 동시에 적용합니다!

#### 2.3 단계별 예시: 2D 경사 하강법
**우리가 최소화하는 것:** 
*   f(x1,x2) = x1²+2x2² 여기서 (x1,x2)는 **독립 변수** (우리가 제어할 수 있음)이고 f(x1,x2)는 **종속 변수** (우리의 선택에 따라 달라짐)입니다. 학습률 η = 0.1로 (x1₀,x2₀) = (3,2)에서 시작하는 알고리즘을 추적해 봅시다.


| Iter | x1 | x2 | f(x1,x2)=x1²+2x2² | ∂f/∂x1=2x1 | ∂f/∂x2=4x2 | x1-η×∂f/∂x1 | x2-η×∂f/∂x2 | New (x1,x2) |
|------|---|---|------------|----------|----------|-----------|-----------|-----------|
| 0 | 3.00 | 2.00 | **17.00** | 6.00 | 8.00 | 3.00-0.6 | 2.00-0.8 | **(2.40, 1.20)** |
| 1 | 2.40 | 1.20 | **8.64** | 4.80 | 4.80 | 2.40-0.48 | 1.20-0.48 | **(1.92, 0.72)** |
| 2 | 1.92 | 0.72 | **4.72** | 3.84 | 2.88 | 1.92-0.384 | 0.72-0.288 | **(1.54, 0.43)** |
| 3 | 1.54 | 0.43 | **2.74** | 3.08 | 1.72 | 1.54-0.308 | 0.43-0.172 | **(1.23, 0.26)** |
| ... | ... | ... | ... | ... | ... | ... | ... | ... |
| 10 | 0.40 | 0.03 | **0.162** | 0.80 | 0.12 | 0.40-0.08 | 0.03-0.012 | **(0.32, 0.018)** |

그래프에서 볼 수 있는 것:
*   **빨간 점**은 (3,2,17)에서 그릇 표면 위에 시작합니다 $\[f(3,2) = 9+8 = 17이므로\]$.
*   각 반복마다: 점은 중심 (0,0,0)을 향해 미끄러져 내려갑니다.
*   각 지점의 **두 개의 경사 화살표**는 x-기울기와 y-기울기를 보여줍니다.
*   점은 (0,0,0)의 바닥으로 나선형으로 내려갑니다.
x와 y 모두 동시에 0으로 수렴합니다! 이 알고리즘은 2D 그릇의 최솟값을 자동으로 찾아냅니다.

이것은 신경망의 모든 가중치를 업데이트하는 데 사용하는 근본적인 기술입니다. 우리는 편미분을 사용하여 전체 오류에 대한 각 가중치의 개별적인 기여도를 계산한 다음, 각 가중치를 올바른 방향으로 약간 조정합니다.

마법은 이렇습니다: 각 변수는 자체 경사를 얻지만, 이들은 모두 함께 최솟값을 찾기 위해 작동합니다. 이를 수백만 개의 변수로 확장하면, 신경망 훈련이 됩니다!

### 3. 연쇄 법칙 - 역전파의 비밀
**묘수:**
```
dy/dx = (dy/du) × (du/dx)
```

이 우아한 공식이 딥러닝을 가능하게 합니다. 이 공식은 원인과 결과의 사슬을 통해 영향력을 추적하며, 사슬이 아무리 길어져도 상관없습니다.

**해결하는 문제:** 딥 네트워크에서는 한 가중치가 최종 오류로부터 20개 레이어 떨어져 있을 수 있습니다. 그 책임은 어떻게 계산할까요? **연쇄 법칙은 각 단계의 영향을 곱하여 총 영향을 찾습니다.**

**아름다운 부분은 이것입니다. 문제가 발생했을 때 누구에게 책임이 있는지 찾기 위해 "책임 전가 게임"을 하는 것과 똑같이 작동합니다.**

**책임 전가 게임 비유:** 팀 프로젝트가 실패했다고 상상해 보세요. 거슬러 올라가 추적해야 합니다:
*   최종 발표가 나빴습니다 (오류).
*   슬라이드가 잘못되었기 때문입니다 (중간 단계).
*   데이터 분석에 결함이 있었기 때문입니다 (이전 단계).
*   원래 데이터 수집이 엉성했기 때문입니다 (근본 원인).

최종 실패에 대해 데이터 수집가가 얼마나 책임이 있는지 찾으려면 각 단계의 책임을 곱합니다: 데이터 → 분석 → 슬라이드 → 발표.

**연쇄 법칙은 정확히 이 작업을 수행합니다:** 중첩된 함수를 통해 책임을 역추적하여 각 변수가 최종 결과에 얼마나 기여하는지 찾습니다.

#### 3.1 여러 변수를 가진 복잡한 함수
여러 변수를 가진 위협적인 중첩 함수가 있다고 상상해 보세요:

**f(x1,x2) = ((2x1 + x2)² + 3x2²)³**

복잡해 보입니다! 여러 변수와 중첩된 연산. 이를 사슬로 분해해 봅시다:
*   u = 2x1 + x2
*   v = u² + 3x2²
*   그러면 f = v³
그래서 우리는 (x1,x2) → u → v → f를 가집니다.

**많은 변수와 단계들! 하지만 걱정하지 마세요. 연쇄 법칙이 이것을 쉽게 계산하게 해줍니다:**

#### 3.2 연쇄 법칙은 복잡한 함수를 다루기 쉽게 만듭니다
이제 마법 같은 부분입니다: 우리는 다변수 경사 하강 알고리즘에서 두 경사 모두를 사용할 수 있습니다!
```
FOR 100 iterations:
  ∂f/∂x1 = 12uv² 
  ∂f/∂x2 = 3v²(2u + 6x2)
  x1 = x1 - η × ∂f/∂x1
  x2 = x2 - η × ∂f/∂x2
RETURN (x1,x2)
```

연쇄 법칙은 여러 변수를 가진 임의로 복잡한 중첩 함수의 경사를 찾을 수 있게 해줍니다. 경사 하강법과 결합하면, 우리는 가장 위협적인 함수조차도 최소화할 수 있습니다!

**이 접근 방식의 힘:** 함수가 아무리 복잡해져도 (깊이 중첩되고, 여러 변수를 가지더라도) 항상 다음을 수행:
1.  **연쇄 법칙을 사용하여 모든 편미분을 찾습니다**.
2.  **경사 하강법을 적용하여 최소화합니다**.

이 체계적인 접근 방식은 모든 미분 가능한 함수에 작동합니다. 이제 수백만 개의 변수와 수천 개의 중첩된 연산을 가진 함수를 다룰 수 있습니다!

### 4. 순전파 - 첫 신경망 구축하기
#### 4.1 신경망이란 무엇인가요?
신경망은 "계층"으로 구성된 단순한 함수들("뉴런"이라고 함)의 집합일 뿐입니다. 각 뉴런은 몇 가지 입력을 받아 단순한 계산을 수행하고 그 결과를 다음 계층으로 전달합니다.

**뉴런:** 각 뉴런은 그저 단순한 함수입니다. \\
f(x,y) = (x + 2y)² 또는 g(a,b) = 3ab와 같이요. 마법 같은 것은 없습니다!

**계층:** 우리는 **의존성** 때문에 뉴런을 계층으로 구성. 요리에 비유하면:
*   **1계층 뉴런:** 원재료(입력 x1, x2)를 사용합니다.
*   **2계층 뉴런:** 1계층의 결과를 사용합니다 (1계층이 완료될 때까지 계산할 수 없음).
*   **3계층 뉴런:** 2계층의 결과를 사용합니다. 이런 식으로 계속됩니다...
이것은 **순방향 흐름**을 만듭니다: 원시 데이터 → 1계층 → 2계층 → 최종 답변.

**계층이 중요한 이유:** 각 계층은 다음 계층이 시작하기 전에 계산을 완료해야 합니다. 이는 각 스테이션이 이전 스테이션에 의존하는 조립 라인과 같습니다.

흥미로운 중첩 함수를 가진 신경망을 구축해 봅시다. 이 신경망은 다음을 가질 것입니다:
*   **2개의 입력** (x1, x2)
*   **1계층에 2개의 뉴런**
*   **2계층에 1개의 뉴런**
*   **학습할 5개의 가중치** (w1, w2, w3, w4, w5)

이것을 **순전파(Forward Pass)**라고 부릅니다. 네트워크가 입력을 읽고 예측을 생성하는 과정입니다. 아직 학습은 없고, 단지 출력을 계산하는 것입니다.

#### 4.2 네트워크 아키텍처

각 뉴런은 그저 중첩 함수일 뿐입니다.
```
Layer 1:
  neuron 1: h1 = (x1 + w1*x2)²
  neuron 2: h2 = w2*x1*x2

Layer 2:
  neuron 1: y_pred = w3*h1 + w4*h2 + w5
```

**우리의 과제:** 이 목표 함수를 학습하도록 네트워크를 훈련시키는 것입니다:
f(x1,x2) = 2x1² + 3x2.

다음은 우리의 3가지 훈련 예시입니다:

| Input (x1,x2) | y_true | What We Want |
|-------------|---------------|--------------|
| (3, 2) | 2(3²) + 3(2) = 18 + 6 = **24** | Network should output 24 |
| (1, 4) | 2(1²) + 3(4) = 2 + 12 = **14** | Network should output 14 |
| (2, 1) | 2(2²) + 3(1) = 8 + 3 = **11** | Network should output 11 |

모든 예시에서 우리 네트워크가 어떻게 작동하는지 봅시다.

**초기 가중치:** w1=1, w2=2, w3=1, w4=1, w5=0.

#### 4.3 **네트워크 결과**

| Input (x1,x2) | y_true | Network Predicts | Difference |
|-------------|----------|------------------|------------|
| (3, 2) | 24 | 37 | -13 |
| (1, 4) | 14 | 33 | -19 |
| (2, 1) | 11 | 13 | -2 |

#### 4.4 오류를 정량화해 봅시다!

**성공을 어떻게 측정할까요?** \\
모든 예시에서 우리 네트워크가 얼마나 틀렸는지 알려주는 단일 숫자가 필요합니다.

**왜 단순히 차이를 더하지 않을까요?** \\
예를 들어 (-13) + (-19) + (-2) = -34입니다. 하지만 +17과 -17의 차이가 있었다면 어떨까요? 그들은 0으로 상쇄되어 네트워크가 실제로는 끔찍한데도 완벽하게 보이게 할 것입니다!

**해결책: 차이를 제곱하세요!** \\
(차이)²는 항상 양수이며, 더 큰 실수는 더 크게 벌점화됩니다.
*   작은 실수: (-2)² = 4
*   큰 실수: (-19)² = 361

**총 제곱 오차:** 
오차 = (-13)² + (-19)² + (-2)² = 169 + 361 + 4 = **534**.

우리 네트워크는 한참 틀렸습니다! f(x1,x2) = 2x1² + 3x2를 학습해야 하지만, 완전히 다른 것을 계산하고 있습니다. 큰 총 오차는 이 네트워크가 절실히 훈련이 필요함을 보여줍니다.
우리는 순전파를 성공적으로 완료했습니다. 우리 네트워크는 예측을 했고, 우리는 그것이 얼마나 틀렸는지 측정했습니다.

다음으로, 이 끔찍한 예측을 수정하기 위해 1-3부의 도구들을 사용할 것입니다. 우리는 모든 복잡한 중첩 연산(연쇄 법칙)을 통해 오류를 역추적하여 각 가중치가 얼마나 기여했는지(편미분) 찾은 다음, 오류를 줄이기 위해 모든 가중치를 조정할 것입니다(경사 하강법).

### 5. 역전파 - 신경망이 학습하는 방법
#### 5.1 핵심 통찰: 신경망은 중첩 함수이다
3부에서 복잡한 중첩 함수를 어떻게 다루었는지 기억하시나요? 신경망도 정확히 똑같습니다!

**비교:**

| 복잡한 함수 (3부)      | 신경망 (4부)                 |
| :------------------- | :-------------------------- |
| 중첩 연산: f(g(h(x))) | 계층형 연산: Layer2(Layer1(inputs)) |
| 변수: x1, x2         | 변수: ???                   |
| 목표: f(x1,x2) 최소화 | 목표: Error(???) 최소화      |
| 도구: 연쇄 법칙 + 경사 하강법 | 도구: 연쇄 법칙 + 경사 하강법 |

**질문: 우리 신경망의 변수는 무엇일까요?** \\
우리가 가진 것을 봅시다:

*   2개의 입력 (x1, x2)
*   1계층에 2개의 뉴런
*   2계층에 1개의 뉴런
*   학습할 5개의 가중치 (w1, w2, w3, w4, w5)

**답변:** x1, x2? **틀렸습니다!**

입력 (x1, x2)는 훈련 데이터에서 우리에게 **주어진** 것입니다. 우리는 그것들을 바꿀 수 없습니다.

**우리가 제어하는 변수는 가중치입니다:** w1, w2, w3, w4, w5.

**업데이트된 비교:**

| 복잡한 함수 (3부)      | 신경망 (4부)                 |
| :------------------- | :-------------------------- |
| 변수: x1, x2         | 변수: w1, w2, w3, w4, w5    |
| 목표: f(x1,x2) 최소화 | 목표: Error(w1,w2,w3,w4,w5) 최소화 |

**돌파구:** \\
우리는 이미 복잡한 중첩 함수를 최소화하는 방법을 알고 있습니다! 신경망은 또 다른 중첩 함수일 뿐입니다. 같은 도구, 같은 접근 방식입니다.

우리는 경사 하강법을 사용하여 오류를 최소화하는 가중치를 찾습니다. 마치 1-3부에서 함수를 최소화하는 x1,x2 값을 찾았던 것처럼요!

3부에서 배운 "책임 전가 게임"을 할 시간입니다! 우리는 오류에서부터 거슬러 올라가 각 가중치가 실수에 대해 얼마나 책임이 있는지 찾아낼 것입니다.

#### 5.2 네트워크 아키텍처
우리 예시로 네트워크를 다시 살펴봅시다: x1=3, x2=2, y_true=24, 예측=37.

```
Layer 1:
  Input:
    constant: x1, x2
    variable: w1, w2
  Output:
    neuron 1: h1 = (x1 + w1×x2)² = (3 + 1×2)² = 25
    neuron 2: h2 = w2×x1×x2 = 2×3×2 = 12

Layer 2:
  Input:
    variable: h1, h2, w3, w4, w5
  Output:
    neuron 1: y_pred = w3×h1 + w4×h2 + w5 = 1×25 + 1×12 + 0 = 37

Error:
  Input:
    constant: y_true = 24
    variable: y_pred = 37
  Output:
    Error = (y_true - y_pred)² = (24 - 37)² = 169
```

이것을 책임 조사의 일종이라고 생각해 보세요. 우리 예측은 틀렸고 (오류 = 169), 우리는 어떤 가중치가 이 실수에 가장 큰 책임이 있는지 알아내야 합니다.

#### 5.3 간단하게 시작하기: w5

가장 간단한 경우부터 시작해 봅시다. w5는 얼마나 책임이 있을까요? \\
w5가 오류에 이르는 경로는 직접적입니다: 오류 ← y_pred ← w5. \\
w5를 변경하는 것이 오류에 어떻게 영향을 미치는지 찾기 위해 연쇄 법칙을 사용합니다:\\
∂Error/∂w5 = ∂Error/∂y_pred × ∂y_pred/∂w5.

각 부분들을 계산하면:
- ∂Error/∂y_pred = ∂/∂y_pred $\[$(y_true - y_pred)²$\]$ = 2×(y_pred - y_true) = 2×(37 - 24) = **26**
- ∂y_pred/∂w5 = ∂/∂w5 $\[w3×h1 + w4×h2 + w5\]$ = **1**

Therefore: **∂Error/∂w5 = 26 × 1 = 26**


#### 5.4 복잡성 추가하기: w1
이제 좀 더 까다로운 가중치를 시도해 봅시다. w1은 얼마나 책임이 있을까요? \\
w1이 오류에 이르는 경로는 더 깁니다: 오류 ← y_pred ← h1 ← w1. \\
연쇄 법칙을 사용하여: \\
∂Error/∂w1 = ∂Error/∂y_pred × ∂y_pred/∂h1 × ∂h1/∂w1.

∂Error/∂y_pred = 26 이므로. 다른 부분을 계산하면:
- ∂y_pred/∂h1 = ∂/∂h1 $\[w3×h1 + w4×h2 + w5\]$ = w3 = **1**
- ∂h1/∂w1 = ∂/∂w1 $\[(x1 + w1×x2)²\]$ = 2×(x1 + w1×x2)×x2 = 2×(3 + 1×2)×2 = **20**

따라서: **∂Error/∂w1 = 26 × 1 × 20 = 520**

#### 5.5 패턴: 중복 부분을 보세요!
```
∂Error/∂w5 = ∂Error/∂y_pred × ∂y_pred/∂w5 = 26 × 1 = 26

∂Error/∂w1 = ∂Error/∂y_pred × ∂y_pred/∂h1 × ∂h1/∂w1 = 26 × 1 × 20 = 520
```
잠깐! **∂Error/∂y_pred = 26**이 두 계산 모두에 나타난다는 것을 주목하세요!

**핵심 통찰!!** 이 중간 계산들은 공유됩니다! 모든 가중치의 경사에는 ∂Error/∂y_pred가 포함됩니다. 이것은 우리가 다음을 할 수 있다는 것을 의미합니다:
1.  **한 번 계산:** ∂Error/∂y_pred = 26을 계산합니다.
2.  **어디서든 재사용:** 이 값을 모든 가중치 경사에 사용합니다.
3.  **뒤로 전파:** 계산을 재사용하며 계층별로 작업합니다.

이것이 역전파의 본질입니다. 우리는 공유된 계산을 재사용하여 네트워크를 통해 오류 경사를 뒤로 전파합니다!

#### 5.6 체계적인 접근 방식: 모든 가중치 한 번에
이제 공유된 계산을 사용하여 모든 가중치 경사를 체계적으로 계산해 봅시다.

먼저, 우리는 필요한 모든 개별 파생물을 계산합니다.
```
Error gradients:
  ∂Error/∂y_pred = 26

Layer 2 gradients:
  ∂y_pred/∂w5 = 1
  ∂y_pred/∂w4 = h2 = 12  
  ∂y_pred/∂w3 = h1 = 25
  ∂y_pred/∂h1 = w3 = 1
  ∂y_pred/∂h2 = w4 = 1

Layer 1 gradients:
  ∂h1/∂w1 = 2×(x1 + w1×x2)×x2 = 20
  ∂h2/∂w2 = x1×x2 = 6
```

이제 각 가중치의 경로를 따라 곱합니다.
```
w5: ∂Error/∂w5 = ∂Error/∂y_pred × ∂y_pred/∂w5 = 26 × 1 = 26
w4: ∂Error/∂w4 = ∂Error/∂y_pred × ∂y_pred/∂w4 = 26 × 12 = 312  
w3: ∂Error/∂w3 = ∂Error/∂y_pred × ∂y_pred/∂w3 = 26 × 25 = 650
w2: ∂Error/∂w2 = ∂Error/∂y_pred × ∂y_pred/∂h2 × ∂h2/∂w2 = 26 × 1 × 6 = 156
w1: ∂Error/∂w1 = ∂Error/∂y_pred × ∂y_pred/∂h1 × ∂h1/∂w1 = 26 × 1 × 20 = 520
```

#### 5.7 경사 하강법 업데이트
이제 이 경사들을 사용하여 가중치를 업데이트합니다. 학습률 η = 0.0001을 사용합니다.

| Weight | Old Value | Gradient | Update | New Value |
|--------|-----------|----------|--------|-----------|
| w5 | 0 | 26 | 0 - 0.0001×26 | **-0.0026** |
| w4 | 1 | 312 | 1 - 0.0001×312 | **0.9688** |
| w3 | 1 | 650 | 1 - 0.0001×650 | **0.935** |
| w2 | 2 | 156 | 2 - 0.0001×156 | **1.9844** |
| w1 | 1 | 520 | 1 - 0.0001×520 | **0.948** |

**방금 무슨 일이 일어났을까요?** \\
우리는 연쇄 법칙을 사용하여 오류에서 각 가중치로 책임을 역추적한 다음, 오류를 줄이는 방향으로 각 가중치를 약간 조정했습니다. 이것이 바로 역전파입니다!

**진실의 순간입니다!** \\
업데이트된 가중치로 네트워크를 다시 실행하여 무엇을 학습했는지 확인해 봅시다.

#### 5.8 새로운 가중치로 순전파
업데이트된 가중치(w1=0.948, w2=1.9844, w3=0.935, w4=0.9688, w5=-0.0026)를 사용하여 계산한 결과:
```
Layer 1:
- h1 = (x1 + w1×x2)² = (3 + 0.948×2)² = (3 + 1.896)² = (4.896)² = **23.97**
- h2 = w2×x1×x2 = 1.9844×3×2 = 11.91

Layer 2:
- y_pred = w3×h1 + w4×h2 + w5 = 0.935×23.97 + 0.9688×11.91 + (-0.0026)
- y_pred = 22.41 + 11.54 - 0.0026 = 33.95
```

#### 5.9 학습 전 vs 학습 후

|            | 학습 전 예측 | 학습 후 예측 | 목표 |
| :--------- | :----------- | :----------- | :--- |
| **예측**   | 37           | 33.95        | 24   |
| **얼마나 틀렸는지** | 13단위 높음  | 10단위 높음  | 완벽 = 0 |

**훌륭합니다!** \\
네트워크가 올바른 방향으로 움직였습니다! 37에서 33.95로 이동하여 목표인 24에 더 가까워졌습니다. 오류는 13단위에서 약 10단위로 감소했습니다. 이것이 바로 진전입니다!

**이것은 수학에서 나오는 지능입니다.** \\
네트워크는 연쇄 법칙을 사용하여 책임을 역추적한 다음, 올바른 방향으로 스스로를 조정했습니다. 더 많은 반복을 통해 목표에 훨씬 더 가까워질 것입니다!


### 6. 여러 훈련 예시 - 모든 데이터로부터 학습하기
**한계:** \\
지금까지 우리는 하나의 예시 (x1=3, x2=2, y_true=24)로만 훈련했습니다. 하지만 실제 네트워크는 수천 또는 수백만 개의 예시로부터 학습합니다!

**질문:** \\
여러 훈련 쌍이 있다면 어떨까요? 이들을 모두 어떻게 처리할까요?

우리 목표 함수 f(x1,x2) = 2x1² + 3x2를 기억하세요. 우리는 세 가지 훈련 예시를 가졌습니다:
*   (3, 2) 입력 시 24 출력
*   (1, 4) 입력 시 14 출력
*   (2, 1) 입력 시 11 출력

우리는 첫 번째 예시만 사용했습니다. 하지만 패턴을 진정으로 학습하려면 우리 네트워크는 모든 데이터를 봐야 합니다!

#### 6.1 두 가지 접근 방식: 온라인 학습 vs 배치 학습
**접근 방식 1: 온라인 학습 (우리가 했던 방식)**
```
For each example (x1, x2, y_true) in training_data:
    1. Forward pass: compute y_pred
    2. Calculate gradients: ∂Error/∂w for all weights  
    3. Update weights: w = w - η × ∂Error/∂w
    4. Move to next example
```

**접근 방식 2: 배치 학습**
```
1. For each example (x1, x2, y_true) in training_data:
     - Forward pass: compute y_pred
     - Calculate gradients: ∂Error/∂w for all weights
     - Store gradients (don't update yet!)
   
2. Sum all gradients: ∂Total_Error/∂w = Σ ∂Error/∂w
3. Update weights once: w = w - η × ∂Total_Error/∂w
```

#### 6.2 배치 학습을 시도해 봅시다

**원본** 가중치(w1=1, w2=2, w3=1, w4=1, w5=0)를 사용합니다.

*   1단계: 모든 예시에 대한 순전파
    -   각 훈련 예시에 대해 네트워크의 예측과 오류를 계산합니다.

    | Example | (x1,x2) | y_true | h1 | h2 | y_pred | Error |
|---------|---------|--------|----|----|--------|-------|
| 1 | (3, 2) | 24 | (3+1×2)² = 25 | 2×3×2 = 12 | 1×25 + 1×12 + 0 = **37** | (24-37)² = **169** |
| 2 | (1, 4) | 14 | (1+1×4)² = 25 | 2×1×4 = 8 | 1×25 + 1×8 + 0 = **33** | (14-33)² = **361** |
| 3 | (2, 1) | 11 | (2+1×1)² = 9 | 2×2×1 = 4 | 1×9 + 1×4 + 0 = **13** | (11-13)² = **4** |


*   2단계: 모든 예시에 대한 경사 계산


    | Example | ∂Error/∂w1 | ∂Error/∂w2 | ∂Error/∂w3 | ∂Error/∂w4 | ∂Error/∂w5 |
    |---------|------------|------------|------------|------------|------------|
    | 1 | 26 × 1 × 20 = **520** | 26 × 1 × 6 = **156** | 26 × 25 = **650** | 26 × 12 = **312** | 26 × 1 = **26** |
    | 2 | 38 × 1 × 10 = **380** | 38 × 1 × 4 = **152** | 38 × 25 = **950** | 38 × 8 = **304** | 38 × 1 = **38** |
    | 3 | 4 × 1 × 6 = **24** | 4 × 1 × 4 = **16** | 4 × 9 = **36** | 4 × 4 = **16** | 4 × 1 = **4** |
    | **TOTAL** | **924** | **324** | **1636** | **632** | **68** |

    *   예시 1: ∂Error/∂y_pred = 2×(37-24) = 26
    *   예시 2: ∂Error/∂y_pred = 2×(33-14) = 38
    *   예시 3: ∂Error/∂y_pred = 2×(13-11) = 4
    그 다음, 각 가중치에 대한 모든 예시의 경사를 합산하여 **총 경사**를 얻습니다.

*    3단계: 총 경사를 사용하여 가중치 업데이트(학습률 η = 0.0001을 사용)

| Weight | Old Value | Total Gradient | Update | New Value |    
|--------|-----------|---------------|--------|-----------|
| w1 | 1 | 924 | 1 - 0.0001×924 | **0.9076** |
| w2 | 2 | 324 | 2 - 0.0001×324 | **1.9676** |
| w3 | 1 | 1636 | 1 - 0.0001×1636 | **0.8364** |
| w4 | 1 | 632 | 1 - 0.0001×632 | **0.9368** |
| w5 | 0 | 68 | 0 - 0.0001×68 | **-0.0068** |

*   **핵심 통찰:** 배치 학습은 모든 예시의 정보를 사용하여 가중치를 업데이트하므로, 개별 예시를 사용하는 온라인 학습보다 더 안정적인 학습 방향을 제공합니다!

#### 6.3  검증: 배치 학습 전후
새로운 가중치(w1=0.9076, w2=1.9676, w3=0.8364, w4=0.9368, w5=-0.0068)를 모든 예시에 적용하여 개선 사항을 확인해 봅시다.

| 예시   | 목표 | 학습 전 (기존 가중치) | 학습 후 (배치 가중치) | 개선 사항           |
| :----- | :--- | :-------------------- | :------------------ | :---------------- |
| (3, 2) | 24   | 37 (13 높음)          | **30.98** (7 높음)  | ✓ 6단위 더 좋아짐 |
| (1, 4) | 14   | 33 (19 높음)          | **27.69** (14 높음) | ✓ 5단위 더 좋아짐 |
| (2, 1) | 11   | 13 (2 높음)           | **10.66** (0.3 낮음) | ✓ 훨씬 가까워짐  |


**새로운 예측에 대한 계산:**
- Example 1: h1=(3+0.9076×2)²=24.52, h2=1.9676×3×2=11.81 → y_pred=0.8364×24.52+0.9368×11.81-0.0068=**30.98**
- Example 2: h1=(1+0.9076×4)²=24.03, h2=1.9676×1×4=7.87 → y_pred=0.8364×24.03+0.9368×7.87-0.0068=**27.69**  
- Example 3: h1=(2+0.9076×1)²=8.46, h2=1.9676×2×1=3.94 → y_pred=0.8364×8.46+0.9368×3.94-0.0068=**10.66**

**놀랍습니다!** 단 한 번의 배치 업데이트 후 세 가지 예측 모두 크게 개선되었습니다!

#### 6.4 여러 예시의 힘
**이것이 중요한 이유:**
*   **단일 예시:** 네트워크가 그 한 가지 경우를 암기할 수 있습니다.
*   **여러 예시:** 네트워크는 모든 경우에 작동하는 패턴을 찾아야 합니다.
*   **결과:** 새로운, 보지 못한 데이터에 대한 더 나은 일반화.

#### 6.6 실제 배치 크기의 절충점
*   **순수 온라인 학습 (배치 크기 = 1):**
    *   ✓ 빠른 업데이트, 적은 메모리
    *   ✗ 노이즈가 많은 경사, 불안정한 학습

*   **전체 배치 학습 (배치 크기 = 모든 데이터):**
    *   ✓ 안정적이고 정확한 경사
    *   ✗ 느리고, 대규모 데이터셋에 엄청난 메모리 필요
        *   모든 예시에 대해 순전파와 역전파를 동시에 계산해야 함 (각각 활성화 저장 공간 필요).
        *   1백만 개의 훈련 예시의 경우: 미니배치보다 1백만 배 더 많은 메모리 필요!

*   **미니배치 학습 (배치 크기 = 32-512):** ***최적의 지점!***
    *   ✓ 충분히 안정적인 경사
    *   ✓ 합리적인 메모리 사용량
    *   ✓ GPU에서 계산 병렬화 가능

*   **실제로는:** 현대 네트워크는 미니배치를 사용합니다:
    *   **작은 모델:** 배치당 32-128개 예시
    *   **대규모 모델 (GPT 등):** 배치당 256-2048개 예시
    *   **매우 큰 데이터셋:** 관리 가능한 크기의 미니배치로 수백만 개의 예시 처리
    이것이 네트워크가 수백만 장의 다른 사진에서 고양이를 인식하고, 언어 간 번역을 하거나, 인간과 같은 텍스트를 생성하는 방법입니다. 신중하게 크기가 조정된 미니배치에서 한 번에 수천 개의 예시를 처리함으로써 말이죠!

### 7. 규모 확장 - 보편적인 패턴
**놀라운 사실:**
```
Our Tiny Network:         5 weights
GPT-4:           1,760,000,000,000 weights
Identical Process:    ✓ Forward Pass
                      ✓ Backpropagation  
                      ✓ Gradient Descent
```

우리의 장난감 예시부터 수조 개의 매개변수를 가진 모델까지, 그것은 동일한 세 단계의 춤입니다. 규모는 모든 것을 바꾸고 아무것도 바꾸지 않습니다.

**놀라운 진실:** 여러분은 지구상의 모든 AI 시스템 내부에서 실행되는 핵심 알고리즘을 방금 마스터했습니다. ChatGPT, 자율주행차, 의료 진단 AI 등 이 모든 것이 우리가 구축한 것의 변형입니다.

**그 외의 모든 것은 이러한 기본 위에 쌓아 올린 공학적 세부 사항일 뿐입니다.**

그렇다면, 우리의 간단한 모델에서 이 거대한 모델들로 어떻게 나아갈까요?

아름다운 답변은 핵심 원리가 전혀 변하지 않는다는 것입니다. 우리가 방금 구축한 엔진, 즉 순전파, 역전파, 경사 하강 업데이트는 가장 진보된 AI 모델조차 구동하는 바로 그 엔진입니다. 유일한 차이점은 규모와 몇 가지 더 정교한 부품들입니다.

여기 우리 간단한 개념들이 어떻게 확장되는지 보여줍니다:

#### 7.1 더 많은 계층과 뉴런

| Our Network | Real Networks |
|-------------|---------------|
| 2 layers | 10-100+ layers |
| 2 hidden neurons | Millions-billions of neurons |
| 5 weights total | Trillions of weights |

무엇이 변할까요? 단지 연쇄 법칙을 위한 "사슬"이 훨씬 더 길어질 뿐입니다. 가장 첫 번째 계층의 가중치에 대한 경사를 찾으려면, 모든 후속 계층을 통해 역전파해야 합니다. 더 많은 계산, 동일한 과정입니다.

#### 7.2 더 실용적인 활성화 함수
우리는 뉴런에 x²을 사용했지만, 실제 네트워크는 학습에 더 적합한 함수를 사용합니다. **핵심 요구 사항:** 경사를 계산할 수 있는 모든 함수 (부분 경사와 같은 근사치도 작동합니다!)!

| Function | Formula | Gradient | Why Popular |
|----------|---------|----------|-------------|
| **ReLU** | max(0, x) | 1 if x>0, else 0* | Simple, fast, prevents gradients from shrinking to zero in deep networks |
| **Sigmoid** | 1/(1+e^(-x)) | sigmoid(x)×(1-sigmoid(x)) | Perfect for final layer when predicting "yes/no" or probabilities |
| **Our x²** | x² | 2x | Works but gradients grow exponentially large, causing instability |


*참고: ReLU의 "경사"는 x=0에서 진정한 수학적 미분값이 아닙니다 (뾰족한 모서리!). 그러나 우리는 0을 실용적인 근사치로 사용합니다. 이 "부분 경사"는 실제에서 잘 작동합니다.

**이러한 선택의 이유?**
*   **ReLU는 기울기 소실을 방지합니다:** 
    -   연쇄 법칙을 사용한 "책임 전가 게임"을 기억하시나요? CEO가 VP를 비난하고, VP가 이사를 비난하고, 이사가 관리자를 비난하는 식으로 100단계 아래로 내려간다고 상상해 보세요. 각 사람이 비난의 30%만 전달한다면 (기울기 = 0.3), 주니어 직원에 도달할 때쯤에는: 0.3^100 ≈ 0 – 비난 신호가 남아있지 않습니다! 주니어 직원들은 결코 학습하지 못합니다. ReLU는 비난의 100%를 전달하므로 (기울기 = 1), 가장 주니어인 사람도 완전한 피드백 신호를 받습니다.
*   **확률을 위한 시그모이드:** 
    -   "스팸일 확률 30%"와 같은 출력이 필요할 때, 시그모이드는 모든 입력을 0-1 범위로 압축합니다.
*   **왜 x²는 안 될까요?** 
    -   경사 2x는 무한히 커집니다. x=1000일 때 경사=2000이 된다고 상상해 보세요. 이는 가중치 업데이트를 엄청나게 크고 혼란스럽게 만듭니다!

**아름다운 점:** 함수를 바꾸는 것은 연쇄 법칙 계산의 한 링크만 변경할 뿐이지만, 전체 역전파 과정은 동일하게 유지.

#### 7.3 다양한 작업에 더 나은 손실 함수

| Task | Loss Function | Example |
|------|---------------|---------|
| **Regression** (predict numbers) | Mean Squared Error: (y_true - y_pred)² | House prices, temperatures |
| **Classification** (cat vs dog) | Cross-Entropy Loss: -log(predicted_probability) | Network outputs: $\[0.8, 0.2\] for \[cat, dog\]$, true label: cat → Loss = -log(0.8) = 0.22 |

**핵심:** 어떤 손실 함수를 사용하든, 그 역할은 동일합니다. 역전파를 시작하기 위해 미분할 수 있는 숫자를 제공하는 것.

### 8. 결론: 그것은 마법이 아니다
신경망이 예술을 생성하든 자동차를 운전하든, 아무리 복잡해 보여도 우리가 방금 살펴본 정확한 과정을 통해 학습

1.  **순전파** - 추측하기
2.  **손실 함수** - 추측이 얼마나 틀렸는지 측정하기
3.  **역전파** - 연쇄 법칙을 사용하여 모든 가중치에 대한 책임을 계산하기
4.  **경사 하강법** - 모든 가중치를 올바른 방향으로 미세 조정하기
5.  **반복** - 이 과정을 수백만 번 수행하기

여러분은 신경망이 난공불락의 블랙박스라고 생각하며 이 여정을 시작했습니다. 하지만 이제 진실을 알게 되었습니다. 그것은 마법이 아닙니다. 계곡의 바닥을 찾고, 한 번에 하나의 노브를 조절하고, 사슬을 따라 메시지를 전달하는 것과 같은 단순하고 직관적인 아이디어들의 연속일 뿐입니다.
