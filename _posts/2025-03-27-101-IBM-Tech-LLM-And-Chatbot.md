---
title: 18차시 1:IBM TECH(LLM & Chatbot)
layout: single
classes: wide
categories:
  - LLM & Chatbot
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


## 1. Large Language Model (LLM) Tuning 방법
- 출처:[What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=2)


### **1.1 LLM과 Foundation Model**
*   LLM (ChatGPT 등): 다양한 인터넷 소스와 방대한 텍스트 데이터셋을 통해 학습된 대규모 기반 모델의 대표적인 예시
*   특징: 범용성과 높은 유연성을 바탕으로 법률 문서 분석, 창의적 글쓰기, 코딩, 번역 등 거의 모든 텍스트 기반 작업 수행 가능
*   핵심 차별점: 사전 훈련된 지식을 다양한 상황에 적용할 수 있는 능력

### **1.2 LLM 성능 향상 방법 비교**

| 방법 | 설명 | 장점 | 단점 |
| --- | --- | --- | --- |
| Fine Tuning | 대규모 레이블링된 특정 도메인 데이터를 활용하여 모델 전체를 재학습하는 정교한 방식 | - 특정 분야에 대해 매우 높은 정확도 달성<br>- 모델의 근본적인 성능 향상 가능 | - 대량의 고품질 레이블 데이터 확보 어려움<br>- 계산 리소스와 시간 집약적<br>- 과적합(Overfitting) 위험 |
| Prompt Tuning | 제한된 데이터로 모델을 특정 작업에 미세 조정하는 경량화된 접근 방식 | - 최소한의 데이터로 작업 특화 가능<br>- 빠르고 효율적인 모델 적응<br>- 계산 리소스 최소화 | - 프롬프트의 해석 및 설명이 어려움<br>- 복잡한 작업에 대한 한계<br>- 성능 예측의 불확실성 |
| Prompt Engineering | 의도한 결과를 이끌어내기 위해 정교하게 설계된 프롬프트를 활용하는 방법 | - 모델 재학습 불필요<br>- 즉각적인 성능 최적화<br>- 비용 효율적 | - 작업별 맞춤형 프롬프트 개발에 전문성 필요<br>- 복잡한 작업에 대한 일관성 부족<br>- 반복적인 실험과 조정 필요 |

### **1.3 프롬프트 종류**

*   **Hard Prompt:** 인간이 직접 텍스트로 작성하는 전통적인 프롬프트 방식 (예: "영어를 프랑스어로 번역해줘")
*   **Soft Prompt:** 머신러닝 알고리즘이 생성한 고차원 벡터 표현. 인간에게는 불투명하지만 모델 성능 측면에서 더 효과적

### **1.4 각 방법의 특징**

*   **Fine Tuning:** 기존 사전 학습 모델에 특정 도메인의 레이블 데이터를 주입하여 모델의 고유 파라미터를 직접 조정
*   **Prompt Engineering:** 입력과 함께 세심하게 설계된 맥락과 지시어를 결합하여 모델의 출력 방향 제어
*   **Prompt Tuning:** AI가 생성한 학습 가능한 임베딩 벡터를 통해 모델의 암묵적 지식 활용

### **1.5 Prompt Tuning의 활용**

*   **Multitask Learning:** 단일 프롬프트로 여러 다른 작업 간 신속하고 유연한 전환 가능
*   **Continual Learning:** 기존 학습 지식을 유지하면서 점진적으로 새로운 작업과 지식 통합

### **1.6 Prompt Tuning의 장점**

*   기존 방법들 대비 더 빠르고 경제적인 모델 특화 접근법
*   최소한의 리소스로 다양한 작업에 대한 모델 적응력 확보
*   지속적인 학습과 모델 진화에 용이한 방법론

## 2. ChatGPT 및 생성형 AI의 위험 요소와 대응 전략
- 출처:[Risks of Large Language Models (LLM)](https://www.youtube.com/watch?v=r4kButlDLUc&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=3)

ChatGPT와 같은 생성형 AI는 영어 작문 능력 향상에 도움이 되지만, 다음과 같은 고유한 위험을 내포하고 있으며, 이에 대한 대비가 필요함.

### **2.1 위험 요소**

1.  **허위 정보 생성 (Hallucinations):**
    *   AI가 실제 이해 없이 문법적으로 맞는 단어를 예측하여 오류를 포함한 답변을 제공할 수 있음.
    *   출처가 불분명하거나 잘못된 정보를 제공하여 사용자의 오해를 유발할 수 있음.
    *   특히 전문 분야에서는 심각한 오류로 이어질 수 있어 전문가의 검증이 필수적임.

2.  **편향성 (Bias):**
    *   학습 데이터의 편향으로 인해 특정 집단(예: 백인 남성)에 치우친 결과가 나타날 수 있음.
    *   다양성을 확보하기 위한 추가적인 프롬프트가 필요할 수 있음.
    *   사회적 고정관념과 차별적 언어를 재생산할 위험성이 존재함.

3.  **동의 (Consent):**
    *   학습 데이터 수집 과정에서 저작권 문제나 데이터 주체의 동의 여부 문제가 발생할 수 있음.
    *   데이터 출처에 대한 정보 부족으로 인해 사용자가 문제점을 파악하기 어려울 수 있음.
    *   개인의 프라이버시 침해 가능성과 지적재산권 문제에 대한 윤리적 고려가 필요함.

4.  **보안 (Security):**
    *   개인 정보 유출, 피싱, 스팸 등 악의적인 목적에 사용될 수 있음.
    *   해킹을 통해 AI 모델의 프로그래밍을 변경하여 부적절한 결과를 유도할 수 있음 (Jailbreaking).
    *   간접적인 프롬프트 주입을 통해 AI의 동작을 변경하여 악성 코드를 유포할 수 있음.
    *   사이버 보안 위협에 대한 지속적인 모니터링과 대응 체계 구축이 중요함.

### **2.2 대응 전략**

1.  **설명 가능성 (Explainability):**
    *   AI 모델의 답변 근거, 데이터 출처, 정보 계보 등을 명확히 제시하여 사용자가 신뢰성을 판단할 수 있도록 함.
    *   지식 그래프(Knowledge Graph)를 활용하여 실제 데이터와 데이터 계보를 연계하여 제공.
    *   AI의 의사결정 과정을 투명하게 공개하여 사용자의 이해와 신뢰를 높임.

2.  **문화 및 감사 (Culture and Audits):**
    *   다양하고 다학제적인 팀을 구성하여 AI 개발 및 운영 과정에서 편향성을 최소화하도록 노력함.
    *   AI 모델 배포 전후에 감사를 실시하여 불공정한 결과에 대한 수정 및 조직 문화 개선에 활용함.
    *   다양한 사회적 배경과 관점을 반영하는 포용적인 개발 프로세스 구축.

3.  **감사 및 책임 (Auditing and Accountability):**
    *   AI 거버넌스 프로세스를 구축하고 관련 법규를 준수하며, 사용자 피드백을 반영할 수 있는 시스템을 마련함.
    *   AI 사용에 대한 법적, 윤리적 책임 메커니즘 개발.
    *   지속적인 모니터링과 성능 평가를 통한 품질 관리.

4.  **교육 (Education):**
    *   AI의 장단점, 책임 있는 AI 큐레이션 원칙, 위험 요소, 환경 비용, 안전 장치 등에 대한 교육을 실시함.
    *   데이터세트가 악의적으로 변경되지 않았는지 확인하고, 사용자가 AI를 통해 얻는 경험을 개선하도록 노력함.
    *   다양한 배경의 사람들이 AI 개발 및 활용에 참여할 수 있도록 교육 기회를 확대함.
    *   AI 리터러시 교육을 통해 사용자의 비판적 사고와 윤리적 판단 능력 향상.


## 3. LLM 환각 현상
- 출처: [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=4)

### **3.1 환각이란?**

*   LLM의 결과물이 사실이나 맥락적 논리에서 벗어나는 현상
*   경미한 불일치부터 완전히 날조되거나 모순적인 진술까지 다양

### **3.2 환각의 종류 (세분화 수준에 따라)**

*   **문장 모순:** LLM이 이전 문장과 모순되는 문장을 생성하는 경우 (예: "하늘은 오늘 파랗다." vs. "하늘은 오늘 초록색이다.")
*   **프롬프트 모순:** 생성된 문장이 프롬프트와 모순되는 경우 (예: 식당에 대한 긍정적인 리뷰 요청에 "음식은 끔찍했고 서비스는 무례했다"라고 응답)
*   **사실적 모순:** 명백한 사실을 틀리게 말하는 경우 (예: "버락 오바마는 미국의 첫 번째 대통령이었다.")
*   **무의미하거나 관련 없는 정보:** 맥락에 맞지 않는 정보를 덧붙이는 경우 (예: "프랑스의 수도는 파리이다. 파리는 유명한 가수의 이름이기도 하다.")

### **3.3 환각 발생 원인**

*   **데이터 품질:**
    *   LLM 학습 데이터에 오류, 편향, 불일치가 포함될 수 있음
    *   학습 데이터가 LLM이 답변해야 할 모든 주제 또는 영역을 다루지 못할 수 있음
    *   LLM이 정확성 또는 관련성을 검증하지 않고 데이터를 일반화할 수 있음
*   **생성 방법:**
    *   빔 서치, 샘플링, 최대 우도 추정, 강화 학습 등의 방법이 유창성, 다양성, 일관성, 창의성, 정확성, 참신성 간의 편향 및 절충을 초래할 수 있음
    *   예: 빔 서치는 낮은 확률의 특정 단어보다 높은 확률의 일반적인 단어를 선호할 수 있음
*   **입력 컨텍스트:**
    *   프롬프트가 불분명하거나, 일관성이 없거나, 모순적인 경우 모델을 혼란스럽게 하거나 오도할 수 있음
    *   컨텍스트 정보가 부족하면 예상치 못한 답변이 나올 수 있음 (예: "고양이가 영어를 할 수 있나요?"에 대한 답변이 대화의 맥락에 따라 달라짐)

### **3.4 환각 최소화 전략**

*   **명확하고 구체적인 프롬프트 제공:** 질문의 의도를 명확하게 전달 (예: "2차 세계 대전은 무엇이었나요?" 대신 "2차 세계 대전의 주요 사건과 주요 관련 국가, 갈등의 주요 원인을 요약해 주시겠어요?")
*   **능동적 완화 전략 사용:** LLM의 설정(예: temperature)을 조정하여 출력의 무작위성을 제어 (temperature가 낮을수록 환각의 기회가 줄어듦)
*   **다중 샷 프롬프팅:** 원하는 출력 형식 또는 컨텍스트에 대한 여러 예제를 제공하여 모델을 효과적으로 프라이밍 (코드 생성, 시 작성, 특정 스타일로 질문에 답변하는 작업에 유용)

## 4. 오픈 소스 LLM (Large Language Model)
- 출처: [Should You Use Open Source Large Language Models?](https://www.youtube.com/watch?v=y9k-U9AuDeM&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=7)

### **4.1 LLM이란?**

*   **인공지능, 딥러닝, 대규모 데이터셋을 활용해 텍스트를 생성하는 기반 모델 (Generative AI):**  
    LLM(Large Language Model)은 인공지능(AI)과 딥러닝 기술을 기반으로, 방대한 텍스트 데이터셋을 학습하여 인간의 언어를 모방하거나 새로운 텍스트를 생성할 수 있는 모델입니다. 이러한 모델은 자연어 처리(NLP) 분야에서 핵심적인 역할을 하며, 질문에 답변하거나 대화를 생성하는 등 다양한 작업에 활용됩니다. 예를 들어, 사용자가 입력한 문장을 기반으로 문맥에 맞는 응답을 생성할 수 있습니다.
*   **Huggingface에 325,000개 이상의 모델 존재, 계속 증가 추세:**  
    Hugging Face와 같은 오픈 소스 플랫폼에는 현재 325,000개 이상의 LLM 및 관련 모델이 등록되어 있으며, 이는 연구자와 개발자들의 높은 관심을 반영합니다. 새로운 모델이 지속적으로 추가되고 있으며, 이는 LLM 기술이 빠르게 발전하고 있음을 보여줍니다.

### **4.2 LLM의 종류**

*   **Proprietary (폐쇄형):**  
    *   **특정 회사가 소유 및 사용 제한 가능 (라이선스):** 폐쇄형 LLM은 특정 기업이나 조직이 소유하며, 사용하려면 라이선스나 구독이 필요할 수 있습니다. 예를 들어, OpenAI의 GPT 시리즈와 같은 모델은 폐쇄형으로 분류됩니다.
    *   **일반적으로 오픈 소스보다 규모가 큼 (파라미터 수):** 이 모델들은 수십억에서 수천억 개의 파라미터를 포함하며, 대규모 데이터와 자원을 활용해 높은 성능을 자랑합니다. 파라미터 수는 모델의 복잡성과 학습 능력을 나타내는 중요한 지표입니다.
    *   **파라미터 수는 비공개인 경우가 많음:** 그러나 폐쇄형 모델은 내부 구조나 학습 데이터, 정확한 파라미터 수가 공개되지 않아 투명성이 부족하다는 단점이 있습니다.
*   **Open Source (개방형):**  
    *   **누구나 자유롭게 접근, 사용, 개선, 수정 가능:** 오픈 소스 LLM은 소스 코드와 모델 세부 사항이 공개되어 있어 누구나 다운로드하고, 필요에 따라 수정하거나 개선할 수 있습니다. 이는 연구자, 개발자, 기업 등이 자유롭게 활용할 수 있는 환경을 제공합니다.

### **4.3 오픈 소스 LLM의 장점**

*   **투명성:**  
    *   **작동 방식, 구조, 학습 데이터에 대한 더 나은 통찰력 제공:** 오픈 소스 LLM은 모델의 설계와 학습 데이터에 대한 정보를 공개하므로, 사용자가 모델의 동작을 분석하고 신뢰성을 평가하기 쉽습니다. 이는 폐쇄형 모델과 비교했을 때 큰 차별점입니다.
*   **Fine-tuning (미세 조정):**  
    *   **특정 사용 사례에 맞게 LLM을 조정하고 자체 데이터로 학습 가능:** 사용자는 자신의 데이터나 특정 목적에 맞춰 모델을 재학습시킬 수 있습니다. 예를 들어, 법률 문서 분석에 특화된 모델을 만들기 위해 법률 데이터를 추가로 학습시킬 수 있습니다.
*   **커뮤니티 기여:**  
    *   **단일 공급업체에 의존하지 않고 다양한 관점을 가진 사람들의 기여를 활용 가능:** 전 세계의 개발자와 연구자가 오픈 소스 LLM에 기여함으로써, 모델은 지속적으로 개선되고 새로운 기능을 추가할 수 있습니다. 이는 단일 기업의 자원에 의존하지 않는 강력한 협업 모델을 만듭니다.

### **4.4 오픈 소스 LLM의 활용 사례**

*   **NASA & IBM: 지리 공간 데이터 기반 오픈 소스 LLM 개발:**  
    NASA와 IBM은 지리 공간 데이터를 활용해 오픈 소스 LLM을 개발하고 있으며, 이는 기후 변화 분석, 자연 재해 예측, 환경 모니터링 등 지구 과학 연구에 사용됩니다. 이러한 협업은 과학적 발견을 가속화하는 데 기여하고 있습니다.
*   **의료 기관: 진단 도구 및 치료 최적화:**  
    의료 분야에서는 환자의 증상 데이터를 분석해 질병을 예측하거나, 치료 계획을 최적화하는 데 오픈 소스 LLM이 활용됩니다. 예를 들어, 환자 기록을 기반으로 의사가 더 나은 결정을 내리도록 돕는 도구로 사용될 수 있습니다.
*   **FinGPT: 금융 산업용 오픈 소스 LLM:**  
    FinGPT는 금융 데이터를 분석하고 주가 예측, 리스크 평가 등에 특화된 오픈 소스 LLM입니다. 금융 전문가들이 복잡한 시장 데이터를 이해하고 의사 결정을 내리는 데 도움을 줍니다.

### **4.5 주요 오픈 소스 LLM**

*   **Llama 2 (Meta AI):**  
    *   **70억 ~ 700억 파라미터, 상업적 사용 가능:** Meta AI에서 개발한 Llama 2는 70억에서 700억 개의 파라미터를 가진 모델로, 연구뿐만 아니라 상업적 용도로도 활용할 수 있습니다. 성능과 효율성 면에서 주목받고 있습니다.
*   **Vicuna:**  
    *   **Llama 모델 기반, 명령어 수행에 특화된 Fine-tuning:** Vicuna는 Llama를 기반으로 하여, 사용자 지시에 따라 더 정확하고 자연스러운 응답을 생성하도록 미세 조정된 모델입니다. 대화형 AI에 적합합니다.
*   **BLOOM (BigScience):**  
    *   **1,000명 이상의 연구자가 참여한 다국어 언어 모델:** BLOOM은 1760억 개의 파라미터를 가진 다국어 모델로, 46개 언어를 지원합니다. BigScience 커뮤니티의 협력으로 개발되었으며, 글로벌 활용 가능성이 높습니다.

### **4.6 LLM의 위험 요소 (Proprietary & Open Source 공통)**

*   **환각 (Hallucinations):**  
    *   **부정확한 데이터, 맥락 이해 부족으로 인해 발생:** LLM이 실제와 다른 잘못된 정보를 생성하는 현상으로, 학습 데이터의 한계나 맥락 파악 실패로 발생할 수 있습니다. 예를 들어, 존재하지 않는 사실을 마치 진실처럼 말할 수 있습니다.
*   **편향 (Bias):**  
    *   **데이터가 다양하지 않거나 대표성을 띄지 못할 경우 발생:** 학습 데이터가 특정 집단이나 관점에 치우쳐 있으면, 모델의 출력도 편향될 수 있습니다. 이는 윤리적 문제나 사회적 갈등을 초래할 수 있습니다.
*   **보안 문제:**  
    *   **개인정보 유출, 사이버 범죄 악용 가능성:** LLM이 민감한 데이터를 생성하거나, 피싱 메일 작성, 가짜 뉴스 생성 등 범죄에 악용될 가능성이 있습니다. 이에 대한 보안 대책이 필요합니다.

### **4.7 오픈 소스 LLM의 미래:**

*   **IBM Watsonx.ai Studio에서 Llama 2 모델 접근 제공:**  
    IBM은 Watsonx.ai Studio를 통해 Llama 2와 같은 오픈 소스 LLM에 대한 접근성을 높이고 있으며, 기업과 개발자가 이를 활용할 수 있도록 지원합니다.
*   **IBM 자체 Foundation Model (Granite) 출시:**  
    IBM은 자체 오픈 소스 모델인 Granite을 개발하여 LLM 기술의 발전에 기여하고 있습니다. 이는 다양한 산업에서의 활용 가능성을 보여줍니다.
*   **지속적인 발전 및 변화가 예상되는 분야:**  
    오픈 소스 LLM은 앞으로도 연구와 커뮤니티의 협력을 통해 성능이 향상되고, 더 안전하고 효율적인 모델로 진화할 것으로 보입니다.

## 5. LLM 보안 위협 심층 분석
- 출처: [Hypnotized AI and Large Language Model Security](https://www.youtube.com/watch?v=gZTQNb0NGjM&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=8)

### **5.1 LLM의 잠재적 위험성**

* **악용 가능성:** LLM의 자연어 이해 능력은 사이버 공격에 악용될 수 있으며, 기존 보안 시스템으로는 탐지하기 어려운 새로운 공격 벡터를 생성합니다.
* **민감 정보 유출:** LLM은 대량의 데이터를 학습하므로, 민감한 정보가 모델에 포함될 수 있으며, 공격자는 이를 악용하여 정보를 유출할 수 있습니다.
* **허위 정보 생성:** 공격자는 LLM을 조작하여 허위 정보를 생성하고 유포함으로써 사회적 혼란을 야기하거나 특정 목적을 달성할 수 있습니다.

### **5.2 주요 공격 시나리오: 프롬프트 주입(Prompt Injection)**

* **정의:** 공격자가 LLM에게 악의적인 명령을 주입하여 LLM의 기존 규칙을 무효화하고 원하는 동작을 수행하도록 유도하는 공격입니다.
* **공격 단계:**
    1.  **주입(Injection):** LLM에게 특정 역할과 규칙을 부여한 후, 악성 명령을 주입하여 LLM의 동작을 변경.
    2.  **SQL Injection과의 유사점:** SQL Injection 공격과 유사하게, 프롬프트 주입은 LLM의 입력값을 조작하여 예상치 못한 결과를 초래합니다.
    3.  **보안 위협 발생 단계:** 모델 훈련, 미세 조정, 배포 후 단계 등 LLM의 생명주기 전반에 걸쳐 발생.
* **공격 예시:**
    * LLM에게 잘못된 답변을 하도록 유도하거나, 특정 사용자의 거래 내역을 열람하도록 조작.
    * LLM에게 숨겨진 명령을 주입하여 예상치 못한 동작을 유도하는 '최면' 상태를 만들 수 있습니다.
    * LLM에게 다중 게임 레이어를 생성하여 악성 로직을 지속적으로 유지시키는 'Inception' 공격이 가능.

### **5.3보안 권고 사항**

* **AI 및 보안 전문가 협력:** LLM 보안 위협에 대한 전문적인 지식을 갖춘 전문가와의 협력을 통해 효과적인 보안 대책을 마련해야 합니다.
* **공격 시나리오 식별:** LLM을 활용한 다양한 공격 시나리오를 식별하고, 이에 대한 대응 방안을 마련해야 합니다.
* **기존 보안 Best Practice 적용:** 입력 및 출력 검사와 같은 기존 보안 Best Practice를 LLM에 적용하여 보안 수준을 강화해야 합니다.
* **지속적인 연구 및 개발:** LLM 보안 위협은 끊임없이 진화하므로, 지속적인 연구 및 개발을 통해 새로운 위협에 대응해야 합니다.
* **사용자 교육:** 사용자들이 LLM의 잠재적인 위험성을 인지하고 안전하게 사용할 수 있도록 교육해야 합니다.

## 6. 챗봇 종류별 비교 및 활용
- 출처: [Do Chatbots Need AI?](https://www.youtube.com/watch?v=93l-2Usc08U&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=10)


### **6.1 규칙 기반 챗봇**

*   **특징:**
    *   **정해진 시나리오 및 키워드 기반으로 작동**:  
        이 챗봇은 미리 정의된 질문과 답변 세트를 기반으로 동작합니다. 사용자가 입력한 텍스트에서 특정 키워드를 인식하여 적절한 응답을 제공합니다.  
    *   **AI 기능 거의 없음**:  
        복잡한 자연어 처리(NLP)나 학습 능력이 부족하며, 단순 패턴 매칭 알고리즘을 사용합니다.  
    *   **단순한 작업에 적합**:  
        주문 접수, FAQ 응답 등 반복적이고 예측 가능한 업무에 효과적입니다.  

*   **한계:**
    *   **예외적인 상황에 대한 대처 미흡**:  
        예상치 못한 질문이나 불만 사항에 대해 적절히 대응하기 어렵습니다. 예를 들어, "피자가 차가워요"와 같은 비정형적인 요청은 처리할 수 없습니다.  
    *   **고객 불만을 야기하여 이탈을 초래할 수 있음**:  
        고객이 원하는 답변을 얻지 못하면 불편함을 느끼고 서비스를 떠날 가능성이 높아집니다.  

*   **예시:**  
    *   "피자 몇 개 주문하시겠습니까?"와 같은 정형화된 질문만 반복하며, 사용자의 자유로운 입력에는 제한적으로 응답합니다.  

### **6.2 AI 기반 챗봇**

*   **특징:**
    *   **자연어 이해 (NLU) 능력 탑재**:  
        자연어 처리 기술을 통해 고객의 다양한 표현을 이해하고 의도를 파악할 수 있습니다. 예를 들어, "페퍼로니 2개"와 "페퍼로니 피자를 두 판 주세요"라는 다른 표현도 동일하게 해석합니다.  
    *   **딥러닝 기반**:  
        데이터 학습을 통해 점차 더 정확한 응답을 제공할 수 있습니다.  
    *   **고객 정보 및 최신 프로모션 활용 가능**:  
        고객의 과거 주문 내역, 선호도 등을 분석하여 개인화된 제안을 제공할 수 있습니다.  
    *   **불만 발생 시, 상담원 연결 기능 제공**:  
        챗봇이 해결할 수 없는 복잡한 문제는 즉시 인간 상담원에게 전달하여 신속한 해결을 도모합니다.  

*   **장점:**
    *   **유연하고 자연스러운 대화 가능**:  
        기존 규칙 기반 챗봇보다 더 자연스럽고 직관적인 대화가 가능합니다.  
    *   **개인화된 서비스 제공**:  
        고객의 행동 패턴과 선호도를 분석하여 맞춤형 서비스를 제공합니다.  
    *   **업무 효율성 향상**:  
        반복적인 업무를 자동화하여 운영 비용을 절감하고, 상담원은 더 중요한 업무에 집중할 수 있습니다.  

*   **예시:**  
    *   "페퍼로니 피자 2개 주세요"라는 요청에 대해 "좋은 선택입니다! 추가 토핑은 필요 없으신가요?"와 같이 자연스럽게 응대합니다.  

### **6.3 생성형 AI 챗봇**

*   **특징:**
    *   **AI 기반 챗봇의 진화된 형태**:  
        딥러닝과 대규모 언어 모델을 활용하여 더욱 창의적이고 공감적인 대화를 구현합니다.  
    *   **고객의 상황과 감정을 이해하고 공감하는 대화 가능**:  
        고객의 문맥과 감정을 분석하여 적절한 응답을 제공합니다.  
    *   **검색 기능을 활용하여 답변의 정확성 및 신뢰성 향상**:  
        외부 데이터베이스나 검색 엔진을 연동하여 실시간으로 최신 정보를 제공합니다.  

*   **장점:**
    *   **더욱 풍부하고 창의적인 대화 가능**:  
        일반적인 질문 외에도 창의적인 아이디어나 조언을 제공할 수 있습니다.  
    *   **고객 만족도 극대화**:  
        고객의 요구를 깊이 이해하고 맞춤형 솔루션을 제공하여 만족도를 높입니다.  

*   **활용:**
    *   **고객의 니즈 파악 및 맞춤형 제안**:  
        고객의 상황에 맞춘 제품 추천이나 서비스 제안이 가능합니다.  
    *   **제품 정보 검색 및 제공**:  
        실시간으로 제품 정보를 검색하고 정확한 답변을 제공합니다.  

*   **주의:**
    *   **상황에 따라 과도한 개성은 오히려 방해될 수 있음**:  
        지나치게 개성적이거나 친밀한 응대로 인해 일부 고객은 불편함을 느낄 수 있습니다.  

*   **예시:**  
    *   "졸업 기념으로 피자 주문하고 싶어요"라는 요청에 대해 "졸업 축하드립니다! 달콤한 디저트도 함께 즐기시는 건 어떠세요?"와 같이 상황에 맞는 공감 능력을 발휘합니다.  

### **6.4 결론**

*   **챗봇 도입 시, 비즈니스 목표와 고객 니즈에 맞는 유형 선택 필요**:  
    규칙 기반 챗봇은 초기 비용이 저렴하고 간단한 업무에 적합하지만, 복잡한 상황에서는 한계가 있습니다. AI 기반 챗봇은 자연스러운 대화와 개인화된 서비스를 제공하며, 생성형 AI 챗봇은 더욱 창의적이고 공감적인 대화가 가능합니다.  

*   **AI 기술은 챗봇의 지능을 향상시키고 고객 경험을 개선하는 데 중요한 역할**:  
    AI 기술은 챗봇의 성능을 크게 향상시키며, 고객 경험을 더 나은 방향으로 변화시킵니다.  

*   **생성형 AI는 창의적이고 공감적인 대화가 필요한 경우 효과적이며, 검색 기능과 결합하여 답변의 신뢰도를 높일 수 있음**:  
    생성형 AI는 특히 감정적 교류가 중요한 상황에서 뛰어난 성과를 보이며, 외부 데이터와의 연동으로 신뢰성 있는 정보를 제공합니다.  

## 7. 인터넷 정보 신뢰성 및 AI 챗봇의 위험성
- 출처: [How Chatbots Could Be 'Hacked' by Corpus Poisoning](https://www.youtube.com/watch?v=RTCaGwxD2uU&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=11)

### **7.1 인터넷 정보의 신뢰성 문제: 정보의 바다 속에서 진실 찾기**

* 인터넷은 방대한 정보의 보고이지만, 그만큼 허위 정보와 오정보가 넘쳐나는 공간이기도 합니다.
* 정보의 출처가 불분명하거나 익명으로 작성된 정보는 신뢰성을 판단하기 어렵게 만듭니다.
* 검색 엔진은 다양한 정보를 제공하지만, 광고, 가짜 뉴스, 편향된 의견 등이 혼재되어 있어 사용자가 직접 정보를 선별해야 하는 어려움이 있습니다.
* 특히, 소셜 미디어와 온라인 커뮤니티에서는 검증되지 않은 정보가 빠르게 확산되어 사회적 혼란을 야기할 수 있습니다.

### **7.2 AI 챗봇의 등장과 장점: 정보 탐색의 새로운 시대**

* AI 챗봇은 사용자의 질문에 대해 자연어 처리 기술을 통해 빠르고 정확한 답변을 제공합니다.
* 검색 엔진에서 수많은 링크를 뒤져 정보를 찾아야 하는 번거로움을 줄여주어 사용자의 시간과 노력을 절약해줍니다.
* AI 챗봇은 방대한 데이터를 학습하여 다양한 분야에 대한 전문적인 지식을 제공할 수 있습니다.
* 이러한 편리함 때문에 AI 챗봇에 대한 의존도는 앞으로 더욱 높아질 것으로 예상됩니다.

### **7.3 AI 챗봇의 신뢰성 문제와 위험성: 양날의 검**

* AI 챗봇은 학습 데이터에 기반하여 답변을 생성하기 때문에, 데이터에 오류나 편향이 포함되어 있을 경우 잘못된 정보를 제공할 수 있습니다.
* 악의적인 사용자가 학습 데이터에 거짓 정보를 주입하여 AI 챗봇의 답변을 조작하는 '코퍼스 포이즈닝' 공격은 심각한 위험을 초래할 수 있습니다.
* 잘못된 정보에 기반한 의사 결정은 개인의 삶뿐만 아니라 사회 전체에 부정적인 영향을 미칠 수 있습니다. 예를 들어, 잘못된 의료 정보나 금융 정보는 심각한 피해를 야기할 수 있습니다.
* 과거 AI 챗봇이 인종차별, 성차별 등 부적절한 언어를 사용하여 논란을 일으킨 사례는 AI 챗봇의 윤리적 문제점을 보여줍니다.

### **7.4 AI에 대한 기대와 검증의 필요성: 신뢰 구축을 위한 노력**

* AI 챗봇의 신뢰성을 높이기 위해서는 정보의 출처를 명확하게 제시하고 검증 기능을 강화해야 합니다.
* AI 챗봇이 답변을 생성하는 과정과 근거를 투명하게 공개하여 사용자가 정보의 신뢰성을 판단할 수 있도록 해야 합니다.
* AI 챗봇이 생성하는 코드에 악성 코드가 삽입될 가능성을 고려하여 보안 시스템을 강화해야 합니다.
* AI 챗봇의 윤리적 문제에 대한 사회적 논의와 규제 마련이 필요합니다.

### **7.5 결론: AI 시대, 현명한 정보 활용법**

* AI 챗봇은 유용한 도구이지만, 맹신해서는 안 되며 정보의 출처를 확인하고 비판적으로 검증하는 습관.
* 특히, 중요한 결정을 내릴 때는 AI 챗봇의 답변뿐만 아니라 다양한 출처의 정보를 종합적으로 고려.
* AI 챗봇의 발전과 함께 정보 윤리에 대한 교육과 사회적 합의가 필요합니다.
* AI 기술의 발전은 인간의 삶을 풍요롭게 할 수 있지만, 그만큼 책임감 있는 사용자의 자세 필요.


## 8. 옴니채널 가상 어시스턴트 구축 필요성
- 출처: [3 Benefits of virtual assistants for Customer Service](https://www.youtube.com/watch?v=j-bmHSZUYlI&list=PLOspHqNVtKAAsiohuZj1Bt4XpA3_bkS3c&index=13)

### **8.1 현대 기업의 핵심 과제: 고객 경험 개선 및 운영 효율성 증대**

* 오늘날 기업들은 치열한 경쟁 속에서 고객 만족도를 높이고 운영 비용을 절감해야 하는 과제에 직면해 있습니다. 특히 고객 서비스 분야는 기업의 이미지를 결정짓는 중요한 요소이지만, 동시에 많은 문제점을 안고 있습니다.

### **8.2 고객 서비스의 현주소: 불편함과 비효율성의 악순환**

* **불편한 고객 경험:**
    * 복잡한 메뉴 구조, 끊임없는 대기 시간, 반복적인 설명 요구는 고객의 불만을 증폭시킵니다.
    * 문제 해결에 소요되는 시간 증가는 고객 이탈로 이어질 수 있습니다.
* **높은 운영 비용:**
    * 고객 서비스 담당자 채용, 교육, 유지에 막대한 비용이 소요됩니다.
    * 24시간 고객 지원을 위한 인력 운영은 현실적으로 매우 어렵습니다.

### **8.3 혁신적인 해결책: 옴니채널 가상 어시스턴트(챗봇) 도입**

* 이러한 문제점을 해결하고 고객 서비스의 혁신을 이루기 위한 최적의 대안은 옴니채널 가상 어시스턴트, 즉 챗봇을 도입하는 것입니다. 챗봇은 다양한 채널을 통해 고객과 소통하며 효율적인 고객 서비스를 제공합니다.

### **8.4 가상 어시스턴트 구축의 3가지 핵심 이점:**

1.  **탁월한 기술력 (Skills):**
    * 최고의 고객 서비스 담당자의 전문 지식을 챗봇에 학습시켜 24시간 활용 가능합니다.
    * watsonx Assistant와 같은 도구를 활용하면 코딩 없이도 직관적인 GUI를 통해 챗봇을 손쉽게 구축할 수 있습니다.
    * 시간과 장소에 제약 없이 24시간 고객 지원이 가능합니다.
2.  **획기적인 비용 절감 (Cost):**
    * 고객 서비스 담당자 유지 비용 대비 챗봇 구축 및 유지 비용을 대폭 절감할 수 있습니다.
    * 빠른 구축 속도를 통해 단기간에 비용 절감 효과를 누릴 수 있습니다.
3.  **극대화된 고객 만족도 (Customers):**
    * 신속하고 정확한 답변 제공으로 고객 대기 시간을 줄이고 만족도를 높일 수 있습니다.
    * 단순 문의는 챗봇이 처리하고, 담당자는 복잡한 문제 해결에 집중하여 업무 효율성을 향상시킬 수 있습니다.

### **8.5 핵심 고려 사항**

* 챗봇은 고객 서비스 담당자를 대체하는 것이 아니라, 상호 보완적인 역할을 수행하며 업무 효율성을 극대화합니다.
* 챗봇은 시간, 자원, 비용 등 핵심 자원을 절약하고 고객 만족도를 향상시키는 데 필수적인 도구입니다.


