---
title: 4차시 6 :StatQuest(Neural Network)
layout: single
classes: wide
categories:
  - Neural Network
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. 신경망(Neural Network): 복잡해 보이지만 그렇지 않습니다

- 출처:[The Essential Main Ideas of Neural Networks](https://www.youtube.com/watch?v=CqOfi41LfDw&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=2)

신경망은 기계 학습(Machine Learning)에서 가장 인기 있는 알고리즘 중 하나이며, 겉으로는 매우 복잡해 보이지만 실제로는 그렇지 않습니다. 이 동영상 시리즈는 신경망을 '블랙박스(black box)'라고 부르는 경향이 있지만, 그 내부를 들여다보고 각 개념과 기술을 단계별로 설명하여 이해하기 쉽게 돕는 것을 목표로 합니다.

### **1.1 신경망의 주요 역할: 데이터에 '구불구불한 선(Squiggle)' 맞추기**

*   **직선으로 불가능한 예측:** 예를 들어, 약물 복용량(저용량, 중용량, 고용량)에 따른 약효(0 또는 1) 데이터를 예측할 때, 데이터에 직선을 아무리 맞춰도 모든 복용량을 정확하게 예측하기 어렵습니다.
*   **신경망의 능력:** 신경망은 이런 데이터에 **'구불구불한 선(squiggle)'**을 맞출 수 있습니다. 이 '구불구불한 선'은 저용량에서 0에 가깝고, 중용량에서 1에 가깝고, 고용량에서 다시 0에 가까워져 데이터를 정확하게 나타냅니다. 매우 복잡한 데이터 세트에도 신경망은 이런 '구불구불한 선'을 맞출 수 있습니다.

### **1.2 신경망의 기본 구성 요소**

신경망은 **노드(nodes)**와 **노드 간의 연결(connections)**로 구성됩니다.

*   **노드와 연결:** 마치 뇌의 뉴런(neurons)과 시냅스(synapses)처럼 보인다고 해서 '신경망'이라는 이름이 붙었습니다.
*   **매개변수 (가중치와 편향):** 각 연결에 있는 숫자들은 **매개변수(parameter values)**라고 불리는데, 이는 데이터를 학습할 때 추정되는 값들입니다. 직선을 데이터에 맞출 때 기울기와 절편을 구하는 것과 비슷합니다. 이 매개변수는 **가중치(weights)**와 **편향(biases)**이라고 불립니다.
*   **활성화 함수(Activation Functions):** 노드 내부에 있는 휘거나 구부러진 선들입니다. 이 선들이 데이터를 따라 '구불구불한 선'을 만드는 기본적인 빌딩 블록이 됩니다.
    *   널리 사용되는 활성화 함수에는 **소프트플러스(SoftPlus)**, **ReLU (Rectified Linear Unit)**, **시그모이드(Sigmoid)** 등이 있습니다. 이 동영상에서는 소프트플러스 함수를 사용합니다.
*   **입력, 출력, 은닉층:**
    *   **입력 노드(Input Node):** 데이터를 입력하는 곳 (예: 약물 복용량).
    *   **출력 노드(Output Node):** 예측 결과가 나오는 곳 (예: 약효 예측).
    *   **은닉층(Hidden Layers):** 입력 노드와 출력 노드 사이에 있는 노드들의 층입니다. 신경망의 성능을 결정하는 중요한 부분이며, 이 층의 수와 각 층의 노드 수는 설계자가 결정합니다. 간단한 신경망은 보통 하나 또는 두 개의 은닉층을 가집니다.

### **1.3 신경망이 '구불구불한 선'을 만드는 과정 (단계별 예시)**

아주 간단한 신경망(입력 노드 1개, 출력 노드 1개, 은닉층에 노드 2개)을 예로 들어 설명합니다.

1.  **입력값 처리:** 약물 복용량(예: 0)을 입력 노드에 넣습니다.
2.  **은닉층 노드로의 연결:** 입력값은 각 연결마다 다른 **가중치(weight)**를 곱하고 **편향(bias)**을 더하여 활성화 함수의 **x축 좌표**를 만듭니다. 예를 들어, 복용량 0에 -34.4를 곱하고 2.14를 더해 2.14라는 x축 좌표를 얻습니다.
3.  **활성화 함수 적용:** 계산된 x축 좌표(예: 2.14)를 활성화 함수(예: 소프트플러스 함수)에 넣어 **y축 값**을 얻습니다. 이 과정을 모든 복용량 값(0부터 1까지)에 대해 반복하면, 특정 모양의 곡선(예: 파란색 곡선)이 만들어집니다.
    *   참고: 은닉층의 각 노드는 동일한 활성화 함수를 사용하더라도 연결의 매개변수가 다르기 때문에, 활성화 함수의 다른 부분을 잘라내거나 변형하여 새로운 모양을 만듭니다.
4.  **곡선 변형 (스케일링):** 새로 만들어진 곡선의 y축 값들을 또 다른 **가중치(weight)**로 곱하여 곡선의 크기를 조절합니다 (예: 파란색 곡선의 y축 값에 -1.3을 곱함). 이 과정으로 곡선은 뒤집히거나 늘어나면서 새로운 모양이 됩니다.
5.  **다른 은닉층 노드의 처리:** 은닉층의 다른 노드도 위와 동일한 과정을 거쳐 또 다른 모양의 곡선(예: 주황색 곡선)을 만듭니다. 이때도 다른 가중치와 편향을 사용하여 다른 모양의 곡선을 만듭니다.
6.  **곡선 결합:** 은닉층의 각 노드에서 만들어진 곡선들(예: 파란색 곡선과 주황색 곡선)의 y축 값들을 서로 더합니다. 이 과정을 통해 마침내 **'녹색 구불구불한 선(green squiggle)'**이 만들어집니다.
7.  **최종 조정:** 마지막으로 이 '녹색 구불구불한 선'의 y축 값에서 마지막 **편향(bias)**을 빼서 전체 선을 위아래로 이동시켜 데이터에 완벽하게 맞춥니다.
8.  **예측:** 이제 새로운 약물 복용량(예: 0.5)이 주어지면, 이 '녹색 구불구불한 선'에서 해당 복용량에 해당하는 y축 값을 찾아 약효를 예측할 수 있습니다.

### **1.4 신경망의 강력함**

이처럼 신경망은 단순한 노드와 연결, 그리고 이 연결에 붙은 가중치와 편향이라는 매개변수들을 조절하여 기본 활성화 함수를 자르고, 뒤집고, 늘리고, 합쳐서 어떤 복잡한 데이터 세트에도 맞는 '구불구불한 선'을 만들어낼 수 있습니다. 더 많은 은닉층과 노드를 사용하면 훨씬 더 복잡한 '구불구불한 선'을 만들 수 있습니다.

## 2. 연쇄 법칙 (Chain Rule): AI 학습의 핵심 도구

- 출처:[The Chain Rule, Clearly Explained!!!](https://www.youtube.com/watch?v=wl1myxrtQHQ&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=3)

연쇄 법칙은 미분(derivative)을 계산하는 방법 중 하나로, 특히 기계 학습(Machine Learning)에서 **신경망(Neural Network)** 같은 모델을 학습시키는 데 필수적인 개념입니다. 복잡한 함수가 여러 개의 간단한 함수로 연결되어 있을 때, 전체 함수의 변화율(미분)을 쉽게 구할 수 있도록 돕습니다. 

### **2.1 미분(Derivative)이란 무엇인가?**

*   **변화의 속도:** 미분은 어떤 것이 다른 것에 대해 얼마나 빠르게 변하는지를 알려줍니다. 예를 들어, StatQuest를 좋아하는 정도에 따라 "멋짐(awesomeness)"이 어떻게 변하는지 나타내는 포물선(awesomeness = likes_statquest²)이 있다고 가정해 봅시다.
*   **접선의 기울기:** 이 포물선의 미분은 곡선 위의 어떤 한 점에서의 **접선(tangent line)의 기울기**를 알려줍니다. 이 기울기는 "멋짐"이 "좋아하는 정도"에 대해 얼마나 빠르게 변하는지를 나타냅니다.
*   **계산 방법:** `likes_statquest²`의 미분은 **멱의 법칙(power rule)**에 따라 `2 * likes_statquest`가 됩니다.

### **2.2 연쇄 법칙의 기본 아이디어: 연결된 변화율**

연쇄 법칙은 한 변수가 다른 변수에 영향을 미치고, 그 다른 변수가 또 다른 변수에 영향을 미치는 **연결된 관계(chained relationship)**에서 최종적인 변화율을 계산할 때 사용됩니다.

**예시 1: 몸무게 → 키 → 신발 사이즈**

*   **관계 1: 몸무게와 키**
    *   사람들의 몸무게와 키 데이터를 보면, 몸무게가 1단위 증가할 때 키가 2단위 증가하는 관계(기울기 2)가 있을 수 있습니다.
    *   즉, `키`의 `몸무게`에 대한 미분은 `2`입니다.
    *   식으로 표현하면 `키 = 2 * 몸무게`가 됩니다 (절편이 0이라고 가정).
*   **관계 2: 키와 신발 사이즈**
    *   사람들의 키와 신발 사이즈 데이터를 보면, 키가 1단위 증가할 때 신발 사이즈가 0.25단위 증가하는 관계(기울기 0.25)가 있을 수 있습니다.
    *   즉, `신발 사이즈`의 `키`에 대한 미분은 `0.25`입니다.
    *   식으로 표현하면 `신발 사이즈 = 0.25 * 키`가 됩니다 (절편이 0이라고 가정).
*   **연결하기:** 몸무게가 주어졌을 때, 키를 예측하고, 그 예측된 키로 신발 사이즈를 예측할 수 있습니다. 즉, **키(height)**가 **몸무게(weight)**와 **신발 사이즈(shoe size)**를 연결하는 고리입니다.
*   **연쇄 법칙 적용:** `신발 사이즈`가 `몸무게`에 대해 얼마나 변하는지 알고 싶다면, 다음과 같이 두 미분을 곱하면 됩니다:
    *   (`신발 사이즈`의 `몸무게`에 대한 미분) = (`신발 사이즈`의 `키`에 대한 미분) * (`키`의 `몸무게`에 대한 미분)
    *   숫자를 대입하면 `0.25 * 2 = 0.5`가 됩니다. 이는 몸무게가 1단위 증가할 때 신발 사이즈가 0.5단위 증가한다는 의미입니다.

**예시 2: 마지막 간식 이후 시간 → 배고픔 → 아이스크림 갈망**

*   **관계 1: 시간과 배고픔:** 마지막 간식 이후 시간이 지날수록 배고픔이 더 빠르게 증가합니다 (지수 함수 형태).
    *   `배고픔`의 `시간`에 대한 미분은 `2 * 시간` (멱의 법칙 사용).
*   **관계 2: 배고픔과 아이스크림 갈망:** 배고픔이 커질수록 아이스크림 갈망도 커지지만, 어느 시점부터는 증가폭이 줄어듭니다 (제곱근 함수 형태).
    *   `아이스크림 갈망`의 `배고픔`에 대한 미분은 `1 / (2 * √배고픔)` (멱의 법칙 사용).
*   **연쇄 법칙 적용:** `아이스크림 갈망`이 `시간`에 대해 어떻게 변하는지 알고 싶다면, **배고픔(hunger)**이 연결고리이므로 두 미분을 곱합니다:
    *   (`아이스크림 갈망`의 `시간`에 대한 미분) = (`아이스크림 갈망`의 `배고픔`에 대한 미분) * (`배고픔`의 `시간`에 대한 미분)
    *   여기에 각 미분식을 대입하고, `배고픔` 자리에 `시간`에 대한 `배고픔` 식을 대입하여 정리하면 `아이스크림 갈망`의 `시간`에 대한 변화율을 얻을 수 있습니다.

### **2.3 숨겨진 연쇄 법칙 (함수가 중첩된 경우)**

위 예시들에서는 각 관계에 대한 방정식이 명확했지만, 실제로는 하나의 복잡한 방정식 안에 여러 함수가 **중첩(nested)**되어 있는 경우가 많습니다. 이때는 **괄호(parentheses)**를 사용하여 "안쪽 내용(the stuff inside)"을 정의하고 연쇄 법칙을 적용할 수 있습니다.

*   예를 들어, `아이스크림 갈망 = √(시간² + 0.5)` 와 같은 식이 있다면,
    *   **"안쪽 내용"**을 `시간² + 0.5`라고 정의합니다.
    *   그러면 `아이스크림 갈망`은 `√("안쪽 내용")`으로 다시 쓸 수 있습니다.
    *   연쇄 법칙은 다음과 같이 적용됩니다:
        *   (`아이스크림 갈망`의 `시간`에 대한 미분) = (`아이스크림 갈망`의 `안쪽 내용`에 대한 미분) * (`안쪽 내용`의 `시간`에 대한 미분)
    *   각 부분을 미분하여 곱하면 됩니다.

### **2.4 기계 학습에서의 연쇄 법칙: 손실 함수(Loss Function) 최소화**

기계 학습 모델은 데이터에 가장 잘 맞는 선(또는 곡선)을 찾기 위해 **손실 함수(Loss Function)**를 최소화합니다. 연쇄 법칙은 이 최소값을 찾는 과정에서 중요한 역할을 합니다.

**예시: 제곱 잔차(Squared Residual) 최소화**

*   **목표:** 관측된 데이터(예: 키와 몸무게)에 가장 잘 맞는 선을 찾으려고 합니다. 이때 예측 값과 실제 값의 차이인 **잔차(residual)**를 사용합니다.
*   **손실 함수:** 잔차를 제곱한 **제곱 잔차(squared residual)**를 최소화하는 것이 일반적입니다. 왜냐하면 제곱하면 음수가 없어지고, 큰 오차에 더 큰 페널티를 주기 때문입니다.
*   **최소값 찾기:** 제곱 잔차를 최소화하는 선의 **절편(intercept)** 값을 찾기 위해, 우리는 `제곱 잔차`의 `절편`에 대한 미분 값을 0으로 만드는 절편을 찾아야 합니다.
*   **연쇄 법칙 적용:**
    *   **잔차(residual)**가 `절편`과 `제곱 잔차`를 연결하는 고리입니다.
    *   연쇄 법칙은 다음과 같습니다:
        *   (`제곱 잔차`의 `절편`에 대한 미분) = (`제곱 잔차`의 `잔차`에 대한 미분) * (`잔차`의 `절편`에 대한 미분)
    *   각 부분의 미분은 다음과 같습니다:
        *   `제곱 잔차`의 `잔차`에 대한 미분: `2 * 잔차` (멱의 법칙)
        *   `잔차`의 `절편`에 대한 미분: `-1` (잔차 식을 미분하여 구함)
    *   이것들을 곱하면 `제곱 잔차`의 `절편`에 대한 미분식을 얻게 되고, 이 미분식이 0이 되는 절편 값을 찾으면 됩니다.

**"안쪽 내용"을 이용한 방식**

*   만약 `제곱 잔차` 함수가 `(관측된 키 - 절편 - 1 * 몸무게)²` 와 같이 중첩된 형태로 주어졌다면,
    *   **"안쪽 내용"**을 `관측된 키 - 절편 - 1 * 몸무게`로 정의합니다.
    *   그러면 `제곱 잔차`는 `("안쪽 내용")²`가 됩니다.
    *   연쇄 법칙은:
        *   (`제곱 잔차`의 `절편`에 대한 미분) = (`제곱 잔차`의 `안쪽 내용`에 대한 미분) * (`안쪽 내용`의 `절편`에 대한 미분)
    *   결과는 앞에서와 동일하게 나옵니다.

### **2.5 결론적으로, 왜 연쇄 법칙이 중요한가?**
기계 학습에서 모델(신경망 포함)은 수많은 매개변수(가중치와 편향)를 가지고 있으며, 이 매개변수들을 조절하여 손실 함수를 최소화합니다. 손실 함수는 보통 여러 단계의 계산을 거쳐 최종 출력으로 연결되는데, 이때 **연쇄 법칙**을 사용하면 각 매개변수가 최종 손실에 얼마나 영향을 미치는지(즉, 미분값) 효율적으로 계산할 수 있습니다. 이 계산은 **역전파(backpropagation)** 알고리즘의 핵심이며, 이를 통해 모델이 "학습"하는 것입니다.

## 3. 경사 하강법(Gradient Descent)

- 출처:[Gradient Descent, Step-by-Step](https://www.youtube.com/watch?v=sDv4f4s2SB8&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=4)

### **3.1 경사 하강법이란 무엇인가요?**
경사 하강법은 통계학, 머신러닝, 데이터 과학 분야에서 **모델의 성능을 최적화하는 데 사용되는 알고리즘**입니다. "최적화"란 모델이 데이터를 가장 잘 설명할 수 있는 **최적의 매개변수(parameters)**를 찾는 과정을 의미합니다. 예를 들어, 선형 회귀에서 선을 데이터에 맞출 때, 절편(intercept)과 기울기(slope)라는 매개변수를 최적화합니다. 경사 하강법은 이러한 매개변수들을 효율적으로 추정하여 최적의 모델을 만듭니다.

### **3.2 왜 경사 하강법을 사용하나요?**
절편이나 기울기 같은 매개변수를 최적화하는 느리고 고통스러운 방법은 많은 값을 일일이 대입해보는 것입니다. 하지만 경사 하강법은 **훨씬 효율적**입니다. 최적의 해에서 멀리 떨어져 있을 때는 계산을 적게 하고, 최적값에 가까워질수록 계산 횟수를 늘려 정밀하게 찾아갑니다. 즉, **멀리 있을 때는 크게 이동하고, 가까이 있을 때는 작게 이동(아기 걸음)하며 최적값을 찾아냅니다**.

### **3.3 경사 하강법은 어떻게 작동하나요? (절편 하나만 최적화하는 예시)**

동영상에서는 먼저 이해를 돕기 위해 **절편(intercept)** 하나만 최적화하는 예시를 보여줍니다.

*   **1단계: 무작위 초기값 선택**
    *   먼저 절편에 대한 무작위 값을 선택합니다. 이는 경사 하강법이 개선할 수 있는 **초기 추측값**입니다. 예를 들어, 절편을 0으로 설정할 수 있습니다.

*   **2단계: 손실 함수(Loss Function) 정의 및 평가**
    *   모델이 데이터를 얼마나 잘 맞추는지 평가하기 위해 **손실 함수**를 사용합니다. 여기서는 **잔차 제곱합(Sum of Squared Residuals)**을 손실 함수로 사용합니다.
    *   **잔차(residual)**는 실제 값(관측된 높이)과 모델이 예측한 값(예측된 높이)의 차이입니다. 잔차 제곱합은 이 잔차들을 제곱하여 모두 더한 값입니다.
    *   손실 함수는 절편 값에 따라 달라지는 U자 형태의 그래프로 시각화할 수 있습니다. 우리는 이 그래프의 **가장 낮은 지점(최소값)**을 찾으려 합니다.

*   **3단계: 손실 함수의 미분(Derivatives) 계산**
    *   손실 함수 그래프의 가장 낮은 지점을 찾기 위해, 손실 함수를 절편에 대해 **미분**합니다. 이 미분 값은 특정 절편에서의 **곡선의 기울기(slope)**를 나타냅니다.
    *   **최적의 값에 가까워질수록 기울기는 0에 가까워집니다**.

*   **4단계: 스텝 크기(Step Size) 결정**
    *   경사 하강법은 이 기울기를 사용하여 다음 단계에서 얼마나 이동할지 결정합니다.
    *   **스텝 크기 = 기울기 × 학습률(Learning Rate)**.
    *   **학습률**은 한 번에 얼마나 크게 이동할지 조절하는 작은 숫자입니다. 기울기가 0에서 멀리 떨어져 있을수록 스텝 크기가 커져 빠르게 이동하고, 0에 가까워질수록 스텝 크기가 작아져 섬세하게 이동합니다.

*   **5단계: 새로운 절편 값 계산 및 반복**
    *   **새로운 절편 = 이전 절편 - 스텝 크기**.
    *   이렇게 새로운 절편 값을 계산한 후, 3단계로 돌아가서 새로운 절편으로 다시 미분 값을 계산하고, 스텝 크기를 구하고, 새로운 절편을 계산하는 과정을 **반복**합니다.

*   **6단계: 중지 조건**
    *   다음 두 가지 경우 중 하나에 해당하면 반복을 멈춥니다:
        *   **스텝 크기가 매우 0에 가까워질 때** (예: 0.001 이하). 이는 기울기가 0에 매우 가까워져 최적값에 도달했음을 의미합니다.
        *   **최대 반복 횟수(예: 1000번 이상)에 도달했을 때**.

### **3.4 여러 매개변수 최적화: 절편과 기울기**

실제 모델에서는 절편 외에 기울기 등 여러 매개변수를 동시에 최적화해야 합니다.

*   **손실 함수 시각화:** 절편과 기울기를 모두 고려하면, 손실 함수는 이제 3D 그래프 형태로 나타납니다. 여전히 이 3D 곡면의 **가장 낮은 지점**을 찾는 것이 목표입니다.
*   **그래디언트(Gradient) 계산:** 여러 매개변수가 있을 때는 각 매개변수에 대해 손실 함수를 미분합니다. 이렇게 **두 개 이상의 미분값을 함께 묶어 놓은 것을 그래디언트(Gradient)라고 부릅니다**. 경사 하강법이라는 이름은 바로 이 그래디언트를 사용하여 손실 함수의 가장 낮은 지점으로 "하강"하기 때문에 붙여졌습니다.
*   **작동 방식:** 절편만 최적화할 때와 동일한 단계들을 거치지만, 이제는 절편과 기울기 **각각에 대한 미분 값(그래디언트)**을 계산하고, 각 매개변수에 대한 **스텝 크기를 동시에 계산**하여 새로운 절편과 기울기 값을 업데이트합니다.

### **3.5 핵심 개념 다시 보기**

*   **손실 함수(Loss Function):** 모델이 얼마나 잘못 예측했는지 측정하는 함수입니다. 경사 하강법은 이 손실 함수의 값을 최소화하는 방향으로 매개변수를 조정합니다.
*   **학습률(Learning Rate):** 스텝 크기를 결정하는 중요한 요소입니다. 학습률이 너무 크면 최적값을 건너뛰거나 발산할 수 있고, 너무 작으면 최적값을 찾는 데 너무 오래 걸릴 수 있습니다.
*   **그래디언트(Gradient):** 손실 함수를 모든 매개변수에 대해 미분한 값들의 묶음입니다. 이 그래디언트가 가리키는 방향으로 이동하면 손실 함수를 빠르게 줄일 수 있습니다.

### **3.6 경사 하강법의 일반적인 단계 요약**

1.  각 매개변수에 대해 **손실 함수를 미분**합니다 (즉, 손실 함수의 **그래디언트**를 계산합니다).
2.  매개변수에 대한 **무작위 초기값을 선택**합니다.
3.  매개변수 값을 미분 값(그래디언트)에 대입합니다.
4.  **스텝 크기를 계산**합니다.
5.  **새로운 매개변수 값을 계산**합니다.
6.  스텝 크기가 매우 작아지거나, 최대 반복 횟수에 도달할 때까지 3단계부터 반복합니다.

### **3.7 확률적 경사 하강법(Stochastic Gradient Descent, SGD)**

수백만 개의 데이터 포인트가 있는 경우 모든 데이터에 대해 미분값을 계산하는 데 시간이 매우 오래 걸릴 수 있습니다. **확률적 경사 하강법(SGD)**은 이러한 문제를 해결하기 위해 **매 단계마다 전체 데이터 세트 대신 무작위로 선택된 데이터의 부분 집합만 사용**하여 계산 시간을 줄입니다.


## 4. 역전파(Backpropagation)의 주요 아이디어
- 출처:[Neural Networks Pt. 2: Backpropagation Main Ideas](https://www.youtube.com/watch?v=IN2XmBhILt4&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=5)

### 4.1 **신경망의 핵심 원리**

1.  **신경망의 기본 이해 (복습)**
    *   이전 영상("Neural Networks Part 1")에서는 신경망이 **활성화 함수(activation functions)**를 사용하여 데이터를 나타내는 **물결선(squiggle)**을 만드는 방법을 설명했습니다.
    *   예를 들어, 낮은 용량과 높은 용량의 약물은 효과가 없지만 중간 용량은 효과가 있는 데이터가 있을 때, 신경망은 이 데이터에 가장 잘 맞는 녹색 물결선을 찾아냅니다.
    *   이때, 물결선은 **가중치(weights)**와 **편향(biases)**을 조정하여 활성화 함수를 뒤집고 늘리는 방식으로 만들어집니다. 하지만 이전 영상에서는 이 가중치와 편향을 어떻게 찾아내는지에 대해서는 다루지 않았습니다.

2.  **역전파의 역할: 가중치와 편향 최적화**
    *   **역전파는 신경망의 가중치와 편향을 최적화하는 방법**입니다. 즉, 신경망이 데이터를 더 정확하게 예측하도록 만드는 과정을 말합니다.
    *   역전파의 주요 아이디어는 크게 두 가지입니다:
        1.  **연쇄 법칙(chain rule)**을 사용하여 **미분값(derivatives)**을 계산합니다.
        2.  이 미분값을 **경사 하강법(gradient descent)**에 적용하여 매개변수(가중치와 편향)를 최적화합니다.
    *   개념적으로 역전파는 신경망의 가장 마지막 매개변수부터 시작하여 거꾸로 거슬러 올라가며 모든 매개변수를 추정합니다.

3.  **간단한 예시: 마지막 편향(b3) 최적화 과정**
    *   영상에서는 이해를 돕기 위해 신경망의 여러 매개변수(w1, w2, w3, w4, b1, b2, b3) 중 **마지막 편향인 b3 하나만 최적화**하는 과정을 보여줍니다. 다른 매개변수들은 이미 최적의 값이라고 가정합니다.
    *   **데이터 처리**: 약물 용량을 신경망에 입력하면, 숨겨진 계층을 거쳐 파란색 곡선과 주황색 곡선이 만들어지고, 이 둘이 합쳐져 **녹색 물결선**이 됩니다.
    *   **초기 설정**: 아직 b3의 최적값을 모르기 때문에, b3를 0으로 초기 설정합니다.
    *   **오차 측정: 잔차 제곱합(Sum of Squared Residuals, SSR)**
        *   b3가 0일 때의 녹색 물결선은 실제 데이터와 많이 떨어져 있습니다.
        *   신경망의 예측(녹색 물결선)이 실제 데이터에 얼마나 잘 맞는지 측정하기 위해 **잔차 제곱합(SSR)**을 계산합니다.
        *   **잔차(residual)**는 **실제 값과 예측 값의 차이**를 의미합니다. 이 잔차들을 각각 제곱하여 모두 더한 것이 잔차 제곱합입니다. b3가 0일 때 SSR은 20.4로 높게 나옵니다.
    *   **b3 조정에 따른 SSR 변화**:
        *   b3 값을 1, 2, 3으로 늘려가면 녹색 물결선이 위로 이동하고, 이에 따라 실제 데이터와의 차이(잔차)가 줄어들어 SSR 값도 7.8, 1.11, 0.46 등으로 작아집니다.
        *   이렇게 여러 b3 값을 대입하여 가장 낮은 SSR 값을 찾는 대신, **경사 하강법**을 사용하면 더 빠르게 최적의 b3 값을 찾을 수 있습니다.

4.  **경사 하강법을 위한 미분값 계산 (핵심!)**
    *   경사 하강법을 사용하려면 **SSR이 b3에 대해 얼마나 변하는지(미분값, 즉 기울기)**를 알아야 합니다.
    *   SSR은 예측값과 관련이 있고, 예측값은 b3와 관련이 있으므로, 이 관계를 계산하기 위해 **연쇄 법칙**을 사용합니다.
    *   **연쇄 법칙**은 다음과 같습니다:
        *   (SSR의 b3에 대한 미분값) = (SSR의 예측값에 대한 미분값) × (예측값의 b3에 대한 미분값)
    *   **계산 과정**:
        *   먼저, SSR의 예측값에 대한 미분값을 계산합니다. 이 값은 `-2 * (실제 값 - 예측 값)` 형태가 됩니다.
        *   다음으로, 예측값의 b3에 대한 미분값을 계산합니다. b3는 물결선을 위아래로 움직이는 역할을 하며, 다른 곡선들(파란색, 주황색)은 b3와 무관하므로 이들의 미분값은 0이고, b3 자체의 미분값은 1이 됩니다. 따라서 이 부분의 미분값은 1입니다.
        *   두 미분값을 곱하면, 최종적으로 **SSR의 b3에 대한 미분값**을 얻게 됩니다. 이 미분값은 b3가 0일 때 -15.7과 같이 특정 기울기를 나타냅니다.

5.  **경사 하강법 적용하여 b3 최적화**
    *   계산된 미분값(기울기)을 **경사 하강법 공식**에 대입하여 **보폭(step size)**을 계산합니다.
    *   예를 들어, 학습률(learning rate)을 0.1로 설정하면, 보폭은 -1.57이 됩니다.
    *   이 보폭을 사용하여 현재 b3 값(0)을 업데이트하면, 새로운 b3 값은 1.57이 됩니다.
    *   b3가 1.57로 변경되면 녹색 물결선이 위로 움직여 잔차가 더 줄어듭니다.
    *   이 과정을 반복하여 새로운 b3 값(예: 2.19)을 계속 계산합니다.
    *   **보폭이 거의 0에 가까워질 때까지** 이 단계를 계속 반복하면, SSR이 가장 낮은 지점, 즉 **최적의 b3 값(예: 2.61)**을 찾게 됩니다.

### 4.2 **결론**

역전파의 핵심 아이디어는 다음과 같습니다:
*   어떤 매개변수(예: b3)가 최적화되지 않았을 때, **연쇄 법칙을 사용**하여 그 매개변수에 대한 **잔차 제곱합의 미분값**을 계산합니다.
*   그다음, 해당 매개변수를 초기 값으로 설정하고, **경사 하강법을 적용**하여 **최적의 매개변수 값**을 찾아냅니다.


## 5. 역전파(Backpropagation)의 세부 사항
- 출처:[Backpropagation Details Pt. 1: Optimizing 3 parameters simultaneously.](https://www.youtube.com/watch?v=iyn2zdALii8&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=6)


1.  **목표 설정**: 이 영상의 목표는 **체인 규칙(Chain Rule)**과 **경사 하강법(Gradient Descent)**이 여러 파라미터(예: `w3`, `w4`, `b3`)에 어떻게 적용되는지 배우고, 관련 표기법을 소개하는 것입니다. 궁극적으로는 신경망의 모든 파라미터를 동시에 최적화하는 것을 목표로 합니다.

2.  **초기 설정**:
    *   특정 약물 복용량(dosage)이 바이러스에 효과적인지 보여주는 **간단한 데이터셋**과 **신경망**을 사용합니다.
    *   이 신경망의 모든 파라미터는 이미 최적화되어 있다고 가정하지만, **마지막 두 가중치 `w3`, `w4`와 마지막 편향 `b3`는 최적화되지 않은 상태**로 시작합니다.
    *   `w3`와 `w4`는 표준 정규 분포에서 무작위 값(예: 0.36, 0.63)으로 초기화되고, `b3`는 0으로 초기화됩니다.

3.  **예측 및 오차 계산**:
    *   신경망에 0에서 1까지의 복용량을 입력하여 숨겨진 레이어의 상단 노드에서 **파란색 곡선**을 얻고, 하단 노드에서 **주황색 곡선**을 얻습니다.
    *   각 곡선은 해당 가중치(`w3`와 `w4`)를 곱한 후, 이들을 `b3`와 함께 합산하여 **녹색 물결선(예측값)**을 생성합니다.
    *   이 녹색 물결선이 실제 데이터에 얼마나 잘 맞는지 **제곱 잔차의 합(Sum of Squared Residuals, SSR)**을 계산하여 측정합니다 (예: 1.4).

4.  **`b3` 최적화 (복습)**:
    *   `w3`와 `w4`가 아직 최적화되지 않았음에도 불구하고, `b3`는 **SSR의 `b3`에 대한 미분값**을 계산하고 이를 경사 하강법에 적용하여 최적화할 수 있습니다.
    *   이 미분 계산은 이전 "Backpropagation Main Ideas" 영상에서 계산했던 것과 **정확히 동일**합니다. 이는 여러 파라미터를 최적화할 때도 **SSR에 대한 미분값이 변하지 않음**을 의미합니다.

5.  **새로운 표기법 소개**:
    *   데이터셋의 개별 데이터 포인트(관측값, 예측값, 복용량)를 나타내는 **인덱스 `i`**를 도입합니다.
    *   입력값인 `dosage_i`는 `input_i`로도 불립니다.
    *   숨겨진 레이어의 각 노드에 대한 활성화 함수의 입력 x-축 좌표는 `x_1,i` (상단 노드)와 `x_2,i` (하단 노드)로 표현됩니다.
    *   활성화 함수를 거친 후의 y-축 좌표는 `y_1,i` (상단 노드)와 `y_2,i` (하단 노드)로 표현됩니다.

6.  **`w3`와 `w4`에 대한 미분 계산**:
    *   `y_1,i`에 `w3`를 곱하고, `y_2,i`에 `w4`를 곱한 것이 예측값(녹색 물결선)에 기여하는 방식입니다.
    *   따라서 **체인 규칙**을 사용하여 **SSR의 `w3`와 `w4`에 대한 미분값**을 계산합니다.
    *   `dSSR/dw3` = (`dSSR/d예측값`) * (`d예측값/dw3`).
    *   `dSSR/dw4` = (`dSSR/d예측값`) * (`d예측값/dw4`).
    *   여기서 **`dSSR/d예측값` 부분은 `b3`의 미분 계산에서 사용된 것과 동일**합니다.
    *   `d예측값/dw3`는 `y_1,i`이며, `d예측값/dw4`는 `y_2,i`입니다.
    *   이 값들을 결합하여 각 가중치에 대한 최종 미분값을 얻습니다.

7.  **다중 파라미터 경사 하강법**:
    *   이제 `w3`, `w4`, `b3`에 대한 모든 미분값을 **경사 하강법 알고리즘**에 대입하여 이 세 파라미터를 최적화할 수 있습니다.
    *   예를 들어, `dSSR/dw3`는 관측값, 예측값, `y_1,i`를 사용하여 계산됩니다 (예: 2.58).
    *   이러한 미분값들을 사용하여 **`w3`, `w4`, `b3`의 새로운 값을 계산**하고, 예측이 더 이상 크게 개선되지 않거나 정해진 단계에 도달할 때까지 **이 과정을 반복**합니다.
    *   애니메이션을 통해 175단계의 경사 하강법 이후 녹색 물결선이 데이터에 잘 맞춰지는 것을 시각적으로 보여줍니다.

요약하자면, 이 영상은 이전 백프로파게이션 개념을 확장하여 **체인 규칙과 경사 하강법을 사용해 여러 신경망 파라미터(`w3`, `w4`, `b3`)를 동시에 효율적으로 최적화하는 방법과 그에 필요한 표기법**을 구체적인 계산 과정을 통해 설명하고 있습니다. 

## 6. 역전파(backpropagation)의 세부 사항 2
- 출처:[Backpropagation Details Pt. 2: Going bonkers with The Chain Rule](https://www.youtube.com/watch?v=GKZoOHXGcLo&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=7)

1.  **신경망 최적화의 목표**
    *   이 동영상은 "Backpropagation Details Part 1"의 연장선으로, 신경망이 데이터를 "녹색 구불구불한 선(green squiggle)"에 맞추도록 모든 가중치(weights)와 편향(biases)을 최적화하는 방법을 목표로 합니다.
    *   최적화는 예측값과 실제값 사이의 **잔차 제곱합(sum of the squared residuals)**을 최소화함으로써 이루어지며, 이를 위해 가중치 `w1`, `b1`, `w2`, `b2`에 대한 잔차 제곱합의 도함수(미분값)를 도출하는 것이 핵심입니다.

2.  **연쇄 법칙(Chain Rule)의 핵심 역할**
    *   신경망에서 잔차 제곱합이 각 가중치(`w1`, `w2`) 및 편향(`b1`, `b2`)에 어떻게 연결되는지 파악하기 위해 **연쇄 법칙**이 사용됩니다. 이는 여러 단계의 함수들이 연결되어 있을 때 각 변수에 대한 최종 결과의 변화율을 계산하는 수학적 방법입니다.

3.  **`w1` 및 `b1`에 대한 도함수 도출 과정**
    *   **신경망의 흐름**: 입력값(`input_i`)은 `w1`과 곱해지고 `b1`이 더해져 활성화 함수의 x축 좌표 `x1,i`를 생성합니다. 이 `x1,i`는 **SoftPlus 활성화 함수**(`log(1 + e^x)`)에 입력되어 `y1,i`를 출력합니다. `y1,i`는 `w3`와 곱해져 최종 예측값을 계산하는 데 기여합니다.
    *   **연쇄 법칙 적용**: 잔차 제곱합(`SSR`)과 `w1`의 관계는 **예측값(predicted values)**, `y1,i`, `x1,i`를 통해 연결됩니다. 따라서 `d(SSR)/dw1`은 다음과 같이 분해될 수 있습니다:
        *   `d(SSR)/d(예측값)`
        *   `d(예측값)/dy1`
        *   `d(y1)/dx1`
        *   `d(x1)/dw1`
    *   **각 부분 계산**:
        *   `d(SSR)/d(예측값)`: `sum(-2 * (관측값 - 예측값))`.
        *   `d(예측값)/dy1`: `w3`.
        *   `d(y1)/dx1` (SoftPlus 함수의 미분): `e^x / (1 + e^x)`. 이 부분은 `log(z)`의 미분(`1/z`)과 `e^x`의 미분(`e^x`)을 연쇄 법칙으로 조합하여 얻어집니다. 여기서 `x`는 활성화 함수의 `x`축 좌표를 의미합니다.
        *   `d(x1)/dw1`: **입력값** (`input_i`).
        *   `d(x1)/db1`: **1**.
    *   **`b1`에 대한 도함수**: `w1`과 거의 동일한 연쇄 법칙 수식을 따르며, `d(x1)/db1` 부분만 `1`로 달라집니다.

4.  **`w2` 및 `b2`에 대한 도함수 도출 과정**
    *   `w2`와 `b2`에 대한 도함수를 계산하는 과정은 `w1`과 `b1`의 경우와 매우 유사합니다. 차이점은 히든 레이어의 "상단 노드" 대신 "하단 노드"를 사용한다는 점입니다. 즉, `input_i`에 `w2`를 곱하고 `b2`를 더하여 `x2,i`를 얻고, 이를 활성화 함수에 넣어 `y2,i`를 얻은 다음, `y2,i`를 `w4`와 곱하는 식입니다.

5.  **경사 하강법을 이용한 최적화**
    *   모든 가중치와 편향에 대한 도함수를 얻은 후에는 **경사 하강법**을 사용하여 모든 매개변수를 동시에 최적화합니다.
    *   **초기화**: 가중치는 표준 정규 분포에서 무작위로 초기화될 수 있으며, 편향은 보통 0으로 초기화됩니다.
    *   **반복 과정**: 각 도함수를 계산하고, 이를 사용하여 "스텝 크기(step size)"와 새로운 매개변수 값을 계산합니다. 이 과정을 예측 성능이 더 이상 크게 개선되지 않거나 특정 기준을 충족할 때까지 반복합니다.
    *   **시각화**: 동영상은 경사 하강법이 450단계 후에 어떻게 "녹색 구불구불한 선"을 데이터에 성공적으로 맞추는지 애니메이션으로 보여줍니다.


## 7. AI 입문자를 위한 ReLU 활성화 함수 소개
- 출처:[Neural Networks Pt. 3: ReLU In Action!!!](https://www.youtube.com/watch?v=68BZ5f7P94E&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=8)

신경망(Neural Networks)은 우리 뇌의 작동 방식을 모방하여 데이터를 학습하고 패턴을 찾아내는 인공지능 모델입니다. 이 신경망의 중요한 구성 요소 중 하나가 바로 **활성화 함수(Activation Function)**입니다. 활성화 함수는 신경망이 복잡한 패턴을 학습할 수 있도록 비선형성(non-linearity)을 부여하는 역할을 합니다.

### **7.1 ReLU란 무엇인가요?**

*   **ReLU**는 **Rectified Linear Unit**의 줄임말입니다.
*   이름처럼 "정류된 선형 단위"를 의미하며, 동영상에서는 "로봇" 같은 소리가 난다고 묘사하기도 합니다.
*   주로 **딥러닝**과 **컨볼루션 신경망(Convolutional Neural Networks)**에서 효과적으로 사용됩니다.

### **7.2 ReLU는 어떻게 작동하나요?**

ReLU의 작동 방식은 매우 간단합니다. 어떤 입력값이 주어졌을 때, **입력값과 0 중에서 더 큰 값을 출력**합니다.

*   **입력값이 음수(Negative)인 경우:** 출력은 항상 **0**이 됩니다.
*   **입력값이 양수(Positive)인 경우:** 출력은 **입력값과 동일**합니다.

**예시를 통해 이해하기:**

동영상에서는 약물 투여량(0에서 1까지)이 바이러스에 얼마나 효과적인지 예측하는 간단한 데이터셋을 예로 들어 설명합니다.

1.  **은닉층(Hidden Layer)에서의 적용**:
    *   처음에 신경망이 **SoftPlus** 활성화 함수를 사용할 때는 데이터에 잘 맞는 곡선 형태(녹색 구불구불한 선)를 만들었습니다.
    *   이를 **ReLU**로 바꾸면, 음수 입력값들은 모두 0으로 바뀌고 양수 입력값들은 그대로 유지되어 데이터가 **"구부러진 파란색 선"(bent blue line)**으로 변환됩니다.
    *   이 구부러진 선은 다른 연결에서 생성된 직선과 합쳐져 **"녹색 쐐기"(green wedge)** 형태를 만듭니다.

2.  **최종 출력층(Output Layer) 앞에서의 적용**:
    *   최종 출력 전에 다시 한번 ReLU 활성화 함수를 적용합니다.
    *   이렇게 하면 "녹색 쐐기"에 있던 음수 값들은 모두 **0**으로 바뀌고, 양수 값들은 그대로 유지됩니다.
    *   그 결과, 데이터는 **"녹색 뾰족한 모양"(green pointy thing)**으로 변환되어 최종 예측값을 나타냅니다.

이처럼 ReLU는 음수 값을 0으로 "정류"하고 양수 값은 그대로 통과시키는 방식으로 데이터의 형태를 효과적으로 변환합니다.

### **7.3 ReLU의 중요성**

ReLU는 비록 곡선 형태가 아니고 방정식이 매우 단순해 보이지만, 다른 활성화 함수와 마찬가지로 신경망의 **가중치(weights)**와 **편향(biases)**을 통해 데이터를 다양한 모양으로 **변형(slice, flip, stretch)**하고, 이러한 변형된 모양들을 서로 **합쳐서(added together)** 데이터에 가장 잘 맞는 복잡한 최종 형태를 만들어낼 수 있습니다. 이것이 딥러닝에서 ReLU가 매우 효과적이고 널리 사용되는 이유입니다.

### **7.4 기술적 상세 (간략하게)**

ReLU 함수는 꺾이는 지점(0)에서 미분(derivative)이 정의되지 않는다는 기술적인 특징이 있습니다. 하지만 이는 **경사 하강법(gradient descent)**과 같이 미분값을 사용하여 신경망을 학습시키는 데 큰 문제가 되지 않습니다. 이 문제를 해결하기 위해 꺾이는 지점의 미분값을 **0 또는 1**로 간단히 정의하여 사용합니다.

요약하자면, ReLU는 간단한 규칙(입력값과 0 중 큰 값 선택)을 통해 신경망이 복잡한 데이터를 학습할 수 있도록 돕는 매우 강력하고 효율적인 활성화 함수입니다.

## 8. 신경망 Pt. 4: 다중 입력 및 출력
- 출처:[Neural Networks Pt. 4: Multiple Inputs and Outputs](https://www.youtube.com/watch?v=83LYR-1IcjA&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=9)


### **8.1 단순 신경망에서 복잡한 신경망으로의 전환**
*   **초기 단순 모델**: 이 시리즈의 앞선 부분에서는 약물 복용량(단일 입력)이 효과적일지(단일 출력)를 예측하는 매우 단순한 신경망을 다루었습니다. 이 경우, 입력(x축)과 출력(y축)은 **2차원 그래프** 위에 표현될 수 있으며, 가중치와 편향이 활성화 함수를 "슬라이스하고, 뒤집고, 늘려서" 데이터에 맞는 2차원 '구불구불한 선'을 만드는 것을 볼 수 있습니다.
*   **다중 입력 및 출력의 필요성**: 하지만 현실 세계의 데이터는 대개 더 복잡합니다. 이 동영상에서는 붓꽃의 **꽃잎 너비(petal width)**와 **꽃받침 너비(sepal width)**라는 두 가지 측정값을 입력으로 받아, 붓꽃의 종(setosa, versicolor, virginica)을 예측하는 신경망을 예시로 사용합니다.

### **8.2 두 개의 입력과 하나의 출력: 3차원 그래프의 등장**
*   **3차원 시각화**: 두 개의 입력(꽃잎 너비, 꽃받침 너비)과 하나의 출력(예: setosa 예측)이 있을 때는 **3차원 그래프**가 필요합니다. 각 입력(꽃잎 너비, 꽃받침 너비)이 각각의 축을 차지하고, 출력(setosa 예측)이 y축을 담당합니다.
*   **"굽은 표면"의 생성**: 신경망은 입력값에 **가중치(weights)**를 곱하고 **편향(bias)**을 더한 후, 이를 ReLU(Rectified Linear Unit)와 같은 **활성화 함수(activation function)**에 통과시킵니다. 이 과정은 숨겨진 계층(hidden layer) 내의 각 노드에서 이루어지며, 3차원 공간에서 **"굽은 표면(bent surface)"**을 형성합니다. 이 표면의 '굽은 부분'은 ReLU 활성화 함수가 출력값을 0으로 설정하는 지점에 해당합니다.
*   **"주름진 표면"으로의 결합**: 숨겨진 계층의 여러 노드에서 생성된 이러한 굽은 표면들은 서로 더해지고, 다시 가중치와 편향을 통해 조정됩니다. 이 과정을 통해 최종적으로 하나의 **"주름진 표면(crinkled surface)"**이 생성됩니다. 이 주름진 표면의 높이(y축 값)는 특정 입력(꽃잎 너비, 꽃받침 너비)에 대한 신경망의 예측 값(예: setosa일 확률)을 나타냅니다. 영상에서는 입력값이 가장 작은 값(0)부터 가장 큰 값(1) 사이로 스케일링(scaled)되었다고 설명합니다.
*   **예측 과정**: 예를 들어, 특정 붓꽃의 꽃잎 너비와 꽃받침 너비에 해당하는 주름진 표면 위의 y축 값을 확인함으로써 해당 붓꽃이 setosa일 확률이 높은지 낮은지를 예측할 수 있습니다.

### **8.3 두 개 이상의 출력: 각 종에 대한 표면 생성**
*   **다양한 종 예측**: 붓꽃 종을 setosa, versicolor, virginica로 분류하는 경우, 신경망은 **각 종에 대해 개별적인 주름진 표면**을 생성합니다.
*   **다른 가중치와 편향**: 각 출력 노드(예: versicolor 출력 노드, virginica 출력 노드)는 숨겨진 계층에서 오는 연결에 **다른 가중치와 편향**을 적용하여 고유한 주름진 표면을 만듭니다. 예를 들어, versicolor를 위한 주름진 표면은 꽃잎 너비가 약 0.4일 때 높은 값을 보이고, virginica를 위한 주름진 표면은 꽃잎 너비가 1에 가까울 때 높은 값을 보입니다.
*   **최종 결정**: 최종적으로, 붓꽃에서 측정된 값을 신경망에 입력하면 각 종에 대한 예측값이 출력됩니다. 예를 들어, setosa에 대해 0.09, versicolor에 대해 0.86, virginica에 대해 0.12와 같은 값이 나올 수 있으며, 이 중 1에 가장 가까운 값(여기서는 versicolor의 0.86)을 가진 종으로 분류합니다.
*   **Argmax/Softmax**: 동영상에서는 두 개 이상의 출력 노드가 있을 때, 최종 결정을 내리기 전에 **Argmax** 또는 **Softmax**와 같은 함수를 사용하는 것이 일반적이며, 이는 다음 영상에서 다룰 것이라고 언급합니다.

이처럼, 신경망은 **가중치와 편향**을 사용하여 입력 데이터를 변환하고, 이를 활성화 함수를 통해 **굽은 표면**으로 만든 다음, 이 표면들을 조합하여 최종적으로 **주름진 표면**을 형성함으로써 복잡한 패턴을 학습하고 예측을 수행합니다. 

## 9. 신경망 Part 5: ArgMax와 SoftMax
- 출처:[Neural Networks Part 5: ArgMax and SoftMax](https://www.youtube.com/watch?v=KpKog-L9veg&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=10)

신경망에서 **다중 출력(multiple outputs)**을 처리할 때 사용되는 **ArgMax와 SoftMax**라는 두 가지 중요한 함수에 대해 설명합니다. 

### **9.1 ArgMax와 SoftMax가 필요한 이유**
신경망이 여러 가지를 예측할 때 (예: 붓꽃의 종 분류), 최종 출력 노드의 **원시 출력 값(raw output values)**은 항상 0과 1 사이가 아닐 수 있습니다. 때로는 1보다 크거나 0보다 작을 수도 있어서 직관적으로 해석하기 어렵습니다. 이러한 원시 출력 값을 더 쉽게 해석하고 신경망을 효과적으로 훈련시키기 위해 ArgMax 또는 SoftMax 레이어를 사용합니다.

### **9.2 ArgMax 함수**
*   **작동 방식**: ArgMax는 원시 출력 값들 중에서 **가장 큰 값을 1로 설정하고 나머지 값들은 모두 0으로 만드는 기능**입니다.
    *   **예시**: 만약 붓꽃 종 분류에서 Setosa가 1.43, Versicolor가 -0.4, Virginica가 0.23의 원시 출력 값을 가졌다면, ArgMax는 Setosa를 1로, Versicolor와 Virginica를 0으로 만듭니다. 이는 Setosa가 가장 큰 값이기 때문입니다.
*   **장점**: 출력이 0과 1로 명확하게 구분되어 **예측을 매우 쉽게 해석**할 수 있습니다.
*   **단점**: ArgMax의 출력 값은 0과 1이라는 **상수(constant)**이기 때문에, 이 함수의 미분 값은 항상 0이 됩니다. 이는 **역전파(backpropagation)를 통해 신경망의 가중치(weights)와 편향(biases)을 최적화하는 데 사용할 수 없음**을 의미합니다. 기울기가 0이면 경사 하강법(gradient descent)을 적용해도 최적의 파라미터 값으로 나아갈 수 없기 때문입니다.

### **9.3 SoftMax 함수**
*   **작동 방식**: SoftMax는 원시 출력 값들을 **0과 1 사이의 값으로 변환**하며, 이 값들의 **총합은 항상 1**이 되도록 합니다. 이는 `e` (자연로그의 밑)를 각 원시 출력 값의 거듭제곱으로 올린 후, 이를 모든 `e`의 거듭제곱 값들의 합으로 나누는 방식으로 계산됩니다.
    *   **예시**: Setosa(1.43), Versicolor(-0.4), Virginica(0.23)의 원시 출력 값에 SoftMax를 적용하면 각각 0.69, 0.10, 0.21과 같은 값들을 얻을 수 있습니다.
*   **장점**:
    *   **0과 1 사이의 값**: 모든 출력 값이 0과 1 사이에 있습니다.
    *   **총합이 1**: 모든 출력 값을 더하면 항상 1이 됩니다.
    *   **예측 확률로 해석 가능**: 출력 값들이 상호 배타적(mutually exclusive)인 경우, 이 값들을 **"예측 확률(predicted probabilities)"**로 해석할 수 있습니다.
    *   **원시 출력 값의 순서 보존**: SoftMax를 거쳐도 가장 큰 원시 출력 값은 가장 큰 SoftMax 출력 값으로, 가장 작은 원시 출력 값은 가장 작은 SoftMax 출력 값으로 변환되어 **원래 순서나 순위를 유지**합니다.
    *   **역전파에 사용 가능**: ArgMax와 달리 SoftMax 함수의 **미분 값은 항상 0이 아니므로**, 이를 **역전파와 경사 하강법에 사용하여 신경망의 가중치와 편향을 최적화**할 수 있습니다.
*   **주의사항**: SoftMax 출력 값을 "예측 확률"로 해석할 수는 있지만, 이 확률 값들의 정확도에 **너무 큰 신뢰를 두어서는 안 됩니다**. 그 이유는 이 확률 값들이 신경망의 가중치와 편향에 의존하고, 이 가중치와 편향은 무작위로 선택된 초기 값에 따라 달라질 수 있기 때문입니다. 초기 값에 따라 분류 성능은 동일해도 다른 확률 값들이 나올 수 있습니다.

### **9.4 ArgMax와 SoftMax의 활용**
일반적으로 신경망에서는 **훈련(training)** 시에는 미분이 가능한 **SoftMax 함수를 사용하여 가중치와 편향을 업데이트**하고, **새로운 데이터를 분류(classify new observations)**할 때는 출력을 쉽게 해석할 수 있는 **ArgMax를 사용**합니다.

### **9.5 추가 개념: 교차 엔트로피(Cross Entropy)**
SoftMax 함수를 사용하여 출력 값이 예측 확률로 주어질 때는, 신경망이 데이터에 얼마나 잘 맞는지를 평가하기 위해 **잔차 제곱합(sum of squared residuals) 대신 교차 엔트로피라는 손실 함수를 자주 사용**합니다.

## 10. SoftMax 함수의 미분(Derivative)
- 출처:[The SoftMax Derivative, Step-by-Step!!!](https://www.youtube.com/watch?v=M59JElEPgIg&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=11)

SoftMax 미분은 신경망이 예측 오류를 줄이기 위해 내부 가중치(weights)를 조정하는 **역전파(backpropagation) 과정에 필수적**입니다. 이전 대화에서 SoftMax의 미분 값이 항상 0이 아니기 때문에 역전파와 경사 하강법에 사용할 수 있다고 설명드렸는데,이 동영상은 바로 그 미분 값이 어떻게 계산되는지를 보여줍니다.

### **10.1 SoftMax 미분이 중요한 이유**
신경망은 예측이 틀렸을 때 그 오류를 바탕으로 가중치와 편향을 업데이트하여 더 정확하게 예측하도록 학습합니다. 이때, **손실 함수(loss function)의 출력에 대한 가중치의 기울기(gradient)를 계산해야 하는데, 이 과정에서 SoftMax 함수의 미분이 사용**됩니다. 미분 값을 알아야 어떤 방향으로 가중치를 조정해야 손실이 줄어들지 알 수 있습니다.

### **10.2 SoftMax 미분 계산 (단계별)**
동영상에서는 붓꽃 분류 예시를 사용하여 SoftMax 미분을 두 가지 경우로 나누어 설명합니다.

*   **경우 1: 특정 종(예: Setosa)의 SoftMax 출력에 대한 해당 종의 원시 출력 값(raw output value) 미분**
    *   **질문**: Setosa가 예측될 확률이 Setosa의 원시 출력 값(즉, SoftMax 레이어에 들어가기 전의 값)에 따라 어떻게 변하는가?
    *   **계산 과정**: 이 미분을 계산하기 위해 **몫 규칙(quotient rule)**을 사용합니다. 복잡한 대수학 단계를 거치지만, 결과적으로 다음과 같이 간결하게 정리됩니다.
    *   **결과**: Setosa의 예측 확률 * (1 - Setosa의 예측 확률).
        *   **예시**: Setosa의 예측 확률이 0.69였다면, 미분 값은 0.69 * (1 - 0.69) = **0.21**이 됩니다.
    *   **의미**: 이 값은 Setosa의 원시 출력 값이 조금 변했을 때 Setosa의 예측 확률이 얼마나 민감하게 변하는지를 나타냅니다.

*   **경우 2: 특정 종(예: Setosa)의 SoftMax 출력에 대한 다른 종(예: Versicolor)의 원시 출력 값 미분**
    *   **질문**: Setosa가 예측될 확률이 Versicolor의 원시 출력 값에 따라 어떻게 변하는가?
    *   **계산 과정**: 이 경우에도 **몫 규칙**을 사용합니다. 중요한 점은, 분자(numerator)가 Setosa의 원시 출력 값에만 의존하기 때문에, Versicolor에 대해 미분하면 0이 됩니다.
    *   **결과**: -Setosa의 예측 확률 * Versicolor의 예측 확률.
        *   **예시**: Setosa의 예측 확률이 0.69이고 Versicolor의 예측 확률이 0.10이었다면, 미분 값은 -0.69 * 0.10 = **-0.07**이 됩니다.
    *   **의미**: 이 값은 Versicolor의 원시 출력 값이 변했을 때 Setosa의 예측 확률이 어떻게 변하는지를 나타냅니다. 음수 값은 Versicolor의 원시 출력 값이 증가하면 Setosa의 예측 확률은 감소한다는 것을 의미합니다.
    *   **참고**: Virginica에 대한 미분도 Versicolor의 경우와 유사한 방식으로 계산됩니다.

### **10.3 핵심 요약**
SoftMax 미분은 신경망이 스스로 학습할 수 있도록 하는 **역전파 알고리즘의 핵심 구성 요소**입니다. 이 미분 값을 통해 신경망은 각 출력 노드에 기여하는 가중치들이 예측 오류에 어떻게 영향을 미치는지 파악하고, 이를 바탕으로 가중치를 업데이트하여 성능을 개선해 나갑니다. 동영상은 이러한 복잡한 미분 과정이 실제로는 논리적인 단계와 대수학을 통해 이루어짐을 보여줍니다.

## 11. 신경망 파트 6: 교차 엔트로피 (Cross Entropy)
- 출처:[Neural Networks Part 6: Cross Entropy](https://www.youtube.com/watch?v=6ArSys5qHAU&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=12)

신경망(Neural Networks)의 중요한 개념 중 하나인 **교차 엔트로피(Cross Entropy)**에 대해 설명합니다. 특히 신경망의 성능을 측정하는 '오류 함수(error function)' 또는 '손실 함수(loss function)'로 교차 엔트로피가 어떻게 사용되는지에 초점을 맞춥니다. 

### **11.1 교차 엔트로피는 언제 사용될까?**

*   **단일 출력값의 경우:** 만약 신경망이 단일 출력값을 가진다면, 일반적으로 **제곱 잔차의 합(Sum of the Squared Residuals)**을 사용하여 신경망이 데이터에 얼마나 잘 맞는지 측정합니다.
*   **다중 출력값의 경우:** 신경망이 여러 출력값을 가질 때, 결과를 해석하기 쉽게 **아그맥스(Argmax)**를 사용하기도 합니다. 하지만 아그맥스는 미분값이 좋지 않아 역전파에는 사용할 수 없습니다.
*   **확률 출력의 경우:** 신경망 훈련을 위해 **소프트맥스(Softmax) 함수**를 사용하여 출력값을 0과 1 사이의 예측 확률로 제한합니다. 이처럼 출력이 0과 1 사이의 값으로 제한될 때, 신경망이 데이터에 얼마나 잘 맞는지 평가하기 위해 **교차 엔트로피**를 자주 사용합니다.

### **11.2 교차 엔트로피 계산 방법**

교차 엔트로피는 겉으로는 복잡하게 들리지만, 신경망에서는 매우 간단하게 적용됩니다.

*   **관측된 종에 대한 예측 확률 사용:** 예를 들어, 붓꽃(Iris) 데이터셋에서 첫 번째 관측값이 '세토사(setosa)' 종으로 알려져 있고, 신경망과 소프트맥스 함수를 거쳐 세토사에 대한 예측 확률이 0.57로 나왔다면, 이때의 교차 엔트로피는 **세토사에 대한 예측 확률(0.57)의 음의 로그(negative log base e)** 값입니다. 즉, **관측된 종에 대한 예측 확률**을 교차 엔트로피 함수에 대입하는 것입니다.
*   **단순화된 형태:** 일반적으로 교차 엔트로피는 여러 출력 클래스(예: 세토사, 버시컬러, 버지니카)에 대한 합산으로 표현되지만, 신경망에서는 관측된 종에 해당하는 항만 살아남고 나머지 항들은 0이 되어 사라지므로, **관측된 종의 예측 확률에 대한 음의 로그 값**만 남게 됩니다.
*   **총 오류 계산:** 훈련 데이터의 각 관측값에 대해 교차 엔트로피 값을 계산한 다음, 이 값들을 모두 더하면 신경망의 **총 오류(total error)**가 됩니다. 이 총 오류는 역전파를 통해 가중치(weights)와 편향(biases)을 조정하여 최소화할 수 있습니다.

### **11.3 교차 엔트로피를 사용하는 이유 (vs. 제곱 잔차)**

신경망이 다중 출력값을 가질 때 왜 제곱 잔차 대신 교차 엔트로피를 사용할까요?

*   **나쁜 예측에 대한 '손실 폭발(Loss Explosion)' 효과:**
    *   소프트맥스 출력값(0~1)을 교차 엔트로피 함수에 대입하여 그래프를 그리면, 예측이 나빠질수록(즉, 예측 확률이 0에 가까워질수록) 손실(loss)이 **급격하게 증가하여 매우 커지는 경향**을 보입니다.
    *   반면, 제곱 잔차를 사용하면 예측이 나빠져도 손실 변화의 폭이 교차 엔트로피만큼 크지 않습니다.
*   **역전파 단계 크기:**
    *   역전파의 단계 크기는 오류 함수의 **미분(derivative) 또는 접선 기울기(slope of the tangent line)**에 부분적으로 의존합니다.
    *   교차 엔트로피는 나쁜 예측에 대해 상대적으로 **큰 미분값**을 가집니다. 이는 신경망이 매우 나쁜 예측을 했을 때, 교차 엔트로피가 더 큰 기울기를 통해 **더 나은 예측으로 향하는 상대적으로 큰 단계**를 밟도록 돕습니다.

결론적으로, 교차 엔트로피는 다중 클래스 분류 문제에서 소프트맥스와 함께 사용될 때, 특히 모델의 예측이 틀렸을 때 그 오류를 더 명확하고 효과적으로 반영하여 모델 학습을 가속화하는 데 중요한 역할을 합니다. 

## 12. 역전파(Backpropagation)와 교차 엔트로피(Cross-Entropy) 미분
- 출처:[Neural Networks Part 7: Cross Entropy Derivatives and Backpropagation](https://www.youtube.com/watch?v=xBEh66V9gZo&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=13)

신경망(Neural Network) 훈련 과정에서 **매개변수를 최적화하는 핵심적인 방법인 역전파(Backpropagation)와 교차 엔트로피(Cross-Entropy) 미분**에 대해 설명합니다. 특히, SoftMax 활성화 함수와 함께 교차 엔트로피를 사용하여 신경망의 성능을 평가하고, 기울기 하강법(Gradient Descent)으로 가중치(weights)와 편향 (biases)을 조정하는 과정을 다룹니다.


1.  **신경망의 예측 과정 (Neural Network Prediction Process)**:
    *   신경망은 꽃잎과 꽃받침 너비 같은 입력값을 받아, 여러 가중치와 편향을 통해 **활성화 함수**를 거쳐 '구부러진 표면'을 만듭니다.
    *   이 '구부러진 표면'들은 합쳐져 붓꽃 종(setosa, versicolor, virginica)에 대한 **원시 출력값(raw output values)**을 생성합니다.
    *   이 원시 출력값은 **SoftMax 함수**를 거쳐 각 붓꽃 종에 대한 최종 **예측 확률**로 변환됩니다. 예를 들어, 'setosa'일 확률이 0.57과 같이 나옵니다.

2.  **교차 엔트로피 (Cross-Entropy) 의 역할**:
    *   신경망이 얼마나 잘 예측했는지 평가하기 위해 **교차 엔트로피**라는 손실 함수(loss function)가 사용됩니다. 예측 확률을 교차 엔트로피 공식에 대입하여 하나의 수치(예: 0.56)를 얻는데, 이 값이 낮을수록 예측이 더 좋다는 의미입니다.

3.  **역전파(Backpropagation)를 위한 미분 (Derivatives for Backpropagation)**:
    *   신경망의 성능을 최적화하려면 가중치와 편향을 조정해야 합니다. 이때 **기울기 하강법**을 사용하며, 이를 위해 교차 엔트로피 값을 **가중치와 편향에 대해 미분**해야 합니다.
    *   동영상에서는 특정 편향 `b_3`를 최적화하는 예를 들어 설명합니다. `b_3`는 'setosa'에 대한 원시 출력값(초록색 쭈글쭈글한 표면)에 직접적인 영향을 줍니다.
    *   `b_3` 값이 변하면 'setosa'의 원시 출력값이 변하고, 이는 SoftMax 함수를 거쳐 모든 종의 예측 확률에 영향을 미치며, 궁극적으로 교차 엔트로피 값까지 변화시킵니다.
    *   **연쇄 법칙(Chain Rule)**을 사용하여 교차 엔트로피를 `b_3`에 대해 미분합니다. 즉, 교차 엔트로피는 예측 확률에, 예측 확률은 원시 출력값에, 원시 출력값은 `b_3`에 연결되어 있기 때문에 이 모든 연결고리를 따라 미분하는 것입니다.

4.  **미분 결과의 이해**:
    *   **관측된 종이 'setosa'인 경우**: 교차 엔트로피를 `b_3`에 대해 미분한 값은 **(setosa의 예측 확률 - 1)** 이 됩니다.
    *   **관측된 종이 'virginica' 또는 'versicolor'인 경우**: 교차 엔트로피를 `b_3`에 대해 미분한 값은 단순히 **(setosa의 예측 확률)** 이 됩니다.
    *   `b_3`가 'setosa'의 원시 출력값에만 직접적으로 영향을 미치기 때문에, 다른 종에 대한 미분 결과에도 'setosa'의 예측 확률이 나타나는 것입니다.

5.  **기울기 하강법 (Gradient Descent)을 통한 최적화 과정**:
    *   최적화는 **총 교차 엔트로피(total cross entropy)를 최소화**하는 `b_3` 값을 찾는 것입니다.
    *   **초기값 설정**: `b_3`에 임의의 초기값(예: -2)을 설정합니다.
    *   **총 교차 엔트로피 계산**: 훈련 데이터를 신경망에 통과시켜 현재 `b_3` 값에서의 총 교차 엔트로피를 계산합니다 (예: 2.67).
    *   **각 관측값에 대한 미분값 계산**: 각 훈련 데이터 샘플에 대해 위에서 구한 미분 공식을 사용하여 교차 엔트로피의 기울기(derivative)를 계산합니다.
    *   **기울기 합산**: 모든 미분값을 더하여 현재 `b_3` 값에서의 전체 기울기(예: -0.77)를 구합니다. 이 기울기는 교차 엔트로피 곡선의 접선 기울기입니다.
    *   **단계 크기(step size) 계산**: 기울기 하강 공식 `단계 크기 = -학습률(learning rate) * 기울기` 를 사용하여 다음 `b_3` 업데이트에 필요한 `단계 크기`를 결정합니다 (예: 학습률 1이면 -0.77).
    *   **`b_3` 업데이트**: `새로운 b_3 = 이전 b_3 + 단계 크기` 공식을 사용하여 `b_3` 값을 업데이트합니다 (예: -2 + (-0.77) = -1.23).
    *   **반복**: 이 과정을 예측 성능이 더 이상 개선되지 않거나 정해진 최대 반복 횟수에 도달할 때까지 반복합니다. 이 예시에서는 `b_3`가 -2에서 -0.03으로 최적화됩니다.

요약하자면, 이 동영상은 신경망이 예측을 만들고, 교차 엔트로피로 예측의 품질을 평가하며, 이 교차 엔트로피 값을 미분하여 특정 매개변수가 예측 오류에 어떻게 기여하는지 파악하고, 최종적으로 이 미분값들을 이용하여 기울기 하강법으로 매개변수를 점진적으로 최적화하는 **역전파의 전체적인 흐름과 수학적 근간**을 명확하게 설명하고 있습니다.

## 13. 합성곱 신경망(Convolutional Neural Networks, CNNs)
- 출처:[Neural Networks Part 8: CNNs](https://www.youtube.com/watch?v=HGwBXDKFk9I&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=14)

### **13.1 일반 신경망(Normal Neural Network)의 한계점**

*   **작은 이미지 분류**: 6x6 픽셀의 작은 흑백 이미지(예: 'O' 또는 'X' 글자)의 경우, 각 픽셀을 입력 노드(총 36개)로 변환하여 일반 신경망으로 분류할 수 있습니다. 각 연결에는 역전파(Backpropagation)로 추정해야 할 가중치(weights)가 필요합니다.
*   **확장성의 문제**:
    *   만약 이미지가 100x100 픽셀로 커지면, 은닉층(hidden layer)의 노드 하나당 10,000개의 가중치를 추정해야 합니다. 이는 매우 비효율적입니다.
    *   **픽셀 이동에 취약**: 이미지가 한두 픽셀 이동했을 때도 제대로 인식하지 못할 수 있습니다.
    *   **픽셀 상관관계 무시**: 이미지 내 인접한 픽셀들은 서로 연관성이 높은 경우가 많지만, 일반 신경망은 이를 활용하기 어렵습니다.

이러한 문제들 때문에 크고 복잡한 이미지 분류에는 **합성곱 신경망(CNN)**이 주로 사용됩니다.

### **13.2 합성곱 신경망(CNN)의 장점**

CNN은 다음 세 가지 이점을 통해 이미지 분류를 실용적으로 만듭니다:

1.  **입력 노드 수 감소**: 신경망으로 들어가는 입력의 수를 효과적으로 줄입니다.
2.  **픽셀 이동 허용**: 이미지 내 픽셀의 작은 이동에도 강건하게 작동합니다.
3.  **픽셀 상관관계 활용**: 복잡한 이미지에서 관찰되는 픽셀 간의 상관관계를 이용합니다.

### **13.3 합성곱 신경망(CNN)의 작동 방식 (단계별 설명)**

CNN이 'O' 글자 이미지를 인식하는 과정을 통해 작동 방식을 살펴보겠습니다.

1. **필터 적용 (합성곱 - Convolution)**

*   **필터(Filter) 정의**: CNN은 먼저 입력 이미지에 **필터**라는 작은 사각형(일반적으로 3x3 픽셀)을 적용합니다. 필터 내 각 픽셀의 강도는 역전파를 통해 학습됩니다 (초기에는 무작위 값이었다가 훈련을 통해 유용한 값으로 변함).
*   **합성곱 연산**:
    1.  필터를 이미지 위에 겹쳐 놓습니다.
    2.  겹쳐진 각 픽셀 값을 서로 곱합니다.
    3.  곱한 값들을 모두 더합니다 (**내적 - Dot Product**이라고도 함).
    4.  이 과정을 **'합성곱(Convolve)'**이라고 부르며, 이것이 합성곱 신경망의 이름이 된 이유입니다.
*   **바이어스(Bias) 추가 및 특성 맵(Feature Map) 생성**:
    1.  필터의 출력값에 **바이어스 항**을 더합니다.
    2.  이 최종 값을 **특성 맵(Feature Map)**이라는 새로운 행렬에 저장합니다.
*   **필터 이동**: 필터는 일반적으로 한 픽셀씩 옆으로 이동하며(다른 CNN은 두 픽셀 이상 이동할 수도 있음), 이 과정을 반복하여 특성 맵 전체를 채웁니다.
*   **상관관계 활용**: 특성 맵의 각 셀은 인접한 픽셀 그룹에 해당하므로, 이미지 내 픽셀 간의 상관관계를 활용하는 데 도움이 됩니다.

**2. ReLU 활성화 함수 적용**

*   특성 맵의 각 값에 **ReLU(Rectified Linear Unit) 활성화 함수**를 적용합니다.
*   ReLU는 음수 값을 0으로 만들고, 양수 값은 그대로 유지합니다.

**3. 풀링(Pooling)**

*   **맥스 풀링(Max Pooling)**: 활성화 함수를 거친 특성 맵에 다시 필터를 적용하는데, 이때는 각 영역에서 **최대 값**만 선택합니다. 풀링 필터는 일반적으로 서로 겹치지 않게 이동합니다.
    *   **효과**: 맥스 풀링은 필터가 이미지에서 가장 잘 일치하는 지점을 선택하여 해당 영역을 압축하는 역할을 합니다.
*   **평균 풀링(Average/Mean Pooling)**: 각 영역의 **평균 값**을 계산하는 방식으로도 풀링을 할 수 있습니다.

**4. 일반 신경망에 연결**

*   최종 풀링 레이어의 결과 값들을 하나의 **열(column) 형태의 입력 노드**로 변환합니다.
*   이 입력 노드들을 **일반적인 신경망**에 연결합니다. 이 신경망은 은닉층과 출력층(예: 'O'와 'X'를 위한 두 개의 출력 노드)을 가집니다.
*   **최종 분류**: 입력 이미지('O' 또는 'X')를 이러한 모든 단계를 거쳐 처리한 후, 일반 신경망이 최종적으로 'O'인지 'X'인지 분류합니다.

### **13.4 CNN의 이점 재확인**

*   **입력 수 감소**: 6x6 픽셀 이미지(36개 입력)를 예시로 들었을 때, 최종적으로 일반 신경망의 입력 노드를 4개로 줄였습니다.
*   **상관관계 활용**: 필터가 단일 픽셀 대신 픽셀 영역을 살펴보면서 이미지 내 상관관계를 고려합니다.
*   **이동 허용**: 'X' 이미지를 한 픽셀 오른쪽으로 이동시킨 경우에도, CNN은 여전히 입력 이미지가 'X'라고 정확하게 분류할 수 있습니다.

이처럼 합성곱 신경망은 이미지 분류를 위한 강력한 도구이며, 아무리 복잡한 CNN이라도 **합성곱(필터 적용), 활성화 함수, 풀링**이라는 세 가지 핵심 단계를 기반으로 합니다. 필요에 따라 출력 값을 SoftMax 함수 등을 통해 더 쉽게 해석할 수도 있습니다.

## 14. 순환 신경망(RNN)
- 출처:[Recurrent Neural Networks (RNNs)](https://www.youtube.com/watch?v=AsNTP8Kwu80&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=15)

### 14.1 순환 신경망(RNN)이란 무엇인가?

순환 신경망(RNN)은 **순차적인 데이터(sequential data)를 처리하는 데 특화된 신경망**입니다. 주식 가격 변동, 날씨 데이터, 음성, 텍스트와 같이 시간이나 순서에 따라 달라지는 데이터를 다룰 때 유용합니다.

1.  **순차 데이터의 특징**: 주식 시장 데이터를 예로 들면, 주가는 시간이 지남에 따라 변하고, 같은 회사라도 시장에 상장된 기간에 따라 보유한 데이터의 양이 다를 수 있습니다. RNN은 이처럼 **다양한 길이의 순차 데이터를 유연하게 처리**할 수 있어야 합니다.
2.  **기존 신경망과의 차이점**: 이전에 보았던 일반적인 신경망들은 고정된 수의 입력값을 받아 예측을 수행합니다. 반면 RNN은 **'피드백 루프(feedback loop)'**라는 독특한 구조를 가지고 있어, 이 루프를 통해 이전 단계의 정보가 다음 단계의 예측에 영향을 미칠 수 있습니다. 예를 들어, 오늘 주가를 예측하기 위해 어제 주가 정보가 오늘 주가 정보와 함께 고려될 수 있습니다.

### 14.2 RNN의 작동 방식: 언롤링(Unrolling)

RNN이 순차적인 입력값을 어떻게 처리하는지 이해하기 쉽게 설명하기 위해 '언롤링(unrolling)'이라는 개념이 사용됩니다.

1.  **피드백 루프의 시각화**: RNN의 피드백 루프는 마치 자기 자신에게 다시 연결되는 것처럼 보일 수 있습니다. 이를 더 쉽게 이해하기 위해 **각 입력 값마다 신경망의 사본을 만들어서 연결하는 방식**이 '언롤링'입니다.
2.  **데이터 처리 과정**: 언롤링된 신경망에서는 어제 값, 오늘 값 등 순차적인 데이터를 각각의 입력값으로 넣을 수 있습니다. 이때 데이터는 항상 **가장 오래된 것부터 최신 순으로 입력**됩니다. 최종적으로 가장 마지막 출력값이 미래(예: 내일)에 대한 예측이 됩니다.
3.  **가중치 및 편향 공유**: 언롤링을 아무리 많이 하더라도, **네트워크 내의 가중치(weights)와 편향(biases)은 모든 입력에 걸쳐 공유됩니다**. 이는 훈련해야 할 매개변수의 수가 입력 데이터의 길이에 따라 늘어나지 않으므로, 모델의 복잡성을 관리하는 데 도움이 됩니다.

### 14.3 RNN의 주요 한계: 기울기 소실/폭주 문제 (Vanishing/Exploding Gradient Problem)

기본적인 RNN은 순차 데이터를 다루는 데 뛰어나지만, 한 가지 큰 문제가 있습니다. **네트워크를 더 많이 언롤링할수록, 즉 처리해야 할 순차 데이터의 길이가 길어질수록 훈련하기가 훨씬 어려워진다는 점**입니다. 이 문제는 **'기울기 소실(Vanishing Gradient) 문제' 또는 '기울기 폭주(Exploding Gradient) 문제'**라고 불립니다.

1.  **문제의 원인**: 이 문제는 주로 피드백 루프 내에 있는 특정 가중치(W sub 2)와 관련이 있습니다. 신경망 훈련은 '역전파(backpropagation)' 과정을 통해 가중치와 편향의 '기울기(gradients)'를 계산하고, 이 기울기를 이용해 손실 함수(loss function)를 최소화하는 방향으로 매개변수를 업데이트합니다.
2.  **기울기 폭주(Exploding Gradient)**: 피드백 루프의 가중치(W sub 2)가 1보다 큰 경우 발생합니다. 입력 값이 언롤링 횟수만큼 W sub 2에 거듭 제곱으로 곱해지면서 **기울기가 엄청나게 커집니다**. 예를 들어, 50일치의 데이터를 처리한다면, W sub 2가 2일 때 2의 50승처럼 매우 큰 숫자가 됩니다. 이렇게 기울기가 너무 커지면 훈련 과정에서 매개변수를 업데이트할 때 너무 큰 폭으로 이동하게 되어, 최적의 값을 찾지 못하고 계속해서 **'튀어 다니는(bounce around)' 현상**이 발생합니다.
3.  **기울기 소실(Vanishing Gradient)**: 반대로 피드백 루프의 가중치(W sub 2)가 1보다 작은 경우 발생합니다. 입력 값이 언롤링 횟수만큼 W sub 2에 거듭 제곱으로 곱해지면서 **기울기가 거의 0에 가까워집니다**. 예를 들어, W sub 2가 0.5일 때 50일치 데이터를 처리하면 0.5의 50승처럼 0에 극도로 가까운 숫자가 됩니다. 기울기가 너무 작아지면 매개변수 업데이트 폭이 너무 작아져서, **모델이 제대로 학습되지 않거나 최적의 값에 도달하기 전에 훈련이 중단될 수 있습니다**.

### 14.4 해결책: Long Short-Term Memory Networks (LSTMs)

이러한 기울기 소실/폭주 문제는 기본적인 RNN의 성능을 제한하는 주된 요인입니다. 이 문제를 해결하기 위한 대중적인 방법 중 하나가 바로 **Long Short-Term Memory Networks (LSTMs)**이며, 이는 다음 StatQuest 동영상에서 자세히 다뤄질 예정입니다. LSTMs는 RNN의 변형으로, '기억 셀(memory cell)'이라는 특별한 구조를 통해 장기 의존성(long-term dependencies)을 효과적으로 학습할 수 있도록 설계되었습니다.

## 15. Long Short-Term Memory (LSTM) 개요
- 출처:[Long Short-Term Memory (LSTM)](https://www.youtube.com/watch?v=YCzL96nL7j0&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=16)

LSTM은 순환 신경망(Recurrent Neural Network, RNN)의 한 유형으로, 기본 순환 신경망의 한계를 극복하기 위해 고안되었습니다.

### **15.1 기본 순환 신경망(RNN)의 문제점**
기본 순환 신경망은 순차적인 데이터를 다루는 데 유용하지만, 학습하기 어렵다는 큰 단점이 있습니다. 이는 **"기울기 폭발(exploding gradient)"** 또는 **"기울기 소실(vanishing gradient)"** 문제 때문입니다.
*   **기울기 폭발**: 피드백 루프의 가중치(weight)가 1보다 크면(예: 2), 네트워크가 여러 번 전개(unroll)될 때 입력값이 이 가중치의 거듭제곱으로 곱해져 매우 큰 숫자가 됩니다. 이로 인해 기울기가 폭발적으로 커져 학습이 불안정해집니다.
*   **기울기 소실**: 피드백 루프의 가중치가 1보다 작으면(예: 0.5), 같은 방식으로 거듭제곱이 되면 입력값이 0에 가까운 매우 작은 숫자가 됩니다. 이로 인해 기울기가 거의 0이 되어 학습이 진행되지 않게 됩니다.
이러한 문제 때문에 기본 RNN은 긴 시퀀스의 데이터를 효율적으로 학습하기 어렵습니다.

### **15.2 LSTM의 핵심 아이디어**
LSTM은 기본 RNN의 이러한 문제, 특히 기울기 폭발/소실 문제를 피하도록 설계되었습니다. 핵심 아이디어는 **과거의 사건들과 최근의 사건들을 구분하여 예측에 사용하는 두 가지 별도의 경로를 사용**한다는 것입니다.
*   **장기 기억(Long-term memory)**을 위한 경로
*   **단기 기억(Short-term memory)**을 위한 경로

### **15.3 LSTM 단위의 구성 요소 및 작동 원리**
LSTM은 기본 RNN보다 훨씬 복잡한 단위를 기반으로 하지만, 각 부분의 역할을 이해하면 어렵지 않습니다. LSTM에는 **셀 상태(Cell State)**와 **히든 상태(Hidden State)**, 그리고 세 가지 **게이트(Gate)**가 있습니다. 또한, 시그모이드(sigmoid)와 하이퍼볼릭 탄젠트(tan-h) 활성화 함수를 사용합니다.
*   **활성화 함수**:
    *   **시그모이드 함수**: 어떤 입력값이든 0에서 1 사이의 값으로 변환합니다. 주로 '얼마나 기억할지' 또는 '얼마나 보낼지' 비율을 결정하는 데 사용됩니다.
    *   **하이퍼볼릭 탄젠트(tan-h) 함수**: 어떤 입력값이든 -1에서 1 사이의 값으로 변환합니다. 주로 새로운 정보를 생성하거나 기존 정보를 변환하는 데 사용됩니다.

*   **주요 구성 요소**:
    *   **셀 상태 (Cell State)**: 단위의 상단을 가로지르는 녹색 선으로 표시되며, **장기 기억**을 나타냅니다. 이 경로는 직접적인 가중치와 편향에 의해 수정되지 않기 때문에 기울기 문제가 발생하는 것을 방지하며, 장기 기억이 여러 단위를 거쳐 흐르도록 돕습니다.
    *   **히든 상태 (Hidden State)**: 분홍색 선으로 표시되며, **단기 기억**을 나타냅니다. 히든 상태는 가중치에 의해 직접 수정될 수 있습니다.

*   **세 가지 게이트**:
    1.  **망각 게이트 (Forget Gate)**: LSTM 단위의 첫 번째 단계입니다. 이전 장기 기억(셀 상태) 중 **얼마나 많은 부분을 잊을지, 즉 기억할 비율을 결정**합니다. 시그모이드 활성화 함수를 사용하여 0에서 1 사이의 값을 출력하며, 이 값이 장기 기억에 곱해져 기억될 비율을 정합니다.
    2.  **입력 게이트 (Input Gate)**: LSTM 단위의 두 번째 단계로, **새로운 잠재적 장기 기억을 생성하고, 그 중 얼마를 현재 장기 기억에 추가할지 결정**합니다.
        *   먼저, 이전 단기 기억과 현재 입력값을 기반으로 하이퍼볼릭 탄젠트 함수를 통해 새로운 **'잠재적 장기 기억'**을 만듭니다.
        *   그다음, 시그모이드 활성화 함수를 통해 이 잠재적 기억 중 **얼마나 많은 비율을 실제 장기 기억에 추가할지 결정**합니다.
        *   이 두 결과를 결합하여 새로운 장기 기억(셀 상태)을 업데이트합니다.
    3.  **출력 게이트 (Output Gate)**: LSTM 단위의 마지막 단계로, **단기 기억을 업데이트하고 전체 LSTM 단위의 최종 출력값을 생성**합니다.
        *   새로운 장기 기억(셀 상태)을 하이퍼볼릭 탄젠트 함수에 통과시켜 **'잠재적 단기 기억'**을 만듭니다.
        *   그리고 이전처럼 시그모이드 활성화 함수를 사용하여 이 잠재적 단기 기억 중 **얼마나 많은 비율을 내보낼지 결정**합니다.
        *   이 두 값을 곱하여 새로운 단기 기억과 동시에 LSTM 단위의 최종 출력값을 얻습니다.

### **15.4 LSTM의 장점 및 예시**
LSTM은 장기 기억과 단기 기억을 위한 별도의 경로를 사용하여 **기울기 폭발/소실 문제를 피하므로, 기본 RNN보다 훨씬 더 많은 시간 동안 데이터를 전개(unroll)하여 더 긴 순차적 데이터를 처리할 수 있습니다**.

예를 들어, 영상에서는 두 회사의 주식 가격 데이터를 사용하여 LSTM이 어떻게 작동하는지 보여줍니다. LSTM은 첫째 날의 특정 이벤트를 기억하고, 이를 바탕으로 넷째 날까지의 데이터를 순차적으로 처리하여 다섯째 날의 주식 가격을 정확하게 예측할 수 있습니다. 이는 LSTM이 중요한 과거 정보를 효과적으로 '기억'하고 '전달'할 수 있음을 보여줍니다.

## 16. 워드 임베딩(Word Embedding) 및 Word2Vec
- 출처:[Word Embedding and Word2Vec](https://www.youtube.com/watch?v=viZrOnJclY0&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=17)

### **16.1 워드 임베딩이란? 숫자로 단어의 의미를 담다**
머신러닝 알고리즘, 특히 신경망(Neural Network)은 단어를 직접 처리하는 데 어려움이 있습니다. 따라서 단어를 컴퓨터가 이해할 수 있는 **숫자 형태**로 변환해야 하는데, 이때 사용되는 것이 바로 **워드 임베딩**입니다. 워드 임베딩의 핵심 목표는 **의미적으로 유사한 단어들이 유사한 숫자(임베딩)를 가지도록** 만드는 것입니다.

### **16.2 왜 단순히 임의의 숫자를 사용하지 않을까요?**
각 단어에 임의의 숫자를 할당하는 방법은 간단하지만 문제가 있습니다. 예를 들어, "great!"과 "awesome!"은 비슷한 의미를 가지지만, 임의의 숫자를 할당하면 서로 매우 다른 숫자(예: 4.2와 -32.1)를 갖게 됩니다. 이렇게 되면 신경망이 "great!"을 처리하는 방법을 학습해도 "awesome!"을 처리하는 데 전혀 도움이 되지 않으므로, 더 복잡하고 많은 훈련이 필요해집니다.

또한, 하나의 단어라도 문맥에 따라 여러 가지 방식으로 사용될 수 있습니다 (예: 긍정적인 "great!"과 비꼬는 "great"). 따라서 각 단어에 여러 개의 숫자를 할당하여 다양한 문맥을 반영할 수 있다면 더 유용할 것입니다.

### **16.3 신경망을 이용한 워드 임베딩 생성 원리**
다행히 우리는 간단한 신경망을 훈련시켜 이러한 작업을 수행하게 할 수 있습니다.

*   **입력 및 임베딩 생성**: 훈련 데이터에 있는 각 고유 단어는 신경망의 입력으로 사용됩니다. 입력은 하나 이상의 **활성화 함수**에 연결되며, 이 활성화 함수의 개수는 각 단어에 할당하려는 숫자의 개수(임베딩 차원)에 해당합니다. 이 연결에 부여되는 **가중치(weights)**들이 궁극적으로 각 단어와 관련된 숫자가 됩니다. 이 가중치들은 처음에는 무작위 값으로 시작하며, 역전파(backpropagation)를 통해 최적화됩니다.
*   **예측 및 훈련**: 이 신경망은 **입력 단어를 사용하여 다음 단어를 예측**하도록 훈련됩니다. 예를 들어, "Troll 2 is great!"이라는 문구에서 "Troll 2"를 입력하면 "is"를 예측하고, "is"를 입력하면 "great!"을 예측하도록 하는 식입니다. 예측을 위해 활성화 함수는 출력층에 연결되고, 분류를 위해 소프트맥스(softmax) 함수가 사용됩니다. 훈련은 교차 엔트로피 손실 함수(cross-entropy loss function)를 사용하여 역전파 방식으로 진행됩니다.
*   **결과**: 훈련을 통해 신경망은 단어의 문맥을 사용하여 가중치(임베딩)를 최적화합니다. 그 결과, 훈련 전에는 관련이 없어 보이던 단어들(예: "Troll 2"와 "Gymkata")이 훈련 후에는 유사한 문맥에서 사용되었기 때문에 **서로 가까운 임베딩 값**을 갖게 됩니다. 즉, **비슷한 단어들은 비슷한 임베딩을 가지게** 되어 언어 처리가 더욱 쉬워집니다.

### **16.4 Word2Vec: 워드 임베딩을 위한 인기 도구**
Word2Vec은 워드 임베딩을 생성하는 데 널리 사용되는 방법입니다. Word2Vec은 다음 두 가지 전략을 사용하여 더 많은 문맥 정보를 포함합니다:

*   **Continuous Bag-of-Words (CBOW)**: 주변 단어들을 사용하여 **가운데 단어를 예측**합니다. 예를 들어, "Troll 2"와 "great!"을 사용하여 "is"를 예측하는 방식입니다.
*   **Skip-gram**: 가운데 단어를 사용하여 **주변 단어들을 예측**합니다. 예를 들어, "is"를 사용하여 주변 단어인 "Troll 2", "great!", "Gymkata"를 예측하는 방식입니다.

### **16.5 실제 적용 및 효율성 향상: Negative Sampling**
실제 워드 임베딩에서는 단순히 2개의 활성화 함수 대신 **100개 이상의 활성화 함수**를 사용하여 각 단어에 많은 임베딩을 생성합니다. 훈련 데이터도 소수의 문장이 아닌 **전체 위키피디아와 같은 거대한 자료**를 사용하며, 어휘는 수백만 단어에 달할 수 있습니다. 이로 인해 최적화해야 할 가중치의 수가 엄청나게 많아져 훈련이 느려질 수 있습니다 (예: 6억 개의 가중치).

Word2Vec은 이러한 훈련 속도를 높이기 위해 **네거티브 샘플링(Negative Sampling)**이라는 기술을 사용합니다. 네거티브 샘플링은 모든 단어에 대해 예측을 수행하는 대신, 우리가 **예측하고 싶지 않은 단어들의 일부를 무작위로 선택**하여 최적화 과정에 포함시킵니다. 이를 통해 매 단계마다 최적화해야 하는 가중치의 수를 크게 줄여 훈련 효율성을 향상시킵니다. 예를 들어, 6억 개의 총 가중치 중에서 매 단계에 약 300개만 최적화합니다.

## 17. Sequence-to-Sequence (Seq2Seq) 인코더-디코더 신경망
- 출처:[Sequence-to-Sequence (seq2seq) Encoder-Decoder Neural Networks](https://www.youtube.com/watch?v=L8HKweZIOmg&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=18)

### **17.1 Seq2Seq 문제란 무엇인가?**
*   Seq2Seq(Sequence-to-Sequence) 문제란 **한 유형의 시퀀스를 다른 유형의 시퀀스로 번역**해야 하는 문제들을 말합니다. 예를 들어, 영어 문장을 스페인어 문장으로 번역하거나, 아미노산 서열을 3D 단백질 구조로 번역하는 것 등이 여기에 해당됩니다.
*   이러한 문제의 특징은 입력 문장과 출력 문장의 **길이가 서로 다를 수 있다**는 점입니다. 예를 들어, "Let's go." (2단어)는 스페인어로 "Vamos." (1단어)로 번역될 수 있습니다.

### **17.2 인코더-디코더 모델의 역할**
*   Seq2Seq 문제를 해결하는 한 가지 방법이 바로 **인코더-디코더(Encoder-Decoder) 모델**입니다. 이 모델은 입력 시퀀스를 처리하는 '인코더'와 출력 시퀀스를 생성하는 '디코더' 두 부분으로 구성됩니다.
*   오늘날의 대규모 언어 모델(Large Language Models)인 ChatGPT와 같은 **트랜스포머(Transformers)의 기반**을 이해하기 위한 중요한 첫 단계이기도 합니다.

### **17.3 인코더(Encoder): 입력 시퀀스를 이해하다**
*   **단어 임베딩(Word Embedding)**: 신경망에 단어를 직접 입력할 수 없으므로, 먼저 **임베딩 계층(embedding layer)**을 사용하여 단어들을 숫자로 변환합니다. 이 숫자를 '토큰(token)'이라고 부릅니다.
*   **LSTM 활용**: 가변적인 길이의 입력과 출력을 처리하기 위해 **Long Short-Term Memory (LSTM)** 신경망을 사용합니다. LSTM은 입력 시퀀스의 각 단어(토큰)를 순차적으로 처리하며, 이때 **동일한 가중치(weights)와 편향(biases)을 재사용**하여 "언롤(unroll)" 방식으로 작동합니다.
*   **계층 및 셀 추가**: 모델이 데이터에 더 잘 맞도록 **추가적인 LSTM 셀이나 계층**을 인코더에 추가할 수 있습니다. 각 계층의 LSTM 유닛 출력(단기 기억 또는 은닉 상태)은 다음 계층의 입력으로 사용됩니다.
*   **문맥 벡터(Context Vector)**: 인코더는 최종적으로 입력 문장 "let's go"의 모든 정보를 담고 있는 **'문맥 벡터'**를 생성합니다. 이 문맥 벡터는 인코더의 마지막 LSTM 계층에서 나오는 장기 및 단기 기억(셀 및 은닉 상태)의 집합입니다.

### **17.4 디코더(Decoder): 문맥 벡터를 번역하다**
*   **문맥 벡터 초기화**: 디코더는 인코더에서 생성된 **문맥 벡터로 LSTM의 장기 및 단기 기억을 초기화**합니다. 디코더의 LSTM은 인코더의 LSTM과는 **다른 가중치와 편향**을 가집니다.
*   **출력 단어 임베딩**: 디코더는 출력 언어(예: 스페인어)에 특화된 **자체 임베딩 계층**을 가집니다. 이 계층은 인코더의 임베딩 계층과 다른 단어 및 기호(토큰)와 다른 가중치를 사용합니다.
*   **디코딩 시작**: 디코더는 일반적으로 문장의 끝을 의미하는 **'EOS(End of Sentence)' 토큰의 임베딩 값**으로 디코딩을 시작합니다 (때로는 'SOS' 토큰을 사용하기도 합니다).
*   **단어 예측**: 디코더의 최상위 LSTM 계층에서 나오는 출력 값은 **완전 연결 계층(fully connected layer)**을 거친 후 **소프트맥스(softmax) 함수**를 통해 다음 단어를 예측합니다. 완전 연결 계층은 기본적인 신경망을 의미합니다.
*   **종료 조건**: 디코더는 **EOS 토큰을 예측**하거나 **사전 설정된 최대 출력 길이**에 도달할 때까지 단어를 계속 예측합니다.
*   **길이 독립성**: 인코더와 디코더가 분리되어 있기 때문에, 입력 텍스트와 번역된 출력 텍스트의 길이가 다를 수 있습니다.

### **17.5 훈련 방법: 티처 포싱(Teacher Forcing)**
*   모델의 가중치와 편향은 **역전파(backpropagation)**를 통해 훈련됩니다.
*   훈련 시에는 **'티처 포싱(teacher forcing)'**이라는 특별한 방법이 사용됩니다. 예측된 토큰을 디코더의 다음 입력으로 사용하는 대신, **알려진 정답 토큰**을 디코더 LSTM의 입력으로 사용합니다. 또한, 디코더가 EOS 토큰을 예측할 때까지 기다리지 않고, **알려진 정답 문장의 길이**에서 예측을 멈춥니다. 이는 훈련 과정을 안정화하고 속도를 높이는 데 도움을 줍니다.

### **17.6 모델의 규모와 복잡성**
*   이해를 돕기 위한 예시 모델은 소수의 단어와 임베딩 값, 2개의 LSTM 계층으로 구성되어 220개의 가중치와 편향을 훈련합니다.
*   그러나 실제 Seq2Seq 모델(예: 오리지널 논문 모델)은 16만 개의 입력 토큰, 8만 개의 출력 토큰, 각 토큰에 1,000개의 임베딩 값, 4개의 LSTM 계층에 각 1,000개의 LSTM 셀을 사용하여 **총 3억 8,400만 개의 가중치와 편향**을 훈련합니다. 이는 모델의 **엄청난 규모와 복잡성**을 보여줍니다.

