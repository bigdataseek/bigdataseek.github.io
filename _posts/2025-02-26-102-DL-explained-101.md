---
title: 3차시 2:Deep Learning Explained 1
layout: single
classes: wide
categories:
  - 딥러닝
  - DeepLearning
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. 딥러닝이란

- 출처: [What is deep learning?](https://www.youtube.com/watch?v=dccdadl90vs&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=1)

### 1.1 **딥러닝이란 무엇인가?**
*   **정의:** 딥러닝은 신경망(neural networks)을 기반으로 하는 기술 그룹으로, 데이터에서 복잡한 패턴을 직접 학습할 수 있는 능력을 가지고 있습니다.
*   **신경망:** 인간의 뇌에서 영감을 받아 만들어진 알고리즘입니다.
    *   신경망은 여러 층의 뉴런으로 구성됩니다.
    *   **세 가지 주요 층:**
        *   **입력 층(Input layer):** 
            *   입력을 받아들이는 부분.
        *   **출력 층(Output layer):** 
            *   네트워크의 예측 또는 결과를 제공하는 부분.
        *   **은닉 층(Hidden layers):** 
            *   입력 층과 출력 층 사이에 위치하며, 이 은닉 층의 수가 많을수록 네트워크가 '깊어지고' 여기서 '딥(deep)'이라는 용어가 유래했습니다. '러닝(learning)'은 기계 학습 또는 네트워크가 복잡한 패턴을 학습할 수 있는 능력에서 나옵니다.
*   **일상생활에 미치는 영향:** 기계 번역, 얼굴 인식, 추천 시스템(예: 넷플릭스) 등 우리가 매일 사용하는 대부분의 기술에 딥러닝이 적용되어 있습니다.

### 1.2  **딥러닝의 역사:**
*   최근 10~15년 동안 우리의 삶에 큰 영향을 미쳤지만, 사실 첫 신경망은 1943년에 제안되었습니다.
*   딥러닝에 대한 관심의 물결이 여러 차례 있었고, 현재는 새로운 관심의 물결 속에 있으며, 이번에는 이 관심이 사라지지 않을 것이라고 여겨지고 있습니다.
*   그 이유는 **많은 데이터의 가용성**, **지속적으로 발전하는 컴퓨팅 파워**, 그리고 **딥러닝 연구의 활발한 진행** 때문.

### 1.3   **컴퓨터 과학, 인공지능(AI), 기계 학습(Machine Learning), 딥러닝의 관계:**
*   **컴퓨터 과학**은 가장 큰 범주입니다 (예: 컴퓨터 보안, 소프트웨어 공학, 분산 시스템 등).
*   **인공지능(AI):** 컴퓨터 과학의 한 분야로, 컴퓨터가 일반적으로 인간에게 전형적인 작업을 정확하고 효율적으로 수행하도록 하는 것이 목표입니다.
*   **기계 학습(Machine Learning):** 인공지능의 한 접근 방식으로, 컴퓨터가 데이터로부터 직접 작업을 수행하는 방법을 배우는 것을 목표로 합니다.
*   **딥러닝:** 기계 학습의 한 부분이며, 그 자체로 기계 학습 안에 포함되는 기술 그룹입니다. 따라서 기계 학습이라고 말할 때는 딥러닝을 포함하는 것입니다.

### 1.4   **전통적인 기계 학습과 딥러닝의 비교:**
*   **특징 추출:**
    *   **전통적인 기계 학습:** 모델을 훈련하기 위해 데이터에서 **수동으로 특징(features)을 추출해야 합니다** (예: 고양이와 개를 분류할 때 뾰족한 귀의 개수, 코 모양, 자세 등 수동으로 정의).
    *   **딥러닝:** **특징을 수동으로 추출할 필요가 없습니다**. 이미지를 있는 그대로 제공하면, 알고리즘 자체가 두 동물을 구별하는 패턴과 특징을 이해합니다.
*   **데이터 요구량:**
    *   **전통적인 기계 학습:** 상대적으로 적은 데이터로도 훈련이 가능합니다.
    *   **딥러닝:** 모델을 정확하게 훈련하려면 전통적인 기계 학습 알고리즘보다 **훨씬 더 많은 데이터가 필요합니다**.
*   **계산 능력 및 시간:**
    *   **전통적인 기계 학습:** 적은 계산 능력으로 짧은 시간이 소요됩니다.
    *   **딥러닝:** 많은 계산이 필요하므로 **더 강력한 머신과 더 긴 훈련 시간이 필요합니다**. (하지만 강력한 머신을 사용할수록 시간은 단축될 수 있습니다).
*   **추상적인 패턴 처리 능력:**
    *   **전통적인 기계 학습:** 추상적인 패턴을 포착하기 어렵거나 불가능할 수 있습니다.
    *   **딥러닝:** **더 추상적인 패턴을 포착할 수 있어** 전통적인 기계 학습으로는 불가능했을 작업을 수행.
        *   **예시:** 자연어 처리(Natural Language Processing, NLP)에서 텍스트의 감성(긍정/부정)을 분석하는 경우, 어떤 특징을 추출해야 할지 파악하기 어려울 수 있지만 딥러닝은 레이블링된 예시만으로도 이를 잘 처리합니다. 고양이와 개를 구별하는 것도 사람이 특징을 만드는 것보다 딥러닝이 데이터를 통해 스스로 추출하는 것이 더 효과적입니다.


## 2. 배치 정규화
- 출처:[Batch normalization](https://www.youtube.com/watch?v=yXOMHOpbon8&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=2)


### 2.1  **배치 정규화란?**
*   신경망에서 **불안정한 기울기 문제(unstable gradients problem)를 해결**하고, 네트워크 훈련 속도를 높이며, 과적합(overfitting) 문제까지 다루는 방법입니다.
*   "정규화(normalization)"는 입력 범위를 0에서 1 사이로 줄이는 것을 의미하며, "표준화(standardization)"는 값의 평균을 0으로, 분산 또는 표준 편차를 1로 변경하는 것을 의미합니다. 배치 정규화는 값을 **표준화**하는 방식으로 작동합니다.

### 2.2   **배치 정규화가 필요한 이유**
*   신경망에 정규화되지 않은 데이터를 입력하면, 네트워크가 최적의 가중치 값을 학습하기 매우 어려워집니다.
*   이는 가중치 값들이 서로 매우 달라지게 만들고, 궁극적으로 **불안정한 네트워크와 기울기 소실(vanishing gradients) 또는 기울기 폭주(exploding gradients) 문제**를 야기할 수 있습니다.
*   일반적으로는 입력값을 정규화하고, 올바른 가중치 초기화 기법 및 활성화 함수를 사용하지만, 훈련 중에도 불안정한 기울기 문제가 다시 발생할 수 있습니다.

### 2.3   **배치 정규화의 작동 방식**
*   배치 정규화는 입력 데이터뿐만 아니라 **네트워크의 모든 레이어의 출력을 정규화**합니다.
*   각 레이어 사이에 배치 정규화 레이어가 삽입되어 이전 레이어의 출력을 처리합니다.
*   **주요 단계**:
    1.  입력 값을 **표준화**하여 평균을 0으로, 분산을 1로 만듭니다.
    2.  표준화된 값에 **스케일(scale) 값(감마, γ)을 곱하고 오프셋(offset) 값(베타, β)을 더합니다**. 이 스케일과 오프셋 값은 하이퍼파라미터가 아니며, 가중치나 편향처럼 훈련 과정에서 학습되는 **학습 가능한 파라미터**입니다.

### 2.4   **배치 정규화의 이점**
*   **불안정한 기울기 문제 해결**: 네트워크가 불안정한 기울기 문제를 극복하는 데 도움을 줍니다.
*   **훈련 속도 향상**: 개별 에폭(epoch)은 더 오래 걸릴 수 있지만, 동일한 정확도를 달성하는 데 필요한 에폭 수가 줄어들어 **총 훈련 시간이 단축**됩니다.
*   **성능 향상**: 더 적은 에폭으로 동일한 정확도를 달성할 수 있으므로, 더 훈련하면 **더 나은 성능**을 얻을 수 있습니다.
*   **입력 데이터 정규화 불필요**: 첫 번째 레이어 앞에 배치 정규화 레이어를 배치하여 **별도로 입력 데이터를 정규화할 필요가 없습니다**.
*   **정규화(Regularization) 필요성 감소**: 과적합을 방지하기 위한 정규화 기법의 필요성을 줄여줍니다.
*   **파라미터 수 감소**: 편향(bias) 대신 오프셋 값을 학습하므로, 조밀 레이어(dense layer)에서 **편향 사용을 비활성화하여 파라미터 수를 줄일 수 있습니다**.

### 2.5   **Keras를 사용한 구현**
*   `BatchNormalization`은 Keras에 미리 정의된 레이어입니다.
*   원하는 두 레이어 사이에 `BatchNormalization` 레이어를 추가하기만 하면 됩니다.
*   **활성화 함수(activation function) 전후 배치**: 원본 논문 저자들은 활성화 함수 *전에* 배치 정규화를 사용하는 것을 선호했지만, 이는 특정 시스템 및 문제에 따라 실험해 볼 가치가 있습니다.
*   **편향(bias) 사용 여부**: 배치 정규화는 오프셋 값을 사용하므로, 조밀 레이어에서 `use_bias=False`로 설정하여 **편향을 비활성화할 수 있습니다**. 이는 네트워크가 더 빨리 훈련되도록 돕고 파라미터 수를 줄입니다.


```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization, Flatten

# 1. 모델 정의
# Sequential API를 사용하여 순차적인 모델을 생성합니다.
model = Sequential()

# Flatten 레이어는 입력 데이터(이미지 등)를 1차원 배열로 변환합니다.
# 이 예시에서는 MNIST 데이터셋을 가정합니다.
model.add(Flatten(input_shape=(28, 28)))

# 첫 번째 Dense 레이어 (512개의 뉴런)
# 배치 정규화의 오프셋(offset) 값이 편향(bias)의 역할을 하므로,
# use_bias=False로 설정하여 편향을 비활성화할 수 있습니다.
model.add(Dense(512, use_bias=False))

# 배치 정규화 레이어 추가
# Dense 레이어와 활성화 함수 사이에 배치 정규화를 추가하는 것이 일반적입니다.
model.add(BatchNormalization())

# 활성화 함수 (ReLU)
model.add(tf.keras.layers.Activation('relu'))

# 두 번째 Dense 레이어 (128개의 뉴런)
model.add(Dense(128, use_bias=False))

# 배치 정규화 레이어 추가
model.add(BatchNormalization())

# 활성화 함수 (ReLU)
model.add(tf.keras.layers.Activation('relu'))

# 출력 레이어 (10개의 클래스, MNIST 데이터셋을 가정)
model.add(Dense(10, activation='softmax'))

# 2. 모델 요약
# 모델의 구조를 확인하여 각 레이어와 학습 가능한 파라미터 수를 볼 수 있습니다.
model.summary()

# 3. 모델 컴파일
# 모델을 훈련하기 전에 손실 함수, 옵티마이저, 지표 등을 설정합니다.
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. (선택 사항) 데이터 로드 및 훈련
# 실제 훈련을 위해서는 훈련 데이터와 검증 데이터가 필요합니다.
# 이 코드는 개념 설명만을 위한 것이므로 실제 훈련은 생략합니다.
# 예시:
# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
# model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))
```

-   tf.keras.layers.BatchNormalization(): 
    *   이 코드가 배치 정규화 레이어를 모델에 추가하는 핵심 부분입니다.

- Dense 레이어의 use_bias=False: 
    *   배치 정규화 레이어는 학습 가능한 오프셋 값(offset)인 beta를 가지고 있어 편향(bias)의 역할을 대신할 수 있습니다. 따라서 Dense 레이어에서 편향을 사용하지 않도록 설정하여 파라미터 수를 줄이고 학습 효율을 높일 수 있습니다.

- 배치 정규화의 위치: 
    *   이 예제에서는 Dense 레이어 다음에 그리고 활성화 함수 전에 BatchNormalization 레이어를 배치했습니다. 이는 일반적으로 권장되는 구현 방식 중 하나입니다.

## 3. 신경망의 과적합(overfitting)을 다루는 정규화(regularization)
- 출처:[Regularization in a Neural Network ](https://www.youtube.com/watch?v=EehRcPo1M-Q&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=3)

### 3.1   **정규화란?**
*   모델이 **과적합되는 것을 방지**하기 위해 사용되는 기술입니다.
*   과적합은 모델이 훈련 데이터에 너무 가깝게 맞춰져 실제 세계 데이터에 잘 일반화되지 못할 때 발생합니다.
*   과적합은 훈련 손실(training loss)은 계속 낮아지지만 검증 손실(validation loss)이 다시 높아지기 시작할 때 감지할 수 있습니다.
*   과적합의 원인은 모델의 **높은 분산(high variance)**, 즉 모델의 높은 유연성(flexibility) 때문이며, 이는 모델에 파라미터가 많을수록 발생할 가능성이 높아집니다 (예: 랜덤 포레스트나 신경망).
*   정규화는 모델의 이러한 유연성을 제한하여 과적합을 피하는 방법입니다. 특히 신경망에서는 **네트워크의 가중치를 낮추는 것**을 의미합니다.
*   가중치가 높다는 것은 특정 입력이나 데이터 포인트의 중요성을 과장한다는 의미이며, 이를 피하기 위해 가중치를 낮추는 것이 목표입니다.

### 3.2   **정규화 기법의 종류**
정규화 기법은 크게 모델의 유연성을 제한하는 방법과 데이터 증강을 사용하는 방법으로 나눌 수 있습니다.

1.  **L1 및 L2 정규화 (Constraining the model)**
    *   아이디어는 손실 함수(loss function)에 가중치를 추가하여 네트워크가 가중치를 높게 가지는 것을 **처벌(punish)**하는 것입니다.
    *   **L1 정규화 (L1 norm, Lasso)**:
        *   모든 가중치의 **절대값 합계**를 손실에 더합니다.
        *   결과적으로 네트워크가 가중치를 **0에 가깝게** 가지도록 장려하여, 일부 뉴런이 네트워크 계산에서 제외될 수 있는 **희소(sparse) 네트워크**를 생성할 수 있습니다.
    *   **L2 정규화 (Ridge regression, Weight decay)**:
        *   모든 가중치의 **제곱 값 합계**를 손실에 더합니다.
        *   L1과 달리 희소 네트워크를 만들지는 않지만, 가중치 값의 차이를 만들고 가중치를 낮춥니다.
    *   **알파(alpha) 매개변수**: L1과 L2 정규화 모두 **알파**라는 매개변수를 조정해야 합니다. 이 값은 페널티에 얼마나 많은 "주의"를 기울일지 결정합니다. 알파 값을 너무 강하게 설정하면 모델이 **과소적합(underfit)**될 수 있고, 너무 약하게 설정하면 모델이 여전히 과적합될 수 있습니다.

2.  **드롭아웃(Dropout) 정규화**
    *   매 훈련 단계마다 각 뉴런이 **비활성화될 확률 `p`**를 가집니다 (이 `p`는 드롭아웃 비율이라고 불리며 훈련 전에 결정해야 합니다).
    *   훈련 중에는 일부 뉴런이 빠지지만, **테스트 시에는 모든 뉴런이 존재**합니다.
    *   이로 인해 테스트 시에는 입력에 `1 - 드롭아웃 비율`을 곱해야 모델이 올바르게 예측할 수 있습니다.

3.  **조기 종료(Early Stopping)**
    *   모델을 훈련할수록 훈련 손실은 감소하지만, 검증 손실은 특정 시점부터 증가하기 시작합니다.
    *   조기 종료는 **검증 손실이 증가하기 시작하는 시점에서 훈련을 멈추는 것**입니다.
    *   하지만 이 기법은 다소 논란이 있을 수 있는데, 모델이 솔루션으로 수렴하도록 완전히 훈련시킨 다음 별도의 프로세스로 과적합을 다루는 것이 좋다고 주장하는 사람들도 있기 때문입니다.

4.  **데이터 증강(Data Augmentation)**
    *   네트워크에 **더 많은, 그리고 더 다양한 데이터를 공급**하는 방법입니다.
    *   새로운 데이터를 얻기 어려울 때, 기존 데이터를 변형하여 훈련 데이터셋을 풍부하게 만드는 것입니다.
    *   예를 들어, 이미지의 경우 뒤집기, 회전, 노출/채도/색상 변경 등의 변환을 적용하여 모델이 다양한 상황에서 일반화할 수 있도록 돕습니다.

## 4. 활성화 함수(Activation Functions)
- 출처:[Activation Functions In Neural Networks Explained ](https://www.youtube.com/watch?v=Fu273ovPBmQ&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=4)


### 4.1   **활성화 함수(Activation Functions)의 정의 및 필요성**:
*   활성화 함수는 **비선형 변환을 적용하여 뉴런이 활성화되어야 할지 여부를 결정**합니다.
*   신경망에서 각 뉴런은 입력에 가중치를 곱하고 편향을 더하는 선형 변환을 적용합니다.
*   만약 활성화 함수가 없다면, 전체 네트워크는 단순히 선형 회귀 모델을 쌓아 올린 것과 같아 복잡한 패턴을 학습할 수 없습니다.
*   활성화 함수는 각 계층(layer) 후에 적용되어 비선형 변환을 제공함으로써 네트워크가 복잡한 작업을 해결하도록 돕습니다.

### 4.2   **주요 활성화 함수의 종류**:
*   **계단 함수(Step Function)**: 
    -   입력이 임계값보다 크면 1, 그렇지 않으면 0을 출력합니다. 뉴런 활성화 여부를 명확히 보여주지만, 너무 단순하여 실제로는 사용되지 않습니다.
*   **시그모이드 함수(Sigmoid Function)**: 
    -   `1 / (1 + e^-x)` 공식을 사용하며, **0과 1 사이의 확률 값**을 출력합니다. 매우 음수일 경우 0에 가깝고, 매우 양수일 경우 1에 가까운 값을 반환합니다. 은닉층에서 가끔 사용되지만, 주로 **이진 분류 문제의 마지막 계층**에서 사용됩니다.
*   **하이퍼볼릭 탄젠트(Hyperbolic Tangent)**: 
    -   **-1과 +1 사이의 값**을 출력하며, 주로 **은닉층**에서 사용되는 일반적인 선택입니다. 시그모이드 함수의 스케일이 조정되고 이동된 형태입니다.
*   **ReLU (Rectified Linear Unit)**: 
    -   **가장 인기 있는 은닉층 활성화 함수** 중 하나입니다. 입력 `x`에 대해 `max(0, x)`를 계산합니다. 입력이 음수이면 0을, 양수이면 그대로 반환합니다. 학습 능력을 크게 향상시킬 수 있습니다.
    -   **죽은 ReLU(Dying ReLU) 문제**: 훈련 중 뉴런이 죽은 상태에 도달하여 어떤 입력에 대해서도 0만 출력할 수 있습니다. 이는 가중치 업데이트가 멈추는 결과를 초래합니다.
*   **Leaky ReLU**: 
    -   죽은 ReLU 문제를 피하기 위해 ReLU를 약간 변형한 함수입니다. 양수일 때는 ReLU와 동일하게 입력 값을 반환하지만, **음수일 때는 0이 아닌 작은 스케일링 인자(`a * x`, 예: `0.001 * x`)를 적용**하여 뉴런이 완전히 죽는 것을 방지합니다. 역시 은닉층에 매우 좋은 선택입니다.
*   **소프트맥스 함수(Softmax Function)**: 
    -   입력 값을 **0과 1 사이의 확률 값으로 압축**하여 출력하며, 입력 값이 높을수록 확률 값도 높아집니다. 주로 **다중 클래스 분류 문제의 마지막 계층**에서 사용됩니다. 소프트맥스를 적용한 후 가장 높은 확률을 가진 클래스를 최종 결과로 결정합니다.

### 4.3   **활성화 함수의 코드 구현**:
*   **TensorFlow (Keras API)**: 각 계층의 선택적 `activation` 인수에 활성화 함수 이름을 지정하거나, `tensorflow.keras.layers`에서 해당 활성화 함수를 계층으로 직접 생성하여 사용할 수 있습니다.

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten

# 방법 1: Dense 레이어의 activation 인수로 지정
model_method1 = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])
print("--- Method 1 (activation argument) ---")
model_method1.summary()

# 방법 2: 별도의 Activation 레이어 추가
model_method2 = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128),
    Activation('relu'),
    Dense(10),
    Activation('softmax')
])
print("\n--- Method 2 (separate Activation layer) ---")
model_method2.summary()
```

*   **PyTorch**: `torch.nn` 아래에서 모든 활성화 함수를 계층으로 찾을 수 있습니다. 네트워크의 `__init__` 함수에서 활성화 함수 계층의 인스턴스를 생성하고, `forward` 함수에서 이 계층을 호출합니다. 또는 `torch.nn.functional`에 정의된 함수를 `forward` 함수에서 직접 사용할 수도 있습니다.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

# 방법 1: nn.Module을 상속받는 클래스 내에서 활성화 함수를 nn.ReLU()로 정의
class NetMethod1(nn.Module):
    def __init__(self):
        super(NetMethod1, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 784)  # Flatten
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return F.softmax(x, dim=1)

# 방법 2: forward 함수 내에서 nn.functional.relu 함수 직접 사용
class NetMethod2(nn.Module):
    def __init__(self):
        super(NetMethod2, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 784)  # Flatten
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return F.softmax(x, dim=1)

# 모델 인스턴스 생성 (모델 구조 확인용)
model_method1 = NetMethod1()
model_method2 = NetMethod2()

print("--- Method 1 (nn.Module class) ---")
print(model_method1)
print("\n--- Method 2 (nn.functional function) ---")
print(model_method2)
```

## 5. 백프로파게이션(Backpropagation)
- 출처:[Backpropagation For Neural Networks Explained](https://www.youtube.com/watch?v=LHLrXavT1gQ&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=5)

### 5.1 목적
- 백프로파게이션은 신경망의 가중치에 대한 손실 함수의 **기울기(gradients)**를 효율적으로 계산하는 알고리즘
- **수학적 표현:**
    - 손실 함수: $L(w)$
    - 가중치: $w = [w_1, w_2, ..., w_n]$
    - 목표: $\frac{\partial L}{\partial w_i}$ 계산 (모든 i에 대해)

### 5.2 연쇄 법칙(Chain Rule):백프로파게이션의 핵심 수학적 원리
-   **일반적인 연쇄 법칙:**
$$\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \cdot \frac{\partial y}{\partial x}$$
-   **다변수 함수에서의 연쇄 법칙:**
$$\frac{\partial L}{\partial w_i} = \sum_{j} \frac{\partial L}{\partial z_j} \cdot \frac{\partial z_j}{\partial w_i}$$

여기서 $z_j$는 중간 계산 노드들입니다.

### 5.3 선형 회귀 예시
* 1.모델 정의
    - 예측 함수: $\hat{y} = w \cdot x$
    - 손실 함수: $L = (y - \hat{y})^2$
* 2.계산 그래프 표현
    ```
    x → [×] → ŷ → [-] → s → [²] → L
        ↑         ↑
        w         y
    ```
* 3.순전파(Forward Pass)
    - 주어진 값: $x = 1, y = 2, w = 1$
    - $\hat{y} = w \cdot x = 1 \times 1 = 1$
    - $s = \hat{y} - y = 1 - 2 = -1$
    - $L = s^2 = (-1)^2 = 1$

*  4.국소 기울기(Local Gradients) 계산:각 연산에 대한 편미분
    1. **제곱 노드:** $L = s^2$
    $$\frac{\partial L}{\partial s} = 2s = 2 \times (-1) = -2$$

    2. **뺄셈 노드:** $s = \hat{y} - y$
    $$\frac{\partial s}{\partial \hat{y}} = 1, \quad \frac{\partial s}{\partial y} = -1$$

    3. **곱셈 노드:** $\hat{y} = w \times x$
    $$\frac{\partial \hat{y}}{\partial w} = x = 1, \quad \frac{\partial \hat{y}}{\partial x} = w = 1$$

*   5.역전파(Backward Pass) - 연쇄 법칙 적용
    -   **목표: $\frac{\partial L}{\partial w}$ 계산**
    -   연쇄 법칙을 적용하면:
    $$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial s} \cdot \frac{\partial s}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w}$$

    값을 대입하면:
    $$\frac{\partial L}{\partial w} = (-2) \times 1 \times 1 = -2$$

*   6.가중치 업데이트: 경사 하강법을 사용

    $$w_{new} = w_{old} - \alpha \cdot \frac{\partial L}{\partial w}$$
    여기서 $\alpha$는 학습률(learning rate)입니다.

    예를 들어, $\alpha = 0.01$이면:
    $$w_{new} = 1 - 0.01 \times (-2) = 1 + 0.02 = 1.02$$

### 5.4 다층 신경망에서의 백프로파게이션

*  일반적인 신경망 구조
    ```
    입력층 → 은닉층1 → 은닉층2 → ... → 출력층 → 손실
    ```

*   수학적 표현
    - **레이어 $l$에서의 계산:**
        - 선형 변환: $z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}$
        - 활성화 함수: $a^{(l)} = \sigma(z^{(l)})$

    -   **역전파 공식:**
        1. **출력층 오차:**
            $$\delta^{(L)} = \frac{\partial L}{\partial z^{(L)}} = \frac{\partial L}{\partial a^{(L)}} \odot \sigma'(z^{(L)})$$

        2. **은닉층 오차 (역방향으로 전파):**
            $$\delta^{(l)} = ((W^{(l+1)})^T \delta^{(l+1)}) \odot \sigma'(z^{(l)})$$

        3. **가중치 기울기:**
            $$\frac{\partial L}{\partial W^{(l)}} = \delta^{(l)} (a^{(l-1)})^T$$

        4. **편향 기울기:**
            $$\frac{\partial L}{\partial b^{(l)}} = \delta^{(l)}$$

        여기서 $\odot$는 원소별 곱셈(element-wise multiplication)을 의미합니다.

### 5.5 백프로파게이션 알고리즘 요약
- 알고리즘 단계:
    1. **순전파:** 입력부터 출력까지 계산하여 예측값과 손실을 구함
    2. **역전파:** 출력층부터 입력층까지 역방향으로 기울기를 계산
    3. **가중치 업데이트:** 계산된 기울기를 사용하여 가중치를 조정

- 시간 복잡도
    - 순전파: $O(n)$ (n = 연결의 수)
    - 역전파: $O(n)$ (순전파와 동일한 복잡도)

    이것이 백프로파게이션의 핵심 장점입니다: **모든 가중치의 기울기를 효율적으로 한 번의 순전파와 역전파로 계산**할 수 있습니다.

## 6. 편향(Bias)과 분산(Variance)
- 출처:[Bias and Variance for Machine Learning ](https://www.youtube.com/watch?v=nbY2KqXSsaE&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=6)

이 두 가지는 데이터 과학에서 매우 중요한 개념으로, 과소적합(underfitting) 및 과대적합(overfitting)과 같은 핵심 개념의 기반이 되며, 이 문제들을 해결하는 방법을 제시합니다.

### 6.1   **편향(Bias)**:
*   **정의**: 모델이 특정 문제에 대해 가지고 있는 **선입견 또는 가정의 양**을 의미합니다.
*   **높은 편향(High Bias)**: 모델의 가정이 많을수록 편향이 높아집니다.
*   **과소적합(Underfitting)**: 높은 편향은 **과소적합**으로 이어집니다. 예를 들어, 선형 회귀(linear regression)는 데이터가 선형 분포를 가진다고 가정하기 때문에 편향이 높을 수 있으며, 비선형 데이터에서는 데이터를 제대로 학습하지 못하여 과소적합을 야기합니다.

### 6.2   **분산(Variance)**:
*   **정의**: 훈련 데이터에 대한 모델의 **민감도**를 나타냅니다. 훈련 데이터가 조금만 바뀌어도 모델의 출력이 크게 변한다면 분산이 높다고 할 수 있습니다.
*   **높은 분산(High Variance)**: 모델이 훈련 데이터에 매우 민감할 때 분산이 높습니다.
*   **과대적합(Overfitting)**: 높은 분산은 **과대적합**으로 이어집니다. 예를 들어, 제한을 두지 않은 의사결정 트리(decision tree)는 모든 훈련 데이터 포인트를 맞추기 위해 복잡하게 성장하므로 유연성이 높아 분산이 높습니다. 이러한 모델은 훈련 시에는 좋은 성능을 보이지만 실제 데이터에서는 제대로 작동하지 않습니다.

### 6.3   **편향-분산 트레이드오프(Bias-Variance Trade-off)**:
*   전통적인 머신러닝 알고리즘에서는 편향을 낮추려고 하면 분산이 높아지고, 분산을 낮추려고 하면 편향이 높아지는 상충 관계가 존재합니다. 목표는 과소적합도 과대적합도 아닌, 데이터에 적절히 맞는 균형을 찾는 것입니다.
*   최근 딥러닝의 발전으로 인해 편향만 낮추거나 분산만 낮출 수 있는 도구들이 생겨 이 트레이드오프에 대한 고민이 줄어들었습니다.

<div style="text-align: center;">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Bias_and_variance_contributing_to_total_error.svg/500px-Bias_and_variance_contributing_to_total_error.svg.png" style="background-color: white; padding: 10px;">
</div >

### 6.4 **높은 편향(과소적합)을 다루는 방법**:
*   **모델 더 오래 훈련시키기**: 모델이 수렴할 충분한 시간이 없었을 수 있으므로 훈련 시간을 늘려볼 수 있습니다.
*   **모델의 복잡성 증가**: 모델이 너무 단순하여 데이터에 대한 가정이 지나치게 많을 수 있으므로, 모델의 복잡도를 높입니다 (예: 의사결정 트리의 최대 깊이 증가).
*   **모델 아키텍처 변경**: 문제에 더 적합한 다른 모델 아키텍처를 시도합니다 (예: 이미지 분류에 심층 신경망 대신 컨볼루션 신경망 사용).

### 6.5   **높은 분산(과대적합)을 다루는 방법**:
*   **더 많은 데이터로 훈련**: 가능하다면 더 많은 훈련 데이터를 도입하면 과대적합을 줄일 수 있습니다. (항상 가능하거나 비용 효율적이지는 않을 수 있습니다).
*   **정규화(Regularization) 사용**: 모델의 복잡성 또는 유연성을 줄여 분산을 낮춥니다. 이는 높은 편향을 다룰 때와 반대되는 접근 방식입니다.
*   **다른 모델 아키텍처 시도**: 현재 사용하는 모델이 문제에 적합하지 않을 수 있으므로 다른 모델 아키텍처를 시도.

### 6.6   **딥러닝을 통한 최신 해결책**:
*   **과소적합(높은 편향)의 경우**: 모델의 복잡도를 높이면서 동시에 정규화를 적용하여 복잡도 증가로 인한 과대적합(높은 분산)을 방지할 수 있습니다.
*   **과대적합(높은 분산)의 경우**: 훈련 데이터를 더 많이 도입하면 모델의 편향을 높이지 않으며 분산을 낮출 수 있다.

## 7. 평가지표(evaluation metrics)
- 출처:[How to evaluate ML models ](https://www.youtube.com/watch?v=LbX4X71-TFI&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=7)

### 7.1 분류(Classification) 태스크를 위한 평가지표

*   **정확도(Accuracy)**
    *   **가장 널리 사용되는 지표**이며, 이해하기 쉽고 단일 숫자로 여러 모델을 비교하기 용이합니다.
    *   맞게 분류된 인스턴스 수를 전체 인스턴스 수로 나눈 값입니다.
    *   **단순하여 때로는 모델의 성능을 과하게 단순화**할 수 있어, 더 상세한 지표가 필요할 수 있습니다.

*   **정밀도(Precision)와 재현율(Recall)**
    *   주로 **이진 분류(binary classification)** 문제(예: 0 또는 1, 참 또는 거짓)에 사용되지만, 다른 분류 태스크에도 적용 가능합니다.
    *   **정밀도**: 모델이 긍정(positive)으로 예측한 모든 인스턴스 중에서 실제로 긍정인 인스턴스의 비율입니다. 즉, "모델이 긍정이라고 말한 것 중 실제로 긍정인 비율"을 나타냅니다.
    *   **재현율**: 실제로 긍정인 모든 인스턴스 중에서 모델이 긍정으로 올바르게 식별한 인스턴스의 비율입니다. 즉, "실제 긍정인 것들 중 모델이 얼마나 많이 포착했는지"를 나타냅니다.
    *   이 두 지표는 **모델에 대한 다른 관점**을 제공하므로, 대부분 함께 사용되며 모델의 문제점을 파악하고 개선하는 데 도움이 됩니다.
    *   **다중 클래스(multi-class) 분류**의 경우, 각 클래스에 대해 이 값을 계산한 후 평균을 내거나, 중요도에 따라 가중 평균을 낼 수 있습니다.

*   **F1 점수(F1 Score)**
    *   **정밀도와 재현율의 조합**으로, 하나의 숫자로 된 값을 제공합니다.
    *   정밀도와 재현율의 **조화 평균(harmonic mean)**으로 계산됩니다.
    *   **다른 지표(예: PR 곡선 또는 ROC 곡선)와 함께 사용하는 것이 가장 좋습니다**.

*   **PR 곡선(Precision-Recall Curve)**
    *   **정밀도와 재현율 간의 관계를 시각적으로 보여주는 그래프**입니다.
    *   **곡선이 그래프의 오른쪽 상단에 가까울수록 모델 성능이 우수**하다는 것을 의미합니다. 이는 높은 정밀도와 높은 재현율을 동시에 달성한다는 뜻입니다.

*   **ROC 곡선(Receiver Operating Characteristic Curve)**
    *   PR 곡선과 유사하게 **참 긍정률(True Positive Rate)과 거짓 긍정률(False Positive Rate)을 비교**하는 그래프입니다.

*   **AUC (Area Under the Curve)**
    *   PR 곡선이나 ROC 곡선 아래의 면적을 계산한 값입니다.
    *   **AUC 값이 높을수록 모델 성능이 우수함**을 나타냅니다.

*   **크로스 엔트로피(Cross Entropy)**
    *   두 확률 분포 간의 **차이 또는 거리를 계산**합니다.
    *   문제 유형에 따라 이진 크로스 엔트로피, 범주형 크로스 엔트로피, 희소 범주형 크로스 엔트로피 등 다양한 구현이 있습니다 (예: Keras 라이브러리).
    *   모델의 예측(확률 분포)과 실제 값(원-핫 인코딩된 분포 등) 간의 거리를 통해 모델의 정확성을 이해하는 데 중요합니다.

### 7.2 회귀(Regression) 태스크를 위한 평가지표

*   **평균 절대 오차(Mean Absolute Error, MAE)**
    *   **모든 예측 오류의 절대값 합계를 평균**한 것입니다.
    *   오차의 음수 값이 양수 값을 상쇄하여 오차가 작게 보이는 것을 방지하기 위해 절대값을 취합니다.

*   **평균 제곱 오차(Mean Squared Error, MSE)**
    *   **모든 예측 오류의 제곱을 평균**한 것입니다.
    *   오차를 제곱함으로써 **큰 오차 값에 더 큰 가중치를 부여**하여 모델 성능에 더 큰 영향을 미치도록 합니다.

*   **평균 제곱근 오차(Root Mean Squared Error, RMSE)**
    *   **MSE 값에 제곱근을 취한 것**입니다.
    *   큰 오차의 중요성을 강조하는 것은 MSE와 같지만, MAE와 같은 스케일로 값을 되돌려 **다른 지표와 비교하고 이해하기 쉽게 만듭니다**.

*   **R-제곱 (결정 계수, R-squared or Coefficient of Determination)**
    *   모델이 데이터에 **얼마나 잘 맞는지를 측정**하는 지표입니다.
    *   실제 값들이 모델이 도출한 곡선(예측선)에서 얼마나 차이 나는지를 나타냅니다.
    *   **0에서 1 사이의 값**을 가지며, 1은 모델이 데이터에 완벽하게 일치함을, 0은 모델이 데이터에 전혀 맞지 않음을 의미합니다.
    *   **값이 높을수록 모델의 적합도가 좋습니다**.

*   **코사인 유사도(Cosine Similarity)**
    *   크로스 엔트로피와 유사하지만 **회귀 문제(실수 값 처리)에 사용**됩니다.
    *   두 벡터(예측 값과 실제 값)가 얼마나 유사한지를 측정합니다.


## 8. 가중치(Weight) 초기화 
- 출처:[Weight Initialization for Deep Feedforward Neural Networks](https://www.youtube.com/watch?v=tYFO434Lpm0&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=8)


### 8.1   **문제점 및 필요성**
*   **불안정한 그래디언트(unstable gradients)**는 딥 뉴럴 네트워크의 주요 문제 중 하나입니다.
*   이 문제 해결을 위해 **올바른 초기화 기법**을 사용하는 것이 중요합니다.
*   네트워크 시작 시 매개변수(가중치 및 편향)를 초기화하는데, 편향(bias)은 대부분 0으로 설정하지만, **가중치를 0으로 초기화하면 네트워크가 무용지물이 될 수 있습니다** (선형 변환만 수행).

### 8.2   **초기 가중치 초기화 방식의 한계**
*   과거에는 평균을 0으로, 표준 편차를 1로 설정하여 가중치를 초기화하는 방식이 주로 사용되었습니다.
*   하지만 2010년 Joshua Bengio와 Xavier Glorot의 연구에 따르면, 이러한 초기화 방식이 **로지스틱 시그모이드(logistic sigmoid) 함수와 함께 사용될 때 불안정한 그래디언트 문제**를 야기할 수 있음을 발견했습니다. 이로 인해 새로운 가중치 초기화 기법들이 제안되었습니다.

### 8.3   **주요 가중치 초기화 기법**
이러한 새로운 기법들은 무작위 분포의 평균과 분산을 다르게 설정하여 구분됩니다.

1.  **Glorot (Xavier) Initialization**
    *   **평균(Mean)**: 0
    *   **분산(Variance)**: `1 / fan_average` (fan_average는 fan-in과 fan-out의 평균)
    *   `fan-in`: 해당 레이어로 들어오는 입력의 수
    *   `fan-out`: 해당 레이어의 출력 수 또는 뉴런의 수
    *   **가장 잘 작동하는 활성화 함수**: 선형(linear), tanh, 소프트맥스(softmax), 로지스틱(logistic) 활성화 함수
    *   Keras 딥러닝 라이브러리의 **기본 가중치 초기화 기법**입니다.

2.  **He Initialization**
    *   **평균(Mean)**: 0
    *   **분산(Variance)**: `2 / fan_in` (해당 레이어로 들어오는 입력의 수)
    *   **가장 잘 작동하는 활성화 함수**: ReLU 또는 ReLU의 변형 (예: ELU)
    *   특히 ELU 또는 다른 ReLU 계열 활성화 함수와 함께 사용하면 **불안정한 그래디언트 문제 해결에 큰 도움**이 됩니다.

3.  **LeCun Initialization**
    *   **평균(Mean)**: 0
    *   **분산(Variance)**: `1 / fan_in` (해당 레이어로 들어오는 입력의 수)
    *   **가장 잘 작동하는 활성화 함수**: SELU 활성화 함수

### 8.4   **결론**
*   가중치 초기화 기법은 매우 **직관적이며 사용하기 쉽습니다**.
*   Keras와 같은 딥러닝 라이브러리를 사용할 때는 **프로젝트에 적합한 가중치 초기화 기법을 선택하는 것이 중요**
*   적절한 가중치 초기화 기법을 사용하더라도 훈련 과정에서 **불안정한 그래디언트 문제에 직면할 수 있으며**, 이 경우 **배치 정규화(Batch Normalization)**와 같은 추가적인 기술이 필요할 수 있습니다.

## 9. 순환 신경망(RNN)
- 출처:[Recurrent Neural Networks (RNNs) ](https://www.youtube.com/watch?v=TLLqsEyt8NI&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=9)

### 9.1 **순환 신경망(RNN)이란?**
*   RNN은 딥러닝에서 중요한 부분이며, 특히 **자연어 처리 분야(텍스트 생성, 텍스트 분류 등)**에서 매우 효과적
*   이미지나 비디오 데이터 작업에도 사용될 수 있습니다.
*   RNN은 시퀀스 데이터를 처리하고, **이전 출력을 현재 입력으로 사용하며 은닉 상태(hidden states)를 갖는 특수한 종류의 신경망**입니다.
*   일반적인 신경망의 주요 단점은 이전 출력을 추적할 수 없다는 점인데, RNN은 이러한 문제를 해결하고자 합니다.

### 9.2 **RNN의 작동 방식**
*   RNN은 **루프(loops)**를 포함하여 정보가 지속될 수 있도록 합니다.
*   이 루프는 다양한 시간 단계(time steps)가 있는 시퀀스 데이터로 해석될 수 있습니다.
*   각 시간 단계에서 입력이 주어지고 은닉 계층에서 계산이 이루어지며 출력이 나옵니다. 이때 **이전 시간 단계의 은닉 상태 정보가 다음 시간 단계로 전달됩니다**.
*   따라서 마지막 시간 단계는 모든 이전 문맥에 대한 정보를 포함하게 됩니다.

<div style="text-align: center;">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/500px-Recurrent_neural_network_unfold.svg.png" style="background-color: white; padding: 20px;">
</div >


### 9.3 **RNN의 강력한 이유 및 유연성**
*   일반적인 신경망이나 컨볼루션 신경망은 이전 상태를 기억하지 못하고, 고정된 크기의 벡터를 입력으로 받고 고정된 크기의 벡터를 출력으로 생성하는 제한이 있습니다.
*   반면 RNN은 **시퀀스 데이터(벡터 시퀀스)**를 처리하며, 입력 시퀀스, 출력 시퀀스 또는 둘 다에서 작동할 수 있어 다양한 애플리케이션에 적용됩니다.
    *   **일대다(One-to-many) 관계**: 하나의 입력에서 여러 출력을 생성 (예: 음악 생성).
    *   **다대일(Many-to-one) 관계**: 여러 입력에서 하나의 출력을 생성 (예: 감성 분류).
    *   **다대다(Many-to-many) 관계**: 여러 입력에서 여러 출력을 생성 (예: 개체명 인식, 기계 번역).

### 9.4 **RNN의 학습 방법**
*   RNN은 다른 신경망과 마찬가지로 **역전파(backpropagation) 알고리즘**을 통해 학습합니다.
*   특히, **시간을 통한 역전파(backpropagation through time)** 방식을 사용하여 모든 시간 단계를 통해 전체 순방향 패스를 수행한 다음, 전체 시퀀스를 통해 역방향 패스를 수행하고 그래디언트를 계산합니다.

### 9.5 **RNN의 문제점 및 해결책**
*   RNN은 학습 과정에서 **소실 그래디언트(vanishing gradient) 또는 폭발 그래디언트(exploding gradient) 문제**가 발생할 수 있습니다.
    *   이는 계층을 통과해야 하는 거리가 길어질수록 곱셈식 그래디언트 계산이 많아지기 때문입니다.
    *   이로 인해 정보가 손실되거나 **장기 의존성(long-term dependencies)을 포착하기 어려워집니다**.
    *   즉, 시간 단계가 많을수록 더 과거의 시간 단계에서 온 정보를 유지하기가 더 어려워집니다.
*   이러한 문제를 해결하기 위한 특별한 RNN 변형이 존재합니다.
    *   **LSTM(Long Short-Term Memory)**
    <div style="text-align: center;">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/500px-Long_Short-Term_Memory.svg.png" style="background-color: white; padding: 20px;">
    </div >
    *   **GRU(Gated Recurrent Units)**
    <div style="text-align: center;">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Gated_Recurrent_Unit.svg/500px-Gated_Recurrent_Unit.svg.png" style="background-color: white; padding: 20px;">
    </div >
    *   이들은 **게이트(gates)라는 메커니즘**을 사용하여 장기 의존성을 학습할 수 있으며, 종종 단순 RNN보다 뛰어난 성능을 보입니다.
    *   다만, 이들은 계산 비용이 훨씬 더 비쌀 수 있으므로 경우에 따라서는 단순 RNN으로도 충분할 수 있습니다.

### 9.6 **코드에서의 RNN 사용**
*   PyTorch와 TensorFlow 같은 딥러닝 프레임워크는 RNN, LSTM, GRU 레이어를 쉽게 사용할 수 있도록 지원합니다.
*   PyTorch에서는 `torch.nn` 모듈에서 해당 레이어를 찾을 수 있으며, 순방향(forward) 패스에서 은닉 상태를 입력해야 합니다.

```python
import torch
import torch.nn as nn

# 하이퍼파라미터
input_size = 10   # 입력 차원
hidden_size = 20  # 은닉 상태 차원
sequence_len = 5  # 시퀀스 길이
batch_size = 3    # 배치 크기

# RNN/LSTM/GRU 레이어 생성 (선택)
rnn = nn.RNN(input_size, hidden_size, batch_first=True)
lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
gru = nn.GRU(input_size, hidden_size, batch_first=True)

# 임의의 입력 데이터 생성
inputs = torch.randn(batch_size, sequence_len, input_size)

# 순방향 전파 (RNN)
hidden_rnn = torch.zeros(1, batch_size, hidden_size)  # 초기 은닉 상태
output_rnn, hidden_rnn = rnn(inputs, hidden_rnn)

# 순방향 전파 (LSTM)
hidden_lstm = (torch.zeros(1, batch_size, hidden_size),
               torch.zeros(1, batch_size, hidden_size))
output_lstm, hidden_lstm = lstm(inputs, hidden_lstm)

# 순방향 전파 (GRU)
hidden_gru = torch.zeros(1, batch_size, hidden_size)
output_gru, hidden_gru = gru(inputs, hidden_gru)

print("RNN 출력 크기:", output_rnn.shape)  # (batch, sequence, hidden)
```

*   TensorFlow에서는 `SimpleRNN`, `LSTM`, `GRU` 레이어를 `sequential` 모델 등에 포함하여 사용할 수 있습니다.

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU

# 하이퍼파라미터
input_size = 10   # 입력 차원
hidden_size = 20  # 은닉 상태 차원
sequence_len = 5  # 시퀀스 길이
batch_size = 3    # 배치 크기

# 모델 생성 (선택)
model = Sequential([
    # SimpleRNN
    SimpleRNN(hidden_size, return_sequences=True, input_shape=(sequence_len, input_size)),
    
    # LSTM
    # LSTM(hidden_size, return_sequences=True),
    
    # GRU
    # GRU(hidden_size, return_sequences=True)
])

# 임의의 입력 데이터 생성
inputs = tf.random.normal((batch_size, sequence_len, input_size))

# 순방향 전파
outputs = model(inputs)
print("출력 크기:", outputs.shape)  # (batch, sequence, hidden)
```

## 10. 계층 정규화(Layer Normalization)
- 출처:[What is Layer Normalization? ](https://www.youtube.com/watch?v=2V3Uduw1zwQ&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=10)

### 10.1    **배치 정규화의 문제점**:
*   **다양한 길이의 시퀀스 데이터에 사용하기 어렵습니다**. 이는 시퀀스 데이터, 특히 순환 신경망(RNN)에서 문제.
*   **작은 배치 크기(batch size)에서는 제대로 작동하지 않습니다**. 배치 정규화는 배치 내에서 평균과 표준 편차를 계산하기 때문에, 배치가 너무 작으면 전체 데이터셋을 대표하는 값을 얻기 어렵습니다.
*   **병렬화(parallelization)가 곤란**. 배치 간의 의존성 때문에 여러 컴퓨터 간에 추가적인 통신과 동기화가 필요.
*   이러한 문제들은 배치 정규화가 배치에 의존하기 때문에 발생합니다.

### 10.2   **계층 정규화(Layer Normalization)란?**:
*   **배치에 대한 의존성을 제거**하고 대신 **계층(layer)을 기반으로 정규화를 계산**합니다.
*   핵심은 **각 데이터 샘플에 대해, 동일한 계층 내의 모든 뉴런의 입력값을 정규화**하는 것입니다.
*   따라서 계층 정규화에서는 **동일한 계층의 모든 뉴런이 동일한 정규화 항(평균 및 분산)을 가집니다**.

### 10.3   **계산 방식의 차이**:
*   **배치 정규화**: 이전 계층의 출력값을 **동일한 배치 내의 여러 데이터 포인트에 걸쳐(수평으로)** 계산하여 정규화합니다. 즉, 동일한 뉴런에 해당하는 여러 배치의 값을 사용하여 평균과 분산을 계산합니다.
*   **계층 정규화**: 이전 계층의 출력값을 **단일 데이터 포인트 내의 여러 뉴런에 걸쳐(수직으로)** 계산하여 정규화합니다. 배치 크기에 관계없이 **데이터 포인트당 값들을 정규화**합니다.

### 10.4   **계층 정규화의 장점**:
*   **배치 크기에 의존하지 않습니다**: 배치 크기가 얼마나 크든 작든 상관없이 데이터 포인트별로 값을 정규화합니다. 원하는 배치 크기를 자유롭게 선택할 수 있습니다.
*   **훈련 시간(training time)과 테스트 시간(test time)의 계산이 동일합니다**: 배치에 의존하지 않으므로, 배치 정규화와 달리 훈련 시와 테스트 시의 계산 방식에 차이가 없습니다.
*   **순환 신경망(RNN)에 더 적합합니다**: 시퀀스의 길이가 다양해도 처리할 수 있으며, 배치 대신 계층(또는 RNN 용어로는 타임스텝)을 기반으로 계산하기 때문입니다.
*   **병렬화가 용이합니다**: 각 뉴런이 자체 계산을 수행하므로, 추가적인 통신이나 동기화가 필요 없습니다.

### 10.5   **계층 정규화의 단점**:
*   **합성곱 신경망(CNN)에서는 항상 잘 작동하지는 않습니다**. CNN 아키텍처를 사용하는 경우 배치 정규화를 선택하는 것이 더 나을 수 있습니다.

## 11. 신경망의 하이퍼파라미터 설정
- 출처:[Neural Networks Summary: All hyperparameters](https://www.youtube.com/watch?v=h291CuASDno&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=11)

### 11.1 주요 하이퍼파라미터

![ALL Hyperparameters](/assets/images/all_hyperparameters.png)

1.   **입력 계층의 뉴런 수 (Number of neurons in the input layer)**:
*   이 값은 **데이터셋의 특징(feature) 수에 따라 결정**됩니다.
*   예를 들어, 데이터에 10개의 특징이 있다면 입력 계층에 10개의 뉴런이 필요합니다. 20x20 픽셀 이미지의 경우, 플래튼(flatten)하여 400개의 입력 뉴런이 필요할 수 있습니다.
*   Keras에서는 `InputShape`를 설정하고 `Flatten` 레이어를 사용하여 입력 뉴런 수를 지정할 수 있습니다.

2.  **출력 계층의 뉴런 수 (Number of neurons in the output layer)**:
*   이 역시 **문제의 종류에 따라 달라집니다**.
*   **이진 분류(binary classification)** 문제의 경우 1개의 출력 뉴런을 사용할 수 있으며, 0에 가까우면 한 클래스, 1에 가까우면 다른 클래스로 분류합니다.
*   **다중 분류(multi-class classification)** 문제에서 4개의 클래스를 분류한다면 4개의 뉴런을 사용하는 것이 일반적입니다.
*   **회귀(regression)** 문제의 경우 보통 1개의 출력 뉴런이면 충분합니다.
*   Keras에서는 `Dense` 레이어를 사용하여 출력 뉴런 수를 설정할 수 있습니다.

3.   **은닉 계층의 수 및 은닉 계층 내 뉴런 수 (Number of hidden layers and neurons in hidden layers)**:
*   이 하이퍼파라미터는 데이터에 따라 결정되지 않고, **해결하려는 문제의 복잡성에 따라 달라집니다**.
*   문제가 복잡할수록 네트워크를 더 깊게(더 많은 계층) 만들거나 은닉 계층의 뉴런 수를 늘릴 수 있습니다.
*   일반적인 경험 법칙(rule of thumb)은 **모델이 과소적합(underfitting)인 경우 뉴런 수를 늘리기 전에 계층 수를 먼저 늘리는 것**이 더 좋습니다.
*   Keras에서 은닉 계층은 `Dense` 레이어 형태로 입력 및 출력 계층 사이에 추가됩니다.

4.  **활성화 함수 (Activation function)**:
*   활성화 함수는 **네트워크의 각 계층마다 다르게 설정**할 수 있습니다.
*   **은닉 계층**에는 선형 활성화 함수를 사용할 수 없습니다. 선형 활성화 함수를 사용하면 신경망이 단순히 입력의 선형 변환이 되어 복잡한 패턴을 학습할 수 없기 때문입니다. `softmax`, `sigmoid`, `relu`, `hyperbolic tangent`와 같은 비선형 함수가 주로 사용됩니다.
*   **출력 계층**에서는 문제의 종류에 따라 선형 활성화 함수를 사용할 수도 있습니다. 예를 들어, 회귀 문제의 경우 선형 활성화 함수를 사용하여 원시 숫자(raw number)를 출력할 수 있습니다. 분류 문제의 출력 계층에서는 `softmax` 함수를 사용할 수 있습니다.
*   Keras에서는 `Dense` 레이어에 `activation` 파라미터를 설정하여 활성화 함수를 지정합니다.

5.   **가중치 초기화 기법 (Weight initialization technique)**:
*   신경망 훈련 전에 파라미터(가중치와 편향)를 설정해야 합니다.
*   편향(biases)은 대부분 0으로 설정되지만, **가중치(weights)는 0으로 설정할 수 없습니다**. 모든 가중치가 0으로 초기화되면 모든 가중치가 동일한 방식으로 업데이트되어 원하는 복잡성을 달성할 수 없습니다.
*   다양한 가중치 초기화 기법이 있으며, Keras에서는 `kernel_initializer` 파라미터를 사용하여 설정할 수 있습니다. 활성화 함수에 따라 적절한 초기화 기법을 선택해야 합니다.

6.  **정규화 (Regularization)**:
*   정규화는 **네트워크가 과적합(overfitting)되는 것을 방지**하기 위해 사용되는 기법입니다.
*   다양한 정규화 기법이 있으며, 각각 내부에 `alpha` 또는 `dropout rate`와 같은 자체 하이퍼파라미터를 가질 수 있습니다.
*   **L1 및 L2 정규화**: Keras에서는 `kernel_regularizer` 파라미터를 통해 `l1` 또는 `l2`를 지정하거나, `keras.regularizers.l2` 함수를 호출하여 `alpha` 파라미터를 설정할 수 있습니다. L1과 L2를 함께 사용할 수도 있습니다.
*   **드롭아웃 정규화 (Dropout regularization)**: 이는 새로운 계층(`Dropout` 레이어)을 추가하여 구현되며, 드롭아웃이 발생할 `rate`를 지정합니다.

7.  **손실 함수 (Loss function)**:
*   **문제의 종류에 따라 결정**됩니다.
*   예를 들어, 두 개 이상의 다른 레이블을 분류하는 문제에는 `sparse categorical cross entropy`와 같은 손실 함수가 사용될 수 있습니다.
*   Keras에서는 모델 컴파일(`compile`) 함수 안에 `loss` 파라미터를 설정하여 손실 함수를 지정합니다. Keras 문서에서 다양한 옵션을 확인할 수 있습니다.

8.  **최적화 알고리즘 및 학습률 (Optimization algorithm and learning rate)**:
*   **최적화 알고리즘**은 네트워크의 가중치를 업데이트하여 다음 훈련 라운드에서 더 나은 성능을 달성하는 방법을 결정합니다.
*   가장 일반적으로 사용되는 최적화 알고리즘은 **확률적 경사 하강법(Stochastic Gradient Descent, SGD)**이며, 이는 Keras의 기본값입니다. `Adam`과 같은 다른 알고리즘도 있습니다.
*   Keras에서는 `compile` 함수 내의 `optimizer` 파라미터를 통해 최적화 알고리즘을 문자열 이름으로 지정하거나 (`'sgd'`), Keras 함수 (`keras.optimizers.Adam()`)를 호출하여 지정할 수 있습니다.
*   **학습률(Learning rate)**은 최적화 알고리즘이 가중치를 업데이트하는 강도를 결정합니다. 최적화 알고리즘을 Keras 함수로 호출할 때 학습률을 지정할 수 있습니다. 학습률 스케줄링과 같은 더 복잡한 방법도 있습니다.

9.  **배치 크기 (Batch size)**:
*   **데이터셋을 나누는 하위 그룹의 크기**를 나타냅니다.
*   신경망은 한 번에 하나의 배치(예: 250개의 데이터 포인트)를 통해 실행되고, 출력을 계산하고, 오차를 계산한 다음, 최적화 알고리즘과 학습률을 사용하여 가중치를 업데이트합니다. 이 과정은 다음 배치에 대해서도 반복됩니다.
*   일반적으로 **작은 배치 크기(2~64)가 더 나은 결과를 생성**하는 경향이 있습니다. 컴퓨터의 이진 특성 때문에 2의 배수로 배치 크기를 설정하는 경우가 많습니다.
*   Keras의 `fit` 함수 내에서 `batch_size` 파라미터를 설정합니다.

10.  **에포크 (Epochs / Number of iterations)**:
*   **전체 데이터셋을 신경망에 한 번 통과시키는 것**을 의미합니다.
*   예를 들어, 1000개의 데이터 포인트가 있고 배치 크기가 250이라면, 4개의 배치를 모두 처리하는 것이 1 에포크를 완료한 것입니다.
*   네트워크가 과소적합인 경우 에포크 수를 늘릴 수 있습니다.
*   Keras의 `fit` 함수 내에서 `epochs` 파라미터를 설정합니다.

11.  **검증 데이터 (Validation data)**:
*   하이퍼파라미터는 아니지만, 훈련 과정에서 **`validation_data`를 `fit` 함수에 포함**하여 모델의 성능을 평가하는 것이 중요합니다.

이러한 하이퍼파라미터 중 일부는 데이터에 따라 결정되고, 일부는 문제의 복잡성에 따라 달라지며, 일부는 다른 하이퍼파라미터 설정에 영향을 줄 수 있는 **상호 의존성을 가질 수 있다**.또한, 배치 크기나 에포크 수와 같은 일부 하이퍼파라미터는 **시행착오(trial-and-error)**를 통해 최적값을 찾아야 한다.
