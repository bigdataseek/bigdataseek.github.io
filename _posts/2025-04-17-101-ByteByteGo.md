---
title: 32차시 1:ByteByteGo
layout: single
classes: wide
categories:
  - ByteByteGo
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. ByteByteGo 시스템 디자인 비디오 시리즈 요약 (1화: HTTP)
- 출처: [What happens when you type a URL into your browser?](https://www.youtube.com/watch?v=AlkDbnbv7dk)

### **1.1 URL (Uniform Resource Locator) 구성 요소:**

*   **Scheme:** 프로토콜 (예: `http://`, `https://`)
    *   `http://`: 일반 HTTP 프로토콜 사용. 데이터가 암호화되지 않아 보안에 취약할 수 있음.
    *   `https://`: 암호화된 연결 사용. SSL/TLS를 통해 데이터가 암호화되며, 보안과 신뢰성을 제공.
*   **Domain:** 도메인 이름 (예: `example.com`)
    *   사람이 읽기 쉬운 주소로, IP 주소를 대신하여 사용. DNS를 통해 IP 주소로 변환됨.
*   **Path:** 서버 상의 디렉토리 (파일 시스템의 디렉토리와 유사)
    *   서버에서 특정 리소스나 페이지를 찾기 위한 경로를 지정.
*   **Resource:** 서버 상의 파일 (파일 시스템의 파일과 유사)
    *   Path와 Resource는 함께 서버에서 로드할 리소스를 지정. 예를 들어, `/images/logo.png`는 `images` 디렉토리 내의 `logo.png` 파일을 가리킴.

### **1.2 URL 입력 후 발생하는 과정:**

1.  **DNS Lookup:**
    *   도메인 이름을 IP 주소로 변환 (DNS 서버를 통해)
    *   캐싱을 통해 속도 향상
        *   브라우저 캐시 -> 운영체제 캐시 -> DNS 리졸버 순으로 확인
        *   DNS 인프라의 여러 서버에서 캐싱 발생
        *   캐싱이 실패할 경우, 루트 DNS 서버부터 순차적으로 쿼리가 진행됨.
2.  **TCP 연결:**
    *   IP 주소를 사용하여 서버와 TCP 연결 설정 (핸드셰이크 과정 포함)
        *   3-way 핸드셰이크: 클라이언트가 SYN 패킷을 보내고, 서버가 SYN-ACK로 응답한 뒤, 클라이언트가 ACK를 보내 연결이 성립.
    *   `Keep-alive` 연결을 사용하여 기존 연결 재사용
        *   여러 요청을 동일한 연결에서 처리하여 성능 최적화.
    *   HTTPS인 경우, SSL/TLS 핸드셰이크를 통해 암호화된 연결 설정
        *   핸드셰이크 과정에서 인증서 교환 및 대칭키 설정.
        *   비용이 많이 들고 SSL session resumption 등의 방법으로 비용을 줄임.
3.  **HTTP 요청 및 응답:**
    *   브라우저가 HTTP 요청을 서버로 전송
        *   요청에는 메서드(GET, POST 등), 헤더, URL 등이 포함됨.
    *   서버는 요청을 처리하고 HTTP 응답을 반환
        *   응답에는 상태 코드(예: 200 OK, 404 Not Found), 헤더, 본문(Content)이 포함됨.
    *   브라우저는 응답을 받아 HTML 콘텐츠 렌더링
        *   DOM(Document Object Model)을 생성하고, CSS와 JavaScript를 적용하여 페이지를 표시.
4.  **추가 리소스 로드:**
    *   JavaScript, 이미지 등 추가 리소스 로드를 위해 DNS Lookup, TCP 연결, HTTP 요청 과정을 반복
        *   브라우저는 병렬 요청을 통해 리소스 로드 속도를 최적화.
        *   HTTP/2를 사용하는 경우, 하나의 연결에서 다중 스트림으로 리소스를 전송하여 성능을 더욱 향상.

## 2. Kafka가 빠른 이유?
- 출처: [System Design: Why is Kafka fast?](https://www.youtube.com/watch?v=UNUz1-msbOM)

### 2.1 Kafka 성능
- **Kafka가 '빠르다'는 것은 높은 처리량(throughput)을 의미하며, 짧은 시간에 많은 양의 데이터를 효율적으로 이동시키는 데 최적화되어 있습니다.** 
- 이는 대규모 데이터 스트리밍 환경에서 실시간 처리가 요구되는 상황에서 특히 유용하며, 데이터의 신속한 전달과 안정적인 처리 성능을 제공합니다.

### 2.2 **Kafka 성능의 핵심적인 두 가지 설계 결정**

1.  **순차적 I/O (Sequential I/O) 활용:**

    *   하드 드라이브의 순차적 접근은 임의 접근보다 훨씬 빠릅니다. 
        - 이는 디스크 헤드가 물리적으로 이동하는 시간을 줄여 데이터 읽기/쓰기 속도를 극대화
    *   Kafka는 **append-only log** 방식을 사용하여 데이터를 순차적으로 기록하여, 빠른 쓰기 속도를 유지 
        - 이 방식은 데이터가 추가될 때 기존 데이터를 수정하지 않고 단순히 뒤에 덧붙이는 구조로, 데이터 무결성을 유지하면서 성능을 최적화합니다.
    *   하드 디스크의 가격 대비 용량 이점을 활용하여 장기간 메시지 보관 비용을 절감합니다. 
        - 이는 대규모 데이터 저장소를 필요로 하는 환경에서 비용 효율성을 극대화하는 데 중요한 역할
    *   또한, 순차적 I/O는 SSD와 같은 고속 스토리지에서도 성능 향상을 제공
        - Kafka의 설계는 이러한 하드웨어 발전에도 적응할 수 있도록 유연성을 갖추고 있습니다.

2.  **Zero Copy 원칙 적용:**

    *   데이터를 디스크와 네트워크 간에 이동시킬 때 불필요한 복사를 최소화하여 효율성을 높입니다. 
        - 이는 데이터 처리 과정에서 발생하는 오버헤드를 줄이고, 시스템 자원을 더 효율적으로 활용
    *   `sendfile()` 시스템 호출을 통해 OS 캐시의 데이터를 네트워크 인터페이스 카드(NIC) 버퍼로 직접 복사합니다. 
        - 이 과정은 데이터가 애플리케이션 메모리를 거치지 않으므로, 메모리 사용량을 줄이고 처리 속도를 높이는 데 기여합니다.
    *   CPU 개입 없이 DMA(Direct Memory Access)를 사용하여 복사 작업을 더욱 효율적으로 처리
        - 이는 CPU가 다른 작업을 수행할 수 있도록 여유를 제공하며, 전체 시스템 성능을 향상시킵니다.
    *   Zero Copy는 특히 대규모 데이터 전송이 빈번히 발생하는 환경에서 네트워크 대역폭을 최적화하고, 데이터 전송 지연(latency)을 최소화하는 데 중요한 역할을 합니다.


## 3. 안전하게 비밀번호를 데이터베이스에 저장하는 방법
- 출처: [System Design: How to store passwords in the database?](https://www.youtube.com/watch?v=zt8Cocdy15c)

### 3.1 **하지 말아야 할 것**

*   **비밀번호를 일반 텍스트로 저장하지 마세요.**  
    - 일반 텍스트로 저장된 비밀번호는 데이터베이스 접근 권한을 가진 누구나 읽을 수 있으며, 이는 내부자 위협뿐만 아니라 외부 해킹 사고에서도 심각한 보안 문제를 야기합니다. 
    - 데이터베이스가 해킹당할 경우 모든 사용자의 비밀번호가 그대로 노출되어 추가적인 피해(예: 다른 웹사이트에서 동일한 비밀번호 재사용)로 이어질 수 있습니다.

### 3.2 **해야 할 것 (OWASP 권장 사항)**

1.  **최신 해싱 알고리즘 사용:**  
    *   **해싱은 단방향 함수이므로 해시된 값을 복호화하여 원래 값을 얻을 수 없습니다.**  
        - 해싱은 비밀번호를 암호화된 형태로 변환하는 과정으로, 복호화가 불가능하기 때문에 해커가 해시 값을 획득하더라도 원래 비밀번호를 알 수 없습니다.  
    *   **비밀번호 보안을 위해 설계된 "느린" 함수를 사용합니다.**  
        - 느린 해싱 알고리즘(예: bcrypt, Argon2, PBKDF2)은 의도적으로 많은 연산 리소스를 소모하도록 설계되어 무차별 대입 공격(Brute-force attack)이나 레인보우 테이블 공격을 효과적으로 방어합니다. 
        - 이는 공격자가 가능한 모든 비밀번호 조합을 시도하는 데 걸리는 시간을 크게 증가시킵니다.  
    *   **MD5, SHA-1과 같은 레거시 해싱 함수는 보안에 취약하므로 사용하지 마세요.**  
        - MD5와 SHA-1은 초기에는 널리 사용되었지만, 현재는 다양한 공격 기법(예: 충돌 공격)에 취약하다는 것이 입증되었습니다. 
        - 이러한 알고리즘은 해시 계산 속도가 매우 빠르기 때문에 무차별 대입 공격에 적합한 환경을 제공

2.  **솔트(Salt) 사용:**  
    *   **솔트는 각 비밀번호에 추가되는 고유한 임의 문자열입니다.**  
        - 솔트는 비밀번호마다 고유하게 생성되며, 이를 통해 동일한 비밀번호라도 서로 다른 해시 값을 생성할 수 있습니다. 
        - 이는 여러 사용자가 동일한 비밀번호를 사용하더라도 데이터베이스 상에서 중복된 해시 값이 나타나지 않도록 합니다.  
    *   **솔트를 사용하면 사전 연산 공격(레인보우 테이블, 데이터베이스 기반 조회 등)을 방어할 수 있습니다.**  
        - 레인보우 테이블은 미리 계산된 해시 값을 이용해 비밀번호를 빠르게 추측하는 공격 기법입니다. 
        - 솔트를 사용하면 이러한 사전 연산 공격이 효과를 발휘하지 못하게 됩니다.  
    *   **솔트는 비밀이 아니며, 일반 텍스트로 데이터베이스에 안전하게 저장할 수 있습니다.**  
        - 솔트는 비밀번호 자체를 보호하기 위한 보조 도구이므로, 솔트 자체가 유출되었다고 해서 보안에 큰 문제가 되지 않습니다. 
        - 중요한 것은 솔트와 비밀번호를 결합한 후 해싱된 결과입니다.

### 3.3 **비밀번호 저장 과정**

1.  **사용자가 제공한 비밀번호와 임의로 생성된 솔트를 결합합니다.**  
    - 솔트는 난수 생성기를 통해 고유하게 만들어지며, 이를 비밀번호 앞 또는 뒤에 추가합니다. 
    - 예를 들어, 비밀번호가 `password123`이고 솔트가 `abc123`이라면 결합된 문자열은 `password123abc123`이 될 수 있습니다.  
2.  **결합된 문자열을 해싱 함수를 사용하여 해시합니다.**  
    - 결합된 문자열을 bcrypt, Argon2, PBKDF2와 같은 최신 해싱 알고리즘으로 처리하여 고정 길이의 해시 값을 생성합니다.  
3.  **해시된 값과 솔트를 데이터베이스에 저장합니다.**  
    - 데이터베이스에는 해시된 값과 해당 솔트를 함께 저장합니다. 
    - 솔트는 해시 값과 분리되지 않으며, 검증 과정에서 필요합니다.

### 3.4 **비밀번호 검증 과정**

1.  **데이터베이스에서 해당 사용자의 솔트를 가져옵니다.**  
    - 로그인 요청 시 입력된 사용자 이름으로 데이터베이스를 조회하여 저장된 솔트를 가져옵니다.  
2.  **사용자가 입력한 비밀번호에 솔트를 추가하여 해시합니다.**  
    - 사용자가 입력한 비밀번호와 데이터베이스에서 가져온 솔트를 결합한 후, 저장 시 사용된 동일한 해싱 알고리즘으로 해시를 계산합니다.  
3.  **계산된 해시 값을 데이터베이스에 저장된 해시 값과 비교합니다.**  
    - 두 해시 값을 비교하여 일치 여부를 확인합니다. 이때, 해시 값은 고정 길이의 문자열이므로 직접 비교가 가능합니다.  
4.  **두 해시 값이 같으면 비밀번호가 유효한 것으로 간주합니다.**  
    - 만약 두 해시 값이 일치한다면, 사용자가 입력한 비밀번호가 올바른 것으로 판단됩니다. 그렇지 않다면 인증 실패로 처리됩니다.


### 3.5 **추가 고려사항**
*   **워크 팩터(Work Factor) 설정:**  
    - 느린 해싱 알고리즘에서는 연산 횟수를 제어하는 매개변수(예: bcrypt의 cost factor, Argon2의 메모리/시간 파라미터)를 조정할 수 있습니다. 
    - 이 값은 하드웨어 성능에 따라 적절히 설정해야 하며, 너무 낮으면 보안이 약화되고 너무 높으면 성능 문제가 발생할 수 있습니다.  
*   **정기적인 알고리즘 업데이트:**  
    - 암호학적 알고리즘은 시간이 지남에 따라 취약점이 발견될 수 있으므로, 최신 표준 및 권장 사항을 주기적으로 검토하고 적용해야 합니다.  
*   **멀티팩터 인증(MFA) 도입:**  
    - 비밀번호만으로 인증을 수행하는 방식은 한계가 있을 수 있으므로, 추가적인 인증 요소(예: OTP, 생체 인식)를 도입하여 보안을 강화하는 것이 좋습니다.

## 4. 베어 메탈, 가상 머신 및 컨테이너에 대한 큰 오해
- 출처: [Big Misconceptions about Bare Metal, Virtual Machines, and Containers](https://www.youtube.com/watch?v=Jz8Gs4UHTO8)

### 4.1 Bare Metal, 가상 머신 (VM), 컨테이너 비교

| 특징 | Bare Metal | 가상 머신 (VM) | 컨테이너 |
|---|---|---|---|
| **정의** | 단독 사용자에게 제공되는 물리적 서버 | 물리적 컴퓨터의 에뮬레이션 | 애플리케이션과 그 의존성을 패키징한 경량화된 형태 |
| **자원 관리** | 완전한 하드웨어 및 소프트웨어 스택 제어 | 하이퍼바이저를 통해 하드웨어 자원 추상화 및 공유 | 컨테이너 엔진을 통해 OS 레벨에서 자원 격리 및 공유 |
| **성능** | 최고 성능 요구 애플리케이션에 적합 | 준수한 성능, 다양한 크기 선택 가능 | 가볍고 빠른 시작 속도 |
| **보안** | 물리적 격리로 최고 수준의 보안 제공 (사이드 채널 공격 방어) | 노이즈 이웃 문제 및 프로세서 설계 결함 공격에 취약 | OS 레벨 취약점에 노출될 가능성 높음 |
| **확장성** | 확장 및 관리가 어려움 | 비교적 쉬운 확장 및 유연성 | 높은 확장성 및 이식성 |
| **비용** | 가장 비쌈 | 중간 | 가장 저렴 |
| **장점** | - 최고 성능  - 높은 보안 및 격리  - 엄격한 규정 준수 | - 비용 효율성  - 유연한 확장성  - 자원 활용도 증가 | - 빠른 배포 및 유지 관리  - 높은 확장성 및 이식성  - 적은 자원 소비 |
| **단점** | - 높은 비용  - 어려운 관리  - 느린 확장 | - 노이즈 이웃 문제  - 보안 취약점 | - OS 레벨 보안 취약점  - 잠재적으로 낮은 보안 |
| **적합 대상** | - 최고 성능 요구 애플리케이션  - 높은 보안 요구 애플리케이션  - 엄격한 규정 준수 필요 | - 일반적인 워크로드  - 유연한 확장성 필요 | - 빠른 배포 및 확장 요구  - 마이크로서비스 아키텍처 |
| **기타** | 물리적 서버 직접 관리 필요 | 하이퍼바이저 (가상 머신 모니터) 필요 | 컨테이너 엔진 필요 |


### 4.2 **적합 대상**
- Bare Metal:고성능 데이터베이스, 금융 서비스, 의료 시스템 등 엄격한 보안과 성능이 요구되는 환경

- 가상 머신 (VM): 일반적인 워크로드와 유연한 확장성이 필요한 환경(예: 클라우드 인프라)

- 컨테이너: 마이크로서비스 아키텍처, CI/CD 파이프라인, 빠른 배포 및 확장이 필요한 환경

FAANG System Design Interview: Design A Location Based Service (Yelp, Google Places)

## 5. 근접 서비스 시스템 설계
- 출처: [FAANG System Design Interview: Design A Location Based Service (Yelp, Google Places)](https://www.youtube.com/watch?v=M4lR_Va97cQ)

### **5.1 소개**

* Yelp, Google 지도와 같이 사용자의 현재 위치를 기반으로 주변의 식당, 주유소 등 다양한 장소를 검색하여 정보를 제공하는 애플리케이션의 핵심 백엔드 시스템인 근접 서비스 시스템 설계를 다룹니다. 이 시스템은 사용자에게 편리하고 정확한 주변 정보 검색 기능을 제공하는 것을 목표로 합니다.

### **5.2 문제 정의 및 설계 범위**

* **목표:** 사용자가 입력한 현재 위치와 지정한 검색 반경을 기준으로 주변에 위치한 사업체 목록을 효율적으로 검색하고 제공하는 기능을 구현합니다. 이를 통해 사용자는 주변의 관심 있는 장소를 쉽게 찾을 수 있다.
* **기능 요구사항:**
    * 사용자의 현재 위도, 경도 정보와 원하는 검색 반경을 입력받아, 해당 반경 내에 위치한 사업체 목록을 반환합니다.
    * 사업체 소유자는 시스템을 통해 자신의 사업체 정보를 추가, 삭제, 수정할 수 있어야 합니다. 다만, 이러한 변경 사항은 실시간으로 사용자 검색 결과에 반영되지 않아도 무방합니다.
    * 사용자는 검색된 사업체 목록에서 특정 사업체를 선택하여 상세 정보를 조회할 수 있어야 합니다. 여기에는 사업체명, 주소, 연락처, 영업시간, 리뷰 등의 정보가 포함될 수 있습니다.
* **비기능 요구사항:**
    * 일일 활성 사용자 수(DAU) 1억 명, 전체 사업체 수 2억 개를 수용할 수 있는 규모를 가정합니다. 이는 시스템의 확장성과 성능을 고려하는 중요한 기준이 됩니다.
    * 사용자 검색 요청에 대한 응답 시간(지연 시간)은 최소화하여 사용자 경험을 향상시켜야 합니다. 일반적으로 수백 밀리초 이내의 응답 시간을 목표로 합니다.
    * 예상치 못한 트래픽 급증 상황에서도 시스템이 안정적으로 서비스를 제공할 수 있도록 높은 가용성을 확보해야 합니다. 이를 위해 시스템의 다중화 및 장애 격리 전략이 필요합니다.

### **5.3 규모 추정**

* 일반적으로 활성 사용자 한 명당 하루 평균 5회의 주변 검색 쿼리가 발생할 것으로 예측합니다. 이는 사용자들의 서비스 이용 패턴을 기반으로 한 추정치입니다.
* 따라서, 전체 시스템에서 발생하는 초당 검색 쿼리 수(QPS)는 다음과 같이 계산됩니다.
    $$\frac{100,000,000 \text{ 명} \times 5 \text{ 회/일}}{24 \text{ 시간/일} \times 3600 \text{ 초/시간}} \approx 5787 \text{ QPS}$$
    약 5,000 QPS의 검색 트래픽을 처리할 수 있도록 시스템을 설계해야 합니다.
* 사업체 데이터 저장 용량은 데이터 스키마에 따라 크게 달라질 수 있습니다. 각 사업체가 가지는 정보의 양과 종류에 따라 필요한 저장 공간이 결정됩니다. 상세한 데이터 스키마 설계 후 정확한 저장 용량을 추정할 수 있습니다.

### **5.4 고수준 설계**

* **API 설계:**
    * 표준화되고 이해하기 쉬운 RESTful API를 사용하여 클라이언트(앱)와 서버 간의 통신을 구현합니다.
    * **검색 API (GET /businesses):** 
        - 사용자의 현재 위도(`latitude`), 경도(`longitude`), 그리고 검색 반경(`radius`)을 쿼리 파라미터로 입력받아, 해당 반경 내의 사업체 목록과 전체 검색 결과 개수를 JSON 형태로 반환합니다. 페이지네이션 기능은 초기 설계의 단순화를 위해 생략합니다.
        ```
        GET /businesses?latitude=37.5665&longitude=126.9780&radius=1000
        ```
        응답 예시:
        ```json
        {
          "total_count": 150,
          "businesses": [
            { "id": "1", "name": "맛있는 식당 A", "latitude": 37.5650, "longitude": 126.9790, ... },
            { "id": "2", "name": "친절한 카페 B", "latitude": 37.5670, "longitude": 126.9775, ... },
            ...
          ]
        }
        ```
    * **사업체 관리 API (CRUD):** 
        - 사업체 정보를 생성(POST), 조회(GET /{business_id}), 수정(PUT /{business_id}), 삭제(DELETE /{business_id})하는 표준적인 API를 제공합니다. 이는 사업체 소유자가 자신의 정보를 관리하는 데 사용되며, API 규약은 일반적인 RESTful API 디자인 패턴을 따른다.
* **데이터 스키마:**
    * **Business Table:** 
        - 각 사업체의 상세 정보를 저장합니다. `business_id`를 기본 키로 사용하여 각 사업체를 고유하게 식별합니다. 이 테이블에는 사업체명, 주소, 연락처, 영업시간, 카테고리, 상세 설명 등 다양한 정보가 포함될 수 있습니다.
    * **위치 기반 검색 Table:** 
        - 빠른 주변 검색을 위해 사업체의 `business_id`와 위치 정보(위도, 경도)를 저장합니다. 특히, 위치 정보를 기반으로 효율적인 검색을 수행할 수 있도록 지리 공간 인덱싱이 필수적으로 적용되어야 합니다.
* **저장 용량 추정:**
    * **Business Table:** 
        - 각 사업체당 평균 1KB의 데이터를 저장한다고 가정하면 (실제로는 이미지, 리뷰 등 더 많은 데이터를 포함할 수 있으므로 추후 상세 분석 필요), 2억 개의 사업체에 대한 총 저장 용량은 약 200GB가 됩니다. 하지만 다양한 추가 정보와 인덱스를 고려하면 수 테라바이트(TB) 수준으로 증가할 수 있습니다.
    * **위치 기반 검색 Table:** 
        - 각 사업체당 `business_id` (8바이트), 위도 (8바이트), 경도 (8바이트)를 저장한다고 가정하면, 총 저장 용량은 약 $2 \times 10^8 \times (8 + 8 + 8) \text{ 바이트} \approx 4.8 \text{ GB}$가 됩니다. 인덱스 크기를 고려하면 약 5GB 수준으로 예상할 수 있습니다.

### **5.5 시스템 아키텍처**

* **로드 밸런서 (Load Balancer):** 
    - 사용자로부터 들어오는 API 요청을 여러 대의 서버로 분산시켜 시스템의 안정성과 성능을 향상시킵니다. 각 요청은 독립적으로 처리되므로 로드 밸런서는 스테이트리스(Stateless)하게 동작합니다.
* **위치 기반 서비스 (Location Based Service - LBS):** 
    - 핵심적인 컴포넌트로서, 사용자의 위치와 검색 반경을 입력받아 데이터베이스에서 해당 범위 내의 사업체를 검색하는 역할을 수행합니다. 읽기 작업이 매우 많고 높은 초당 쿼리 수(QPS)를 처리해야 하며, 각 요청 간의 상태를 유지할 필요가 없는 스테이트리스한 특징을 가집니다.
* **사업체 서비스 (Business Service):** 
    - 사업체 객체에 대한 생성(Create), 읽기(Read), 수정(Update), 삭제(Delete) (CRUD) 요청을 처리합니다. 사업체 정보 변경은 자주 발생하지 않으므로 쓰기 QPS는 상대적으로 낮지만, 상세 정보 조회 요청이 많으므로 읽기 QPS는 높을 수 있습니다. 성능 향상을 위해 캐싱 전략을 고려할 수 있습니다.
* **데이터베이스 클러스터 (Database Cluster):** 
    - 시스템의 안정성과 성능을 위해 데이터베이스를 클러스터 형태로 구성합니다. 읽기 및 쓰기 트래픽 비율과 데이터 접근 패턴을 고려하여 Primary-Secondary (주-부) 구조를 채택할 수 있습니다. Primary 서버는 쓰기 요청을 처리하고, Secondary 서버(Read Replica)는 읽기 요청을 분산 처리하여 읽기 성능을 향상시킵니다. 데이터 복제 과정에서 약간의 지연이 발생할 수 있지만, 사업체 정보 변경의 즉시성이 중요하지 않으므로 큰 문제는 되지 않습니다.

### **5.6 심층 분석**

* **위치 기반 검색을 위한 데이터베이스 선택:**
    * **지리 공간 데이터베이스 (Geospatial Database):** 효율적인 지리 공간 데이터 처리 및 쿼리를 지원하는 특화된 데이터베이스를 고려할 수 있습니다.
        * **Redis GEOHASH:** Redis의 Sorted Set 자료 구조와 Geohash를 결합하여 빠르고 간편하게 주변 검색 기능을 구현할 수 있습니다. 메모리 기반이므로 매우 빠른 읽기 성능을 제공합니다.
        * **PostgreSQL with PostGIS 확장:** 강력한 공간 정보 처리 기능을 제공하는 PostGIS 확장을 PostgreSQL에 추가하여 사용할 수 있습니다. 복잡한 지리 공간 쿼리를 효율적으로 처리할 수 있으며, 데이터의 영속성을 보장합니다.
    * 데이터베이스 선택 시에는 성능 요구 사항, 데이터의 복잡성, 개발 및 운영의 편의성 등을 종합적으로 고려해야 합니다.
    * **지리 공간 인덱싱 알고리즘 이해:** 선택한 데이터베이스의 성능을 극대화하기 위해서는 내부적으로 사용되는 지리 공간 인덱싱 알고리즘에 대한 이해가 필수적입니다.
* **지리 공간 인덱싱 알고리즘:**
    * **Naive 접근 방식:** 단순히 모든 사업체의 위치 정보를 순회하며 사용자와의 거리를 계산하여 검색 반경 내에 있는지 확인하는 방식입니다. 데이터 양이 많아질수록 성능이 크게 저하되므로 실제 서비스에는 적합하지 않습니다.
    * **위도/경도 인덱싱:** 일반적인 B-Tree 인덱스 등을 사용하여 위도와 경도 컬럼에 각각 인덱스를 생성하는 방식입니다. 하지만 2차원 공간 데이터를 1차원 인덱스로 처리하므로 범위 검색 효율성이 떨어질 수 있습니다.
    * **해시 기반 솔루션:**
        * **Even Grid:** 지도를 동일한 크기의 격자로 나누고 각 격자에 속하는 사업체를 관리하는 방식입니다. 사업체 분포가 불균형할 경우 특정 격자에 데이터가 집중되어 검색 성능이 저하될 수 있습니다.
        * **Geohash:** 2차원 위치 정보(위도, 경도)를 짧은 1차원 문자열(Geohash)로 변환하여 공간을 계층적으로 분할하고 인덱싱합니다.
            * 지도를 재귀적으로 분할하는 이진 트리 구조를 기반으로 합니다. Geohash의 길이가 길어질수록 더 정밀한 위치 정보를 나타냅니다.
            * **기본적인 Geohash 구현의 문제점:** 지리적으로 매우 가까운 두 지점이라도 Geohash 값이 완전히 다르거나 공유하는 접두사가 없을 수 있습니다. 이는 검색 시 인접한 사업체를 누락시키는 원인이 될 수 있습니다.
            * **해결책:** 검색 시 대상 Geohash뿐만 아니라 인접한 8개의 Geohash에 속하는 사업체까지 함께 검색하여 이러한 문제를 해결합니다.
    * **트리 기반 솔루션:**
        * **Quadtree, Google S2:** 지도를 재귀적으로 4분할하는 Quadtree나 구면을 효율적으로 분할하는 Google S2와 같은 공간 인덱싱 구조를 활용합니다.
        * **주요 특징:** 일반적으로 메모리 기반 데이터 구조로 구현되어 빠른 검색 성능을 제공합니다. 복잡한 공간 쿼리에 효율적입니다.
* **Geohash를 이용한 지리 공간 인덱스 테이블 구조:**
    * 테이블 구조: `geohash` (문자열), `business_id` (정수)를 복합 키로 설정하여 Geohash 값으로 그룹화된 사업체 ID를 저장합니다.
    * 검색 시 특정 Geohash 값 또는 특정 접두사를 가지는 Geohash 값을 SQL LIKE 연산자를 사용하여 효율적으로 찾을 수 있습니다. 예를 들어, 특정 정밀도의 Geohash를 기준으로 검색하거나, 더 짧은 접두사를 사용하여 넓은 영역을 검색할 수 있습니다.
* **Geohash 기반 검색 테이블 확장:**
    * 데이터셋 크기가 약 6GB 수준으로 예상되므로, 초기에는 단일 데이터베이스 서버로 충분히 처리 가능합니다.
    * 높은 읽기 QPS를 처리하기 위해 Read Replica를 추가하여 읽기 트래픽을 분산시키는 것을 우선적으로 고려합니다. 만약 Read Replica로도 성능 개선이 어렵다면, Geohash 값의 범위를 기준으로 데이터베이스를 샤딩(Sharding)하는 방식을 고려할 수 있습니다.
* **캐싱:**
    * Business Table의 데이터셋 크기가 커질 경우, 자주 접근하는 사업체 정보를 캐싱 계층에 저장하여 데이터베이스 부하를 줄이고 응답 속도를 향상시키는 것을 고려합니다. Redis와 같은 인메모리 데이터베이스를 캐시 서버로 활용할 수 있습니다. 캐시 전략으로는 LRU (Least Recently Used) 또는 LFU (Least Frequently Used) 등을 적용할 수 있습니다.

### **5.7 최종 설계 및 요청 흐름**

* 사용자가 모바일 앱 등을 통해 주변 검색 요청을 보내면, 로드 밸런서는 이 요청을 가용한 위치 기반 서비스(LBS) 인스턴스 중 하나로 라우팅합니다.
* LBS는 사용자의 현재 위치(위도, 경도)와 검색 반경을 기반으로, 데이터베이스에 저장된 Geohash 값을 이용하여 검색에 필요한 Geohash 정밀도를 결정하고, 해당 Geohash와 인접한 Geohash 값들을 계산
* LBS는 계산된 Geohash 값들을 이용하여 데이터베이스에 쿼리를 전송하고, 해당 Geohash 영역 내에 속하는 사업체의 ID 및 위치 정보를 가져옵니다.
* LBS는 데이터베이스로부터 받은 사업체들의 위치 정보와 사용자 위치를 비교하여 실제 거리를 계산하고, 검색 반경 내에 있는 사업체들을 필터링합니다. 최종적으로 거리 순으로 정렬하거나 다른 기준에 따라 순위를 결정하여 결과를 사용자에게 반환합니다.

## 6. Scan To Pay 시스템 작동 방식
- 출처: [Scan To Pay in 2 Minutes](https://www.youtube.com/watch?v=XS8ACikD2qs)

### **6.1 개요**

* Paytm, PayPal, Venmo와 같은 디지털 지갑 앱을 활용하여, 판매 시점(POS) 단말기에서 실시간으로 생성되는 QR 코드를 소비자가 스마트폰으로 스캔하여 간편하게 결제하는 현대적인 방식입니다. 이 방식은 기존의 카드 결제나 현금 결제에 비해 빠르고 안전하며 위생적인 장점을 제공합니다.

### **6.2 작동 방식**

Scan To Pay 시스템은 판매자와 소비자 간의 원활한 결제 처리를 위해 다음과 같은 두 단계로 나뉩니다.

1.  **판매자 QR 코드 생성 및 표시:**

    * 결제가 시작되면 계산대 직원은 POS 시스템에서 결제 버튼을 누릅니다.
    * POS 시스템은 결제할 총 금액과 고유한 주문 식별자(ID)를 결제 서비스 제공업체(PSP, Payment Service Provider)의 서버로 안전하게 전송합니다.
    * PSP 서버는 수신된 결제 정보(총 금액, 주문 ID 등)를 데이터베이스에 저장하고, 이 정보를 기반으로 일회성으로 사용할 수 있는 QR 코드의 URL(Uniform Resource Locator)을 생성합니다. 이 URL은 특정 결제 건에 대한 정보를 담고 있습니다.
    * 생성된 QR 코드 URL은 다시 POS 시스템으로 빠르게 전송됩니다.
    * POS 시스템은 수신한 QR 코드 URL을 결제 단말기 화면에 표시합니다.
    * 이 모든 과정은 소비자가 인지하기 어려울 정도로 짧은 시간(일반적으로 1초 이내) 안에 신속하게 이루어집니다.

2.  **소비자 QR 코드 스캔 및 결제:**

    * 소비자는 자신의 스마트폰에 설치된 디지털 지갑 앱(예: Paytm, PayPal, Venmo)을 실행하고, 앱 내의 QR 코드 스캔 기능을 활성화합니다.
    * 스마트폰 카메라를 POS 단말기에 표시된 QR 코드에 가져다 대면, 앱은 QR 코드를 인식하고 해당 QR 코드에 담긴 결제 정보를 읽어 들여 결제할 총 금액을 소비자에게 보여줍니다.
    * 소비자는 표시된 결제 금액을 확인한 후, 앱 내의 결제 버튼을 눌러 결제를 승인합니다.
    * 디지털 지갑 앱은 소비자의 결제 승인 정보를 PSP 서버로 전송하여 해당 QR 코드가 결제되었음을 알립니다.
    * PSP 서버는 해당 QR 코드의 상태를 데이터베이스에서 '결제 완료'로 변경하고, 결제 성공 메시지를 소비자의 디지털 지갑 앱으로 실시간으로 전송합니다.
    * 동시에, PSP 서버는 판매자의 POS 시스템에도 해당 QR 코드를 통해 소비자가 결제를 완료했음을 통지하여, 판매자는 결제 성공 여부를 즉시 확인할 수 있습니다.

### **6.3특징**

* **동적 QR 코드 (Dynamic QR Code):** 매번 결제 시마다 고유하게 생성되는 QR 코드로, 정해진 금액과 주문 정보를 담고 있어 보안성이 높고 오직 한 번만 사용할 수 있습니다. 이는 결제 위변조의 위험을 줄여줍니다.
* **정적 QR 코드 (Static QR Code):** 미리 생성되어 인쇄된 QR 코드를 소비자가 스캔하여 결제하는 방식도 존재하지만, 본 설명에서는 동적 QR 코드 방식을 다루었으며, 정적 QR 코드 방식에 대한 자세한 내용은 추후 영상에서 더 자세히 설명될 예정입니다.

## 7. 일관된 해싱(Consistent Hashing): 안정적인 분산 시스템 구축
- 출처: [Consistent Hashing \| Algorithms You Should Know #1](https://www.youtube.com/watch?v=UF9Iqmg94tk)

### **7.1 공통점**

* 놀랍게도, 고가용성과 확장성을 핵심으로 하는 현대적인 대규모 분산 시스템들, 예를 들어 아마존의 NoSQL 데이터베이스 서비스인 **DynamoDB**, 강력한 분산형 NoSQL 데이터베이스 **Apache Cassandra**, 수많은 사용자를 처리하는 채팅 플랫폼 **Discord**, 그리고 전 세계 사용자에게 빠르고 안정적으로 콘텐츠를 제공하는 **Akamai CDN**은 모두 핵심 기술로 **일관된 해싱**을 채택하고 있습니다. 이는 일관된 해싱이 현대 분산 시스템의 중요한 요구 사항을 충족시키는 데 매우 효과적인 기술임을 시사합니다.

### **7.2 일관된 해싱이란?**

* 상상해보세요. 방대한 양의 데이터를 여러 대의 서버에 나누어 저장해야 하는 상황에서, 서버가 추가되거나 예기치 않게 다운되는 경우 기존의 단순 해싱 방식은 데이터의 상당 부분을 다른 서버로 옮겨야 하는 심각한 문제를 야기합니다. **일관된 해싱**은 바로 이러한 문제점을 해결하기 위해 등장한 혁신적인 해싱 기법입니다. 핵심 아이디어는 대규모 분산 시스템에서 데이터가 여러 서버에 분산되어야 할 때, 서버 수가 변동되어도 **데이터 재분배를 최소화**하여 시스템의 안정성과 효율성을 극대화하는 데 있습니다.

### **7.3 왜 사용할까? (장점)**

* 일관된 해싱은 분산 시스템 설계자들에게 다음과 같은 매력적인 이점을 제공합니다.
    * **데이터 균등 분배:** 마치 여러 개의 접시에 음식을 똑같이 나누듯, 데이터를 서버에 최대한 균등하게 분배하여 특정 서버에 부하가 집중되는 현상을 방지하고 **예측 가능한 성능**을 유지할 수 있도록 돕습니다. 이는 시스템 전체의 안정성과 응답성을 향상시키는 중요한 요소입니다.
    * **서버 추가/제거 시 영향 최소화:** 기존의 해싱 방식에서는 서버가 추가되거나 제거될 때 해시 테이블 전체가 변경되어 대부분의 데이터를 재분배해야 하는 부담이 있었습니다. 하지만 일관된 해싱은 서버 변경 시 **기존 데이터의 대부분은 원래 서버에 그대로 유지**되므로, 재분배되는 데이터의 양을 획기적으로 줄여 시스템의 부하를 최소화하고 운영 효율성을 높입니다. (이는 기존 해싱의 고질적인 문제점을 스마트하게 해결한 결과입니다.)
    * **가용성 향상:** 만약 특정 서버에 장애가 발생하더라도, 일관된 해싱은 장애가 발생한 서버의 데이터에만 영향을 미치도록 설계되어 **전체 시스템의 가용성을 유지**하는 데 크게 기여합니다. 다른 정상적인 서버들은 여전히 서비스를 제공할 수 있으므로, 사용자 경험 저하를 최소화할 수 있습니다.

### **7.4 작동 방식**

1.  **해시 링 구성:**
    * 마치 원형의 경기장 트랙을 상상해보세요. 먼저, 각 **서버의 이름**과 저장할 **객체의 키**를 동일한 **해시 함수**(예: MD5, MurmurHash 등)를 사용하여 고유한 숫자 값으로 변환합니다.
    * 이렇게 해싱된 값들을 특정한 숫자 범위(**hash space**)에 매핑하고, 이 범위를 마치 원처럼 연결하여 **해시 링**을 만듭니다. 이 링은 모든 가능한 해시 값들의 공간을 나타냅니다.
    * 각 서버를 해시 함수를 통해 얻은 자신의 해시 값에 해당하는 위치에 이 가상의 해시 링 위에 배치

2.  **객체 배치:**
    * 이제 저장할 **객체의 키**를 동일한 해시 함수로 해싱하여 해시 링 상의 특정 위치에 매핑합니다.

3.  **서버 찾기:**
    * 객체의 해시 값 위치에서 시작하여 해시 링을 따라 **시계 방향**으로 이동합니다. 처음으로 만나게 되는 서버가 바로 해당 객체를 담당하게 될 서버입니다. 마치 룰렛 게임에서 공이 멈춘 곳의 숫자에 해당하는 사람에게 상품이 주어지는 것과 유사한 방식입니다.

### **7.5 문제점 및 해결책: 불균등한 데이터 분배**

* **문제:** 초기 설계에서 간과될 수 있는 부분은, 서버들이 해시 링에 무작위로 배치될 경우, 각 서버 사이에 담당하는 해시 값의 범위가 달라져 **각 서버에 할당되는 데이터 양이 불균등**해질 수 있다는 점입니다. 특정 서버는 너무 많은 데이터를 관리하게 되어 과부하가 걸리고, 다른 서버는 상대적으로 여유로워지는 상황이 발생할 수 있습니다.

* **해결책:** 이러한 불균등 문제를 해결하기 위한 핵심적인 아이디어가 바로 **가상 노드(Virtual Nodes)**
    * 각각의 실제 서버를 해시 링 위에 **하나가 아닌 여러 개의 가상의 노드**로 표현합니다. 예를 들어, 하나의 물리 서버에 대해 100개 또는 200개의 가상 노드를 생성하여 해시 링 곳곳에 배치하는 것입니다.
    * 이렇게 **가상 노드의 수를 늘릴수록**, 각 서버가 담당하는 해시 값의 범위가 더욱 세분화되어 데이터 분배가 훨씬 더 **균등**해지는 효과를 얻을 수 있습니다. 마치 하나의 피자를 여러 조각으로 나누어 여러 사람이 공평하게 나눠 먹는 것과 같습니다.
    * 하지만 가상 노드의 수를 늘리는 것은 각 가상 노드에 대한 정보를 저장해야 하므로 **메타데이터 저장 공간 증가**라는 일종의 **trade-off**가 존재합니다. 시스템 설계 시 이러한 점을 고려하여 적절한 가상 노드 수를 결정해야 합니다.

### **7.6 실제 사용 예시**

* **NoSQL 데이터베이스 (DynamoDB, Cassandra):** 
    - 대규모 데이터를 효율적으로 관리하기 위해 데이터를 여러 파티션으로 나누어 저장하고, 일관된 해싱을 사용하여 서버 추가 또는 제거 시 **데이터 재분배를 최소화**하여 시스템의 안정성과 확장성을 확보
* **콘텐츠 전송 네트워크 (Akamai CDN):** 
    - 전 세계 사용자에게 웹 콘텐츠를 빠르게 전달하기 위해 수많은 **엣지 서버**에 콘텐츠를 분산 저장합니다. 이때 일관된 해싱을 사용하여 사용자 요청에 가장 가까운 서버를 효율적으로 찾고, 서버 변경 시 캐시된 콘텐츠의 대부분을 유지하여 효율적인 콘텐츠 전송을 가능하게 합니다.
* **로드 밸런서 (Google Load Balancer):** 
    - 사용자 트래픽을 여러 백엔드 서버에 분산시키는 역할을 합니다. 일관된 해싱을 적용하면 특정 사용자의 연결을 가능한 한 동일한 서버로 유지하여 **지속적인 연결**을 보장하고, 서버 장애 시 다른 서버로의 **재연결 수를 줄여** 사용자 경험의 안정성을 높입니다.

## 8. Redis가 빠른 이유: 핵심 설계 결정
- 출처: [System Design: Why is single-threaded Redis so fast?](https://www.youtube.com/watch?v=5TRFpFBccQM)

### **8.1 인 메모리 데이터베이스**

* **본질적인 속도 우위:** 
    - RAM(Random Access Memory)에 데이터를 저장하고 접근하는 것은 물리적 디스크의 회전 및 탐색 과정이 필요 없는 디스크 I/O(Input/Output)보다 **수백에서 수천 배** 더 빠릅니다. 이는 Redis의 핵심적인 성능 이점입니다.
* **높은 처리량과 낮은 지연 시간:** 
    - 빠른 메모리 접근 덕분에 Redis는 초당 수많은 읽기 및 쓰기 작업을 매우 짧은 지연 시간 내에 처리할 수 있습니다. 이는 실시간 데이터 처리, 캐싱 등 성능이 중요한 애플리케이션에 필수적입니다.
* **데이터 크기 제약:** 
    - 모든 데이터가 주 메모리에 상주해야 하므로, 저장할 수 있는 데이터셋의 크기는 서버의 물리적인 메모리 용량에 의해 제한됩니다. 대규모 데이터 처리를 위해서는 메모리 확장 또는 데이터 분산 전략이 필요할 수 있습니다.
* **간결한 구현과 안정성:** 
    - 디스크 I/O 관련 복잡한 로직이 없어 코드 구현이 상대적으로 단순합니다. 이는 잠재적인 버그 발생 가능성을 줄이고 시스템의 전체적인 안정성을 높이는 데 기여합니다.

### **8.2 싱글 스레드 아키텍처**

* **동시성 문제 회피:** 
    - 멀티 스레드 환경에서 흔히 발생하는 공유 자원에 대한 경쟁 상태(race condition), 락(lock) 관리, 스레드 간 동기화 등의 복잡성을 근본적으로 제거하여 개발 및 유지보수를 용이하게 하고 예측 불가능한 오류 발생 가능성을 줄입니다.
* **단순하고 이해하기 쉬운 코드 경로:** 
    - 단일 실행 흐름은 코드의 이해도를 높이고 디버깅을 단순화합니다. 이는 개발 생산성 향상과 시스템의 안정적인 운영에 도움이 됩니다.
* **효율적인 I/O 처리:** 
    - Redis는 I/O 멀티플렉싱 기술 중 하나인 `epoll` (리눅스), `kqueue` (macOS, BSD) 등을 사용하여 **단일 스레드**로 수천 개의 클라이언트 연결을 동시에 효율적으로 처리할 수 있습니다. 이벤트 기반 방식으로, 실제로 데이터를 요청한 클라이언트에게만 작업을 할당하므로 불필요한 컨텍스트 스위칭 오버헤드를 줄입니다.
* **CPU 활용률 제한 및 확장 전략:** 
    - 단일 스레드이기 때문에 단일 CPU 코어만을 활용합니다. CPU 집약적인 작업 부하에서는 성능 병목이 발생할 수 있습니다. 이러한 단점을 극복하기 위해 일반적으로 여러 개의 Redis 인스턴스를 서로 다른 포트와 설정으로 단일 서버에서 실행하여 사용 가능한 CPU 코어를 최대한 활용하는 전략을 사용

### **8.3 효율적인 자료 구조**

* **메모리 최적화 및 빠른 접근:** 인 메모리 환경에서는 데이터의 영구성을 위한 디스크 저장 방식을 고려할 필요 없이, 데이터 접근 및 조작에 최적화된 다양한 자료 구조(예: 빠른 조회를 위한 해시 테이블, 순서 유지를 위한 연결 리스트와 스킵 리스트, 집합 연산을 위한 집합 자료 구조 등)를 자유롭게 선택하고 구현할 수 있습니다. 각 자료 구조는 특정 유형의 작업에 대해 매우 높은 성능을 제공합니다.

### **8.4 결론** 
- Redis는 인 메모리 데이터베이스의 빠른 접근 속도, 싱글 스레드 아키텍처의 안정성과 효율적인 I/O 처리, 그리고 각 작업에 최적화된 다양한 자료 구조의 활용이라는 핵심적인 설계 결정을 통해 **사용 편의성, 견고한 안정성, 뛰어난 성능**을 효과적으로 결합하여 최고의 성능 및 안정성 절충안을 제공하는 강력한 인 메모리 데이터 저장소입니다.

## 9. HTTP 버전별 발전 과정
- 출처: [HTTP/1 to HTTP/2 to HTTP/3](https://www.youtube.com/watch?v=a-sBfyiXysI)

### **9.1 HTTP/1 (1996년): 초기 웹 통신의 기반**

* **TCP 기반:** 모든 통신이 신뢰성 있는 연결을 제공하는 TCP(Transmission Control Protocol) 위에서 이루어졌습니다. 이는 데이터 손실 없이 순서대로 전달됨을 보장했지만, 연결 설정 및 해제에 비용이 발생
* **서버 요청마다 별도의 TCP 연결 필요:** 웹 페이지 내의 각 리소스(HTML, CSS, 이미지, JavaScript 등)를 요청할 때마다 새로운 TCP 연결을 맺고 끊어야 했습니다. 이는 불필요한 핸드셰이크 과정(three-way handshake)을 반복하여 성능 저하의 원인이 되었습니다.

### **9.2 HTTP/1.1 (1997년): 성능 개선의 첫걸음**

* **Keep-alive 메커니즘 도입**: 
    - **연결 재사용 가능 (persistent connection):** 하나의 TCP 연결을 통해 여러 개의 HTTP 요청과 응답을 주고받을 수 있게 되었습니다.
    * **TCP three-way handshake 비용 절감, 요청 지연 감소:** 불필요한 연결 설정을 줄여 페이지 로딩 시간을 단축시켰습니다.
* **HTTP Pipelining 추가:** 
    - 클라이언트가 이전 요청에 대한 응답을 기다리지 않고 여러 개의 요청을 연속적으로 보낼 수 있게 되었습니다.
    * **이론상 여러 요청을 응답 대기 없이 전송 가능:** 네트워크 지연 시간을 줄여 잠재적인 성능 향상을 가져올 수 있었습니다.
    * **응답 순서가 요청 순서와 동일해야 함:** 서버는 요청받은 순서대로 응답해야 했기 때문에, 특정 응답이 지연되면 후속 응답들도 함께 지연되는 문제가 발생했습니다.
    * **구현의 어려움, 프록시 서버 문제 등으로 지원 중단:** 많은 서버와 프록시 서버에서 파이프라이닝을 제대로 처리하지 못하여 실제 활용도는 낮았고, 결국 대부분의 브라우저에서 지원이 중단되었습니다.
* **Head-of-Line Blocking 문제 발생 (애플리케이션 레벨):** 
    - 하나의 TCP 연결 내에서 특정 요청에 대한 응답이 지연되면, 그 뒤에 오는 다른 요청들의 응답도 함께 지연되는 현상이 발생했습니다. 이는 연결 재사용의 장점을 상쇄시키는 주요 문제점이었습니다.
    * **브라우저는 다수의 TCP 연결을 통해 병렬 요청 처리:** Head-of-Line Blocking 문제를 완화하기 위해 브라우저들은 하나의 도메인에 대해 여러 개의 TCP 연결을 맺어 병렬적으로 리소스를 요청하는 방식을 사용했습니다. 이는 근본적인 해결책은 아니었습니다.

### **9.3 HTTP/2 (2015년): 현대적인 웹 통신의 시작**

* **HTTP Streams 도입: 단일 TCP 연결에서 여러 스트림으로 요청 전송:** 
    - 하나의 TCP 연결 내에서 독립적인 여러 개의 논리적인 데이터 흐름(스트림)을 통해 동시에 여러 개의 요청과 응답을 처리할 수 있게 되었습니다.
* **각 스트림은 독립적으로 전송 및 수신 가능:** 
    - 특정 스트림의 지연이 다른 스트림에 영향을 미치지 않아 Head-of-Line Blocking 문제를 애플리케이션 레이어에서 해결했습니다.
* **애플리케이션 레이어에서 Head-of-Line Blocking 해결:** 
    - 스트림 기반의 다중화 덕분에 응답 순서와 요청 순서가 더 이상 중요하지 않게 되었고, 먼저 도착하는 응답부터 처리할 수 있게 되었습니다.
* **서버 푸시 기능:** 
    - 서버가 클라이언트의 명시적인 요청 없이도 필요하다고 예상되는 리소스를 미리 클라이언트에게 전송할 수 있게 되었습니다. 이는 페이지 로딩 시간을 더욱 단축시키는 데 기여했습니다.

### **9.4 HTTP/3 (2022년): 새로운 전송 프로토콜로의 전환**

* 기존 TCP 대신 **QUIC** 프로토콜 사용 (**UDP 기반**): 
    - 신뢰성, 보안, 성능을 향상시킨 새로운 전송 프로토콜인 QUIC(Quick UDP Internet Connections)을 채택했습니다. UDP를 기반으로 하지만, 자체적인 흐름 제어, 혼잡 제어, 오류 복구 메커니즘을 제공하여 TCP의 단점을 극복하고자 했습니다.
* **QUIC Streams: 전송 레이어에서 스트림을 기본 요소로 사용:** 
    - QUIC 프로토콜 자체에서 스트림 개념을 지원하여, HTTP/2의 스트림 다중화 기능을 더욱 효율적으로 구현할 수 있게 되었습니다.
    * **새로운 연결 없이 스트림 생성 가능:** TCP와 달리 연결 설정 과정 없이 스트림을 생성하고 데이터를 전송할 수 있어 지연 시간을 줄였습니다.
    * **각 스트림은 독립적으로 전송:** 하나의 스트림에서 패킷 손실이 발생하더라도 다른 스트림의 전송에는 영향을 미치지 않습니다.
    * **패킷 손실이 다른 스트림에 미치는 영향 최소화 (전송 레이어 Head-of-Line Blocking 해결):** QUIC는 각 스트림별로 독립적인 흐름 제어 및 재전송 메커니즘을 제공하여 TCP 레벨에서의 Head-of-Line Blocking 문제를 근본적으로 해결했습니다.
* **모바일 환경에 최적화:**
    * **Connection ID:** TCP 연결은 IP 주소와 포트 번호의 조합으로 식별되는 반면, QUIC는 Connection ID라는 논리적인 연결 식별자를 사용합니다. 따라서 모바일 환경에서 IP 주소나 네트워크 인터페이스가 변경되더라도 연결이 끊어지지 않고 유지될 수 있어 사용자 경험을 향상시킵니다.
* **현재 25% 웹사이트에서 사용, 많은 웹 브라우저 지원:** 
    - HTTP/3는 점차 도입률을 높여가고 있으며, 주요 웹 브라우저들에서 이미 지원하고 있어 앞으로 웹 성능 개선에 크게 기여할 것으로 예상됩니다.

### **9.5 요약**

- HTTP는 초기 TCP 기반의 단순한 요청-응답 방식에서 시작하여, 연결 재사용(HTTP/1.1), 스트림 다중화(HTTP/2), 그리고 혁신적인 전송 프로토콜 QUIC의 도입(HTTP/3)을 통해 웹 통신의 성능과 효율성을 꾸준히 발전시켜 왔습니다. 
- 특히 HTTP/3는 UDP 기반의 QUIC 프로토콜을 통해 모바일 환경에서의 연결 안정성을 획기적으로 개선하고, 전송 레이어에서의 Head-of-Line Blocking 문제를 해결함으로써 더욱 빠르고 안정적인 웹 경험을 제공하는 데 중요한 역할을 하고 있습니다.

## 10. RESTful API
- 출처: [What Is REST API? Examples And How To Use It: Crash Course System Design #3](https://www.youtube.com/watch?v=-mN3VyJuCjM)

### **10.1 REST란?**

*   **정의:** Representational State Transfer의 약자로, 2000년대 초반부터 웹 API 구축의 공통 표준으로 자리 잡은 규칙 집합  
    *   **부연 설명:** REST는 특정 프로그래밍 언어나 플랫폼에 종속되지 않으며, HTTP 프로토콜을 기반으로 동작합니다. 이는 웹 서비스 간 상호 운용성을 높이고, 다양한 클라이언트(웹 브라우저, 모바일 앱 등)가 서버와 통신할 수 있도록 설계되었습니다.
*   **특징:** API (Application Programming Interface) 표준 중 하나로, 모바일 및 웹 애플리케이션이 서버와 통신하는 데 사용됨  
    *   **부연 설명:** REST는 HTTP 프로토콜의 기본 메커니즘(URI, HTTP 메소드, 상태 코드 등)을 활용하여 자원을 관리합니다. 이를 통해 개발자는 직관적이고 일관된 방식으로 데이터를 주고받을 수 있습니다.
*   **RESTful API:** REST 표준을 따르는 API (예: Twilio, Stripe, Google Maps)  
    *   **부연 설명:** Twilio는 문자 메시지 전송, Stripe는 결제 처리, Google Maps는 지도 데이터 제공을 위한 RESTful API를 제공합니다. 이러한 API들은 개발자가 외부 서비스를 손쉽게 통합할 수 있도록 설계되었습니다.

### **10.2 RESTful API의 기본 요소**

*   **자원 (Resources):**
    *   고유한 URI (Uniform Resource Identifiers)로 식별되는 자원들의 집합  
        *   **부연 설명:** URI는 자원을 유일하게 식별하는 주소 역할을 합니다. 예를 들어, `/users/123`은 ID가 123인 사용자를 나타냅니다.
    *   URI는 서버 상의 다양한 유형의 자원을 구별  
        *   **부연 설명:** 자원은 일반적으로 명사로 표현되며, 동사는 사용하지 않습니다. 예를 들어, `/products`는 제품 목록을 나타내지만 `/getAllProducts`와 같은 동사 형태는 REST 원칙에 어긋납니다.
*   **HTTP 요청 (Request):**
    *   클라이언트가 자원에 접근하기 위해 서버에 보내는 요청  
        *   **부연 설명:** HTTP 요청은 클라이언트가 서버에 어떤 작업을 수행할지 명령하는 메시지입니다. 예를 들어, 새로운 사용자를 등록하려면 POST 요청을 보낼 수 있습니다.
    *   **구성:**
        *   **HTTP Verb (Method):** 자원에 대한 작업을 지정 (POST, GET, PUT, DELETE)  
            *   **부연 설명:** 각 HTTP 메소드는 특정 작업을 나타냅니다. 예를 들어, GET은 데이터를 조회하고, POST는 새로운 데이터를 생성합니다.
        *   **URI:** 접근하려는 자원의 위치  
            *   **부연 설명:** URI는 요청 대상이 되는 자원의 경로를 정의합니다. 예를 들어, `/users/456`은 ID가 456인 사용자 정보를 가리킵니다.
        *   **Request Body (Optional):** JSON 형식의 데이터 페이로드  
            *   **부연 설명:** 요청 본문은 서버에 전달할 데이터를 포함합니다. 예를 들어, 사용자 생성 요청 시 사용자의 이름, 이메일 등을 JSON 형식으로 전송할 수 있습니다.
    *   **CRUD:**
        *   **POST:** Create (생성)  
            *   **부연 설명:** 새로운 자원을 생성할 때 사용합니다. 예: 새로운 제품을 등록하기 위해 `/products` 엔드포인트에 POST 요청을 보냅니다.
        *   **GET:** Read (읽기)  
            *   **부연 설명:** 자원을 조회할 때 사용합니다. 예: 특정 사용자의 정보를 가져오기 위해 `/users/123`에 GET 요청을 보냅니다.
        *   **PUT:** Update (수정)  
            *   **부연 설명:** 기존 자원을 수정할 때 사용합니다. 예: 사용자 정보를 업데이트하기 위해 `/users/123`에 PUT 요청을 보냅니다.
        *   **DELETE:** Delete (삭제)  
            *   **부연 설명:** 자원을 삭제할 때 사용합니다. 예: 특정 제품을 제거하기 위해 `/products/789`에 DELETE 요청을 보냅니다.
*   **HTTP 응답 (Response):**
    *   서버가 요청을 처리한 후 클라이언트에게 보내는 결과  
        *   **부연 설명:** 응답은 요청의 성공 여부와 함께 필요한 데이터를 포함합니다. 예를 들어, 사용자 생성 요청에 대한 성공 응답은 새로 생성된 사용자의 ID를 반환할 수 있습니다.
    *   **구성:**
        *   **HTTP Status Code:** 요청 처리 결과를 나타내는 코드 (200: 성공, 400: 클라이언트 오류, 500: 서버 오류)  
            *   **부연 설명:** 상태 코드는 요청 결과를 한눈에 파악할 수 있도록 도와줍니다. 예: 404는 찾을 수 없는 자원을 나타내며, 503은 서버가 일시적으로 사용 불가능함을 의미합니다.
        *   **Response Body (Optional):** JSON 형식의 데이터 페이로드  
            *   **부연 설명:** 응답 본문은 요청 결과와 관련된 데이터를 포함합니다. 예: 사용자 조회 요청에 대한 응답 본문에는 사용자의 이름, 이메일 등의 정보가 포함될 수 있습니다.

### **10.3 RESTful API의 주요 특징**

*   **Stateless (무상태성):**
    *   서버와 클라이언트가 서로의 정보를 저장할 필요가 없음  
        *   **부연 설명:** 각 요청은 독립적이므로, 서버는 이전 요청에 대한 정보를 기억하지 않습니다. 이는 확장성과 신뢰성을 높이는 중요한 특징입니다.
    *   각 요청은 독립적으로 처리됨  
        *   **부연 설명:** 예를 들어, 사용자가 로그인한 상태를 유지하려면 클라이언트가 매번 인증 토큰을 요청에 포함해야 합니다.
    *   확장성이 뛰어나고 예측 가능한 동작  
        *   **부연 설명:** 무상태성 덕분에 서버는 여러 대로 확장될 수 있으며, 클라이언트는 일관된 방식으로 요청을 보낼 수 있습니다.
*   **멱등성 (Idempotency):**
    *   동일한 요청을 여러 번 보내도 결과가 동일해야 함 (POST는 일반적으로 멱등성을 보장하지 않음)  
        *   **부연 설명:** 예를 들어, `/users/123`에 PUT 요청을 여러 번 보내도 사용자 정보는 한 번만 수정됩니다. 그러나 POST 요청은 매번 새로운 자원을 생성하므로 멱등성을 보장하지 않습니다.

### **10.4 RESTful API 설계 시 고려 사항**

*   **Pagination (페이지네이션):**
    *   API 엔드포인트가 많은 양의 데이터를 반환할 때 사용  
        *   **부연 설명:** 페이지네이션은 클라이언트가 한 번에 처리할 데이터의 양을 줄여 성능을 최적화하는 데 도움을 줍니다.
    *   `limit` (페이지당 항목 수) 및 `offset` (시작 위치) 파라미터를 활용  
        *   **부연 설명:** 예: `/products?limit=10&offset=20`은 21번째부터 30번째까지의 제품 목록을 반환합니다.
    *   미지정 시 서버는 기본값을 사용  
        *   **부연 설명:** 기본값은 서버에서 설정되며, 클라이언트는 이를 변경하여 원하는 데이터를 가져올 수 있습니다.
*   **Versioning (버전 관리):**
    *   API 변경 시 하위 호환성을 제공하기 위해 필요  
        *   **부연 설명:** API가 변경되면 기존 클라이언트가 오작동할 수 있으므로, 버전 관리를 통해 호환성을 유지합니다.
    *   URI에 버전을 접두사로 추가하는 방식이 일반적 (예: `/v1/products`)  
        *   **부연 설명:** 예: `/v1/products`와 `/v2/products`는 서로 다른 버전의 제품 API를 나타냅니다. 클라이언트는 적절한 버전을 선택하여 사용합니다.

### **10.5 REST의 장점 및 활용**

*   **장점:** 단순하고 효과적이며, 광범위하게 사용됨  
    *   **부연 설명:** REST는 HTTP 프로토콜의 기본 메커니즘을 활용하므로 복잡한 설정 없이 쉽게 구현할 수 있습니다. 또한, 다양한 플랫폼과 언어에서 사용 가능합니다.
*   **활용:** 웹 애플리케이션, 모바일 앱, IoT 기기 등 다양한 환경에서 데이터 교환을 위해 사용  
    *   **부연 설명:** 예를 들어, 스마트 홈 디바이스(IoT)는 RESTful API를 통해 사용자의 모바일 앱과 데이터를 주고받을 수 있습니다.

## 11. LSM 트리 (Log Structured Merge Tree)
- 출처: [The Secret Sauce Behind NoSQL: LSM Tree](https://www.youtube.com/watch?v=I6jB0nM9SKU)

### **11.1 배경**

*   **NoSQL 데이터베이스 (예: Cassandra) 인기 급증**
    *   NoSQL 데이터베이스는 대규모 데이터 처리와 확장성을 요구하는 시스템에서 주로 사용됩니다. 특히 RDBMS의 ACID 특성을 일부 포기하면서도 높은 성능과 유연성을 제공합니다.
    *   예를 들어, 소셜 미디어 플랫폼이나 전자상거래 웹사이트에서는 실시간 데이터 처리가 중요하며, 이를 위해 NoSQL 데이터베이스가 적합합니다.
*   **모바일 앱, IoT 기기 등 데이터 폭증으로 인한 빠른 쓰기 성능 요구 증가**
    *   모바일 앱과 IoT 기기는 매초마다 방대한 양의 데이터를 생성합니다. 이러한 데이터는 실시간으로 수집되고 저장되어야 하며, 이를 위해서는 빠른 쓰기 성능이 필수적입니다.
    *   예를 들어, 스마트폰의 위치 데이터나 IoT 센서의 온도 데이터는 연속적으로 발생하며, 이를 처리하기 위해 효율적인 쓰기 메커니즘이 필요합니다.
*   **LSM 트리는 빠른 쓰기에 최적화된 데이터 구조**
    *   LSM 트리는 데이터를 메모리에 임시 저장한 후 일괄적으로 디스크에 기록하는 방식으로 동작합니다. 이는 쓰기 작업을 순차 I/O로 변환하여 성능을 극대화합니다.
    *   이를 통해 SSD와 같은 스토리지에서도 높은 쓰기 처리량을 달성할 수 있습니다.

### **11.2 LSM 트리 vs B-Tree**

| 특징      | B-Tree                               | LSM 트리                             |
| ------- | ------------------------------------ | --------------------------------- |
| **최적화 대상**  | 읽기                                 | 쓰기                                |
| **쓰기 방식**   | 임의 I/O, 다중 페이지 업데이트 (비용 높음) | 순차 I/O, 메모리 버퍼링 후 일괄 디스크 쓰기 (비용 낮음) |

*   B-Tree는 데이터를 균형 잡힌 트리 구조로 유지하여 임의 접근(Random Access)을 최적화합니다. 따라서 읽기 작업이 많은 환경에서 우수한 성능을 발휘합니다.
*   LSM 트리는 쓰기 작업을 메모리에서 처리하고, 이후 디스크에 순차적으로 기록하는 방식으로 쓰기 성능을 극대화합니다.



*   B-Tree는 데이터를 삽입하거나 삭제할 때 트리 구조를 재조정해야 하므로 임의 I/O 작업이 많이 발생합니다. 이는 SSD보다는 HDD에서 더 큰 비용을 초래합니다.
*   LSM 트리는 쓰기 작업을 메모리에서 먼저 처리하고, 특정 크기가 되면 디스크에 한번에 기록하므로 쓰기 과정에서의 비용을 크게 줄입니다.

### **11.3 LSM 트리 작동 방식**

*   **Memtable:**
    *   메모리에 쓰기 데이터를 일시적으로 저장하는 공간 (정렬된 이진 트리 구조)
        - Memtable은 일반적으로 Skip List나 Red-Black Tree와 같은 자료구조를 사용하여 데이터를 정렬된 상태로 유지합니다.
    *   특정 크기 도달 시 SSTable로 Flush
        - Memtable의 크기가 일정 임계치를 초과하면 디스크에 SSTable(Sorted String Table) 파일로 저장됩니다. 이 과정은 Write-Ahead Logging(WAL)을 통해 데이터 손실을 방지합니다.
*   **SSTable (Sorted String Table):**
    *   정렬된 Key-Value 쌍을 저장하는 불변 파일
        - SSTable은 한 번 생성되면 변경되지 않으며, 새로운 업데이트는 새로운 SSTable에 추가됩니다. 이는 동시성 제어를 단순화하고 데이터 무결성을 보장합니다.
    *   LSM 트리의 가장 최신 세그먼트
        - 여러 개의 SSTable 중 가장 최근에 생성된 파일이 최신 데이터를 포함합니다.
    *   새로운 업데이트는 기존 SSTable을 덮어쓰지 않고 새로운 SSTable에 추가
        - 이 방식은 쓰기 성능을 극대화하지만, 시간이 지남에 따라 중복된 데이터가 누적될 수 있습니다.
*   **삭제 처리 (Tombstone):**
    *   삭제 요청 시 Tombstone 마커를 최신 SSTable에 추가
        - Tombstone은 삭제된 데이터의 존재를 표시하는 플래그 역할을 합니다. 실제 데이터는 Compaction 과정에서 제거됩니다.
    *   읽기 시 Tombstone 발견 시 삭제된 객체로 간주 (추가 공간 필요)
        - Tombstone이 존재하는 경우 해당 데이터는 읽기 작업에서 제외됩니다. 그러나 Tombstone 자체가 디스크 공간을 차지하므로, 이를 관리하는 것이 중요합니다.
*   **읽기 요청 처리:**
    *   Memtable 검색 -> 최신 SSTable부터 순차적으로 검색
        - 읽기 작업은 Memtable에서 시작하여, 필요한 경우 SSTable을 순차적으로 검색합니다. 이 과정에서 Bloom Filter나 Summary Table을 활용하여 검색 범위를 줄일 수 있습니다.
    *   SSTable이 정렬되어 있어 효율적인 검색 가능
        - SSTable은 Key-Value 쌍이 정렬된 상태로 저장되기 때문에 이진 검색(Binary Search)을 통해 빠르게 데이터를 찾을 수 있습니다.
*   **문제점:**
    *   SSTable 증가 시 읽기 성능 저하
        - 시간이 지날수록 SSTable의 개수가 늘어나면서 읽기 작업 시 검색해야 할 파일 수가 증가합니다. 이는 성능 저하로 이어질 수 있습니다.
    *   업데이트/삭제로 인한 불필요한 데이터 증가 (디스크 공간 낭비)
        - 중복된 데이터와 Tombstone이 누적되면 디스크 공간이 비효율적으로 사용됩니다.
*   **해결책: Compaction (병합 및 압축):**
    *   백그라운드에서 주기적으로 SSTable 병합 및 오래된 데이터 제거
        - Compaction은 중복된 데이터를 제거하고, Tombstone이 표시한 데이터를 완전히 삭제하며, 하나의 SSTable로 병합합니다.
    *   디스크 공간 확보 및 읽기 성능 향상
        - Compaction을 통해 디스크 공간을 절약하고, 읽기 작업 시 검색해야 할 SSTable 수를 줄여 성능을 향상시킵니다.
    *   Merge Sort 알고리즘과 유사한 방식 사용
        - Compaction은 두 개 이상의 SSTable을 병합하면서 중복된 데이터를 제거하고, 정렬된 상태를 유지합니다.

### **11.4 Compaction 전략**

*   **Size Tiered Compaction:** 쓰기 처리량 최적화
    *   Size Tiered Compaction은 비슷한 크기의 SSTable을 묶어 병합하는 방식입니다. 이는 쓰기 작업이 많을 때 효율적이지만, 읽기 성능이 저하될 수 있습니다.
    *   예를 들어, 작은 SSTable들이 일정 개수를 넘어가면 하나의 큰 SSTable로 병합됩니다.
*   **Leveled Compaction:** 읽기 성능 최적화
    *   Leveled Compaction은 SSTable을 여러 레벨로 나누고, 각 레벨의 크기를 지수적으로 증가시키는 방식입니다. 이는 읽기 성능을 향상시키지만, 쓰기 작업이 더 많은 I/O를 필요로 합니다.
    *   예를 들어, Level 0에는 작은 SSTable들이 있고, Level 1에는 더 큰 SSTable들이 있는 식으로 구성됩니다.
*   **핵심:**
    *   SSTable 수를 관리 가능한 수준으로 유지
        - 너무 많은 SSTable은 읽기 성능을 저하시킬 수 있으므로, 적절한 수준으로 유지하는 것이 중요
    *   SSTable을 레벨로 구성 (각 레벨은 지수적으로 커짐)
        - 각 레벨의 크기가 지수적으로 증가함으로써 데이터를 효율적으로 관리할 수 있습니다.
    *   많은 I/O 소모 (잘못 튜닝 시 시스템 성능 저하)
        - Compaction 과정에서 많은 I/O 작업이 발생하므로, 이를 잘못 설계하면 시스템 전체의 성능이 저하될 수 있습니다.

### **11.5 LSM 트리 최적화**

*   **목표:** B-Tree 수준의 읽기 성능 확보
    *   LSM 트리는 기본적으로 쓰기 성능에 최적화되어 있지만, 읽기 성능도 중요한 요소입니다. 이를 위해 다양한 최적화 기법이 사용됩니다.
*   **일반적인 방법:**
    *   **Summary Table:** 각 레벨의 디스크 블록의 Min/Max 범위를 메모리에 저장하여 불필요한 검색 방지 (랜덤 I/O 감소)
        - Summary Table은 각 SSTable의 Key 범위를 메모리에 저장하여, 읽기 작업 시 불필요한 SSTable 검색을 피할 수 있도록 합니다.
    *   **Bloom Filter:** Key 존재 가능성을 빠르게 판단하여 불필요한 레벨 검색 방지 (특히 존재하지 않는 Key 검색 시 유용)
        - Bloom Filter는 특정 Key가 SSTable에 존재할 가능성을 빠르게 확인하여, 존재하지 않는 Key에 대한 검색을 사전에 차단합니다.

### **11.6 결론**

*   LSM 트리는 높은 쓰기 성능을 지원하는 NoSQL 데이터베이스의 핵심 기술
    *   LSM 트리는 대규모 데이터를 효율적으로 처리할 수 있는 구조, NoSQL 데이터베이스에서 널리 사용
*   적절한 튜닝 (특히 Compaction)이 중요
    *   LSM 트리의 성능은 Compaction 전략과 설정에 크게 의존합니다. 따라서 시스템의 요구사항에 맞춰 적절히 튜닝하는 것이 필수적입니다.


## 12. Bloom Filter
- 출처: [Bloom Filters \| Algorithms You Should Know #2 \| Real-world Examples](https://www.youtube.com/watch?v=V3pzxngeLqw)

### **12.1 Bloom Filter란?**

*   **정의:** 공간 효율적인 확률적 자료 구조  
    *   Bloom Filter는 데이터를 저장하는 데 필요한 메모리를 최소화하도록 설계된 자료 구조입니다. 정확한 정보를 제공하지 않고, 특정 데이터가 집합에 포함되었을 가능성만을 알려줍니다. 이는 "확률적"이라는 특성을 가집니다.

*   **역할:** 특정 요소가 집합에 있는지 확인 (존재 여부 판별)  
    *   Bloom Filter는 데이터베이스나 캐시 시스템에서 특정 키 또는 값이 존재하는지를 빠르게 확인하는 데 사용됩니다. 완벽한 정확성을 보장하지 않지만, 매우 빠르고 메모리 효율적으로 동작합니다.

*   **특징:**
    *   **False Positive (오탐):** 발생 가능 (실제로는 없지만 있다고 판단)  
        *   False Positive는 Bloom Filter의 주요 제약사항 중 하나입니다. 예를 들어, 특정 URL이 악성 사이트 목록에 없다고 하더라도 Bloom Filter가 "있다"고 오인할 수 있습니다. 하지만 이러한 오탐 비율은 필터의 크기와 해시 함수 개수를 조절하여 줄일 수 있습니다.
        
    *   **False Negative (미탐):** 발생 불가능 (실제로는 있지만 없다고 판단)  
        *   만약 Bloom Filter가 특정 요소가 "없다"고 판단했다면, 이는 100% 확실합니다. 즉, Bloom Filter는 절대 "있는데 없다"고 잘못 판단하지 않습니다.
        
    *   **삭제 불가:** 한 번 추가된 요소는 삭제할 수 없음  
        *   Bloom Filter는 비트 배열을 사용하므로, 특정 요소를 삭제하면 다른 요소에도 영향을 미칠 수 있습니다. 따라서 한 번 추가된 데이터는 삭제할 수 없습니다. 필요하다면 새로운 Bloom Filter를 생성해야 합니다.

### **12.2 Bloom Filter 사용처**

*   **NoSQL 데이터베이스:** 존재하지 않는 키에 대한 디스크 읽기 횟수 감소  
    *   NoSQL 데이터베이스(예: Redis, Cassandra)는 대용량 데이터를 처리하는 데 최적화되어 있습니다. Bloom Filter를 사용하면 실제로 데이터가 없는 경우 디스크 접근을 방지하여 성능을 크게 향상시킬 수 있습니다.

*   **CDN (Content Delivery Network):** "일회성" 페이지 캐싱 방지 (Akamai 사용 사례)  
    *   CDN은 웹 콘텐츠를 빠르게 전달하기 위해 캐싱을 사용합니다. 그러나 사용자 요청이 한 번뿐인 페이지를 캐싱하면 메모리 낭비가 발생할 수 있습니다. Bloom Filter를 사용하면 이런 일회성 요청을 효과적으로 필터링할 수 있습니다.

*   **(과거) 웹 브라우저 (Chrome):** 악성 URL 식별 (현재는 다른 방법 사용)  
    *   과거에는 Chrome이 악성 URL 목록을 Bloom Filter로 관리했습니다. 클라이언트 측에서 Bloom Filter를 사용함으로써 서버와의 통신을 최소화하면서도 빠르게 위험한 사이트를 탐지할 수 있었습니다. 현재는 더 정교한 기술로 대체되었습니다.

*   **패스워드 검증기:** 취약한 패스워드 사용 방지  
    *   사용자가 설정한 패스워드가 일반적으로 알려진 취약한 패스워드 목록에 포함되어 있는지 확인하는 데 Bloom Filter를 사용할 수 있습니다. 이를 통해 사용자에게 더 안전한 패스워드를 선택하도록 유도할 수 있습니다.

### **12.3 Bloom Filter 작동 방식**

1.  **해시 함수:** 빠르고 균등하게 분포된 출력을 생성하는 여러 개의 해시 함수 사용  
    *   Bloom Filter는 여러 개의 독립적인 해시 함수를 사용합니다. 각 해시 함수는 입력 데이터를 비트 배열의 특정 위치로 매핑합니다. 해시 함수의 성능과 분포가 Bloom Filter의 정확도와 효율성에 큰 영향을 미칩니다.

2.  **비트 배열 (buckets):** 모든 비트가 0으로 초기화된 큰 비트 배열 사용  
    *   비트 배열은 Bloom Filter의 핵심 구성 요소입니다. 각 비트는 특정 데이터의 존재 여부를 나타내며, 초기 상태에서는 모두 0으로 설정됩니다.

3.  **요소 추가:**
    *   해시 함수를 사용하여 요소의 해시 값을 계산  
        *   입력 데이터를 해시 함수에 적용하여 여러 개의 해시 값을 계산합니다. 각 해시 값은 비트 배열의 특정 위치를 가리킵니다.
        
    *   해당 해시 값에 해당하는 비트 배열의 비트를 1로 설정  
        *   계산된 해시 값에 해당하는 비트 배열의 위치를 1로 변경합니다. 이렇게 하여 데이터가 추가되었다는 표시를 남깁니다.

4.  **요소 존재 여부 확인:**
    *   해시 함수를 사용하여 요소의 해시 값을 계산  
        *   존재 여부를 확인하려는 데이터에 대해 동일한 해시 함수를 적용하여 해시 값을 계산합니다.
        
    *   해당 해시 값에 해당하는 비트 배열의 비트가 모두 1인지 확인  
        *   계산된 해시 값에 해당하는 비트 배열의 위치를 확인합니다. 만약 모든 비트가 1이라면 해당 데이터가 "아마도" 집합에 포함된 것으로 판단합니다.
        
        *   모두 1: "아마 있음" (False Positive 가능성)  
            *   비트 배열의 모든 관련 비트가 1이라면, 해당 데이터가 집합에 포함되었을 가능성이 있습니다. 그러나 False Positive가 발생할 수 있으므로, 정확한 확인을 위해서는 추가적인 검증이 필요합니다.
            
        *   하나라도 0: "확실히 없음"  
            *   관련 비트 중 하나라도 0이라면, 해당 데이터는 집합에 포함되지 않았다고 확신

5. **False Positive 제어:** Bloom filter의 크기를 조정하여 제어 가능  
    *   False Positive 비율은 Bloom Filter의 크기(비트 배열의 길이)와 사용하는 해시 함수의 개수에 따라 달라집니다. 일반적으로 필터를 더 크게 만들거나 해시 함수를 적절히 조정하면 False Positive 비율을 줄일 수 있습니다.

### **12.4 장점과 단점**

*   **장점:**
    *   **공간 효율성:** 해시 테이블보다 훨씬 적은 메모리 사용  
        *   Bloom Filter는 데이터를 저장하지 않고 비트 배열만 사용하기 때문에, 해시 테이블이나 다른 자료 구조에 비해 훨씬 적은 메모리로 동일한 작업을 수행할 수 있습니다.

*   **단점:**
    *   False Positive 발생 가능  
        *   False Positive는 Bloom Filter의 고유한 특징이며, 이를 완전히 제거할 수는 없습니다. 그러나 적절한 설계를 통해 False Positive 비율을 최소화할 수 있습니다.
        
    *   요소 삭제 불가  
        *   Bloom Filter는 데이터를 추가할 때 비트 배열의 특정 위치를 1로 설정합니다. 그러나 삭제를 지원하지 않으므로, 특정 데이터를 제거하려면 새로운 Bloom Filter를 생성해야 합니다.


### **12.5 결론**  
- Bloom Filter는 메모리 효율적인 확률적 자료 구조로, 데이터의 존재 여부를 빠르게 확인하는 데 유용합니다. False Positive라는 제약이 있지만, 이를 제어할 수 있는 방법이 있으며 다양한 분야에서 활용되고 있습니다.

## 13. Back-of-the-Envelope Math
- 출처: [Back-Of-The-Envelope Estimation / Capacity Planning](https://www.youtube.com/watch?v=UC5xf8FbdJc)

### 13.1 핵심 내용

**목적:** 시스템 디자인의 타당성을 빠르게 검증 (정확도보다 빠른 판단이 중요)  
- **설명:** 복잡한 시스템 설계 초기 단계에서 모든 세부 사항을 고려하기는 어렵습니다. 따라서 대략적인 계산으로 비용, 성능, 확장성 등을 평가하여 설계 방향을 결정합니다. 이 과정에서 중요한 것은 "대략 맞는" 추정이며, 여기서 도출된 결과는 구체적인 설계의 기준점으로 활용됩니다.

**정확도:** 실제 수치와 1~2 자릿수 차이로 충분  
- **설명:** 백오프더엔벨롭 계산의 목표는 완벽한 정확도가 아니라, 현실적으로 실행 가능한지 여부를 파악하는 것입니다. 예를 들어, 필요한 서버 수가 100대인지 1,000대인지 판단하는 것이 중요하며, 이 정도 오차 범위 내에서는 의사결정에 큰 영향을 미치지 않습니다.

### 13.2 **활용 예시**

*   웹 서비스: 초당 1백만 요청 처리 필요 -> 웹 서버 클러스터 구성 및 100대 필요  
    - **설명:** 웹 서비스는 사용자 요청을 처리할 수 있는 서버의 용량과 트래픽 패턴에 따라 확장됩니다. 예를 들어, 한 서버가 초당 1만 요청을 처리할 수 있다면, 100대의 서버가 필요하다고 추정할 수 있습니다. 이를 통해 예산과 인프라 요구사항을 미리 계획할 수 있습니다.

*   데이터베이스: 초당 10개 쿼리 처리 -> 단일 서버로 충분, 샤딩/캐싱 불필요  
    - **설명:** 데이터베이스의 경우, 트래픽이 낮다면 단일 서버로도 충분히 운영 가능합니다. 그러나 트래픽이 증가하면 샤딩(데이터 분할)이나 캐싱(데이터 임시 저장) 같은 고급 기법을 고려해야 합니다. 백오프더엔벨롭 계산은 이러한 결정을 미리 검토하는 데 유용합니다.


### **13.3 주요 계산 대상**

*   서비스 레벨: 초당 요청 수 (Requests Per Second, RPS)  
    - **설명:** RPS는 웹 서비스나 API에서 얼마나 많은 요청이 발생하는지를 나타내는 지표입니다. 이를 통해 필요한 서버 수와 네트워크 대역폭을 추정할 수 있습니다.

*   데이터베이스 레벨: 초당 쿼리 수 (Queries Per Second, QPS)  
    - **설명:** QPS는 데이터베이스에 얼마나 많은 질의가 발생하는지를 나타냅니다. 이를 통해 데이터베이스 서버의 성능 요구사항과 최적화 필요성을 판단할 수 있습니다.

### **13.4 RPS 계산 시 주요 요소**

1.  **DAU (Daily Active Users):** 일일 활성 사용자 수 (MAU에서 추정 가능)  
    - **설명:** DAU는 하루 동안 서비스를 실제로 사용하는 사용자 수를 의미합니다. MAU(Monthly Active Users)의 일정 비율로 추정할 수 있으며, 서비스 특성에 따라 다르게 설정됩니다.

2.  **DAU 당 사용량:** 서비스별 DAU당 예상 사용량 (트위터의 경우, 게시물 작성 비율)  
    - **설명:** 사용자가 서비스를 얼마나 자주 이용하는지는 서비스 유형에 따라 다릅니다. 예를 들어, 소셜 미디어에서는 게시물 작성, 댓글 달기 등이 주요 행동입니다.

3.  **확장 요소 (Scaling Factor):** 하루 중 트래픽 최고조 시점과 평균 사용량의 차이 (출퇴근 시간, 주말 등)  
    - **설명:** 트래픽은 하루 중 특정 시간대(예: 점심시간, 저녁시간)에 급증할 수 있습니다. 이를 고려하지 않으면 피크 시간대에 서비스가 느려질 수 있으므로, 확장 요소를 반영합니다.

### **13.5 트위터 예시 (가정)**

*   MAU: 3억 명, DAU: 1.5억 명 (MAU의 50%)  
    - **설명:** 일반적으로 MAU의 절반 정도가 DAU로 가정합니다. 이는 서비스의 활성 사용자 비율을 나타내는 기본적인 추정치입니다.

*   DAU 당 트윗 수: 0.5개 (25%가 트윗 작성, 평균 2개)  
    - **설명:** 전체 사용자 중 일부만 트윗을 작성한다고 가정합니다. 예를 들어, 25%의 사용자가 하루에 평균 2개의 트윗을 작성한다면, DAU 당 평균 트윗 수는 0.5개가 됩니다.

*   확장 요소: 2배 (아침 시간 트래픽 급증)  
    - **설명:** 아침 시간에는 사용자가 많아져 트래픽이 평균보다 두 배 더 많아질 수 있습니다. 이를 반영하여 안정적인 서비스를 제공합니다.

*   계산: (1.5억 DAU * 0.5 트윗/DAU * 2) / 86,400초 = 약 1,500 트윗/초  
    - **설명:** 계산 과정을 통해 초당 발생하는 트윗 수를 추정합니다. 이를 통해 트위터의 서버가 초당 1,500개의 트윗을 처리할 수 있어야 함을 알 수 있습니다.

### **13.6 계산 간소화 기법**

1.  **과학적 표기법:** 큰 수를 간단하게 표현 (곱셈 -> 덧셈, 나눗셈 -> 뺄셈)  
    - **설명:** 큰 숫자를 직접 계산하는 것은 번거롭습니다. 예를 들어, 1.5억을 $ 1.5 \times 10^8 $로 표현하면 계산이 간단해집니다.

    *   예: 1.5억 DAU = $ 1.5 \times 10^8 $, 86,400초 = $ 10^5 $

2.  **묶어서 계산:** 10의 지수끼리, 나머지 숫자끼리 묶어서 계산  
    - **설명:** 곱셈과 나눗셈을 할 때, 10의 지수 부분과 나머지 숫자 부분을 따로 계산하면 속도가 빨라집니다.

### 13.7 **암기하면 유용한 단위 변환**

*   $ 10^3 = KB $ (천)
*   $ 10^6 = MB $ (백만)
*   $ 10^9 = GB $ (십억)
*   $ 10^{12} = TB $ (조)
*   $ 10^{15} = PB $ (페타바이트)  
    - **설명:** 데이터 저장 용량을 계산할 때 자주 사용되는 단위입니다. 이를 통해 저장 공간 요구사항을 쉽게 추정할 수 있습니다.

### **13.8 저장 용량 계산 예시 (트위터 멀티미디어)**

*   1일 트윗 수: 1.5억 개  
    - **설명:** 하루 동안 발생하는 트윗 수를 기준으로 저장 용량을 계산합니다.

*   사진: 10%가 사진 포함, 평균 100KB, 3개 복제, 5년 보관  
    - **설명:** 사진이 포함된 트윗의 비율과 파일 크기를 고려하여 저장 용량을 계산합니다. 또한, 데이터의 안정성을 위해 복제본을 만들고 장기간 보관해야 합니다.

*   동영상: 1%가 동영상 포함, 평균 100MB, 3개 복제, 5년 보관  
    - **설명:** 동영상은 사진보다 훨씬 큰 용량을 차지하므로, 이를 별도로 계산합니다.

*   계산 결과: 사진 저장 9PB, 동영상 저장 900PB  
    - **설명:** 사진과 동영상의 저장 용량을 합산하여 총 저장 용량을 추정합니다. 이를 통해 스토리지 인프라를 설계합니다.


## 14. 고성능 시스템 구축을 위한 데이터베이스 선택 시 고려사항
- 출처: [How To Choose The Right Database?](https://www.youtube.com/watch?v=kkeFE6iRfMM)

### **14.1 현재 데이터베이스 재검토**

*   **대안 탐색 이유 명확히 파악 (성능 저하 등):**  
    - 현재 사용 중인 데이터베이스가 더 이상 요구 사항을 충족하지 못하는 원인을 명확히 분석해야 합니다. 
    - 예를 들어, 트래픽 증가로 인한 성능 저하, 특정 쿼리의 병목 현상, 또는 하드웨어 제한 등 문제의 근본 원인을 식별하는 것이 중요합니다. 이는 불필요한 마이그레이션을 방지하고 최적의 해결책을 도출하는 데 기여합니다.

*   **문제 해결 가능성 검토:**  
    *   **데이터베이스 설명서 정독 및 설정 조정:**  
        - 많은 경우, 데이터베이스 성능 문제는 기본 설정으로 인해 발생할 수 있습니다. 데이터베이스 제공업체의 공식 문서를 철저히 검토하고, 적절한 설정(예: 인덱스 최적화, 메모리 할당 조정)을 통해 문제를 해결할 가능성이 큽니다.  
    *   **커뮤니티 전문가에게 도움 요청:**  
        - 해당 데이터베이스에 대한 경험을 가진 커뮤니티나 전문가와 협력하면, 비용 없이 효과적인 솔루션을 얻을 수 있습니다. 또한, 커뮤니티에서 자주 언급되는 팁은 실질적인 문제 해결에 유용
    *   **애플리케이션 아키텍처 개선 (캐시, 읽기 복제본, 샤딩 등):**  
        - 데이터베이스 자체의 한계를 넘어서는 문제라면, 애플리케이션 단에서의 구조 개선이 필요할 수 있습니다. 예를 들어, 캐싱 도입(예: Redis), 읽기 전용 복제본 구성, 또는 샤딩(데이터 분할)과 같은 기술을 활용하여 부하를 분산할 수 있습니다.  

*   **핵심:**  
    - 데이터베이스 마이그레이션은 기존 데이터의 무결성을 위협할 수 있으며, 상당한 시간과 비용이 소요됩니다. 따라서, 기존 데이터베이스를 유지할 수 있는지 신중하게 판단하는 것이 중요합니다. 
    - 특히, 마이그레이션 과정에서 발생할 수 있는 서비스 중단, 데이터 손실, 그리고 학습 곡선 등의 리스크를 반드시 고려해야 합니다.

### **14.2 새로운 데이터베이스 선택 시 고려사항**

*   **안정성:**  
    - 오래되고 검증된 데이터베이스를 선호하는 것이 일반적입니다.
    -  예를 들어, MySQL이나 PostgreSQL과 같은 관계형 데이터베이스는 수십 년간의 안정성과 신뢰성을 입증받았으며, 다양한 산업에서 널리 사용되고 있습니다. 새로 출시된 데이터베이스는 혁신적인 기능을 제공할 수 있지만, 아직 충분히 검증되지 않았을 가능성이 높습니다.

*   **전문가 풀:**  
    - 새로운 데이터베이스를 도입할 때는 해당 기술에 대한 전문가를 확보할 수 있는지도 중요한 고려사항입니다. 경험이 풍부한 관리자나 개발자가 부족하다면, 데이터베이스 운영 및 유지보수에 어려움을 겪을 수 있습니다. 따라서, 채용 시장에서 해당 기술의 인력 풀을 조사하는 것이 필수적입니다.

*   **트레이드오프:**  
    *   **"무한 확장성"과 같은 과장된 마케팅 문구 경계:**  
        - 모든 데이터베이스는 특정한 한계를 가지고 있습니다. "무한 확장성"이나 "초고속 처리"와 같은 과장된 표현에 현혹되지 말고, 실제 성능과 제약 조건을 명확히 확인해야 합니다.  
    *   **설명서의 "제한 사항" 및 FAQ 섹션 확인 (실제 제약 조건 파악):**  
        - 데이터베이스 제공업체의 공식 문서에서 "Limitations" 또는 "FAQ" 섹션을 꼼꼼히 읽어보는 것이 중요합니다. 이는 실제 운영 환경에서 직면할 수 있는 문제를 미리 파악하는 데 도움이 됩니다.  

*   **NoSQL 데이터베이스:**  
    - NoSQL 데이터베이스는 대규모 데이터를 효율적으로 처리할 수 있는 확장성을 제공합니다. 하지만, ACID 트랜잭션 보장이 제한적이거나, 데이터 모델링의 유연성이 떨어질 수 있습니다. 따라서, NoSQL 데이터베이스를 선택하기 전에 애플리케이션의 요구 사항과 데이터 특성을 면밀히 분석해야 합니다.

*   **정보 수집:**  
    - 데이터베이스 관련 정보를 수집할 때는 다양한 경로를 활용해야 합니다. 예를 들어, GitHub 이슈를 통해 실제 사용자들이 겪고 있는 문제를 확인하거나, 해당 데이터베이스의 커뮤니티 채팅방에 참여하여 의견을 교환할 수 있습니다. 이러한 활동은 데이터베이스 선택에 있어 중요한 통찰력을 제공합니다.

### **14.3 데이터베이스 옵션 좁히기**

*   **현실적인 테스트 환경 구축:**  
    *   **실제 데이터 및 액세스 패턴 사용:**  
        - 테스트 환경에서는 실제 운영 환경과 동일한 데이터 세트와 액세스 패턴을 사용해야 합니다. 이를 통해 데이터베이스가 실제 워크로드에서 어떻게 수행될지 정확히 평가할 수 있습니다.  
    *   **비용이 많이 들지만 필수적인 단계:**  
        - 현실적인 테스트 환경을 구축하는 데는 상당한 비용이 들 수 있습니다. 그러나, 잘못된 데이터베이스 선택으로 인해 발생할 수 있는 장기적인 손실을 감안하면, 이 단계는 필수적입니다.  

*   **벤치마킹:**  
    *   **P99 측정 (평균값은 의미 없음):**  
        - 평균 응답 시간은 전체 성능을 정확히 반영하지 못할 수 있습니다. P99(99% 백분위수)와 같은 지표를 통해 대부분의 요청이 얼마나 빠르게 처리되는지 확인해야 합니다.  
    *   **실제 워크로드 복제 및 한계점 파악:**  
        - 벤치마킹에서는 실제 워크로드를 가능한 한 정확히 복제해야 하며, 데이터베이스의 한계점을 명확히 파악해야 합니다.  
    *   **노드 장애, 네트워크 파티션 시 데이터 손상 테스트, 샤딩 테스트 등:**  
        - 데이터베이스의 내결함성과 확장성을 검증하기 위해, 노드 장애나 네트워크 파티션과 같은 예외 상황에서도 데이터가 손상되지 않는지 테스트해야 합니다. 또한, 샤딩과 같은 분산 처리 기능도 충분히 검증해야 합니다.

### **14.4 마이그레이션 계획**

*   **단계별 마이그레이션 계획 작성 및 동료 검토:**  
    - 데이터베이스 마이그레이션은 매우 복잡한 작업이므로, 철저한 계획을 수립해야 합니다. 각 단계별로 실행할 작업, 예상되는 리스크, 그리고 롤백 계획을 포함해야 하며, 동료들과의 검토를 통해 계획의 완성도를 높여야 합니다.

*   **가능하다면 소규모 서비스부터 마이그레이션하여 경험 축적:**  
    - 처음부터 전체 서비스를 마이그레이션하는 것은 큰 리스크를 동반합니다. 따라서, 우선적으로 소규모 서비스나 비즈니스 영향이 낮은 부분부터 마이그레이션을 시작하여 경험을 축적하고, 이후 점진적으로 확대하는 접근 방식을 권장합니다.


## 15. 유튜브 & 트위치 라이브 스트리밍 작동 방식
- 출처: [How Does Live Streaming Platform Work? (YouTube live, Twitch, TikTok Live)](https://www.youtube.com/watch?v=7AMRfNKwuYo)

### **15.1 라이브 스트리밍의 어려움**

라이브 스트리밍은 실시간으로 진행되는 콘텐츠를 전 세계 시청자에게 제공하기 때문에 기술적으로 여러 도전 과제를 안고 있습니다. 이러한 어려움은 다음과 같은 요소들로 구체화됩니다:

*   **실시간에 가까운 비디오 전송:**  
    - 라이브 스트리밍은 실시간성을 유지해야 하므로, 데이터 전송 지연을 최소화하는 것이 중요합니다. 지연 시간(latency)이 길어질 경우 시청자의 몰입도가 떨어지고, 특히 상호작용이 중요한 게임 스트리밍이나 실시간 채팅에서는 치명적일 수 있습니다.

*   **높은 연산 능력 요구 (비디오 처리):**  
    - 고해상도 비디오를 실시간으로 인코딩하고, 다양한 해상도와 비트레이트로 변환(트랜스코딩)하는 작업은 매우 높은 컴퓨팅 성능을 필요로 합니다. 이는 스트리머의 장비뿐 아니라 플랫폼 서버에서도 중요한 요소입니다.

*   **대용량 비디오 콘텐츠 전송 시간 소요:**  
    - 비디오 데이터는 대용량의 파일 크기를 가지기 때문에, 이를 빠르고 안정적으로 전달하려면 효율적인 네트워크 인프라가 필수적입니다. 특히 전 세계적으로 분산된 시청자들에게 일관된 품질을 제공하려면 CDN(Content Delivery Network)과 같은 기술이 필요합니다.

### **15.2 스트리머 -> 시청자 전송 과정**

라이브 스트리밍의 전체 과정은 여러 단계로 나뉘며, 각 단계에서 특정 기술과 프로토콜이 사용됩니다. 아래는 주요 단계와 그 세부 내용입니다.

1.**스트리머 시작:**
스트리머는 자신의 영상을 촬영한 후 이를 플랫폼으로 전송하기 위해 다양한 도구를 활용
*   **OBS 등 인코더 사용:**  
    - OBS(Open Broadcaster Software)와 같은 소프트웨어 인코더는 비디오를 압축하고 실시간으로 스트리밍할 수 있도록 설정합니다. 이는 CPU/GPU 리소스를 적절히 활용하여 높은 품질의 비디오를 생성합니다.
*   **유튜브 등 플랫폼은 웹캠/모바일 앱으로 간편하게 스트리밍 지원:**  
    - 복잡한 설정 없이도 웹캠이나 모바일 앱을 통해 쉽게 스트리밍을 시작할 수 있는 환경을 제공합니다. 이는 초보 스트리머나 캐주얼 사용자에게 매우 유용합니다.

2.**인코딩:**
비디오 데이터는 네트워크를 통해 전송되기 전에 적절한 형식으로 패키징되어야 합니다.
*   **비디오 스트림을 전송 프로토콜로 패키징:**  
    - 비디오는 특정 프로토콜을 통해 전송되며, 이는 데이터 손실을 최소화하고 효율적인 전송을 보장
*   **주요 프로토콜: RTMP (TCP 기반, Adobe Flash에서 시작):**  
    - RTMP(Real-Time Messaging Protocol)는 과거 Adobe Flash 시대부터 사용된 프로토콜로, TCP 기반으로 안정적인 데이터 전송을 제공합니다. 현재도 많은 플랫폼에서 기본 프로토콜로 사용
*   **대안: SRT (UDP 기반, 낮은 지연, 열악한 네트워크에 강점, but 아직 지원 미흡):**  
    - SRT(Secure Reliable Transport)는 UDP 기반으로 설계되어 RTMP보다 낮은 지연 시간을 제공하며, 불안정한 네트워크 환경에서도 강력한 성능을 발휘합니다. 하지만 아직 모든 플랫폼에서 완벽히 지원되지 않는 한계가 있습니다.

3.**Point-of-Presence (POP) 서버:**
POP 서버는 스트리머와 플랫폼 사이의 중간 역할을 수행합니다.
*   **전 세계에 위치, 스트리머에게 가장 가까운 서버로 연결 (DNS/Anycast):**  
    - POP 서버는 전 세계에 분산 배치되어 있으며, 스트리머는 DNS 또는 Anycast 기술을 통해 자신과 물리적으로 가장 가까운 서버에 연결됩니다. 이는 초기 연결 지연을 줄이고 안정적인 데이터 전송을 보장
*   **빠르고 안정적인 백본 네트워크를 통해 플랫폼으로 전송:**  
    - POP 서버는 고속 백본 네트워크를 통해 플랫폼의 메인 서버로 데이터를 전달합니다. 이 과정에서 데이터 무결성과 전송 속도가 최우선으로 고려됩니다.

4.**플랫폼 처리:**
플랫폼은 받은 비디오 데이터를 시청자에게 제공하기 위해 여러 단계의 처리를 거칩니다.
*   **다양한 품질/비트레이트 제공 (Adaptive Bitrate Streaming):**  
    - 시청자의 네트워크 상태에 따라 비디오 품질을 자동으로 조정하는 기술입니다. 이를 통해 느린 인터넷 환경에서도 원활한 시청이 가능합니다.
*   **처리 단계:**
    1.  **트랜스코딩:**  
        원본 비디오를 다양한 해상도(예: 1080p, 720p, 480p 등)와 비트레이트로 변환합니다. 이 과정은 고성능 서버에서 실행되며, 많은 컴퓨팅 리소스를 소모합니다.
    2.  **세분화:**  
        비디오를 짧은 세그먼트(몇 초 단위)로 분할하여 관리 및 전송 효율성을 높입니다.
    3.  **패키징:**  
        HLS(HTTP Live Streaming), DASH(Dynamic Adaptive Streaming over HTTP)와 같은 표준 스트리밍 형식으로 포장합니다. 이는 다양한 디바이스와 플랫폼에서 호환성을 보장합니다.

5.**CDN (콘텐츠 전송 네트워크):**
CDN은 시청자와 가장 가까운 서버에서 데이터를 캐싱하여 전송합니다.
*   **HLS manifest 및 비디오 청크 캐싱 (last-mile 지연 감소):**  
    - CDN은 HLS manifest 파일과 비디오 세그먼트를 캐싱하여 마지막 단계(last-mile)에서 발생할 수 있는 지연을 줄이고, 더 빠른 로딩 시간을 제공합니다.

6.**시청자 시청:**
최종적으로 시청자는 비디오 플레이어를 통해 스트리밍된 콘텐츠를 시청합니다.
*   **비디오 플레이어로 전송, 약 20초 지연 (glass-to-glass latency):**  
    - glass-to-glass latency는 카메라에서 촬영된 영상이 시청자의 화면에 도달하기까지 걸리는 전체 지연 시간을 의미합니다. 일반적으로 HLS/DASH 기반 스트리밍에서는 약 20초 정도의 지연이 발생

### **15.3 지연 시간 (Latency) 개선**

지연 시간은 라이브 스트리밍의 핵심 문제 중 하나로, 이를 줄이기 위한 다양한 방법이 연구되고 있습니다.
*   **스트리머 또는 플랫폼에서 비디오 품질 일부 희생하여 개선 가능:**  
    - 비디오 품질(예: 해상도, 프레임 레이트)을 조금 낮추면 전송 용량을 줄여 지연 시간을 단축할 수 있습니다. 이는 특히 낮은 네트워크 대역폭 환경에서 효과적입니다.
*   **플랫폼에서 제공하는 상호작용 수준 조절 기능 활용 가능 (블랙박스 형태):**  
    - 일부 플랫폼은 내부적으로 지연 시간을 최적화하는 알고리즘을 제공합니다. 예를 들어, 유튜브의 "저지연 모드"는 지연 시간을 줄이는 대신 일부 품질 저하를 감수합니다.
*   **스트리머는 카메라 -> 플랫폼 간 지연 시간 최소화에 집중 필요:**  
    - 스트리머는 자신의 장비와 네트워크 환경을 최적화하여 카메라에서 플랫폼으로의 지연 시간을 최소화해야 합니다. 예를 들어, 유선 인터넷 사용, 고성능 인코더 활용 등이 포함됩니다.
