---
title: 25차시 9:IBM TECH(종합 내용)
layout: single
classes: wide
categories:
  - IBM TECH(종합 내용)
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 81. Gen AI를 활용한 계약서 내용 추출 
- 출처: [Content Extraction using Large Language Models & JavaScript](https://www.youtube.com/watch?v=GyIaXarpq9w)

### **81.1 문제점**

* **방대한 계약서 분량:** 통상적인 계약서는 50페이지를 훌쩍 넘는 경우가 많아, 내용을 일일이 검토하는 데 많은 시간과 노력이 소요됨. 이는 계약 검토의 효율성을 저해하고, 중요한 정보를 놓칠 가능성을 높임.
* **정보 접근의 어려움:** 필요한 특정 정보를 계약서 내에서 빠르게 찾아내기 어려워, 계약 내용을 기반으로 의사 결정을 내리거나 후속 조치를 취하는 데 상당한 지연이 발생함.

### **81.2 해결책**

* **Gen AI (LLM) 기반 지능형 계약 분석 시스템 구축:**
    * **대화형 정보 추출:** 자연어 처리 능력이 뛰어난 LLM을 활용하여, 사용자가 계약서와 마치 대화하듯이 필요한 정보를 질문하고 즉시 답변을 얻을 수 있도록 지원함. 이는 정보 검색 시간을 획기적으로 단축시키고, 사용 편의성을 높임.
    * **자동 요약 및 구조화된 정보 제공:** 추출된 핵심 정보를 바탕으로 20분 이내에 사람이 이해하기 쉬운 요약 문서를 자동으로 생성하고, 주요 조항을 구조화된 형태로 제공하여 계약 내용의 핵심을 빠르게 파악할 수 있도록 지원함.

### **81.3 사용 LLM 및 역할**

* **Granite.13b.chat (IBM watsonx.ai 기반):** 계약서 텍스트로부터 제목, 계약 당사자 이름, 서비스 내용, 효력 발생일, 보상 조건 등 주요 정보를 정확하게 추출하고, 이를 체계적인 JSON (JavaScript Object Notation) 형식으로 변환하는 역할을 수행함. JSON 형식은 데이터 교환 및 후속 처리의 표준으로, 추출된 정보를 다른 시스템이나 애플리케이션에서 용이하게 활용할 수 있도록 함.
* **Mistral Large (OpenAI 또는 유사 성능 모델):** Granite.13b.chat에서 추출된 JSON 형식의 비정형 데이터를 분석하여, 사람이 직관적으로 이해할 수 있는 표 (Table) 형태로 시각화하는 역할을 담당함. 이는 복잡한 계약 내용을 한눈에 파악할 수 있도록 돕고, 정보의 가독성을 크게 향상시킴.

### **81.4 구현 방법 상세 설명**

1.  **개발 환경 구축 및 필수 요소 준비:**
    * **계약서 파일:** PDF 형식의 계약서 파일을 준비하며, 샘플 코드에서는 편의를 위해 특정 공용 디렉토리에 위치시키는 것을 가정함. 실제 운영 환경에서는 다양한 저장소 (클라우드 스토리지, 사내 서버 등)와의 연동이 필요할 수 있음.
    * **필수 라이브러리 설치:**
        * **Langchain 및 Langchain Community:** PDF 문서 로딩 및 텍스트 분할, LLM과의 연동 등 Gen AI 기반 문서 처리 파이프라인 구축에 필수적인 라이브러리임.
        * **dotenv:** API 키, 프로젝트 ID 등 민감한 환경 변수를 안전하게 관리하기 위해 사용됨.
        * **axios (또는 requests):** 외부 API (watsonx.ai 등)에 HTTP 요청을 보내고 응답을 처리하는 데 필요한 라이브러리임.
        * **Node.js file system module (Python의 경우 `os` 또는 `io`):** 생성된 요약 결과를 `.md` (Markdown) 형식의 파일로 저장하는 데 사용됨.
    * **watsonx 자격 증명 확보:** IBM Cloud 계정에서 API 키 및 watsonx 프로젝트 ID를 발급받고, watsonx.ai API 엔드포인트를 확인하여 `.env` 파일에 안전하게 저장함.

2.  **핵심 기능 구현:**
    * **통합 함수 개발:** 계약서 로딩부터 정보 추출, 표 변환, 결과 저장까지의 전체 과정을 하나의 함수로 통합하여 관리의 용이성을 높임.
    * **API 인증:** watsonx API 호출 시 필요한 Bearer 토큰을 획득하는 로직을 구현하여, 안전하게 API를 사용할 수 있도록 함.
    * **PDF 로딩 및 전처리:** Langchain의 PDF Loader를 사용하여 계약서 PDF 파일을 로드하고, 텍스트 추출 및 필요에 따른 전처리 (텍스트 정제, 분할 등) 과정을 수행함.
    * **첫 번째 LLM (Granite.13b.chat) 호출 및 JSON 추출:**
        * 계약서 텍스트를 프롬프트와 함께 Granite.13b.chat 모델에 전달하여, 사용자가 정의한 정보 (제목, 이름, 서비스, 효력 발생일, 보상)를 추출하도록 지시함.
        * 모델의 응답에서 불필요한 문자 (예: JSON 형식을 감싸는 백틱)를 제거하여, 유효한 JSON 형식의 데이터만 확보함.
    * **두 번째 LLM (Mistral Large) 호출 및 표 변환:**
        * 첫 번째 LLM에서 추출된 JSON 형식의 데이터를 Mistral Large 모델에 입력하고, 사람이 읽기 쉬운 Markdown 표 형식으로 변환하도록 요청함. 효과적인 표 생성을 위해 적절한 프롬프트 엔지니어링이 중요함.
    * **결과 저장:** Node.js의 `fs.writeFile` (또는 Python의 파일 입출력 기능)을 사용하여, 변환된 표 형식의 계약 요약 내용을 `.md` 확장자를 가진 텍스트 파일로 저장함. Markdown 형식은 텍스트 기반으로 가독성이 뛰어나며, 다양한 플랫폼에서 쉽게 렌더링할 수 있다는 장점이 있음.

### **81.5 기대되는 결과 및 확장 가능성**

* **효율적인 계약 내용 파악:** Gen AI를 통해 추출 및 요약된 계약 내용을 통해, 사용자는 방대한 분량의 계약서를 일일이 검토할 필요 없이 핵심 정보를 빠르게 파악하고 이해할 수 있게 됨.
* **시간 및 비용 절감:** 계약 검토에 소요되는 시간과 노력을 획기적으로 줄여 업무 효율성을 높이고, 관련 비용을 절감할 수 있음.
* **의사 결정 지원 강화:** 계약 내용에 대한 빠르고 정확한 이해를 바탕으로, 신속하고 효과적인 의사 결정을 내릴 수 있도록 지원함.
* **다양한 활용 분야:** 추출된 계약 정보는 데이터베이스에 저장하여 관리하거나, 다른 비즈니스 시스템과 연동하여 다양한 방식으로 활용될 수 있음 (예: 계약 만료일 알림, 특정 조항 검색 등).
* **지속적인 성능 개선:** LLM 모델의 발전과 프롬프트 엔지니어링 기법 개선을 통해, 계약 내용 추출 및 요약의 정확성과 효율성을 지속적으로 향상시킬 수 있음. 또한, 다양한 유형의 계약서에 대한 학습을 통해 시스템의 범용성을 확대할 수 있음.

## 82. Tool Calling
- 출처: [What is Tool Calling? Connecting LLMs to Your Data](https://www.youtube.com/watch?v=h8gMhXYAv1k)

### **82.1 Tool Calling 이란?**

- LLM(대규모 언어 모델)이 데이터베이스, API 등 실시간 데이터에 접근할 수 있도록 하는 기술. 주로 챗 인터페이스에서 활용된다.  
    - LLM은 자체적으로 모든 정보를 가지고 있지 않기 때문에, 외부 도구를 호출하여 최신 정보나 특정 작업을 수행한다. 예를 들어, 사용자와의 대화 중 실시간 주식 가격이나 날씨 정보를 제공하려면 Tool Calling이 필수적이다.

### **82.2 전통적인 Tool Calling**

*   **구조:** 클라이언트 애플리케이션과 LLM으로 구성  
    - 클라이언트 애플리케이션은 사용자가 입력한 요청을 처리하고 LLM과 소통하는 중간 역할을 한다. LLM은 도구 호출 로직을 분석하고 추천하는 핵심 엔진이다.

*   **과정:**  
    1. **클라이언트 애플리케이션은 메시지와 Tool Definition을 LLM에게 전달**  
       - 사용자가 "오늘 서울 날씨가 어때?"라고 물으면, 메시지("오늘 서울 날씨가 어때?")와 함께 날씨 API에 대한 Tool Definition(호출 방법, 필요한 입력값 등)이 LLM에 전달된다.  
    2. **LLM은 메시지와 Tool Definition을 분석하여 호출해야 할 Tool을 추천**  
       - LLM은 사용자의 의도를 파악하고, "날씨 API"가 필요하다고 판단하여 호출 방법을 제안한다.  
    3. **클라이언트 애플리케이션은 추천된 Tool을 호출하고 결과를 LLM에게 전달**  
       - 클라이언트가 날씨 API를 호출해 "서울, 20도, 맑음" 같은 데이터를 받아 LLM에 보낸다.  
    4. **LLM은 Tool 결과를 해석하여 다음 Tool 호출을 추천하거나 최종 답변을 제공**  
       - LLM은 "서울 날씨는 맑고 20도네요"라는 답변을 생성하거나, 추가 질문(예: "우산이 필요할까?")에 따라 다른 도구(예: 강수량 API)를 추천할 수 있다.

*   **Tool Definition:**  
    *   **Tool 이름:** 예: "WeatherAPI"  
    *   **Tool 설명 (사용법, 사용 시기 등):** "날씨 정보를 조회할 때 사용하며, 도시 이름과 날짜를 입력으로 받음"  
    *   **Tool 호출에 필요한 입력 파라미터:** "city=Seoul, date=today" 같은 형식으로 정의됨  
    - Tool Definition은 도구 사용 설명서처럼 LLM이 어떤 도구를 언제, 어떻게 써야 하는지 알려주는 역할

*   **Tool 종류:** API(예: 날씨, 주식), 데이터베이스(예: 고객 정보 조회), 코드 인터프리터(예: 수학 계산) 등 다양  
    - 도구의 범위는 단순 데이터 조회부터 복잡한 연산까지 확장 가능하며, LLM의 활용성을 극대화한다.

*   **예시:**  
    *   **사용자 질문:** "마이애미의 온도는?"  
    *   **Tool:** 날씨 API  
    *   **LLM은 질문과 날씨 API Tool Definition을 분석하여 API 호출 방법을 클라이언트에 제공:** "WeatherAPI(city=Miami, unit=Fahrenheit)"  
    *   **클라이언트는 API를 호출하여 날씨 정보(예: 71도)를 LLM에게 전달**  
    *   **LLM은 Tool 결과를 분석하여 최종 답변 (예: "마이애미 날씨는 좋네요. 71도입니다.") 제공**  
    - 이 과정은 LLM이 실시간 데이터를 기반으로 자연스러운 대화를 가능하게 하는 전형적인 사례다.

*   **단점:**  
    *   **LLM이 환각(Hallucination) 현상을 일으킬 수 있음:** LLM이 잘못된 도구를 추천하거나 존재하지 않는 정보를 만들어낼 가능성이 있다. 예를 들어, "마이애미 온도가 300도"라는 터무니없는 답변을 줄 수도 있다.  
    *   **LLM이 부정확한 Tool 호출을 할 수 있음:** Tool Definition을 잘못 해석해 엉뚱한 API를 호출하거나 필요한 파라미터를 누락할 수 있다.

### **82.3 Embedded Tool Calling**

*   **개념:** 라이브러리 또는 프레임워크를 사용하여 LLM 및 Tool Definition과 상호작용하는 방식  
    - 전통적인 방식과 달리, 중간에 도구 호출을 관리하는 전용 라이브러리가 추가되어 LLM의 부담을 줄이고 정확성을 높인다.

*   **구조:** 클라이언트 애플리케이션과 LLM 사이에 라이브러리 존재  
    - 라이브러리는 도구 호출의 "중재자" 역할을 하며, LLM과 클라이언트 간의 원활한 소통을 돕는다.

*   **역할:**  
    *   **Tool Definition 저장 및 관리:** 모든 도구의 정의를 중앙에서 관리해 LLM이 직접 분석할 필요를 줄임.  
    *   **Tool 호출 실행:** LLM이 추천한 도구를 실제로 실행하고 오류를 처리한다.

*   **과정:**  
    1. **클라이언트 애플리케이션은 메시지를 라이브러리로 전달 (예: "마이애미의 온도는?")**  
       - 사용자의 질문이 라이브러리로 먼저 들어간다.  
    2. **라이브러리는 메시지에 Tool Definition을 추가하여 LLM에게 전달**  
       - 라이브러리가 "날씨 API" 정의를 메시지에 붙여 LLM에 보낸다.  
    3. **LLM은 Tool 호출 정보를 라이브러리로 전달**  
       - LLM은 "WeatherAPI(city=Miami)"를 호출하라고 라이브러리에 지시한다.  
    4. **라이브러리는 Tool을 실행하고 최종 답변을 클라이언트 애플리케이션에 제공 (예: "마이애미는 71도입니다.")**  
       - 라이브러리가 API를 호출하고 결과를 받아 직접 답변을 생성하거나 LLM에 다시 보내 자연스러운 문장으로 변환할 수 있다.

*   **장점:**  
    *   **LLM의 환각 현상 방지:** 라이브러리가 도구 호출을 관리하므로 LLM이 잘못된 정보를 생성할 가능성이 줄어든다.  
    *   **Tool 호출 실행 관리 및 재시도 기능 제공:** API 호출이 실패할 경우 라이브러리가 자동으로 재시도하거나 오류를 처리해 안정성을 높인다.

### **82.4 결론**

*   **전통적인 Tool Calling은 LLM이 직접 Tool 호출을 결정하지만, 환각 현상 등의 단점이 존재**  
    - LLM이 모든 판단을 맡아 처리 속도는 빠를 수 있으나, 정확성에서 취약점이 드러난다.  
*   **Embedded Tool Calling은 라이브러리를 통해 Tool 호출을 관리하여 환각 현상을 방지하고 Tool 실행을 지원**  
    - 라이브러리가 중간에서 도구 호출을 체계적으로 관리해 신뢰성을 높인다.  
*   **Embedded Tool Calling은 API, 데이터베이스, 코드 등 다양한 Tool 활용에 유용**  
    - 복잡한 작업 환경에서도 유연하게 대응 가능하며, 실시간 데이터 활용의 새로운 표준으로 자리 잡을 가능성이 크다.


## 83. AI 웹 애플리케이션 구축
- 출처: [Building AI Applications with Large Language Models](https://www.youtube.com/watch?v=xBSMBEowLcY&t=1s)

### **83.1 개요**

*   최근 웹 개발자들이 **AI 어플리케이션** (예: 챗봇, 코드 어시스턴트, 추천 시스템 등)을 직접 구축하거나 통합하는 사례가 늘어나고 있음  
*   AI 기술이 복잡하게 느껴질 수 있지만, **기본 원리와 구조를 이해하면 구현 자체는 비교적 단순**함  
*   특히, LLM 기반 어플리케이션에서는 **"질문 → 응답"이라는 대화형 흐름**이 핵심이며, 이를 단계별로 이해하면 개발에 큰 도움이 됨

### **83.2 일반적인 어플리케이션 구조**

*   **UI (User Interface):** 사용자가 질문이나 명령을 입력하는 창구 (예: 입력 폼, 챗 인터페이스)  
    → 프론트엔드에서 사용자와 LLM 사이의 인터랙션을 담당  
*   **라이브러리/프레임워크:** UI와 백엔드(API) 사이를 연결하고, 요청/응답 흐름을 관리 (예: Flask, FastAPI, Streamlit, React 등)  
    → 일부 프레임워크는 AI 응답을 렌더링하거나 상태를 관리하는 기능도 제공  
*   **API:** GPT, Claude, Gemini 등 **LLM을 제공하는 외부 API**  
    → 클라우드 기반으로 제공되며, 프롬프트를 보내고 응답을 받는 형태로 사용

### **83.3 AI 어플리케이션 구현 패턴 3가지**

| 패턴                    | 설명                                                                                                                                                                                                                                                                                                                                        | 구현 방식                                   |
| :---------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------ |
| **기본 프롬프팅**           | *   사용자의 질문에 대해, LLM이 더 정확한 답변을 하도록 **프롬프트에 명확한 지시문**을 함께 포함함 (예: "친절한 어시스턴트가 되어줘", "거짓 정보를 제공하지 마")<br>*   이 방식은 **가장 단순하지만 빠르게 결과를 얻을 수 있는 방법**이며, 초기 프로토타입이나 데모 제작에 적합함                                                                                             | API 또는 SDK 활용 (LLM 제공 업체 제공)      |
| **RAG (검색 증강 생성)** | *   사용자의 질문을 **임베딩(embedding)**한 후, 벡터 DB에서 **유사한 문서나 데이터(context)**를 검색<br>*   검색된 내용을 바탕으로 LLM이 더 정확하고 **문맥에 맞는 답변**을 생성함<br>*   RAG는 내부 문서를 기반으로 한 챗봇이나 고객센터에 유용하며, 사전 데이터 구축과 벡터화 과정이 필요함                                                                                                  | 라이브러리/프레임워크 활용 (LangChain, LlamaIndex 등)                  |
| **AI 에이전트**             | *   질문을 받은 **에이전트**가 이를 분석하고, 필요한 경우 **외부 도구(API, DB 조회, 웹 크롤링 등)**를 이용해 정보를 수집하거나 작업을 수행<br>*   에이전트는 여러 단계를 **계획하고 실행하는 능력**을 가지며, 복잡한 문제 해결에 적합<br>*   **다중 에이전트 시스템**에서는 여러 전문 역할의 에이전트를 조율하는 **슈퍼바이저 에이전트**가 동작할 수 있음                                                    | 프레임워크/라이브러리 활용 (LangGraph, AutoGen, CrewAI 등 다양한 구현 방식 존재) |


### **83.4 핵심 내용 요약**

*   **기본 프롬프팅:** 질문과 함께 간단한 지시사항을 프롬프트에 담아 LLM의 답변 품질을 향상시킴  
*   **RAG:** 사용자의 질문과 유사한 문서를 벡터 DB에서 검색하여, LLM에게 정확한 컨텍스트를 제공  
*   **AI 에이전트:** 도구 활용이 가능한 지능형 에이전트가 질문을 분석하고, 필요한 행동을 수행하여 종합적인 답변을 생성


## 84. LLM(대규모 언어 모델)의 사고 능력에 대한 의문
- 출처: [Can AI Think? Debunking AI Limitations](https://www.youtube.com/watch?v=CB7NNsI27ks)

### **84.1 주요 내용**
1. **수학 문제 예시:** 
    - LLM이 "작은 키위 5개"라는 불필요한 정보에 얽매여 계산 오류를 범하는 사례를 제시하며, LLM의 추론 능력에 대한 의문을 제기함. 이는 LLM이 문제의 본질을 파악하지 못하고 맥락과 무관한 정보에 영향을 받는 취약점을 보여주는 예시로, 진정한 이해력의 부재를 시사함.

2. **확률적 패턴 매칭:** 
    - LLM은 훈련 데이터에서 가장 유사한 패턴을 찾아 답변하는 경향이 있으며, 이 때문에 맥락을 제대로 이해하지 못하고 오류를 범할 수 있음. 이는 LLM이 실제로 문제를 이해하고 해결하는 것이 아니라, 통계적 패턴을 기반으로 응답을 생성한다는 점을 강조하며, 실제 인간의 사고 과정과는 근본적으로 다름을 시사함.

3. **토큰 편향:** 
    - LLM은 입력 토큰의 작은 변화에도 민감하게 반응하며, 이는 프롬프트 엔지니어링을 통해 개선할 수 있지만, 근본적인 한계를 드러냄. 동일한 의미를 가진 문장이라도 표현 방식에 따라 완전히 다른 결과를 도출하는 현상은 LLM의 진정한 이해력 부재를 보여주는 증거로 볼 수 있음.

4. **사고의 모방:** 
    - LLM은 단순히 고도의 자동 완성 시스템처럼 다음 단어, 문장, 문단을 예측하는 방식으로 작동할 수 있으며, 이는 진정한 사고와는 거리가 멀다는 비판이 제기됨. LLM이 보여주는 '사고'는 실제 사고가 아닌 방대한 데이터에서 추출한 패턴의 재생산에 가까우며, 의식적 사고 과정과는 본질적으로 다른 메커니즘임.

5. **추론 시간 연산:** 
    - 최근 모델들은 추론 시간 연산을 통해 LLM의 추론 능력을 향상시키고 있으며, 훈련 데이터 개선과 프롬프트 엔지니어링을 통해 더욱 발전할 가능성이 있음. 이러한 기술적 발전은 LLM의 추론 능력을 향상시키지만, 이것이 진정한 사고 능력의 발달인지, 단순히 더 정교한 시뮬레이션인지에 대한 철학적 질문은 여전히 남아있음.

6. **사고 vs 시뮬레이션:** 
    - LLM은 의식, 목표 지향성, 주관적 이해, 적응성 없이 실제 사고와 언어 사용 패턴에 맞는 응답을 생성하여 사고의 외형을 흉내내는 것일 뿐이라는 주장이 제기됨. LLM은 내적 경험이나 의도 없이 인간의 인지 과정을 모방하는 것으로, 겉으로는 유사해 보이지만 본질적으로는 다른 프로세스임을 강조함.

### **84.2 핵심 질문**
* LLM은 진정으로 사고하는가, 아니면 사고를 시뮬레이션하는가? 이 질문은 인공지능의 본질과 의식에 대한 철학적 탐구로 이어지며, 인간 고유의 능력과 기계적 모방의 경계에 대한 근본적인 의문을 제기함.
* 인간의 사고와 AI의 사고는 어떻게 다른가? 인간의 사고는 경험, 의식, 정서, 맥락적 이해를 바탕으로 하는 반면, AI의 '사고'는 패턴 인식과 통계적 예측에 기반한 프로세스로 볼 수 있음.

### **84.3 주요 용어**
* LLM (Large Language Model): 
    - 대규모 언어 모델로, 방대한 텍스트 데이터로 훈련되어 인간과 유사한 텍스트를 생성할 수 있는 인공지능 시스템.
* 확률적 패턴 매칭 (Probabilistic Pattern Matching): 
    - LLM이 훈련 데이터에서 유사한 패턴을 찾아 답변하는 방식으로, 진정한 이해보다는 통계적 유사성에 기반함.
* 토큰 편향 (Token Bias): 
    - 입력 토큰의 작은 변화가 LLM의 추론 결과에 큰 영향을 미치는 현상으로, LLM의 맥락 이해 능력의 한계를 보여줌.
* 체인 오브 소트 프롬프팅 (Chain of Thought Prompting): 
    - LLM에게 단계별 추론 과정을 포함하도록 유도하는 프롬프트 엔지니어링 기술로, 복잡한 문제 해결 능력을 향상시킴.
* 추론 시간 연산 (Inference Time Compute): 
    - LLM이 답변을 생성하기 전에 추론 시간을 갖도록 하는 기술로, 더 정확하고 깊이 있는 응답을 생성하는 데 도움을 줌.

## 85. 대규모 언어 모델 (LLM) 컨텍스트 창 (Context Window)
- 출처: [What is a Context Window? Unlocking LLM Secrets](https://www.youtube.com/watch?v=-QVoIxEpFkM)

### **85.1 컨텍스트 창이란?**

*   LLM의 "작업 기억 (working memory)"에 해당  
    *   인간의 단기 기억과 유사한 개념으로, 모델이 현재 처리 중인 정보를 일시적으로 보관하는 공간
    *   이 공간을 벗어난 정보는 점차 희미해지거나 완전히 소실됨
*   LLM이 대화 내용을 잊지 않고 얼마나 길게 대화를 이어갈 수 있는지를 결정  
    *   예: 4,000 토큰 컨텍스트 창은 약 3,000단어 분량의 대화 기록 유지 가능
    *   대화가 길어질수록 초반 내용은 자연스럽게 맥락에서 사라짐
*   컨텍스트 창을 넘어서는 대화 내용은 LLM이 기억하지 못함  
    *   "이전에 말한 내용을 기반으로..."라는 질문에 오류 발생 가능성 증가
*   기억하지 못하는 내용은 추론에 의존하며, 환각 (hallucination) 현상 발생 가능성 증가  
    *   맥락 부재 시 모델은 그럴듯한 허구의 답변을 생성할 수 있음

### **85.2 토큰 (Token) 이란?**

*   LLM이 언어를 처리하는 최소 단위  
    *   컴퓨터가 이해할 수 있는 텍스트의 "원자(atom)" 개념
*   문자, 단어의 일부분, 전체 단어, 짧은 구절 등이 될 수 있음  
    *   영어: "unhappiness" → ["un", "happiness"] (2 토큰)
    *   한국어: "사랑해요" → ["사랑", "해요"] (2 토큰)
*   문맥에 따라 같은 문자라도 토큰으로 분리될 수도, 그렇지 않을 수도 있음 (예: "a"가 단어일 때 vs. 단어의 일부일 때)  
    *   "a pen" → ["a", "pen"] (2 토큰)
    *   "apple" → ["apple"] (1 토큰)
*   **토크나이저 (Tokenizer):** 언어를 토큰으로 변환하는 도구 (토크나이저마다 결과가 다를 수 있음)  
    *   모델 제조사별로 고유한 토크나이저 사용 (예: GPT-4 vs Claude 3)
    *   한국어는 공백 기반 분리가 어려워 전용 토크나이저 필요
*   일반적으로 영어 단어 1개는 1.5개 정도의 토큰으로 표현됨 (단어 100개 = 약 150 토큰)  
    *   한국어는 영어보다 평균 1.2~1.3배 더 많은 토큰 소모
    *   "반갑습니다" → 2-3 토큰 (모델에 따라 상이)

### **85.3 컨텍스트 창의 크기**

*   초기 LLM: 약 2,000 토큰  
    *   GPT-3 초기 버전 기준 약 1,500단어 수준
    *   중간 길이 논문 초록(200자) 약 10편 분량
*   IBM Granite 3 모델: 128,000 토큰  
    *   약 300페이지 분량의 문서 처리 가능
    *   영화 대본 2편 분량(일반적인 시나리오 약 60,000단어)
*   더 큰 컨텍스트 창을 가진 모델도 존재  
    *   Claude 3 (200K 토큰): 약 150,000단어 또는 500페이지 책 처리
    *   GPT-4 Turbo (128K): 기술 문서 전체 분석 가능

### **85.4 컨텍스트 창에 포함되는 요소**

*   사용자 입력 (프롬프트)  
    *   현재 질문뿐 아니라 이전 대화 기록 전체
*   모델 응답  
    *   생성된 모든 답변도 컨텍스트 창 공간 차지
*   **시스템 프롬프트 (system prompt):** 모델의 동작 방식 설정 (사용자에게는 숨겨져 있는 경우가 많음)  
    *   "너는 전문 번역가야" 같은 역할 지시문
    *   약 500-1,000토큰 정도 소모
*   사용자가 첨부한 문서 또는 소스 코드  
    *   PDF/PPT 파일 변환 시 예상보다 2-3배 더 많은 토큰 발생 가능
*   검색 증강 생성 (RAG)을 위한 외부 데이터  
    *   벡터 데이터베이스에서 검색된 참조 자료들

### **85.5 컨텍스트 창 크기의 중요성**

*   컨텍스트 창 크기가 클수록 모델이 더 많은 정보를 기억하고 활용 가능  
    *   장편 소설 분석, 긴 코드베이스 이해, 복잡한 논리 흐름 추적 가능
    *   예: 100K 토큰 창에서는 3시간 분량의 회의 기록 전체 분석
*   특정 작업에 대한 최적 창 크기 존재  
    *   이메일 답장: 2K-4K 토큰  
    *   학술 논문 검토: 8K-32K 토큰  
    *   법률 문서 분석: 64K-128K 토큰

### **85.6 긴 컨텍스트 창의 문제점**

*   **높은 연산 비용:** 입력 토큰 수가 2배로 늘어나면 처리 능력은 4배로 증가 (계산 복잡도가 토큰 수에 따라 제곱으로 증가)  
    *   ️128K 토큰 처리 시 2K 토큰 대비 약 4,096배 더 많은 계산 필요
    *   클라우드 비용 직결 → API 가격 상승 요소
*   **모델 성능 저하:** 정보 과부하, 인지적 지름길 사용 등으로 모델 성능 저하 가능성 (중간에 있는 정보보다 앞뒤에 있는 정보에 더 집중하는 경향)  
    *   "중간 내용 무시 현상"(Lost-in-the-Middle): 128K 중 20K-40K 구간에서 정확도 15-30% 하락
    *   장문 문서에서 특정 사실을 찾을 때 25% 낮은 정확도
*   **보안 문제:** 악성 콘텐츠 삽입을 통한 공격 (jailbreaking) 가능성 증가  
    *   시스템 프롬프트를 100페이지 분량의 텍스트 속에 숨겨 전달
    *   암호화된 명령어를 장문의 무의미한 텍스트에 삽입

### **85.7 결론**

*   컨텍스트 창 크기는 모델 성능에 중요한 영향을 미침  
    *   작은 창: 빈번한 맥락 상실  
    *   과도하게 큰 창: 연산 자원 낭비 및 성능 저하
*   적절한 컨텍스트 창 크기를 선택하는 것이 중요 (정보량과 연산 비용, 성능, 보안 간의 균형)  
    *   일반적 권장 사항:  
        - 간단한 Q&A: 4K-8K  
        - 문서 분석: 문서 길이 × 1.3 (안전 계수)  
        - 장기 대화: 32K+ (주기적 요약 메커니즘 병행)

## 86. Lag-Llama 모델을 활용하여 식물 관리를 최적화
- 출처: [Time Series Forecasting with Lag Llama](https://www.youtube.com/watch?v=MOOPuizuf6o)

### **86.1 목표**
- **뉴욕의 야간 최저 기온 예측**: 이 프로젝트는 뉴욕의 10월과 11월 시간별 기온 데이터를 기반으로, 야간 최저 기온을 예측하는 것이 핵심입니다. 이는 특정 화분(오렌지 맘)이 빙점 이하의 온도에서 손상될 수 있기 때문에 실내로 옮겨야 할 시기를 결정하기 위함입니다.
- **실제 응용 가능성**: Lag-Llama 모델을 통해 기존의 전통적인 방법보다 더 정확하고 신뢰할 수 있는 예측을 제공하며, 이를 통해 식물 관리에 직접적인 영향을 미칠 수 있습니다.

### **86.2 데이터**
- **데이터 소스**: ACS Web services에서 수집된 시간별 기온 데이터를 사용합니다. 이 데이터는 뉴욕시의 실제 기온 변화를 반영하며, 특히 가을철(10월~11월)의 기온 패턴을 분석하는 데 적합합니다.
- **데이터의 중요성**: 시간별 데이터는 시계열 예측 모델에서 매우 중요한 입력입니다. 이는 날씨의 계절적 패턴, 주기성, 그리고 갑작스러운 변동성을 모두 포착할 수 있기 때문입니다.


### **86.3 Lag-Llama 모델의 특징**
1. **Zero-shot forecasting**:
   - 사전 학습 없이 새로운 데이터셋에 적용 가능합니다. 이는 모델이 이미 다양한 시계열 데이터를 학습했기 때문에, 특정 도시나 지역의 데이터에 맞게 fine-tuning할 필요가 없다는 것을 의미합니다.
   - 예를 들어, 뉴욕의 기온 데이터를 바로 예측할 수 있습니다.

2. **대규모 시계열 데이터셋으로 학습됨**:
   - Lag-Llama 모델은 Meta AI에서 개발한 Foundation 모델로, 글로벌 기온, 경제 지표, 판매량 등 다양한 유형의 시계열 데이터로 사전 학습되었습니다. 이는 모델이 일반화된 시계열 패턴을 학습했음을 의미합니다.

3. **Transformer 구조 기반**:
   - Transformer 아키텍처는 자연어 처리(NLP)에서 널리 사용되며, 복잡한 패턴과 장기 의존성을 효과적으로 학습할 수 있습니다. 이는 시계열 데이터에서도 유사한 강점을 발휘합니다.

4. **ARIMA와 유사한 Lag feature 활용**:
   - ARIMA 모델은 과거 데이터를 기반으로 미래를 예측하는 전통적인 시계열 모델입니다. Lag-Llama 모델 역시 과거 데이터를 활용하지만, Transformer 구조를 통해 더 복잡한 비선형 패턴을 학습할 수 있습니다.

### **86.4 프로젝트 단계**
1. **환경 설정**
- **GitHub 저장소 복제**:
  - IBM watsonx.ai studio를 사용하여 작업 환경을 구성합니다. 그러나 다른 머신러닝 환경에서도 동일한 작업이 가능합니다.
- **Hugging Face 저장소**:
  - Hugging Face는 오픈 소스 모델 및 리소스를 공유하는 플랫폼입니다. 여기서 Lag-Llama 모델의 사전 학습된 가중치를 다운로드합니다.
- **GluonTS 라이브러리 설치**:
  - GluonTS는 시계열 데이터를 다루고 예측 모델을 구현하기 위한 PyTorch 기반 라이브러리입니다. 데이터 처리, 모델 학습, 예측 평가 등을 지원합니다.

2. **데이터 준비**
- **결측값 보간**:
  - 시간별 데이터에는 결측값이 포함될 수 있습니다. 이를 해결하기 위해 보간(interpolation) 기법을 사용하여 데이터를 채웁니다. 이는 예측 모델의 성능을 향상시키는 데 중요합니다.

3. **모델 설정**
- **prediction_length**:
  - 예측할 시간 단계 수를 정의합니다. 여기서는 8시간(하룻밤) 동안의 기온을 예측합니다.
- **context_length**:
  - 과거 데이터를 참조할 기간을 설정합니다. 여기서는 1주일(7일)의 데이터를 활용하여 예측 모델이 과거 패턴을 학습하도록 합니다.

4. **예측 모델 생성**
- **Lag Estimator**:
  - Lag-Llama 모델의 파라미터를 복사하여 사용자 정의 예측기를 생성합니다.
- **Lag Predictor**:
  - `create_predictor` 메서드를 사용하여 최종 예측 모델을 생성합니다.

5. **예측 생성**
- **11월 말 기온 예측**:
  - 모델을 사용하여 11월 말의 기온을 예측합니다. 이는 오렌지 맘 화분을 실내로 옮길 시기를 결정하는 데 중요한 정보입니다.
- **make_evaluation_predictions**:
  - GluonTS 라이브러리의 메서드를 사용하여 예측 결과를 생성합니다.

6. **예측 평가**
- **MAPE (Mean Absolute Percentage Error)**:
  - 예측 모델의 정확도를 평가하기 위해 MAPE를 사용합니다. 이는 실제 값과 예측 값의 차이를 백분율로 표현한 지표입니다.
- **Evaluator 객체**:
  - GluonTS의 Evaluator 객체를 사용하여 예측 성능을 체계적으로 분석합니다.

7. **결과 시각화 및 분석**
- **예측 결과 그래프**:
  - 실제 기온, 예측 기온, 그리고 50% 및 90% 예측 구간을 시각화합니다. 이는 예측의 신뢰도를 확인하는 데 도움을 줍니다.
- **화분 이동 시기 결정**:
  - 50% 예측 구간이 빙점(0°C) 이하로 내려갈 경우, 화분을 실내로 옮기는 것이 안전하다고 판단합니다.

8. **결론**
- **Foundation 모델의 유망성**:
  - Lag-Llama 모델은 시계열 예측에서 높은 성능을 보여주며, 다양한 분야에 응용 가능성을 제시합니다.
- **응용 가능성**:
  - 이 프로젝트는 Lag-Llama 모델을 활용하여 식물 관리에 직접적인 도움을 줄 수 있음을 보여줌.

### **86.5 주요 용어**
- **Lag-Llama**:
  - Meta AI에서 개발한 Foundation 모델로, 시계열 예측에 특화되어 있습니다.
- **Foundation Model**:
  - 대량의 데이터로 사전 학습된 모델로, 다양한 작업에 적용할 수 있습니다.
- **Zero-shot forecasting**:
  - 사전 학습 없이 새로운 데이터셋에 바로 적용 가능한 예측 방식입니다.
- **GluonTS**:
  - 시계열 데이터를 처리하고 예측 모델을 구현하기 위한 오픈 소스 라이브러리입니다.
- **MAPE (Mean Absolute Percentage Error)**:
  - 예측 정확도를 평가하는 지표로, 실제 값과 예측 값의 차이를 백분율로 나타냅니다.
- **Prediction Interval**:
  - 예측값의 불확실성을 나타내는 구간으로, 신뢰도를 평가하는 데 사용됩니다.

### **86.7 마무리**
- 이 프로젝트는 Lag-Llama 모델을 활용하여 뉴욕의 야간 최저 기온을 예측하고, 이를 통해 오렌지 맘 화분을 실내로 옮길 시기를 결정하는 데 초점을 맞추고 있습니다. 이를 통해 시계열 예측 모델의 실용적 가치를 확인할 수 있으며, 식물 관리 외에도 다양한 분야에 응용 가능성을 제시합니다. 

- Lag-Llama 모델은 Zero-shot forecasting과 Transformer 구조를 통해 시계열 데이터 예측에서 뛰어난 성능을 보여주며, 이를 통해 실질적인 문제 해결에 기여할 수 있습니다.  

- Lag-Llama 모델은 시계열 예측의 혁신적인 도구로, 화분 관리뿐만 아니라 농업, 기후 연구 등 다양한 분야에서 활용될 수 있습니다.

## 87. 텍스트-이미지 생성 모델 (Diffusion Models)
- 출처: [Diffusion Models for AI Image Generation](https://www.youtube.com/watch?v=x2GRE-RzmD8)

### **87.1 핵심 아이디어**

* **비유 설명:** 
    - 마치 맑은 물에 잉크를 한 방울씩 떨어뜨리면 점점 물 전체로 퍼져나가 흐릿해지는 것처럼, 이미지 생성 과정은 깨끗한 이미지에 점진적으로 무작위 노이즈를 더해 완전히 망가뜨리는 과정(정방향 확산)을 거칩니다. 
    - 그런 다음, 이 완전히 노이즈로 뒤덮인 상태에서 잉크가 퍼지는 과정을 거꾸로 되돌리듯, 단계적으로 노이즈를 제거하여 원래의 깨끗한 이미지를 복원하는 방식(역방향 확산)으로 새로운 이미지를 만들어냄.

### **87.2 구성 요소**

1.  **Forward Diffusion (정방향 확산): 이미지 파괴 과정**
    * **점진적 노이즈 추가:** 
        - 원본 이미지를 여러 단계에 걸쳐 조금씩 흐릿하게 만듭니다. 각 단계마다 이미지의 세부 정보는 점차 사라지고 결국에는 단순한 노이즈 덩어리처럼 보이게 됩니다.
    * **마르코프 체인:** 
        - 각 단계에서의 이미지 상태는 바로 이전 단계의 상태에만 영향을 받습니다. 즉, 현재의 흐릿한 이미지는 바로 직전의 덜 흐릿한 이미지에 노이즈를 추가한 결과이며, 그 이전 단계의 정보는 직접적으로 영향을 주지 않습니다. 이는 계산 효율성을 높이는 중요한 특징입니다.
    * **가우시안 노이즈:** 
        - 이미지의 각 픽셀 값에 평균이 0이고 특정 분산을 갖는 무작위 값을 더합니다. 이는 자연스러운 형태의 노이즈이며, 통계적으로 다루기 용이합니다.
    * **노이즈 스케줄러:** 
        - 각 단계에서 추가되는 가우시안 노이즈의 분산(퍼짐 정도)을 결정하는 역할을 합니다. 이 스케줄러를 통해 노이즈를 얼마나 빠르고 강하게 추가할지를 조절할 수 있으며, 최종 이미지 생성 품질에 큰 영향을 미칩니다. 
        - 예를 들어, 초반에는 미세한 노이즈를 추가하고 후반으로 갈수록 더 큰 노이즈를 추가할 수도 있습니다.

2.  **Reverse Diffusion (역방향 확산): 이미지 복원 및 생성 과정**
    * **노이즈 제거 학습:** 
        - 완전히 노이즈로 뒤덮인 이미지에서 원래 이미지의 특징을 되살리기 위해, U-Net이라는 특별한 형태의 심층 신경망 모델을 학습시킵니다. 
        - 이 모델은 각 시간 단계에서 이미지에 추가된 노이즈를 "예측"하고, 그 예측된 노이즈를 제거하는 방식으로 이미지를 점진적으로 깨끗하게 만듭니다.
    * **U-Net 모델:** 
        - 이미지 처리 분야에서 뛰어난 성능을 보이는 합성곱 신경망 구조입니다. 
        - 인코더-디코더 구조를 가지며, 스킵 커넥션을 통해 저수준 특징과 고수준 특징을 결합하여 세밀한 이미지 복원에 효과적입니다.
    * **반복적인 노이즈 제거:** 
        - 모델은 한 번에 모든 노이즈를 제거하는 것이 아니라, 아주 작은 양의 노이즈를 단계적으로 제거하는 과정을 반복합니다. 이 과정을 통해 점차적으로 의미 있는 이미지 구조가 나타나게 됩니다.

3.  **Conditional Diffusion (조건부 확산) / Guided Diffusion (안내 확산): 원하는 대로 이미지 생성**
    * **텍스트 프롬프트 활용:** 
        - 사용자가 원하는 이미지에 대한 설명을 텍스트 형태로 입력하면, 모델은 이 텍스트의 의미를 이해하고 그에 맞는 이미지를 생성합니다.
    * **텍스트 임베딩:** 
        - 텍스트 프롬프트를 컴퓨터가 이해할 수 있는 숫자 벡터 형태로 변환하는 기술입니다. 이를 통해 텍스트의 의미를 모델에 효과적으로 전달할 수 있습니다. 
        - 다양한 자연어 처리 모델(예: Transformer)을 사용하여 고품질의 텍스트 임베딩을 얻을 수 있습니다.
    * **이미지-텍스트 쌍 학습:** 
        - 모델은 수많은 이미지와 그에 대한 텍스트 설명을 함께 학습합니다. 이를 통해 특정 텍스트가 주어졌을 때 어떤 이미지 특징이 나타나야 하는지를 학습합니다.
    * **셀프 어텐션 가이던스:** 
        - 텍스트 프롬프트 내의 각 단어(또는 토큰)가 생성될 이미지의 어떤 특정 영역이나 특징에 집중해야 하는지를 모델 스스로 학습하고 조절합니다. 
        - 예를 들어, "파란색 꽃"이라는 프롬프트가 주어졌을 때, 모델은 "파란색"이라는 단어에 집중하여 이미지 내의 꽃 영역을 파란색으로 생성하도록 안내합니다.
    * **분류기 없는 가이던스:** 
        - 별도의 분류기 모델 없이, 텍스트 프롬프트의 특정 단어가 이미지 생성 과정에 미치는 영향을 강화하는 방식입니다. 이를 통해 사용자가 원하는 스타일이나 특징을 더욱 뚜렷하게 반영하는 이미지를 생성할 수 있습니다. 
        - 예를 들어, "고양이"라는 단어의 영향을 높이면 고양이의 특징이 더욱 강조된 이미지가 생성될 수 있습니다.

**활용 분야:**

* **텍스트-이미지 생성:** 
    - 주어진 텍스트 설명을 기반으로 완전히 새로운 이미지를 생성합니다 (예: DALL-E 3, Stable Diffusion).
* **이미지-이미지 변환:** 
    - 특정 이미지의 스타일을 다른 이미지에 적용하거나, 이미지의 해상도를 높이거나, 흑백 이미지를 컬러로 변환하는 등 다양한 이미지 편집 작업에 활용됩니다.
* **이미지 복원 (in-painting):** 
    - 이미지의 특정 부분을 지우고 그 부분을 자연스럽게 채워 넣는 기술입니다.
* **오디오, 비디오 생성:** 
    - 이미지뿐만 아니라 오디오나 비디오 데이터를 생성하는 데에도 Diffusion 모델의 기본 원리가 응용될 수 있습니다.
* **다양한 산업 분야:** 
    - 마케팅 콘텐츠 제작, 의료 영상 분석, 신약 개발을 위한 분자 모델링 등 창의성과 데이터 생성이 중요한 다양한 분야에서 혁신적인 도구로 활용될 수 있습니다.

**결론:** 
- Diffusion models은 노이즈를 점진적으로 다루는 독특한 접근 방식을 통해 매우 현실적이고 다양한 이미지를 생성할 수 있는 강력한 기술입니다. 특히 텍스트 프롬프트와 결합하여 사용자의 의도를 정확하게 반영하는 이미지를 만들 수 있다는 점에서 인공지능 기반 콘텐츠 생성 분야에 큰 영향을 미치고 있습니다.

## 88. 반지도 학습 (Semi-Supervised Learning)
- 출처: [What is Semi-Supervised Learning?](https://www.youtube.com/watch?v=C3Lr6Waw66g)

### **88.1 정의**

*   레이블된 데이터가 부족할 때, 레이블되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 방법.  
    *   즉, 소량의 정답(레이블)이 있는 데이터와 대량의 정답이 없는 데이터를 함께 사용하여, 모델이 더 많은 패턴을 학습하도록 돕는 기법입니다. 예를 들어, 이미지 분류에서 고양이 사진 10장만 레이블이 있고 나머지 1,000장은 레이블이 없는 경우, 이 1,000장을 버리지 않고 활용하는 방식입니다.

### **88.2 필요성 (Why?)**

*   **과적합(Overfitting) 방지:** 레이블된 데이터가 적으면 모델이 훈련 데이터에만 너무 맞춰져 새로운 데이터에 대한 일반화 능력이 떨어짐. 레이블되지 않은 데이터를 활용하여 데이터셋을 확장하는 효과를 획득.
    *   예를 들어, 학생이 교과서 몇 페이지로만 시험을 준비하면 그 부분만 외우게 되지만, 추가적인 참고 자료를 보면 더 넓은 이해를 할 수 있는 것과 비슷합니다. 레이블되지 않은 데이터는 모델이 더 풍부한 맥락을 파악하게 해줍니다.
*   **데이터 레이블링 비용 절감:** 데이터 레이블링은 시간과 비용이 많이 들고, 특히 전문 지식을 요구하는 경우 더욱 어려움.  
    *   의료 이미지처럼 전문가가 질병 여부를 판단해야 하는 경우, 모든 데이터에 레이블을 붙이는 데는 막대한 자원이 필요합니다. 반지도 학습은 이런 부담을 줄여줍니다.

### **88.3 작동 방식 (How?)**

*   **래퍼(Wrapper) 방법:**  
    *   레이블된 데이터로 기본 모델을 훈련.  
        *   예: 고양이와 강아지를 구분하는 모델을 10장의 레이블된 사진으로 처음 학습시킵니다.
    *   훈련된 모델을 사용하여 레이블되지 않은 데이터에 대한 **가짜 레이블(Pseudo-label)**을 예측.  
        *   이 모델이 1,000장의 레이블 없는 사진을 보고 “이건 고양이일 확률 90%”처럼 추측합니다.
    *   높은 신뢰도를 가진 가짜 레이블을 원래 레이블된 데이터와 결합하여 새로운 데이터셋을 생성.  
        *   확률 90% 이상인 경우만 믿고, 10장 + 새로 만든 500장의 데이터셋을 만듭니다.
    *   새로운 데이터셋으로 모델을 재훈련. 이 과정을 반복하며 가짜 레이블의 품질을 향상시킴.  
        *   반복할수록 모델이 더 똑똑해지고, 가짜 레이블도 점점 실제에 가까워집니다.
*   **비지도 전처리(Unsupervised Pre-processing):**  
    *   **오토인코더(Autoencoder)**를 사용하여 이미지의 주요 특징 (모서리, 모양, 질감 등)을 추출하여 더 간결하고 의미 있는 방식으로 표현.  
        *   오토인코더는 사진을 압축했다가 복원하며 중요한 부분(고양이 귀 모양 등)을 학습합니다.
    *   추출된 특징을 사용하여 지도 학습 모델을 훈련시켜 일반화 능력을 향상시킴.  
        *   이렇게 하면 잡음이나 불필요한 세부 사항에 덜 민감한 모델이 됩니다.
*   **클러스터링 기반 방법:**  
    *   유사한 데이터 포인트는 동일한 클래스에 속할 가능성이 높다는 **클러스터 가정(Cluster Assumption)**을 이용.  
        *   비슷한 모양의 사진은 같은 동물일 가능성이 높다는 아이디어입니다.
    *   K-평균(K-means)과 같은 클러스터링 알고리즘을 사용하여 레이블된 데이터와 레이블되지 않은 데이터를 클러스터로 그룹화.  
        *   예: 사진을 3개의 그룹으로 나눠서 고양이/강아지/기타로 묶습니다.
    *   동일한 클러스터 내의 레이블된 데이터의 레이블을 사용하여 레이블되지 않은 데이터에 가짜 레이블을 할당.  
        *   고양이 사진이 많은 클러스터에 있는 미레이블 사진도 고양이로 추정합니다.
*   **능동 학습(Active Learning):**  
    *   모델이 신뢰도가 낮은 가짜 레이블을 가진 샘플을 식별.  
        *   “이 사진은 50% 고양이, 50% 강아지”처럼 헷갈리는 경우를 찾습니다.
    *   사람이 해당 샘플에 레이블을 지정하도록 요청하여 모델 성능을 향상시킴.  
        *   전문가에게 “이건 뭐예요?”라고 물어보고 답을 추가해 학습합니다.

### **88.4 방법들의 조합**

*   다양한 반지도 학습 기술을 결합하여 더 나은 성능을 얻을 수 있음.  
    *   예시: 비지도 전처리 -> 클러스터링 기반 방법 -> 래퍼 방법 순으로 적용하고, 능동 학습을 통해 모델이 분류하기 어려워하는 샘플을 개선.  
        *   먼저 오토인코더로 특징을 뽑고, 클러스터링으로 그룹화한 뒤, 가짜 레이블을 붙이고, 마지막으로 사람에게 어려운 부분만 물어보는 식으로 단계별로 최적화합니다.

### **88.5 결론** 
- 반지도 학습은 레이블된 데이터와 레이블되지 않은 데이터를 함께 활용하여 모델을 훈련시키는 방법으로, 데이터 레이블링 비용을 절감하고 모델의 일반화 능력을 향상시키는 데 유용합니다.  
    *   이는 마치 선생님(레이블된 데이터)이 조금만 가르쳐주고, 학생(모델)이 스스로 책(레이블되지 않은 데이터)을 읽으며 학습을 보완하는 과정과 같습니다.

## 89. AI 개발을 위한 데이터 관리
- 출처: [Big Data Rules For AI: Essential Data Management Principles](https://www.youtube.com/watch?v=AtXqpveCWQU)


### **89.1 주요 목표**  
AI 개발 시간 단축 및 정확도 향상  
- 데이터가 잘 정리되어 있으면 모델 학습 및 검증 과정이 더 효율적으로 진행되며, 오류 발생 가능성을 줄일 수 있습니다. 특히 반복적인 실험과 모델 개선 과정에서 데이터 품질이 AI 성능에 직접적인 영향을 미침.

### **89.2 핵심 내용**  
AI 개발 및 결과 개선을 위한 데이터 수집, 정리, 관리에 대한 아키텍처 및 가이드라인 제시  
- AI 시스템이 작동하기 위한 기반인 데이터의 흐름을 체계적으로 설계하고, 표준화된 절차를 통해 일관된 품질을 유지함으로써 재사용성과 확장성을 확보할 수 있습니다.

### **89.3 적용 범위**  
데이터 레이크, 데이터 패브릭 등 모든 데이터 아키텍처에 적용 가능한 원칙  
- 특정 플랫폼이나 시스템에 국한되지 않고, 다양한 환경에서 유연하게 활용 가능한 데이터 관리 원칙을 제공합니다. 이는 클라우드, 온프레미스, 하이브리드 환경에서도 동일하게 적용될 수 있습니다.

### **89.4 필수 투자**  
AI 중요성 및 규정 준수 요구 증대로 데이터 아키텍처 표준 준수를 위한 투자 필수  
- AI의 영향력이 커지면서 데이터 프라이버시, 보안, 윤리 등 규제가 강화되고 있습니다. 이에 따라 데이터 관리 인프라에 대한 전략적 투자가 점점 더 중요해지고 있으며, 기업 경쟁력과 직결됩니다.

### **89.5 핵심 단계**

1. **데이터 저장소:**

    * 모든 데이터는 합의된 위치에 저장  
      - 팀 간 데이터 공유 및 일관된 접근을 위해 중앙화된 저장소(예: 데이터 레이크, 클라우드 스토리지)를 활용합니다.

    * 배치 또는 스트림 방식으로 외부 소스에서 데이터 수집  
      - 정해진 주기로 수집하는 배치 처리와 실시간 수집이 필요한 스트리밍 방식을 상황에 따라 적절히 선택해야 합니다.

2. **표준화된 데이터 조직:**

    * 수집되는 데이터의 종류 (개인 정보, 금융 데이터 등) 명확히 정의 및 문서화  
      - 데이터 분류 및 보호 기준 설정을 통해 보안 및 컴플라이언스 요구사항을 충족시킵니다.

    * 데이터의 고유성, 조인/병합 방법, 보존 정책에 따른 제거 시점 등 문서화  
      - 데이터 활용 시 혼란을 방지하고, 정확한 데이터 해석을 가능하게 하며, 저장 공간 관리 측면에서도 효과적입니다.

3. **데이터 수집 (Ingestion) 레이어:**

    * 자동화된 방식으로 데이터 수집 프로세스 구축 및 데이터 품질 검증  
      - 수작업 개입을 줄이고, 품질 오류 발생 시 빠르게 탐지 및 대응할 수 있도록 합니다.

    * 데이터 표준 준수 여부 강제화  
      - 스키마, 포맷, 인코딩 등의 표준을 명확히 하여 데이터 일관성을 확보합니다.

4. **데이터 저장:**

    * AI에 효율적인 방식으로 데이터 저장 (문서 또는 객체 스토리지 활용)  
      - 정형/비정형 데이터에 따라 적절한 저장 방식을 선택하여 성능과 확장성 모두를 고려합니다.

    * 데이터 레이크 내에서 발생하는 모든 변경 사항 추적  
      - 데이터 변경 이력을 기록함으로써 회귀 분석이나 문제 발생 시 추적 및 복원이 가능합니다.

5. **AI 활용:**

    * 데이터 과학자 및 AI 전문가가 데이터 레이크에서 데이터 쿼리 및 활용  
      - 통합된 인터페이스를 통해 다양한 데이터 소스에 접근하고, 분석 및 모델링에 바로 활용할 수 있도록 설계합니다.

    * 데이터 태깅을 통해 데이터 사용처 및 결합 모델 정보 파악 (AI 거버넌스)  
      - 데이터가 어떤 목적에 사용되었는지, 어떤 모델에 투입되었는지를 명확히 하여 책임성과 추적 가능성을 높입니다.

    * **전통적 AI:** 훈련 및 테스트 데이터 세트 태깅 및 문서화  
      - 실험의 재현성 확보 및 데이터 재사용 시 정확한 맥락 전달을 위한 필수 작업입니다.

    * **생성형 AI (Generative AI):** RAG 패턴 적용 시 벡터화 전 데이터 태깅 (데이터 재사용 기회 확보)  
      - 검색 기반 생성(RAG) 모델의 효율성과 정확도를 위해 사전 태깅이 필요하며, 추후 재사용성을 극대화할 수 있습니다.

    * **모델 미세 조정 (Fine-tuning):** LLM에 추가되는 데이터 태깅  
      - 대규모 언어 모델을 특정 도메인이나 목적에 맞게 조정할 때, 어떤 데이터가 사용되었는지를 명확히 기록해 두는 것이 필수적입니다.

### **89.6 결론**

* 데이터 관리 원칙 준수를 통해 AI 개발 시간 단축 및 정확도 향상 가능  
  - 초기 설계부터 데이터 품질을 확보하면 반복적인 수정 작업이 줄어들고, 모델의 성능 개선 속도 향상.

* 초기 단계에서 데이터 품질 관리 및 거버넌스 구축 중요  
  - 시작이 잘못되면 이후 수정 비용이 기하급수적으로 증가하므로, 초기에 데이터 표준과 거버넌스를 설정하는 것이 중요합니다.

* AI 개발 전반에 걸쳐 데이터 품질 유지 및 추적 필수  
  - 데이터는 정적인 자원이 아니라 지속적으로 변화하는 자산이며, 그 품질을 꾸준히 관리해야 AI 시스템도 신뢰할 수 있습니다.

## 90. DeepSeek AI 모델
- 출처: [What is DeepSeek? AI Model Basics Explained](https://www.youtube.com/watch?v=KTonvXhsxpc)

### **90.1 DeepSeek 소개**

* 중국 베이징에 본사를 둔 인공지능 스타트업으로, 2023년 설립되어 단기간에 급성장한 기업입니다.
* 2025년 3월, OpenAI를 제치고 미국 애플 앱스토어 무료 앱 다운로드 1위를 차지하며 글로벌 AI 시장에서 강력한 경쟁자로 부상했습니다.
* 고성능 AI 모델을 경쟁사 대비 현저히 낮은 비용으로 제공한다는 핵심 가치 제안으로 시장에서 주목받고 있으며, 비용 효율성과 성능의 균형을 중시합니다.

### **90.2 핵심 모델: DeepSeek R1**

* **R (Reasoning)**: 복잡한 문제 해결을 위한 인간형 추론 능력에 중점을 둔 모델입니다.
* 벤치마크 테스트에서 OpenAI의 o1 모델과 유사하거나 일부 영역(특히 수학적 문제 해결과 코드 생성)에서 더 우수한 성능을 보였습니다.
* DeepSeek 주장: o1보다 훨씬 적은 칩으로 학습되었으며, 실행 비용은 약 96% 저렴하여 기업들에게 경제적인 AI 솔루션을 제공합니다.
* **특징:**
    * 메타인지(metacognition) 기능을 통해 복잡한 문제를 여러 단계로 분해하고 체계적으로 접근합니다.
    * 깊은 사고가 필요한 문제에 대해 최대 수 분까지 "사고 시간"을 투자하여 정확도를 높입니다.
    * 사용자에게 Chain of Thought(사고 사슬) 과정을 투명하게 공개: 문제 재정의, 논리적 추론 단계, 오류 발견 시 자기 수정, 최종 결론 도출 등의 사고 과정을 모두 보여줍니다.

### **90.3 DeepSeek 모델 발전 과정**

* DeepSeek R1은 체계적인 모델 발전 로드맵의 결과물이며, 다음과 같은 진화 과정을 거쳤습니다:
    * **DeepSeek v1 (2024년 1월)**: 
        - 670억 파라미터 규모의 기본 모델로, 전통적인 Transformer 아키텍처를 사용하여 자연어 처리 능력을 구현했습니다.
    * **DeepSeek v2 (2024년 6월)**: 
        - 2360억 파라미터로 확장되었으며, Multi-Headed Laden Attention 메커니즘과 DeepSeek 고유의 Mixture of Experts(MoE) 기술을 도입하여 추론 속도와 정확도를 크게 향상시켰습니다.
    * **DeepSeek v3 (2024년 12월)**: 
        - 6710억 파라미터의 대규모 모델로, 강화학습 방법론을 적극 도입하고 NVIDIA H800 GPU에 최적화된 로드 밸런싱 기술을 적용했습니다.
    * **DeepSeek R1-Zero (2025년 1월)**: 
        - 순수하게 강화학습만을 활용한 첫 번째 추론 특화 모델로, 실험적 성격이 강했습니다.
    * **DeepSeek R1**: 
        - R1-Zero를 기반으로 강화학습과 지도학습을 효과적으로 결합하여 추론 능력과 일반적인 언어 이해력 사이의 최적 균형을 달성했습니다.

### **90.4 Distilled 모델 (지식 증류 모델)**

* 대규모 "교사 모델"(Teacher Model)의 지식과 능력을 더 작은 "학생 모델"(Student Model)로 효율적으로 전달하는 기술적 접근법입니다.
* 단순한 모델 압축을 넘어 아키텍처의 근본적 변환(예: 복잡한 MoE 구조에서 계산 효율적인 표준 Transformer로의 전환)을 통해 성능과 효율성의 균형을 추구합니다.
* 이 기술로 모바일 기기에서도 고성능 AI 경험을 제공할 수 있는 경량화된 모델을 개발했습니다.

### **90.5 DeepSeek의 저비용 운영**

* 주요 경쟁사 대비 현저히 적은 컴퓨팅 자원으로 유사한 성능을 달성했습니다(DeepSeek v3 학습에 약 2,000개 GPU 사용 vs Meta Llama 4 학습에 100,000개 이상 GPU 사용).
* **효율성 비결:**
    * Chain of Thought 추론과 강화학습의 시너지: 모델이 자체적으로 가장 효율적인 사고 패턴을 발견하고 최적화하는 능력을 개발했습니다.
    * Mixture of Experts (MoE) 아키텍처의 혁신적 활용:
        * 대규모 신경망을 다양한 전문 영역별 "전문가" 서브네트워크로 분할하여 모듈화했습니다.
        * 입력 데이터의 특성에 따라 관련 전문가 네트워크만 선택적으로 활성화함으로써 계산 리소스를 효율적으로 사용합니다.
        * 학습 단계에서의 초기 비용 투자는 높지만, 실제 운영 시 추론 속도와 에너지 효율성이 크게 향상됩니다.
        * 이 접근법은 Mistral AI와 IBM Granite 같은 다른 선도적 AI 모델에서도 채택되고 있는 산업 표준 기술입니다.

### **90.6 결론**
* DeepSeek R1은 경제적 효율성과 최첨단 성능을 결합한 혁신적 AI 추론 모델로, 고급 AI 기능의 민주화에 기여하고 있습니다.
* DeepSeek의 접근법은 AI 추론 모델 분야에서 대규모 자본 없이도 혁신이 가능함을 보여주며, 향후 AI 기술 발전의 다양화와 글로벌 경쟁 활성화에 중요한 이정표가 될 것으로 전망됩니다.