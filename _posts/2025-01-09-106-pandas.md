---
title: 1차시 6(빅데이터 분석):Pandas
layout: single
classes: wide
categories:
  - Pandas
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 1. Pandas
- 출처: [Pandas Full Python Course - Data Science Fundamentals](https://www.youtube.com/watch?v=EhYC02PD_gc)

>판시구불 탐접클반 필그정병 
>
>(판)다스는 (시)작시 데이터(구)조를 (불)러오고 데이터를 (탐)색하고 (접)근하여 \
>(클)리닝을 (반)복하며, 또한 데이터를 (필)터링과 (그)룹화하여 그것을 (정)렬하고 (병)합한다.

### 1.1 Pandas는 왜 중요할까요?

  * **데이터를 쉽게 다룰 수 있어요**: Pandas는 파이썬에서 데이터를 쉽게 넣고 빼고, 정리하고, 분석할 수 있도록 만들어졌어요.
  * **핵심은 '데이터프레임'**: Pandas의 가장 중요한 개념은 **데이터프레임(DataFrame)**이라는 거예요. 이건 마치 엑셀 시트나 데이터베이스의 테이블처럼 **표 형태로 데이터를 저장**하는 구조라고 생각하면 돼요. 대부분의 데이터는 이 데이터프레임 형태로 되어 있거나 쉽게 바꿀 수 있어서, 머신러닝 모델을 만들거나 통계 분석, 시각화 등을 할 때 아주 유용하게 쓰여요.
  * **다양한 기능**: 데이터프레임에서 원하는 데이터를 찾고(쿼리), 걸러내고(필터링), 요약하고(집계), 묶고(그룹화), 정렬하고, 여러 개의 표를 합치는(연결, 병합) 등 데이터와 관련된 거의 모든 작업을 할 수 있어요.

**예제: 데이터프레임의 편리함**

우리가 흔히 보는 엑셀 표와 같은 데이터를 Pandas의 **데이터프레임**으로 만들어 보세요.

```python
import pandas as pd

# 딕셔너리를 사용하여 데이터프레임 생성
data = {
    '이름': ['철수', '영희', '민수', '수지'],
    '나이': [25, 30, 28, 22],
    '도시': ['서울', '부산', '대구', '서울']
}
df = pd.DataFrame(data)
print(df)
```

출력 결과:

```
  이름  나이  도시
0  철수  25  서울
1  영희  30  부산
2  민수  28  대구
3  수지  22  서울
```

-----

### 1.2 Pandas (시)작하기: 설치와 기본 사용법

Pandas를 사용하려면 먼저 컴퓨터에 설치해야 해요.

  * **설치**: 명령 프롬프트나 터미널을 열고 다음 명령어 중 하나를 입력하세요.
    ```bash
    pip install pandas
    # 또는
    pip3 install pandas
    ```
  * **편리한 개발 환경**: 데이터 과학 작업에는 **Jupyter Lab(주피터 랩)**이나 **Jupyter Notebook(주피터 노트북)**을 사용하는 게 좋아요. 코드를 한 줄씩 실행할 수 있어서 데이터를 매번 다시 불러오거나 모델을 재학습할 필요 없이 편하게 작업할 수 있답니다.
  * **불러오기**: 파이썬 코드에서 Pandas를 사용하려면 항상 맨 위에 다음 코드를 추가해야 해요.
    ```python
    import pandas as pd
    ```
    여기서 `as pd`는 '앞으로 Pandas를 `pd`라는 짧은 이름으로 부를게\!'라는 약속이에요. 이렇게 하면 코드를 더 짧게 쓸 수 있어서 편리하죠.

-----

### 1.3 Pandas의 핵심 데이터 (구)조: Series와 DataFrame

Pandas는 데이터를 **Series(시리즈)**와 **DataFrame(데이터프레임)**이라는 두 가지 형태로 다뤄요.

  * **Series (시리즈)**

      * **데이터프레임의 '한 줄' 또는 '한 칸'**: Series는 데이터프레임의 **단일 컬럼(열)**이라고 생각하면 돼요.
      * **값과 인덱스**: 파이썬의 '딕셔너리(사전)'처럼 값을 가지고 있고, 각 값에 대한 **인덱스(Index)** 또는 **레이블(Label)**을 가지고 있어요. 인덱스는 기본적으로 0부터 시작하는 숫자지만, 'a', 'b', 'c'처럼 우리가 원하는 이름을 붙일 수도 있어요.
      * **인덱스는 중복 가능**: 데이터베이스의 '기본 키'와 다르게 Series의 인덱스는 중복될 수도 있어요.
      * **빠른 접근**: 이 인덱스를 사용하면 데이터에 빠르게 접근할 수 있답니다.

    **예제: Series 만들기**

    ```python
    import pandas as pd

    # 리스트로 Series 만들기 (기본 인덱스)
    s1 = pd.Series([10, 20, 30, 40])
    print("Series 1 (기본 인덱스):\n", s1)

    print("\n---\n")

    # 딕셔너리로 Series 만들기 (사용자 지정 인덱스)
    data = {'사과': 1000, '바나나': 1500, '오렌지': 1200}
    s2 = pd.Series(data)
    print("Series 2 (사용자 지정 인덱스):\n", s2)

    print("\n---\n")

    # Series에서 특정 값 접근
    print("사과 가격:", s2['사과'])
    print("첫 번째 값 (인덱스 0):", s1[0])

    print("\n---\n")
    
    # 중복된 인덱스를 가진 Series 만들기
    s = pd.Series(['apple', 'banana', 'cherry'], index=['fruit', 'fruit', 'berry'])
    s_fruit = s['fruit']

    print("중복된 인덱스를 가진 series:\n",s)
    print("\ns_fruit:\n", s_fruit)
    ```

    출력 결과:

    ```
    Series 1 (기본 인덱스):
     0    10
    1    20
    2    30
    3    40
    dtype: int64

    ---

    Series 2 (사용자 지정 인덱스):
     사과     1000
    바나나    1500
    오렌지    1200
    dtype: int64

    ---

    사과 가격: 1000
    첫 번째 값 (인덱스 0): 10
    
    s_fruit:
    fruit     apple
    fruit    banana
    dtype: object
    ```

  * **DataFrame (데이터프레임)**

      * **Series들의 모임**: 데이터프레임은 여러 개의 Series(컬럼)가 합쳐져서 만들어진 **표 형태의 구조**예요.
      * **만들기**: 보통 파이썬 딕셔너리를 사용해서 만들어요. 딕셔너리의 '키'가 컬럼 이름이 되고, '값'은 해당 컬럼의 데이터 리스트가 돼요.
        * DataFrame을 만들 때, 각 열의 데이터는 여러 값을 담고 있는 리스트나 배열 같은 반복 가능한(iterable) 객체여야 합니다.
      * **인덱스 관리**: 데이터프레임도 기본적으로 0부터 시작하는 행 인덱스를 가지고 있어요. 특정 컬럼을 행의 인덱스로 설정하거나(`df.set_index()`), 인덱스를 다시 일반 컬럼으로 되돌릴 수 있어요(`df.reset_index()`).
          * **주의**: `df = df.set_index('컬럼명')`처럼 변경된 내용을 다시 변수에 할당해야 적용돼요. `inplace=True` 옵션은 가급적 사용하지 않는 것이 좋아요.
      * **데이터 정렬**: 데이터프레임끼리 계산할 때는 인덱스를 기준으로 데이터를 맞춰서 계산해요.

    **예제: DataFrame 만들기 및 인덱스 설정**

    ```python
    import pandas as pd

    data = {
        '이름': ['철수', '영희', '민수', '수지'],
        '나이': [25, 30, 28, 22],
        '도시': ['서울', '부산', '대구', '서울']
    }
    df = pd.DataFrame(data)
    print("초기 데이터프레임:\n", df)

    print("\n---\n")

    # '이름' 컬럼을 인덱스로 설정
    df_indexed = df.set_index('이름')
    print("'이름'을 인덱스로 설정한 데이터프레임:\n", df_indexed)

    print("\n---\n")

    # 인덱스를 다시 일반 컬럼으로 되돌리기
    df_reset = df_indexed.reset_index()
    print("인덱스를 다시 리셋한 데이터프레임:\n", df_reset)
    ```

    ```python
    # 값을 리스트로 감싸기
    # 컬럼마다 여러 행을 담을 수 있는 ‘시퀀스형(Sequence)’ 을 기대
    new_data_pandas = pd.DataFrame({
    'fixed acidity': [7.4],  # 리스트로 감싸기
    'volatile acidity': [0.70],
    # ...
    })

    # index를 명시적으로 지정
    # 스칼라(단일 값)만 넣고 싶다면: index=[...] 를 꼭 지정.
    new_data_pandas = pd.DataFrame({
    'fixed acidity': 7.4,
    'volatile acidity': 0.70,
    # ...
    }, index=[0]) 
    ```

    출력 결과:

    ```
    초기 데이터프레임:
       이름  나이  도시
    0  철수  25  서울
    1  영희  30  부산
    2  민수  28  대구
    3  수지  22  서울

    ---

    '이름'을 인덱스로 설정한 데이터프레임:
           나이  도시
    이름
    철수    25  서울
    영희    30  부산
    민수    28  대구
    수지    22  서울

    ---

    인덱스를 다시 리셋한 데이터프레임:
       이름  나이  도시
    0  철수  25  서울
    1  영희  30  부산
    2  민수  28  대구
    3  수지  22  서울
    ```

-----

### 1.4 데이터 (불)러오고 저장하기

Pandas는 다양한 형식의 데이터를 쉽게 불러오고 저장할 수 있게 해줘요.

  * **저장하기 (`to_csv()`, `to_json()` 등)**:
    ```python
    df.to_csv('내_데이터.csv') # 데이터프레임을 CSV 파일로 저장
    ```
    `index=False` 옵션을 추가하면 저장할 때 행 인덱스가 파일에 포함되지 않아서 깔끔해요.
  * **불러오기 (`pd.read_csv()`, `pd.read_json()` 등)**:
    ```python
    my_df = pd.read_csv('내_데이터.csv') # CSV 파일을 데이터프레임으로 불러오기
    ```
    만약 데이터를 저장할 때 행 인덱스도 같이 저장했는데, 불러올 때 인덱스 컬럼이 추가로 생긴다면 `index_col=0` 옵션을 사용해서 첫 번째 컬럼을 인덱스로 지정해주면 돼요.

**예제: CSV 파일 저장 및 불러오기**

```python
import pandas as pd

data = {
    '제품': ['노트북', '마우스', '키보드'],
    '가격': [1200000, 30000, 70000],
    '재고': [10, 50, 30]
}
df_products = pd.DataFrame(data)

# 데이터프레임을 CSV 파일로 저장 (인덱스 제외)
df_products.to_csv('products.csv', index=False)
print("products.csv 파일이 생성되었습니다.")

# 저장된 CSV 파일 불러오기
loaded_df = pd.read_csv('products.csv')
print("\n불러온 데이터프레임:\n", loaded_df)
```

출력 결과 (콘솔):

```
products.csv 파일이 생성되었습니다.

불러온 데이터프레임:
     제품      가격  재고
0  노트북  1200000  10
1  마우스    30000  50
2  키보드    70000  30
```

(실제 'products.csv' 파일이 저장된 경로에 생성됩니다.)

-----

### 1.5 데이터 (탐)색

데이터를 분석하기 전에 전체적인 모습을 파악하는 것이 중요해요.

  * **미리보기**:
      * `df.head(n)`: 데이터프레임의 **맨 위 `n`개** 행을 보여줘요 (기본값은 5개).
      * `df.tail(n)`: 데이터프레임의 **맨 아래 `n`개** 행을 보여줘요.
      * `df.sample(n)`: 데이터프레임에서 **무작위로 `n`개** 행을 뽑아 보여줘요.
  * **기본 정보 확인**:
      * `df.columns`: 데이터프레임의 **모든 컬럼 이름**을 리스트로 보여줘요.
      * `df.info()`: 각 컬럼의 이름, **비어있지 않은 값의 개수(결측치 확인)**, 데이터 타입 등 데이터프레임의 **간략한 요약 정보**를 한눈에 볼 수 있어요. 다양한 데이터 타입이 섞여 있으면 성능이 느려질 수 있어요.
  * **통계 정보 확인**:
      * `df.describe()`: 숫자형 컬럼에 대한 **요약 통계(평균, 최소/최대값 등)**를 한 번에 보여줘요.
      * `df['컬럼명'].mean()`: 특정 컬럼의 **평균**을 계산해요. `.min()`, `.max()`, `.std()` (표준 편차), `.median()` (중앙값), `.sum()` 등 다양한 통계 함수를 사용할 수 있어요.
      * info만 출력, 나머진 메서드는 반환값이 있다.
  * **데이터 시각화**: Pandas는 Matplotlib이라는 그림 그리는 도구와 연동해서 데이터를 쉽게 그림으로 보여줄 수 있어요.
      * `df['컬럼명'].hist()`: 특정 컬럼의 데이터가 어떻게 분포되어 있는지 **히스토그램**으로 보여줘요.
      * `df.hist()`: 모든 숫자형 컬럼에 대한 히스토그램을 한 번에 그려줘요.
      * `df['컬럼명'].plot()`: 기본적으로 선 그래프를 그려주며, `plot.bar`(막대 그래프), `plot.pie`(파이 그래프) 등으로 변경할 수도 있어요.

**예제: 데이터 탐색 기본 기능**

```python
import pandas as pd
import numpy as np # 결측치 생성을 위해 numpy 사용

data = {
    '이름': ['철수', '영희', '민수', '수지', '동수', '미영'],
    '나이': [25, 30, 28, 22, np.nan, 35], # 동수 나이 결측치
    '도시': ['서울', '부산', '대구', '서울', '제주', '부산'],
    '점수': [85, 92, 78, 95, 60, 88]
}
df_explore = pd.DataFrame(data)

print("1. 데이터프레임 맨 위 3개 행:\n", df_explore.head(3))

print("\n---\n")

print("2. 데이터프레임 컬럼 이름:\n", df_explore.columns)

print("\n---\n")

#info만 출력, 나머진 메서드는 반환값이 있다
print("3. 데이터프레임 요약 정보 (결측치, 타입 등):\n")
df_explore.info()

print("\n---\n")

print("4. 숫자형 컬럼 요약 통계:\n", df_explore.describe())

print("\n---\n")

print("5. '나이' 컬럼의 평균:", df_explore['나이'].mean())
```

출력 결과:

```
1. 데이터프레임 맨 위 3개 행:
    이름  나이  도시  점수
0  철수  25.0  서울  85
1  영희  30.0  부산  92
2  민수  28.0  대구  78

---

2. 데이터프레임 컬럼 이름:
 Index(['이름', '나이', '도시', '점수'], dtype='object')

---

3. 데이터프레임 요약 정보 (결측치, 타입 등):

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6 entries, 0 to 5
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   이름      6 non-null      object
 1   나이      5 non-null      float64
 2   도시      6 non-null      object
 3   점수      6 non-null      int64
dtypes: float64(1), int64(1), object(2)
memory usage: 324.0+ bytes

---

4. 숫자형 컬럼 요약 통계:
              나이         점수
count   5.000000   6.000000
mean   28.000000  84.666667
std     4.949747  12.825287
min    22.000000  60.000000
25%    25.000000  79.750000
50%    28.000000  86.500000
75%    30.000000  91.000000
max    35.000000  95.000000

---

5. '나이' 컬럼의 평균: 28.0
```

-----

### 1.6 데이터 (접)근 및 조작

원하는 데이터만 선택하거나 값을 바꾸는 방법을 알아볼게요.

  * **특정 값/행/열 선택**:
      * `df.loc[]` (레이블 기반): **인덱스 이름**이나 **컬럼 이름**을 사용해서 선택해요.
        ```python
        df.loc['앨리스']        # '앨리스' 인덱스를 가진 행 선택
        df.loc['앨리스', '나이']  # '앨리스' 행의 '나이' 컬럼 값 선택
        ```
      * `df.iloc[]` (정수 위치 기반): **정수 위치(순서)**를 사용해서 선택해요.
        ```python
        df.iloc[0]          # 첫 번째 행 선택
        df.iloc[0, 1]       # 첫 번째 행의 두 번째 컬럼 값 선택
        ```
      * `df.at[]` / `df.iat[]`: 단일 값을 빠르게 선택하거나 변경할 때 `loc`/`iloc`보다 효율적이에요.
  * **데이터 변경**: `df.at['앨리스', '나이'] = 60`처럼 특정 셀이나 행의 값을 바꿀 수 있어요.(at은 레이블기반, iat은 인덱스기반 사용)
  * **새로운 행 추가**: `df.loc['존'] = [90, '선생님']`처럼 새로운 인덱스 이름을 사용해서 새로운 행을 쉽게 추가할 수 있어요.
  * **슬라이싱**: `df.iloc[0:2]`처럼 파이썬의 슬라이싱 문법을 사용해서 여러 행을 한 번에 선택할 수 있어요.
  * **컬럼 단위 연산**: `df['나이'] = df['나이'] * 2`처럼 컬럼 전체에 대해 수학 계산을 할 수 있어요.
  * **`apply()` 함수**: 데이터프레임의 컬럼(Series)이나 행에 **직접 만든 함수**를 적용할 때 사용해요. `axis=1`을 지정하면 행 단위로 함수를 적용할 수 있어요.

**예제: 데이터 접근 및 조작**

```python
import pandas as pd

data = {
    '이름': ['철수', '영희', '민수', '수지'],
    '나이': [25, 30, 28, 22],
    '도시': ['서울', '부산', '대구', '서울']
}
df_access = pd.DataFrame(data, index=['a', 'b', 'c', 'd']) # 인덱스를 a,b,c,d로 설정
print("초기 데이터프레임:\n", df_access)

print("\n---\n")

# 1. 'b' 인덱스의 행 선택 (loc)
print("1. 'b' 인덱스 행:\n", df_access.loc['b'])

print("\n---\n")

# 2. 첫 번째 행 선택 (iloc)
print("2. 첫 번째 행:\n", df_access.iloc[0])

print("\n---\n")

# 3. 'c' 인덱스의 '나이' 컬럼 값 선택 (loc)
print("3. 'c' 인덱스 '나이' 값:", df_access.loc['c', '나이'])

print("\n---\n")

# 4. 'b' 인덱스의 '나이'를 31로 변경 (at)
# 0번째 인덱스의 1번째 컬럼의 값을 40으로 변경(iat)
df_access.at['b', '나이'] = 31
print("4. 'b' 인덱스 '나이' 변경 후:\n", df_access)
df_access.iat[0,1] = 40
print("4.2 0번째 인덱스의 1번째 컬럼의 값 변경후: \n", df_access)
print("\n---\n")

# 5. 새로운 행/열 추가
df_access.loc['e'] = ['재원', 29, '광주']
print("5. 새로운 행 추가 후:\n", df_access)
df_access['성별'] = ['남','여','남','여','남']
print("\n5-2 새로운 컬럼 추가후\n",df_access)

print("\n---\n")

# 6. '나이' 컬럼의 모든 값에 10 더하기
df_access['나이'] = df_access['나이'] + 10
print("6. '나이' 컬럼에 10 더하기 후:\n", df_access)

print("\n---\n")

# 7. '나이' 컬럼에 짝수인지 홀수인지 표시하는 새로운 컬럼 추가 (apply)
# apply는 열 또는 행 전체를 이용한 연산
# map()은 전체 셀에 대한 적용
def check_even(age):
    return '짝수' if age % 2 == 0 else '홀수'

df_access['나이_유형'] = df_access['나이'].apply(check_even)
print("7. '나이_유형' 컬럼 추가 후:\n", df_access)

df_access = df.map(lambda x: x+1 if isinstance(x, int) else x)
print("7-2. 데이터프레임의 요소가 숫자인 경우 1 추가:\n", df_access)

# 8. 열 삭제하기: drop() 메서드 + axis=1 사용
df_access = df_access.drop('열이름', axis=1)
print("8. drop() 사용 후 :\n", df)

# 9. 조건에 따라 여러 값 변경 : loc[], mask(), where[]
# 예제 데이터프레임
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
    'score': [85, 92, 78, 65, 96],
    'attendance': [10, 5, 8, 3, 12]  # 출석일수
})

print("원본 데이터프레임:\n", df)

# loc[] – 라벨 기반 조건 접근
df.loc[df['score'] > 90, 'attendance'] = 15
print("9. loc 적용 후:\n",df)

# 조건에 맞는 부분만 바꾸기
# attendance가 10 이상인 경우를 9로 변경
df['attendance'] = df['attendance'].mask(df['attendance'] >= 10, 9)
print("9.2 mask 적용 후:\n",df)

# where는 반대: 조건이 참인 경우만 유지하고 나머지에 값을 대체
# attendance가 10 이상이 아닌 경우를 0으로 변경
df['attendance'] = df['attendance'].where(df['attendance'] >= 10, 0)
print("9.3 where 적용 후:\n", df)

#10.replace() – 특정 값 대체
#df['attendance'] = df['attendance'].replace({0: 10}) 사용하거나
df.replace({'attendance': {0: 10}}, inplace=True) 
print("10. replace 적용 후: \n",df)
```

출력 결과:

```
초기 데이터프레임:
   이름  나이  도시
a  철수  25  서울
b  영희  30  부산
c  민수  28  대구
d  수지  22  서울

---

1. 'b' 인덱스 행:
 이름    영희
나이    30
도시    부산
Name: b, dtype: object

---

2. 첫 번째 행:
 이름    철수
나이    25
도시    서울
Name: a, dtype: object

---

3. 'c' 인덱스 '나이' 값: 28

---

4. 'b' 인덱스 '나이' 변경 후:
   이름  나이  도시
a  철수  25  서울
b  영희  31  부산
c  민수  28  대구
d  수지  22  서울

---

5. 새로운 행 추가 후:
   이름  나이  도시
a  철수  25  서울
b  영희  31  부산
c  민수  28  대구
d  수지  22  서울
e  재원  29  광주

---

6. '나이' 컬럼에 10 더하기 후:
   이름  나이  도시
a  철수  35  서울
b  영희  41  부산
c  민수  38  대구
d  수지  32  서울
e  재원  39  광주

---

7. '나이_유형' 컬럼 추가 후:
   이름  나이  도시 나이_유형
a  철수  35  서울    홀수
b  영희  41  부산    홀수
c  민수  38  대구    짝수
d  수지  32  서울    짝수
e  재원  39  광주    홀수
```

-----

### 1.7 데이터 (클)리닝

실제 데이터에는 빠져있거나(결측치), 잘못된 값들이 많아요. 이런 '더러운' 데이터를 깔끔하게 정리하는 것이 데이터 클리닝이에요.

  * **결측치 (Missing Values)**: 데이터가 비어있는 값은 보통 `NaN`(Not a Number, 숫자가 아님)으로 표시돼요.
      * `df.info()`로 비어있지 않은 값의 개수를 확인해서 결측치를 찾을 수 있어요.
  * **결측치 처리**:
      * `df.dropna()`: `NaN` 값이 있는 **모든 행을 삭제**해요.
      * `df.fillna(값)`: `NaN` 값을 특정 값(예: 0, -1)으로 **채워 넣어요**.
      * `df['컬럼명'].fillna(df['컬럼명'].mean())`: 특정 컬럼의 **평균값** 등으로 `NaN` 값을 채우는 똑똑한 방법도 있어요.
      * `df['컬럼명'].notna()`: `NaN`이 아닌 값에 대해 `True`를 반환해서 결측치가 없는 행만 걸러낼 때 사용해요.

**예제: 결측치 처리**

```python
import pandas as pd
import numpy as np

data = {
    '제품': ['노트북', '마우스', '키보드', '모니터', '웹캠'],
    '가격': [1200000, 30000, np.nan, 250000, 50000], # 키보드 가격 결측치
    '재고': [10, np.nan, 30, 5, 20], # 마우스 재고 결측치
    '판매량': [5, 20, 15, 3, np.nan] # 웹캠 판매량 결측치
}
df_clean = pd.DataFrame(data)
print("초기 데이터프레임 (결측치 포함):\n", df_clean)

print("\n---\n")

print("1. 각 컬럼의 Non-Null 개수 확인 (info()):\n")
df_clean.info()

print("\n---\n")

# 2. 결측치가 있는 모든 행 삭제
df_dropna = df_clean.dropna()
print("2. 결측치 있는 행 삭제 후:\n", df_dropna)

print("\n---\n")

# 3. '가격' 컬럼의 결측치를 해당 컬럼의 평균값으로 채우기
mean_price = df_clean['가격'].mean()
df_fillna_price = df_clean.fillna({'가격': mean_price})
print("3. '가격' 결측치를 평균으로 채운 후:\n", df_fillna_price)

print("\n---\n")

# 4. 모든 결측치를 0으로 채우기
df_fillna_zero = df_clean.fillna(0)
print("4. 모든 결측치를 0으로 채운 후:\n", df_fillna_zero)
```

출력 결과:

```
초기 데이터프레임 (결측치 포함):
     제품        가격    재고   판매량
0  노트북  1200000.0  10.0   5.0
1  마우스    30000.0   NaN  20.0
2  키보드        NaN  30.0  2.0
3  모니터   250000.0   5.0   3.0
4  웹캠     50000.0  20.0   NaN

---

1. 각 컬럼의 Non-Null 개수 확인 (info()):

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5 entries, 0 to 4
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   제품      5 non-null      object
 1   가격      4 non-null      float64
 2   재고      4 non-null      float64
 3   판매량     4 non-null      float64
dtypes: float64(3), object(1)
memory usage: 288.0+ bytes

---

2. 결측치 있는 행 삭제 후:
     제품        가격    재고  판매량
0  노트북  1200000.0  10.0  5.0
3  모니터   250000.0   5.0  3.0

---

3. '가격' 결측치를 평균으로 채운 후:
     제품        가격    재고   판매량
0  노트북  1200000.0  10.0   5.0
1  마우스    30000.0   NaN  20.0
2  키보드   382500.0  30.0  2.0  # NaN이 평균값으로 채워짐
3  모니터   250000.0   5.0   3.0
4  웹캠     50000.0  20.0   NaN

---

4. 모든 결측치를 0으로 채운 후:
     제품        가격    재고  판매량
0  노트북  1200000.0  10.0  5.0
1  마우스    30000.0   0.0  20.0
2  키보드        0.0  30.0  2.0
3  모니터   250000.0   5.0  3.0
4  웹캠     50000.0  20.0  0.0
```

-----

### 1.8 데이터 (반)복: 행과 열을 하나씩 훑어보기

데이터프레임의 각 행이나 열을 반복해서 처리해야 할 때가 있어요.

  * **행 단위 반복**: `for index, row in df.iterrows():` 형태로 사용해서 데이터프레임의 각 행을 하나씩 살펴볼 수 있어요. `row`는 해당 행의 값을 담고 있는 Series 객체예요.
  * **컬럼 단위 반복**: `for col_name, col_series in df.items():` 형태로 사용해서 각 컬럼을 하나씩 살펴볼 수 있어요.

**예제: 행/컬럼 반복**

```python
import pandas as pd

data = {
    '이름': ['철수', '영희', '민수'],
    '나이': [25, 30, 28],
    '도시': ['서울', '부산', '대구']
}
df_iter = pd.DataFrame(data)

print("1. 행 단위로 반복 (iterrows):\n")
for index, row in df_iter.iterrows():
    print(f"인덱스: {index}, 이름: {row['이름']}, 나이: {row['나이']}, 도시: {row['도시']}")

print("\n---\n")

print("2. 컬럼 단위로 반복 (items):\n")
for col_name, col_series in df_iter.items():
    print(f"컬럼 이름: {col_name}")
    print(col_series) # 해당 컬럼의 Series 출력
    print("---")
```

출력 결과:

```
1. 행 단위로 반복 (iterrows):

인덱스: 0, 이름: 철수, 나이: 25, 도시: 서울
인덱스: 1, 이름: 영희, 나이: 30, 도시: 부산
인덱스: 2, 이름: 민수, 나이: 28, 도시: 대구

---

2. 컬럼 단위로 반복 (items):

컬럼 이름: 이름
0    철수
1    영희
2    민수
Name: 이름, dtype: object
---
컬럼 이름: 나이
0    25
1    30
2    28
Name: 나이, dtype: int64
---
컬럼 이름: 도시
0    서울
1    부산
2    대구
Name: 도시, dtype: object
---
```

-----

### 1.9 데이터 (필)터링 및 쿼리

특정 조건을 만족하는 데이터만 골라낼 때 사용해요.

  * **불리언 인덱싱**: 조건을 만족하면 `True`, 아니면 `False`를 가진 Series를 만들어서, `True`인 행만 선택하는 방식이에요.
    ```python
    df[df['나이'] > 50] # 나이가 50보다 많은 사람만 선택
    ```
  * **조건 결합**: `&` (그리고), `|` (또는), `~` (아닌) 연산자를 사용해서 여러 조건을 함께 적용할 수 있어요.
    ```python
    df[(df['나이'] > 50) & (df['직업'].notna())] # 나이가 50보다 많고 직업이 비어있지 않은 사람 선택
    ```
  * **문자열/날짜 시간 메소드**: 컬럼 이름 뒤에 `.str`이나 `.dt`를 붙여서 문자열이나 날짜/시간 데이터에 대한 특별한 작업을 할 수 있어요.
      * `df['이름'].str.endswith('이')`: 이름이 '이'로 끝나는지 확인
      * `df['생일'].dt.year > 1950`: 생일의 연도가 1950년보다 뒤인지 확인
  * **`isin()` 메소드**: 특정 컬럼의 값이 주어진 리스트 안에 포함되는지 확인할 때 사용해요.
  * **`query()` 메소드**: 조건문을 문자열 형태로 직접 써서 데이터를 필터링할 수 있는 또 다른 방법이에요. 가독성이 좋고, 데이터가 많을 때 성능 이점도 있을 수 있지만, 모든 필터링 문법을 지원하지는 않아요.

**예제: 데이터 필터링**

```python
import pandas as pd

data = {
    '이름': ['철수', '영희', '민수', '수지', '동수'],
    '나이': [25, 30, 28, 22, 35],
    '도시': ['서울', '부산', '대구', '서울', '제주'],
    '성별': ['남', '여', '남', '여', '남']
}
df_filter = pd.DataFrame(data)
print("초기 데이터프레임:\n", df_filter)

print("\n---\n")

# 1. 나이가 28세 이상인 사람 필터링
df_age_over_28 = df_filter[df_filter['나이'] >= 28]
print("1. 나이가 28세 이상인 사람:\n", df_age_over_28)

print("\n---\n")

# 2. 도시가 '서울'이면서 성별이 '여'자인 사람 필터링
df_seoul_female = df_filter[(df_filter['도시'] == '서울') & (df_filter['성별'] == '여')]
print("2. 도시가 서울이면서 성별이 여자인 사람:\n", df_seoul_female)

print("\n---\n")

# 3. 이름에 '수'가 들어가는 사람 필터링 (문자열 메소드)
df_name_contains_su = df_filter[df_filter['이름'].str.contains('수')]
print("3. 이름에 '수'가 들어가는 사람:\n", df_name_contains_su)

print("\n---\n")

# 4. 도시가 '서울' 또는 '부산'인 사람 필터링 (isin)
df_seoul_busan = df_filter[df_filter['도시'].isin(['서울', '부산'])]
print("4. 도시가 서울 또는 부산인 사람:\n", df_seoul_busan)

print("\n---\n")

# 5. query() 메소드를 사용하여 나이가 30 이상인 사람 필터링
df_query_age = df_filter.query('나이 >= 30')
print("5. query()를 사용하여 나이가 30 이상인 사람:\n", df_query_age)

# 나이 30 이상이고 지역이 서울인 사람
df_query_age2 = df_filter.query('나이 >= 30 and 지역 == "서울"')
print("5-2. query()를 사용하여 나이 30 이상이고 지역이 서울인 사람:\n", df_query_age2)
```

출력 결과:

```
초기 데이터프레임:
   이름  나이  도시 성별
0  철수  25  서울  남
1  영희  30  부산  여
2  민수  28  대구  남
3  수지  22  서울  여
4  동수  35  제주  남

---

1. 나이가 28세 이상인 사람:
   이름  나이  도시 성별
1  영희  30  부산  여
2  민수  28  대구  남
4  동수  35  제주  남

---

2. 도시가 '서울'이면서 성별이 '여'자인 사람:
   이름  나이  도시 성별
3  수지  22  서울  여

---

3. 이름에 '수'가 들어가는 사람:
   이름  나이  도시 성별
0  철수  25  서울  남
2  민수  28  대구  남
3  수지  22  서울  여
4  동수  35  제주  남

---

4. 도시가 '서울' 또는 '부산'인 사람:
   이름  나이  도시 성별
0  철수  25  서울  남
1  영희  30  부산  여
3  수지  22  서울  여

---

5. query()를 사용하여 나이가 30 이상인 사람:
   이름  나이  도시 성별
1  영희  30  부산  여
4  동수  35  제주  남
```

-----

### 1.10 데이터 (그)룹화: 데이터를 묶어서 요약하기

특정 기준(예: 직업, 지역)별로 데이터를 묶어서 각 그룹의 평균, 합계 등을 계산할 때 사용해요.

  * `df.groupby('컬럼명')`: 특정 컬럼의 같은 값을 가진 데이터끼리 묶어요.
  * 묶은 데이터에 `mean()`, `min()`, `max()`, `sum()` 같은 **집계 함수**를 적용하면 각 그룹별 통계치를 쉽게 얻을 수 있어요. 여러 개의 집계 함수를 동시에 적용할 수도 있답니다.

**예제: 데이터 그룹화**

```python
import pandas as pd

data = {
    '도시': ['서울', '부산', '서울', '대구', '부산', '서울'],
    '성별': ['남', '여', '남', '여', '남', '여'],
    '판매량': [100, 150, 120, 80, 200, 90],
    '수익': [50, 70, 60, 40, 90, 45]
}
df_group = pd.DataFrame(data)
print("초기 데이터프레임:\n", df_group)

print("\n---\n")

# 1. 도시별 판매량 평균 계산
df_avg_sales_by_city = df_group.groupby('도시')['판매량'].mean()
print("1. 도시별 판매량 평균:\n", df_avg_sales_by_city)

print("\n---\n")

# 2. 도시별, 성별별 판매량과 수익의 합계 계산(아래 방법보다 더 유연)
# .groupby(...).agg() + 튜플 방식
df_group_multi = df_group.groupby(['도시', '성별']).agg(
    총판매량=('판매량', 'sum'),
    총수익=('수익', 'sum')
)
print("2. 도시별, 성별별 총판매량과 총수익:\n", df_group_multi)


# 2.2 .groupby(...)[[열]].sum()
df_group_multi2 = df_group.groupby(['도시','성별'])[['판매량','수익']].sum()
print("2-2. 도시별, 성별별 총판매량과 총수익:\n", df_group_multi2)
```

`agg()` 매개변수 유형 분류

| 유형 | 설명 | 예시 |
| :--- | :--- | :--- |
| **단일 함수** | 하나의 집계 함수를 문자열, 함수 객체, 또는 람다 함수 형태로 전달합니다. 시리즈에 적용할 때 특히 유용하며, 단일 열에 대한 단일 집계 결과를 얻을 수 있습니다. | `df['A'].agg('sum')` <br> `df.agg(np.mean)` <br> `df.agg(lambda x: x.max() - x.min())` |
| **함수 리스트** | 여러 개의 집계 함수를 리스트 형태로 전달합니다. 각 함수에 대해 별도의 열이 생성되며, 동일한 열에 대해 여러 집계 결과를 한 번에 얻을 수 있습니다. | `df['A'].agg(['sum', 'mean'])` <br> `df[['A', 'B']].agg(['sum', 'mean'])` |
| **함수 딕셔너리** | 열 이름과 집계 함수를 키-값 쌍으로 매핑하여 전달합니다. 서로 다른 열에 대해 서로 다른 집계 함수를 적용할 때 유용하며, 결과의 열 이름을 커스터마이징할 수 있습니다. 값으로는 단일 함수, 함수 리스트, 또는 중첩 딕셔너리를 사용할 수 있습니다. | `df.agg({'A': 'sum', 'B': 'mean'})` <br> `df.agg({'A': ['sum', 'max'], 'B': 'mean'})` <br> `df.agg(min_max = ('A', lambda x: x.max() - x.min()))` |

출력 결과:

```
초기 데이터프레임:
   도시 성별  판매량  수익
0  서울  남  100  50
1  부산  여  150  70
2  서울  남  120  60
3  대구  여   80  40
4  부산  남  200  90
5  서울  여   90  45

---

1. 도시별 판매량 평균:
 도시
대구     80.0
부산    175.0
서울    103.333333
Name: 판매량, dtype: float64

---

2. 도시별, 성별별 총판매량과 총수익:
         총판매량  총수익
도시 성별
대구 여     80   40
부산 남    200   90
   여    150   70
서울 남    220  110
   여     90   45
```

-----

### 1.11 데이터 (정)렬

  * `df.sort_values(by='컬럼명')`: 특정 컬럼의 값을 기준으로 데이터프레임을 정렬해요.
  * `ascending=False` 옵션을 추가하면 내림차순(큰 값부터 작은 값 순서)으로 정렬할 수 있어요.

**예제: 데이터 정렬**

```python
import pandas as pd

data = {
    '이름': ['철수', '영희', '민수', '수지'],
    '나이': [25, 30, 28, 22],
    '점수': [85, 92, 78, 95]
}
df_sort = pd.DataFrame(data)
print("초기 데이터프레임:\n", df_sort)

print("\n---\n")

# 1. '나이' 컬럼을 기준으로 오름차순 정렬 (기본값)
df_sorted_by_age = df_sort.sort_values(by='나이')
print("1. '나이' 기준 오름차순 정렬:\n", df_sorted_by_age)

print("\n---\n")

# 2. '점수' 컬럼을 기준으로 내림차순 정렬
df_sorted_by_score_desc = df_sort.sort_values(by='점수', ascending=False)
print("2. '점수' 기준 내림차순 정렬:\n", df_sorted_by_score_desc)
```

출력 결과:

```
초기 데이터프레임:
   이름  나이  점수
0  철수  25  85
1  영희  30  92
2  민수  28  78
3  수지  22  95

---

1. '나이' 기준 오름차순 정렬:
   이름  나이  점수
3  수지  22  95
0  철수  25  85
2  민수  28  78
1  영희  30  92

---

2. '점수' 기준 내림차순 정렬:
   이름  나이  점수
3  수지  22  95
1  영희  30  92
0  철수  25  85
2  민수  28  78
```

-----

### 1.12 데이터 (병)합, 연결, 조인

여러 개의 데이터프레임을 하나로 합쳐야 할 때 사용하는 기능이에요.

  * **Concatenating (연결)**: 데이터프레임을 단순히 위아래로(행 기준) 또는 옆으로(열 기준) 쌓아 올리는 거예요.
      * `pd.concat([df1, df2])`: 행을 위아래로 연결 (기본값)
      * `pd.concat([df1, df2], axis=1)`: 열을 옆으로 연결 (두 데이터프레임의 인덱스가 같을 때 유용)
  * **Merging (병합)**: 두 데이터프레임에 **공통된 컬럼**이 있을 때, 그 컬럼의 값을 기준으로 데이터를 합치는 거예요. 마치 엑셀에서 VLOOKUP을 하는 것과 비슷해요.
      * `pd.merge(df1, df2, on='공통컬럼명', how='병합방식')`
      * **`how` 매개변수**: 어떻게 합칠지 결정해요.
          * `'inner'` (기본값): 두 표 모두에 있는 공통된 데이터만 합쳐요.
          * `'outer'`: 두 표의 모든 데이터를 합치고, 없는 부분은 `NaN`으로 채워요.
          * `'left'`: 왼쪽 표의 모든 데이터를 기준으로 합치고, 오른쪽 표에 없는 부분은 `NaN`으로 채워요.
          * `'right'`: 오른쪽 표의 모든 데이터를 기준으로 합치고, 왼쪽 표에 없는 부분은 `NaN`으로 채워요.
  * **Joining (조인)**: `merge`와 비슷하지만, **인덱스를 기준**으로 데이터를 합치는 방법이에요.

**예제: 데이터 연결(Concatenate)**

```python
import pandas as pd

# 두 개의 DataFrame 생성
df1 = pd.DataFrame({
    '이름': ['Alice', 'Bob'],
    '나이': [25, 30]
})

df2 = pd.DataFrame({
    '이름': ['Charlie', 'David'],
    '나이': [35, 40]
})

# 행 방향으로 연결 (axis=0, 기본값)
df_concat_row = pd.concat([df1, df2], axis=0, ignore_index=True)
print("🔻 행 방향 연결 결과:")
print(df_concat_row)
```
**예제: 데이터 병합 (Merge)**

```python
import pandas as pd

# 학생 정보 데이터프레임
students = pd.DataFrame({
    '학번': [1, 2, 3, 4],
    '이름': ['김철수', '이영희', '박민수', '최수진'],
    '학과': ['컴퓨터', '경영', '컴퓨터', '디자인']
})
print("학생 정보 (students):\n", students)

print("\n---\n")

# 성적 정보 데이터프레임
grades = pd.DataFrame({
    '학번': [1, 2, 3, 5], # 5번 학번은 학생 정보에 없음
    '과목': ['수학', '영어', '수학', '국어'],
    '점수': [90, 85, 78, 92]
})
print("성적 정보 (grades):\n", grades)

print("\n---\n")

# 1. inner merge: 학번이 양쪽에 모두 있는 데이터만 병합 (기본값)
merged_inner = pd.merge(students, grades, on='학번', how='inner')
print("1. Inner Merge (양쪽에 모두 있는 학번만):\n", merged_inner)

print("\n---\n")

# 2. left merge: students 기준으로 병합 (grades에 없는 학번은 NaN)
merged_left = pd.merge(students, grades, on='학번', how='left')
print("2. Left Merge (학생 정보 기준으로):\n", merged_left)

print("\n---\n")

# 3. outer merge: 양쪽의 모든 데이터를 포함하여 병합 (없는 부분은 NaN)
merged_outer = pd.merge(students, grades, on='학번', how='outer')
print("3. Outer Merge (모든 학번 포함):\n", merged_outer)
```

출력 결과:

```
학생 정보 (students):
   학번   이름   학과
0   1  김철수  컴퓨터
1   2  이영희   경영
2   3  박민수  컴퓨터
3   4  최수진  디자인

---

성적 정보 (grades):
   학번  과목  점수
0   1  수학  90
1   2  영어  85
2   3  수학  78
3   5  국어  92

---

1. Inner Merge (양쪽에 모두 있는 학번만):
   학번   이름   학과  과목  점수
0   1  김철수  컴퓨터  수학  90
1   2  이영희   경영  영어  85
2   3  박민수  컴퓨터  수학  78

---

2. Left Merge (학생 정보 기준으로):
   학번   이름   학과  과목    점수
0   1  김철수  컴퓨터  수학  90.0
1   2  이영희   경영  영어  85.0
2   3  박민수  컴퓨터  수학  78.0
3   4  최수진  디자인   NaN   NaN

---

3. Outer Merge (모든 학번 포함):
   학번   이름   학과  과목    점수
0   1  김철수  컴퓨터  수학  90.0
1   2  이영희   경영  영어  85.0
2   3  박민수  컴퓨터  수학  78.0
3   4  최수진  디자인   NaN   NaN
4   5    NaN  NaN  국어  92.0
```

**예제: 데이터 병합 (join)**

- 인덱스를 기준으로 병합하므로, 인덱스가 잘 정렬된 데이터프레임에 적합.
- 열 기준 병합을 하려면 먼저 `set_index()`로 열을 인덱스로 설정해야 함.
- 간단한 인덱스 기반 병합에서 코드가 더 간결함.
- 예시:

```python
#4. 데이터 join
df1 = pd.DataFrame({'value1': [1, 2, 3]}, index=['A', 'B', 'C'])
df2 = pd.DataFrame({'value2': [4, 5, 6]}, index=['B', 'C', 'D'])
joined_result = df1.join(df2, how='inner')
# 결과: 인덱스가 'B', 'C'인 행만 병합
print("4. 데이터를 조인한 결과", joined_result)
```

```
   value1  value2
B       2       4
C       3       5
```

