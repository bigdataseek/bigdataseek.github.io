---
title: 16차시 2:IBM TECH(Understanding AI Models)
layout: single
classes: wide
categories:
  - IBM TECH
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 11. 오토인코더
- 출처: [What are Autoencoders?](https://www.youtube.com/watch?v=qiUEgSCyY5o&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=11)

### 11.1 **개념**
- **오토인코더**
  - 비지도 학습을 기반으로 한 신경망으로, 입력 데이터를 효율적으로 압축하고 이를 다시 복원하는 방법을 학습. 
  - 이 과정에서 단순히 데이터를 줄이는 데 그치지 않고, 데이터의 핵심적인 패턴과 구조를 파악하는 데 초점.
- **주요 구성 요소**
  - **인코더(Encoder)** 
    - 입력 데이터를 받아 이를 압축하여 "코드(code)"라는 잠재 공간 표현으로 변환하는 역할
    - 이 과정에서 데이터의 차원이 줄어들며, 중요한 정보만 남게 됩니다.
  - **디코더(Decoder)** 
    - 압축된 코드로부터 원래 입력 데이터와 최대한 유사한 출력을 생성합니다. 
    - 디코더는 인코더가 만든 코드를 해석하여 원본 데이터를 재구성하는 데 집중합니다.
- **핵심 목표** 
  - 관찰된 데이터에서 의미 있는 특징을 추출하고, 불필요한 노이즈를 제거함으로써 신호와 노이즈를 명확히 분리하는 것입니다. 이를 통해 데이터의 본질을 효과적으로 학습합니다.

### 11.2 **압축과의 차이**
- 오토인코더는 단순히 파일 크기를 줄이는 일반적인 압축 방식과는 다릅니다. 일반 압축이 데이터의 용량을 줄이는 데 초점을 맞춘다면, 
- 오토인코더는 **데이터의 본질적인 특징을 학습**하는 데 목적이 있습니다. 
- 즉, 단순히 데이터를 줄이는 것을 넘어 데이터의 구조적 특성과 패턴을 이해하고 이를 기반으로 복원하는 데 중점.

### 11.3 **활용 예시**
- **이미지 처리**
  - **이미지 특징 추출 및 노이즈 제거** 
    - 오토인코더는 이미지에서 중요한 시각적 특징을 추출하고, 노이즈가 섞인 이미지를 깨끗하게 복원하는 데 사용.
  - **이미지 해상도 향상** 
    - 저해상도 이미지를 고해상도로 변환하는 데 활용되며, 디테일을 살려줍니다.
  - **흑백 이미지 컬러화** 
    - 흑백 이미지를 입력받아 컬러 이미지를 생성하는 작업에도 적용됩니다.
  - **손상된 이미지 복원 (Denoising Autoencoder)** 
    - 손상되거나 노이즈가 심한 이미지를 원래 상태로 복원하는 데 특히 효과적입니다.
- **이상 감지(Anomaly Detection):**
  - 정상적인 데이터 패턴에서 벗어난 이상 징후를 탐지하는 데 사용됩니다. 
  - 오토인코더는 정상 데이터를 학습한 뒤, 이와 다른 패턴을 가진 데이터를 이상으로 인식합니다.
  - **활용 분야** 
    - 제조업에서의 결함 감지, 금융에서의 사기 탐지, 네트워크 보안에서의 침입 탐지 등 다양한 실무에서 유용하게 적용.

### 11.4 **구조 상세**
- **인코더** 
  - 여러 계층으로 구성되어 있으며, 각 계층을 거치면서 입력 데이터가 점차 압축됩니다. 이 과정에서 데이터의 차원이 줄어들고, 핵심 정보가 농축됩니다.
- **코드 (Bottleneck)** 
  - 인코더의 출력으로 생성된 가장 압축된 형태의 데이터 표현입니다. 
  - 이는 잠재 공간 표현(latent representation)이라고도 불리며, 데이터의 본질적인 특징을 담음.
- **디코더** 
  - 코드로부터 원래 데이터를 복원하는 역할을 합니다. 디코더는 압축된 정보를 해석하여 입력 데이터와 최대한 가까운 출력을 생성하도록 설계됩니다.

### 11.5 **장점**
- **노이즈 제거** 
  - 데이터에서 불필요한 잡음을 효과적으로 걸러내어 깨끗한 신호를 추출합니다.
- **관련 특징 인식** 
  - 데이터 내에서 중요한 패턴과 특징을 자동으로 학습하고 식별합니다.
- **이상 징후 감지** 
  - 정상 데이터와의 차이를 기반으로 이상치를 탐지하는 데 탁월한 성능을 발휘합니다.

### 11.6 **결론**
- 오토인코더는 다양한 종류의 데이터를 처리하는 데 유용한 도구 상자로서, 특히 **노이즈 제거**, **특징 추출**, **이상 감지**와 같은 작업에서 뛰어난 효과를 보입니다. 이미지 처리부터 이상 탐지에 이르기까지 다방면에서 활용되며, 데이터의 본질을 이해하고 이를 기반으로 효율적인 처리를 가능하게 하는 강력한 신경망 모델.


## 12. 지식 그래프(Knowledge Graph)
- 출처: [What is a Knowledge Graph?](https://www.youtube.com/watch?v=y7sXDpffzQQ&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=12)

### **12.1 지식 그래프란?**
- **개념**
  - 지식 그래프는 두 개체 간의 의미론적 정보를 표현하는 방식으로, 개체와 개체 간의 관계를 구조화된 형태로 나타냅니다. 
  - 이는 데이터를 단순히 나열하는 것을 넘어, 데이터 간의 상호작용과 의미를 명확히 드러내는 데 목적.
- **구성 요소**
    - **노드(Node)** 
      - 객체, 사람, 장소 등을 나타내며, 지식 그래프의 기본 단위입니다. 
      - 예를 들어, "파리", "프랑스", "커피"와 같은 구체적인 개체가 노드로 표현됩니다.
    - **엣지(Edge)**
      - 노드 간의 관계를 정의합니다. 
      - 예를 들어, "수도"라는 엣지는 "파리"와 "프랑스"를 연결하여 파리가 프랑스의 수도임을 나타냅니다. 엣지는 관계의 성격을 구체적으로 표현하는 역할을 합니다.
- **특징**
    - 다양한 개체를 표현할 수 있습니다. 영화, 배우, 레시피뿐만 아니라 역사적 사건, 과학적 개념 등 거의 모든 주제를 다룰 수 있어 범용성이 뛰어납니다.
    - 개체 간의 관계 및 속성을 이해할 수 있게 해줍니다. 단순히 개체를 나열하는 데 그치지 않고, 그 사이의 연결고리를 통해 깊은 통찰을 제공합니다.
    - 다양한 데이터 소스를 결합하여 정보를 추론할 수 있습니다. 예를 들어, 서로 다른 출처의 데이터를 통합하여 새로운 사실을 도출하거나 예측을 수행할 수 있습니다.

### **12.2 지식 그래프 활용 예시**
- **가상 비서**
  - 사용자의 질문에 대한 답변을 제공하는 데 지식 그래프를 활용합니다. 
  - 예를 들어, "캐나다의 수도는?"이라는 질문이 주어지면, 지식 그래프는 "캐나다"와 "수도" 관계에 있는 "오타와"를 찾아 신속히 답변을 생성합니다.
- **데이터 분석**
  - census 데이터와 온라인 리뷰를 결합하여 특정 지역의 중국 음식점 수를 예측하는 데 사용됩니다. 
  - 이는 서로 다른 데이터 소스를 융합하여 통계적 분석이나 트렌드 파악을 가능하게 합니다.
- **자연어 처리 (NLP)**
  - 비정형 텍스트를 분석하여 구조화된 데이터셋을 생성하고, 텍스트 내 개체 간의 연관 관계를 파악. 
  - 예를 들어, 뉴스 기사에서 사람, 장소, 사건 간의 관계를 추출해 데이터베이스를 구축할 수 있습니다.
- **상업적 활용**
    - **유튜브**
      - 시청자가 좋아할 만한 동영상을 추천하기 위해 사용자의 시청 기록과 동영상 간의 관계를 분석합니다. 이를 통해 개인화된 콘텐츠를 제공하여 사용자 경험을 향상시킵니다.
    - **보험**
      - 보험금 청구의 진위 여부를 판단하여 사기를 방지합니다. 청구 데이터와 관련 정보를 지식 그래프로 연결하여 비정상적인 패턴을 탐지할 수 있습니다.
    - **유통**
      - 제품 간의 관계를 파악하여 고객에게 맞춤형 상품을 추천합니다. 예를 들어, 고객이 구매한 제품과 연관된 다른 제품을 제안하여 판매를 증진시킵니다.

### **12.3 지식 그래프 예시**
- **도시 관계**:
    - **파리 --(수도)--> 프랑스**
      - 파리가 프랑스의 수도임을 나타냅니다. 
      - 이는 지식 그래프가 실세계의 사실을 간단명료하게 표현하는 방식을 보여줍니다.
    - **파리 --(도시)--> 로마 제국**
      - 파리가 역사적으로 로마 제국의 일부였음을 나타냅니다. 
      - 하나의 노드가 여러 관계를 가질 수 있음을 보여주는 예입니다.
- **인간-커피-수면 관계**
    - **인간 --(소비)--> 커피**
      - 인간이 커피를 소비한다는 일상적인 사실을 표현합니다.
    - **인간 --(필요)--> 수면**
      - 인간에게 수면이 필수적임을 나타냅니다.
    - **커피 --(방해)--> 수면**
      - 커피가 수면을 방해한다는 관계를 정의하며, 이를 바탕으로 "오후 5시 이후 카페인 섭취를 자제하는 것이 권장된다"는 실용적인 조언을 도출할 수 있습니다.

## 13. 몬테카를로 시뮬레이션
- 출처: [What is Monte Carlo Simulation?](https://www.youtube.com/watch?v=7TqhmX92P6U&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=13)


### 13.1 **개요**
- **불확실한 사건의 가능한 결과를 예측하는 수학적 기법**  
  - 몬테카를로 시뮬레이션은 복잡하거나 불확실성이 높은 상황에서 결과를 예측하기 위해 개발된 강력한 도구입니다. 
  - 이 기법은 무작위성을 활용하여 다양한 가능성을 탐색하며, 수학적 계산만으로는 해결하기 어려운 문제를 접근 가능하게 만듭니다.

- **무작위 변수의 개입으로 예측이 어려운 프로세스나 시스템에서 다양한 결과의 확률을 모델링**  
  - 예를 들어, 날씨 변화나 시장 변동성과 같이 무작위 변수가 영향을 미치는 시스템에서는 모든 경우의 수를 계산하기 어렵습니다. 
  - 몬테카를로 시뮬레이션은 이러한 상황에서 무작위성을 모델링하여 가능한 결과들의 확률 분포를 추정하는 데 유용합니다.

- **무작위 표본 추출을 통해 여러 가능한 결과를 생성하고 평균 결과를 계산**  
  - 이 방법은 무작위로 선택된 데이터를 기반으로 수많은 시나리오를 생성한 뒤, 그 결과를 평균 내거나 통계적으로 분석하여 최종 결론을 도출합니다. 
  - 특정 이벤트가 발생할 확률이나 예상 수익률을 계산할 때 평균값을 통해 현실적인 추정치를 얻는다.


### 13.2  **작동 방식**
- **무작위 표본 추출 활용** 
  - 가능한 결과들을 무작위로 추출하여 확률 계산  
  - 몬테카를로 시뮬레이션의 핵심은 무작위 표본 추출입니다. 이를 통해 시스템의 다양한 가능성을 대표하는 표본을 생성하고, 이 표본을 분석하여 전체 결과의 확률을 추정합니다. 
  - 이 과정은 복잡한 수학적 공식 대신 반복적인 시뮬레이션으로 문제를 해결합니다.

- **예시** 
  - 주사위 두 개를 굴려 7이 나올 확률 계산 시, 모든 경우의 수를 직접 계산하는 대신 무작위 표본 추출을 통해 확률 추정  
  - 주사위 두 개를 굴리는 경우, 가능한 결과는 총 36가지(6×6)입니다. 이론적으로 7이 나올 확률은 6/36(약 16.67%) 
  - 몬테카를로 시뮬레이션에서는 주사위를 수천 번 굴리는 시뮬레이션을 실행하여 7이 나오는 빈도를 계산하고 이를 확률로 변환합니다. 시뮬레이션 횟수가 증가할수록 결과는 이론적 값에 수렴.


### 13.3 **활용 분야**
- **투자 및 포트폴리오 관리** 
  - 금융 분야에서 몬테카를로 시뮬레이션은 주식 가격 변동, 금리 변화 등 불확실한 요소를 반영하여 포트폴리오의 미래 성과를 예측합니다. 
  - 예를 들어, 특정 자산 배분이 장기적으로 어떤 수익률을 낼지 시뮬레이션을 통해 확인

- **위험 분석, 옵션 가격 결정, 예비 용량 계획**
  - 위험 분석에서는 프로젝트 실패 확률이나 손실 가능성을 평가하고, 옵션 가격 결정에서는 금융 파생상품의 가치를 추정합니다. 
  - 예비 용량 계획에서는 전력 공급망의 안정성을 확보하기 위해 필요한 예비 자원을 계산하는 데 사용.

- **의학, 천체 물리학, Wordle**
  - 의학에서는 신약 개발 시 임상 시험 결과를 예측하거나, 천체 물리학에서는 별의 진화 과정을 모델링하는 데 활용됩니다. 
  - 심지어 Wordle과 같은 퍼즐 게임에서도 최적의 단어 선택 전략을 찾기 위해 시뮬레이션 실행

### 13.4 **실행 방법**
1. **예측 모델 설정**  
   - **예측할 종속 변수 및 예측 변수에 영향을 주는 독립 변수(입력 위험 변수) 식별**  
     - 시뮬레이션의 첫 단계는 예측하고자 하는 목표(종속 변수)와 그에 영향을 미치는 요인(독립 변수)을 정의하는 것입니다. 
     - 예를 들어, 주식 포트폴리오의 수익률을 예측한다면 수익률이 종속 변수이고, 시장 금리나 주가 변동성이 독립 변수.

2. **확률 분포 지정**  
   - **독립 변수의 확률 분포 정의 (과거 데이터 또는 분석가의 주관적 판단 활용)**  
     - 각 독립 변수가 가질 수 있는 값과 그 확률을 정의합니다. 
     - 예를 들어, 주가 변동성은 과거 데이터를 기반으로 정규 분포를 따를 수 있다고 가정
   - **가능한 값의 범위와 각 값에 대한 확률 가중치 할당**  
     - 변수의 최소값과 최대값을 설정하고, 각 값이 나타날 가능성에 가중치를 부여합니다. 
     - 이는 시뮬레이션의 현실성을 높이는 중요한 단계입니다.

3. **시뮬레이션 실행**  
   - **독립 변수의 무작위 값을 반복적으로 생성**  
     - 정의된 확률 분포를 바탕으로 무작위 값을 생성하여 다양한 시나리오를 만듭니다.  
   - **가능한 조합의 대표적인 표본을 얻을 때까지 반복**  
     - 수백, 수천 번의 시뮬레이션을 실행하여 결과의 패턴을 파악합니다.  
   - **표본 내 변동 범위 계산 (분산 및 표준 편차 활용)**  
     - 결과의 신뢰성을 평가하기 위해 분산과 표준 편차를 계산하여 예측값의 변동성을 분석
   - **샘플링 횟수가 많을수록 정확도 향상**  
     - 시뮬레이션 반복 횟수가 증가할수록 무작위성에 의한 오차가 줄어들고, 결과가 실제 값에 수렴.

## 14. 데이터 모델 예측의 3가지 주요 함정
- 출처: [Overfitting, Underfitting, and Bad Data Are Ruining Your Predictive Models](https://www.youtube.com/watch?v=0RT2Q0qwXSA&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=14)

### 14.1 과소 적합 (Underfitting)
**과소 적합**은 모델이 데이터의 패턴을 제대로 학습하지 못해 예측 성능이 떨어지는 상황을 의미합니다. 이는 모델이 너무 단순해서 데이터의 복잡한 관계를 반영하지 못할 때 발생합니다.

- **정의** 
  - 모델이 입력 및 출력 변수 간의 관계를 정확하게 포착하지 못하는 경우입니다. 
  - 예를 들어, 복잡한 비선형 데이터를 선형 모델로 설명하려 하면 데이터의 주요 추세를 놓치게 됩니다.
- **원인** 
  - 모델이 너무 단순하여 데이터의 주요 추세를 파악하지 못하기 때문입니다. 
  - 이는 모델의 구조가 데이터의 복잡성을 담아낼 만큼 충분히 유연하지 않을 때 나타납니다.
- **특징**
  - **높은 편향 (High Bias)** 
    - 모델이 데이터의 실제 패턴을 체계적으로 잘못 반영하여 예측이 일관되게 틀립니다.
  - **낮은 분산 (Low Variance)** 
    - 모델이 단순하기 때문에 데이터의 작은 변화에도 예측 결과가 크게 흔들리지 않습니다.
  - **훈련 데이터에서도 문제점을 보임** 
    - 모델이 훈련 데이터조차 제대로 설명하지 못해, 훈련 데이터에 대한 성능도 낮습니다.
- **해결 방안**
  - **규제 감소 (Decrease Regularization)** 
    - 규제는 모델의 복잡성을 제한하는 기법인데, 이를 줄이면 모델이 입력과 출력 간의 관계를 더 자유롭게 학습할 수 있습니다. 
    - 예를 들어, L1/L2 규제의 강도를 낮추는 방법이 있습니다.
  - **훈련 데이터 증가 (Increase Training Data)** 
    - 더 많은 데이터를 제공하면 모델이 데이터의 패턴을 더 잘 파악할 기회가 늘어납니다. 
    - 데이터가 부족하면 모델이 일반화된 규칙을 학습하기 어렵습니다.
  - **특성 선택 (Feature Selection)** 
    - 예측에 중요한 특징을 추가하거나 기존 특성의 중요도를 조정합니다. 
    - 예를 들어, 상관관계 분석을 통해 유의미한 변수를 추가할 수 있습니다.

### 14.2 과대 적합 (Overfitting)
**과대 적합**은 모델이 훈련 데이터에 지나치게 맞춰져 새로운 데이터에 대한 예측 능력이 떨어지는 경우를 말합니다. 이는 모델이 데이터의 노이즈까지 학습하여 일반화에 실패하는 문제입니다.

- **정의** 
  - 모델이 훈련 데이터에 너무 정확하게 맞춰져 새로운 데이터에 대한 예측 정확도가 떨어지는 경우. 
  - 훈련 데이터의 특이한 패턴이나 이상치까지 모델이 학습해버리면 실제 환경에서 성능이 저하됩니다.
- **원인** 
  - 과소 적합 문제를 해결하려다 모델을 지나치게 복잡하게 만들었을 때 발생합니다.
  -  너무 많은 매개변수나 깊은 네트워크 구조가 원인이 될 수 있습니다.
- **특징**
  - **낮은 오류율 (Low Error Rate)** 
    - 훈련 데이터에 대한 오류가 매우 낮아, 훈련 데이터에서는 뛰어난 성능을 보입니다.
  - **높은 분산 (High Variance)** 
    - 새로운 데이터에 대한 예측이 불안정하고, 데이터의 작은 변화에도 결과가 크게 달라집니다.
  - **훈련 데이터의 노이즈를 실제 신호로 오인** 
    - 모델이 데이터의 실제 패턴뿐 아니라 무작위 노이즈까지 학습합니다.
- **해결 방안**
  - **데이터 증강 (Data Augmentation)** 
    - 노이즈가 포함된 데이터를 추가하여 모델이 노이즈에 덜 민감하도록 만듭니다. 
    - 예를 들어, 이미지 데이터라면 회전, 크기 조정 등을 통해 데이터를 늘릴 수 있습니다.
  - **앙상블 방법 (Ensemble Methods)** 
    - 여러 모델을 결합하여 예측의 안정성을 높입니다. 
    - 배깅(Bagging)이나 부스팅(Boosting) 같은 기법이 대표적입니다.
  - **조기 종료 (Early Stopping)** 
    - 모델이 훈련 데이터의 노이즈를 학습하기 전에 훈련을 중단합니다. 검증 데이터의 성능을 모니터링하여 적절한 시점에서 학습을 멈춥니다.

### 14.3 불량 데이터 (Bad Data)
**불량 데이터**는 부정확하거나 관련이 없거나 불완전한 데이터를 의미하며, 이는 모델의 성능을 저하시키고 편향된 결과를 초래할 수 있습니다.

- **정의** 
  - 부정확하거나 관련 없거나 불완전한 데이터입니다. 
  - 예를 들어, 결측값이 많거나 잘못 기록된 데이터가 이에 해당합니다.
- **영향** 
  - 모델의 성능이 저하되고, 편향된 의사 결정을 유발합니다. 
  - 특정 데이터가 누락되면 해당 그룹에 대한 예측이 왜곡될 수 있습니다.
- **예방**
  - **데이터 정확성 및 완전성 확보** 
    - 교차 검증을 통해 데이터의 정확성을 점검합니다. 
    - 예를 들어, 여러 소스에서 데이터를 비교하거나 결측값을 보완합니다.
  - **이상치 제거 (Outlier Removal)** 
    - 이상치가 모델에 미치는 영향을 줄이기 위해 이를 식별하고 제거하거나 조정합니다. 
    - 예를 들어, 통계적 기법(예: IQR)을 사용해 이상치를 탐지할 수 있습니다.
  - **최신 데이터 유지** 
    - 오래된 데이터는 현재 상황을 반영하지 못하므로, 주기적으로 데이터를 업데이트

## 15. 경사 하강법(Gradient Descent)
- 출처: [Gradient Descent Explained](https://www.youtube.com/watch?v=i62czvwDlsw&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=15)

### **15.1 경사 하강법이란?**
- **어두운 산에서 길을 찾는 것과 유사** 
  - 경사 하강법을 쉽게 이해하려면, 어둠 속에서 산 아래로 내려가는 상황을 상상해보세요. 앞이 보이지 않더라도 발밑의 경사를 느끼며 가장 가파른 내리막길 방향으로 조금씩 이동하면 결국 산 아래에 도달할 수 있습니다. 
  - 마찬가지로, 경사 하강법은 모델의 성능을 개선하기 위해 비용 함수의 기울기를 따라 최적의 방향으로 점진적으로 나아가는 방법입니다.
- **머신러닝 모델, 특히 신경망을 훈련시키는 데 사용되는 최적화 알고리즘** 
  - 경사 하강법은 머신러닝 모델이 데이터를 학습하며 오류를 줄이고 예측 정확도를 높일 수 있도록 돕는 핵심 도구입니다. 신경망에서는 특히 중요한데, 복잡한 데이터 패턴을 학습하기 위해 필수적입니다.
- **모델이 훈련 데이터를 통해 학습하고 정확도를 향상시킬 수 있도록 함** 
  - 훈련 데이터를 바탕으로 모델의 파라미터(가중치와 편향)를 조정하여 예측 결과를 실제 값에 가깝게 만듭니다.

### **15.2 신경망과 경사 하강법**

- **신경망은 연결된 뉴런들의 계층으로 구성** 
  - 신경망은 입력층, 은닉층, 출력층으로 이루어진 뉴런 네트워크입니다. 
  - 각 뉴런은 입력 데이터를 받아 가중합을 계산하고, 활성화 함수를 통해 다음 층으로 정보를 전달.
- **각 계층은 가중치(weights)와 편향(biases)을 가지며, 이는 네트워크를 통해 정보 전달 방식을 결정** 
  - 가중치는 입력 데이터의 중요도를 조절하고, 편향은 출력 값을 조정하는 역할을 합니다. 이 값들이 신경망의 학습 결과에 직접적인 영향을 미칩니다.
- **신경망은 레이블이 지정된 훈련 데이터를 통해 학습하여 최적의 가중치와 편향을 찾음** 
  - 예를 들어, 이미지 분류 모델이라면 이미지와 해당 레이블(예: "고양이" 또는 "개")을 학습하여 가중치와 편향을 조정합니다.
- **경사 하강법은 비용 함수(cost function)의 최솟값을 찾는 데 사용됨**
  - **비용 함수는 모델의 예측 값이 실제 값과 얼마나 다른지를 나타냄** 
    - 비용 함수는 일반적으로 평균 제곱 오차(MSE)나 교차 엔트로피 같은 형태로 정의되며, 값이 작을수록 모델 성능이 좋습니다.
  - **경사 하강법은 비용 함수를 최소화하는 방향으로 작은 단계를 반복적으로 수행** 
    - 비용 함수의 기울기(gradient)를 계산하여 그 반대 방향으로 파라미터를 조금씩 조정합니다. 기울기는 비용 함수가 가장 빠르게 증가하는 방향을 나타내므로, 반대 방향으로 이동하면 비용이 감소.
  - **각 단계의 크기를 학습률(learning rate)이라고 함** 
    - 학습률은 파라미터를 얼마나 크게 조정할지를 결정하는 값으로, 너무 크면 최솟값을 지나칠 수 있고, 너무 작으면 학습이 느려질 수 있습니다.

### **15.3 예시**
- **집값 예측**
  - **신경망을 훈련하여 집의 위치, 크기 등의 정보와 실제 판매 가격을 학습시킴** 
    - 신경망은 집의 특징(위치, 크기, 방 개수 등)을 입력으로 받아 판매 가격을 예측하도록 훈련됩니다. 훈련 데이터는 실제 판매 가격이 포함된 레이블입니다.
  - **새로운 집 정보가 주어지면, 신경망은 예상 판매 가격을 예측** 
    - 학습이 끝난 모델은 새로운 집의 데이터를 입력받아 가격을 추정합니다.
  - **예측 가격과 실제 가격의 차이를 통해 비용 함수를 계산, 경사 하강법을 사용하여 가중치와 편향을 조정** 
    - 예측값과 실제값의 차이를 비용 함수로 계산한 뒤, 경사 하강법으로 기울기를 구하고 파라미터를 업데이트하여 오차를 줄입니다. 이 과정을 반복하면 모델이 점점 더 정확한 예측을 하게 됩니다.

### **15.4 경사 하강법의 종류**

- **배치 경사 하강법 (Batch Gradient Descent)**
  - **훈련 데이터셋의 모든 데이터 포인트를 사용하여 비용 함수를 계산하고 모델을 업데이트**   
    - 전체 데이터에 대해 기울기를 한 번에 계산하므로 정확도가 높습니다.
  - **계산 효율성은 높지만, 큰 데이터셋의 경우 처리 시간이 오래 걸림** 
    - 데이터가 많아질수록 계산 비용이 급격히 증가합니다.
- **Stochastic 경사 하강법 (Stochastic Gradient Descent, SGD)**
  - **각 훈련 데이터 포인트를 개별적으로 평가하고 모델을 업데이트** 
    - 데이터 하나씩 처리하므로 업데이트가 빠르게 이루어집니다.
  - **속도는 빠르지만, 계산 효율성은 낮음** 
    - 기울기의 변동이 커서 학습 경로가 불안정할 수 있습니다.
- **미니 배치 경사 하강법 (Mini-Batch Gradient Descent)**
  - **훈련 데이터셋을 작은 배치로 나누어 각 배치에 대해 업데이트를 수행** 
    - 예를 들어, 32개 또는 64개 데이터로 묶어 처리합니다.
  - **계산 효율성과 속도 사이의 균형을 제공** 
    - 배치와 SGD의 장점을 결합하여 안정성과 속도를 동시에 확보합니다. 현재 딥러닝에서 가장 널리 사용되는 방식입니다.

### **15.5 경사 하강법의 문제점**

- **비볼록(Non-convex) 문제**
  - **비용 함수가 복잡한 형태를 가질 경우, 경사 하강법이 전역 최솟값(global minimum)을 찾지 못하고 지역 최솟값(local minimum)에 갇힐 수 있음** 
    - 비용 함수가 여러 개의 최솟값을 가질 때, 최적의 해가 아닌 부분적인 해에 도달할 수 있습니다.
  - **특히 saddle point(안장점)에서 잘못된 판단을 내릴 수 있음** 
    - 안장점은 기울기가 0이지만 최솟값이 아닌 지점으로, 학습이 멈출 위험이 있습니다.
- **Vanishing/Exploding Gradients (기울기 소실/폭발)**
  - **깊은 신경망에서 기울기가 너무 작아지거나(vanishing gradients) 너무 커지는(exploding gradients) 문제 발생 가능** 
    - 깊은 층을 가진 신경망에서는 역전파 과정에서 기울기가 점점 작아지거나 커질 수 있습니다.
  - **기울기 소실은 네트워크 초기 레이어의 학습 속도를 감소, 기울기 폭발은 불안정한 모델을 만듦** 
    - 이를 해결하기 위해 ReLU 같은 활성화 함수나 가중치 초기화 기법(Xavier 초기화 등)이 사용

## 16. 제한된 볼츠만 머신(RBM)
- 출처: [What is an RBM (Restricted Boltzmann Machine)?](https://www.youtube.com/watch?v=L3ynnRgpZwg&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=16)

### 16.1 RBM이란?
- **비지도 학습을 위한 확률적 그래프 모델**  
  - 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)은 레이블 없이 데이터를 학습하는 비지도 학습 방식에 기반한 모델로, 확률론적 접근을 통해 데이터의 분포를 추정합니다.  
- **데이터 내 숨겨진 구조 발견에 사용**  
  - RBM은 데이터 속에 숨겨진 패턴이나 특징을 찾아내는 데 강점을 가지며, 복잡한 데이터셋에서 의미 있는 정보를 추출합니다.  
- **동영상 추천 시스템에 적합**  
  - 특히 사용자 행동 데이터를 분석해 개인화된 추천을 제공하는 동영상 추천 시스템과 같은 실세계 응용 분야에서 효과적으로 활용됩니다.  

### 16.2 RBM의 구조
- **가시층(Visible Layer)** 
  - 노드로 구성, 훈련 데이터 입력  
  - 가시층은 우리가 관찰할 수 있는 데이터를 입력받는 노드들로 이루어져 있습니다. 
  - 예를 들어, 사용자가 본 동영상 목록이나 이미지 픽셀 값 등이 이에 해당합니다.  
- **숨김층(Hidden Layer)** 
  - 노드로 구성, 가시층의 특징을 학습  
  - 숨김층은 가시층 데이터의 숨겨진 특징(예: 동영상의 주제나 스타일)을 학습하는 노드들로 구성되며, 데이터의 고차원적 표현을 생성합니다.  
- **연결** 
  - 가시층의 모든 노드는 숨김층의 모든 노드와 연결 (one-to-many)  
  - 가시층과 숨김층 사이에는 완전 연결(fully connected) 구조가 형성되며, 각 연결은 데이터의 상호작용을 나타냅니다.  
- **제한** 
  - 같은 층 내의 노드끼리는 연결되지 않음  
  - RBM의 "제한"이라는 이름 
    - 가시층 내 노드 간, 혹은 숨김층 내 노드 간 연결이 없다는 특성에서 유래하며, 이는 계산 복잡성을 줄이고 학습을 효율적으로 만듭니다.  
- **가중치(Weights)** 
  - 엣지에 연결되어 있으며, 노드가 활성화될 확률을 나타냄  
  - 각 연결에는 가중치가 할당되어 있으며, 이 가중치는 특정 노드가 활성화될 가능성을 조절하는 역할

### 16.3 RBM의 작동 방식
- **훈련**  
  - 다수의 입력을 제공하여 네트워크 훈련
    - RBM은 대량의 훈련 데이터를 입력받아 네트워크를 학습시키며, 이 과정에서 데이터의 분포를 모델링합니다.  
  - 가시층 노드는 훈련 데이터를 받음
    - 훈련 데이터(예: 사용자의 동영상 시청 기록)가 가시층에 입력되며, 이 데이터가 학습의 시작점
  - 가중치와 곱해져 숨김층에서 편향 값과 더해짐
    - 가시층 데이터는 가중치와 곱해진 후 숨김층으로 전달되고, 여기서 편향(bias) 값과 합산되어 숨김층 노드의 활성화 여부를 결정합니다.  
- **순방향 패스(Feed Forward Pass)**  
  - 가시층 유닛과 숨김층 유닛 간의 긍정적/부정적 연관성 식별
    - 순방향 패스에서는 입력 데이터와 숨김층 노드 간의 관계를 분석해 긍정적이거나 부정적인 연관성을 파악
- **역방향 패스(Feed Backwards Pass):**  
  - 가중치, 편향 조정 및 층 사이의 모든 엣지에 대한 확률 기록  
    - 역방향 패스에서는 학습된 정보를 바탕으로 가중치와 편향을 미세 조정하며, 각 연결에 대한 확률 값을 업데이트합니다.  
- **훈련 데이터를 통해 숨겨진 노드를 활성화하는 패턴 학습 (데이터셋 전체의 확률 분포 학습)**  
  - 이러한 반복 과정을 통해 RBM은 데이터 내 숨겨진 패턴을 학습하고, 전체 데이터셋의 확률 분포를 근사하게 됩니다.  

### 16.4 동영상 추천 시스템 예시
- **가시층** 
  - 사용자가 시청한 동영상 목록  
  - 가시층에는 사용자가 실제로 시청한 동영상 데이터가 입력됩니다. 
  - 예를 들어, "고양이 영상"이나 "파이썬 강의" 같은 목록이 이에 해당합니다.  
- **숨김층** 
  - 동영상 분류 (예: 주제 - 머신러닝, 파이썬, 고양이, 스타일 - 데모, 브이로그, 강연)  
  - 숨김층은 동영상의 특징을 나타내는 분류를 학습합니다. 주제(머신러닝, 고양이 등)나 스타일(강연, 브이로그 등)이 이에 포함됩니다.  
- **RBM은 사용자의 시청 기록을 기반으로 가중치와 편향을 조정하여 사용자가 특정 주제/스타일의 동영상에 얼마나 관심 있는지 판단**  
  - 사용자가 어떤 동영상을 많이 봤는지 분석해 가중치와 편향을 조정함으로써, 사용자가 좋아할 만한 주제나 스타일의 동영상을 예측하고 추천합니다.  

### 16.5 RBM의 활용 분야
- **협업 필터링 (추천 엔진)**  
  - 사용자와 아이템 간의 관계를 분석해 개인화된 추천을 제공(예: 넷플릭스 추천 시스템).  
- **특징 추출**  
  - 이미지나 텍스트 데이터에서 중요한 특징을 자동으로 추출해 데이터 표현을 개선합니다.  
- **패턴 인식 (필기 인식 등)**  
  - 손글씨 숫자 인식과 같이 복잡한 패턴을 학습하고 분류하는 데 유용합니다.  
- **데이터셋 내 구조 파악 (사건 발생 원인 계층 구조 등)**  
  - 데이터의 계층적 구조나 상호작용을 분석해 사건의 원인과 결과를 이해하는 데 기여합니다.  

### 16.6 RBM의 장점
- **수동으로 모든 노드를 반복하고 가중치를 조정하는 코드를 작성하지 않고도 데이터에 대해 학습 가능**  
  - RBM은 복잡한 수작업 대신 자동화된 학습 과정을 통해 데이터를 효율적으로 학습하며, 개발자가 일일이 가중치를 조정할 필요 없이 모델이 스스로 최적화됩니다.  


## 17. 결정체 지능(Crystallized Intelligence)과 유동성 지능(Fluid Intelligence)
- 출처: [Fluid vs. Crystallized Intelligence](https://www.youtube.com/watch?v=T7Wr7wVK5Wo&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=17)


### **17.1 소개**
- **퀴즈 도입**  
  프랑스 수도와 수열 완성 문제는 각각 결정체 지능과 유동성 지능을 대표하는 예시입니다.  
  - "프랑스 수도는?" → 학습된 지식을 활용하는 결정체 지능  
  - "A 1 B 2 C 다음은?" → 논리적 추론과 새로운 패턴 인식 능력인 유동성 지능  

- **머신러닝과의 연관성 강조**  
  - AI 시스템은 인간의 두 가지 지능을 모방하거나 결합하여 더 복잡한 작업을 수행할 수 있습니다. 
  - 예를 들어, 자연어 처리(NLP) 시스템은 사전 학습된 데이터(결정체 지능)와 새로운 입력 데이터에 대한 적응력(유동성 지능) 모두가 필요합니다.

### **17.2 결정체 지능 (Crystallized Intelligence)**
- **정의**  
  결정체 지능은 시간이 지남에 따라 축적된 정보, 기술, 경험을 바탕으로 작동합니다. 이는 오랜 학습 과정을 통해 형성되며, 특정 맥락에서 이미 알고 있는 지식을 활용하는 능력을 의미합니다.  

- **특징**  
  - **사실 기반:** 역사적 사실, 언어 규칙, 수학 공식 등 명확하게 정의된 지식을 사용합니다.  
  - **경험 의존적:** 개인의 학습 경험과 환경에 크게 영향을 받습니다.  
  - **예시 확장**  
    - "프랑스 수도는?" → 지리적 지식 활용  
    - "수학 문제 풀기" → 기존 수학 법칙 적용  

- **AI 적용**  
  - **IBM Watson**  
    Watson은 방대한 양의 텍스트 데이터를 분석하고 질문에 대한 답을 찾는 능력을 보여줍니다. 이는 주로 결정체 지능에 해당하며, 사전 학습된 데이터베이스를 검색하여 정답을 도출합니다.  
  - **시스템 모델**  
    - 대규모 데이터셋을 학습한 딥러닝 모델(예: GPT, BERT)은 결정체 지능을 구현합니다.  
    - 예를 들어, GPT는 수백만 개의 문서를 학습하여 문맥에 맞는 답변을 생성합니다.  

### **17.3 유동성 지능 (Fluid Intelligence):**
- **정의**  
  유동성 지능은 새로운 상황에서 창의적으로 문제를 해결하거나 추론을 통해 패턴을 발견하는 능력을 말합니다. 이는 습득된 지식에 의존하지 않고, 순수한 논리적 사고와 적응력을 강조합니다.  

- **특징**  
  - **추론 및 논리:** 패턴 인식, 추상적 사고, 문제 해결 능력 등을 포함합니다.  
  - **독립성:** 기존 학습된 지식 없이도 새로운 문제를 해결할 수 있습니다.  
  - **예시 확장**  
    - "A 1 B 2 C 다음은?" → 패턴 인식과 논리적 추론  
    - "미로 탈출하기" → 직관적 사고와 공간 감각  

- **AI 적용**  
  - **새로운 문제 해결**  
    - 강화 학습(Reinforcement Learning)은 유동성 지능의 좋은 예입니다.  
    - 예: 알파고(AlphaGo)는 바둑의 기본 규칙만 학습하고, 이후 스스로 게임 전략을 개발
  - **적응형 시스템**  
    - 실시간으로 변화하는 환경에서 최적의 솔루션을 찾아내는 AI(예: 자율주행차, 로봇).  

### **17.4 결정체 지능과 유동성 지능의 결합**
- **문제 해결의 필수성**  
  현실 세계의 대부분의 문제는 단일 지능만으로 해결되기 어렵습니다. 두 지능이 상호 보완적으로 작용해야

- **AI 여행 시스템 예시**  
  - **결정체 지능**  
    - 파리의 관광지 정보, 역사적 배경, 교통 시스템 등의 데이터를 기반으로 여행 계획을 수립
    - 예: "에펠탑은 몇 시까지 운영되나요?" → 기존 데이터베이스에서 답변 제공.  
  - **유동성 지능**  
    - 사용자의 선호도(예: 음식, 활동), 예산, 일정 등을 분석하여 최적의 맞춤형 여행 일정을 생성
    - 예: "비오는 날씨에 적합한 실내 활동 추천" → 새로운 상황에 적응.  

- **인간과 AI의 비교**  
  - **인간**  
    - 결정체 지능 = 학습된 지식  
    - 유동성 지능 = 지식을 활용해 새로운 문제를 해결하는 능력  
  - **AI**  
    - 결정체 지능 = 사전 학습된 데이터셋과 모델  
    - 유동성 지능 = 새로운 입력 데이터에 적응하고 문제를 해결하는 능력  

### **17.5 결론**
- **두 지능의 중요성**  
  결정체 지능과 유동성 지능은 상호 보완적이며, 복잡한 문제 해결에는 두 지능이 모두 필요합니다.  

- **AI 발전 방향**  
  - 현재 AI는 결정체 지능 측면에서 매우 발달했지만, 유동성 지능 측면에서는 여전히 한계
  - 미래의 AI는 두 지능을 더욱 효과적으로 결합하여 인간처럼 창의적이고 적응력 있는 시스템으로 진화

- **미래 전망**  
  - **결정체 + 유동성 지능의 융합**  
    - 예: 의료 진단 시스템은 기존 의료 데이터(결정체)와 새로운 환자 증상(유동성)을 분석하여 최적의 치료법을 제안합니다.  
  - **초지능(Superintelligence) 가능성**  
    - 두 지능의 완벽한 통합은 초지능으로 이어질 가능성이 있습니다.  


## 18. 분산 AI(Distributed AI)
- 출처: [Edge AI vs. Distributed AI](https://www.youtube.com/watch?v=jevuDDjFEsM&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=18)


### 18.1 **핵심 내용:**
- **분산 AI 정의** 
  - 데이터 및 AI 애플리케이션을 분산된 클라우드 환경에서 확장할 수 있도록 하는 컴퓨팅 패러다임으로, 기존 중앙집중식 AI 모델의 한계를 극복하고 더욱 유연하고 효율적인 AI 생태계를 구현하는 접근법. 
  - 이는 지리적으로 분산된 다양한 환경에서 AI 자원을 효과적으로 활용하고 관리할 수 있게 해줍니다.

- **분산 클라우드 환경** 
  - 퍼블릭 클라우드, 온프레미스, 엣지 환경을 통합 관리하는 단일 창구(Single Pane of Glass) 애플리케이션 라이프사이클 관리를 제공합니다. 
  - 이는 기업이 다양한 IT 인프라를 복잡한 설정 없이 seamless하게 관리할 수 있도록 지원하며, 애플리케이션 배포와 관리의 복잡성을 획기적으로 줄여줍니다.

- **분산 AI 등장 배경** 
  - 클라우드 기반 AI에서 엣지 AI를 거쳐 분산 AI로 발전하는 진화의 과정을 보여줍니다. 
  - 이는 AI 기술이 점점 더 분산화되고 지능화되는 트렌드를 반영하며, 기업의 디지털 혁신과 AI 활용 전략의 패러다임 변화를 의미합니다.

### 18.2 **AI 발전 여정**
1. **클라우드 기반 AI**
- 플랜트(또는 사업 운영 위치)에서 발생하는 대규모 데이터를 중앙 데이터 센터 또는 퍼블릭 클라우드로 전송하여 AI 파이프라인을 통한 의사 결정 프로세스를 수행합니다.
-  이 모델은 초기 AI 도입 단계에서 중요한 역할을 했지만, 데이터 전송과 관련된 여러 가지 기술적 제약이 존재했습니다.
- 의사 결정 결과를 다시 플랜트로 전달하여 자동화를 구현하는 방식을 채택했습니다.
- 주요 문제점으로는 대량 데이터 전송으로 인한 네트워크 연결 문제, 심각한 지연 시간, 민감한 데이터의 보안 리스크 등이 있었습니다.

2. **엣지 AI**
- 분산 클라우드 환경을 활용하여 데이터 생성 지점(플랜트)에서 직접 실시간 의사 결정을 수행합니다.
- 중앙 코어(Core)는 애플리케이션 배포 및 라이프사이클 관리에 집중하는 역할을 담당합니다.
- 데이터 전송 필요성을 크게 줄이고, 실시간 의사 결정을 가능하게 하는 획기적인 접근 방식을 제공.
- 그러나 여전히 다수의 로케이션과 어플리케이션에 적용 시 추가적인 해결 과제들이 존재합니다.

3. **분산 AI (Hub-and-Spoke 모델)**
- 데이터 위치(Spoke)와 AI 기능 위치(Hub)를 전략적으로 분리하여 최대한의 유연성을 확보합니다.
- 데이터가 존재하는 클라우드(Spoke)와 AI 기능 및 제어 평면이 위치한 클라우드(Hub)로 아키텍처를 구성합니다.
- Hub에서 Spoke로 애플리케이션을 배포하고 데이터 및 AI 라이프사이클을 통합 관리합니다.

### 18.3 **분산 AI의 해결 과제**
1. **데이터 중력(Data Gravity):**
- 대량의 데이터가 Hub로 집중됨에 따라 발생하는 리소스 부담과 네트워크 대역폭 제한 문제를 해결해야 합니다.
- 지능형 데이터 수집(Intelligent Data Collection) 방식을 통해 정말 중요하고 가치 있는 데이터만을 선별적으로 수집하는 전략을 채택합니다.

2. **이질성(Heterogeneity):**
- Spoke마다 존재하는 제품, 고객 특성 등의 다양성으로 인해 Hub에서 학습된 단일 모델이 모든 Spoke에 균일하게 적용되기 어려운 문제가 있습니다.
- 각 Spoke의 특성에 맞게 AI 파이프라인 및 애플리케이션을 동적으로 조정(Adaptation)하고, 지속적으로 성능을 모니터링(Monitoring)하는 접근법을 제시합니다.

3. **규모(Scale):**
- Spoke의 수가 증가하고 다양한 애플리케이션 및 데이터 유형이 도입됨에 따라 관리의 복잡성이 기하급수적으로 증가합니다.
- 데이터 및 AI 라이프사이클의 자동화(Automation)를 통해 이러한 복잡성을 효과적으로 관리할 수 있는 방안을 모색합니다.

4. **리소스 제약(Resource Constraints):**
- 플랜트나 소규모 매장과 같은 일부 Spoke 환경은 계산 능력, 저장 공간 등의 리소스가 매우 제한적.
- 피처 추출(Feature extraction), 모델 압축(Model Compression), 가지치기(Pruning) 등의 최적화(Optimization) 기법을 통해 제한된 리소스 환경에서도 효율적인 AI 운영을 가능하게 합니다.

## 19. AI 기반 자동화를 사용하여 자동 클레임 처리 가속화
- 출처: [Use AI-Powered Automation to Accelerate Auto Claims Processing](https://www.youtube.com/watch?v=6dyrBRcC5KA&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=19)


### 19. 1 **문제 상황**

- 매일 전 세계적으로 수많은 교통사고 발생
  - 전 지구적으로 연간 약 5천만 건의 교통사고가 발생하며, 이는 매일 평균 13만 건 이상의 사고를 의미합니다. 이러한 사고는 개인과 사회에 심각한 영향을 미치는 글로벌 안전 문제입니다.

- 사고는 스트레스, 위험, 막대한 비용 발생 (국가 GDP의 2~8% 손실) 
  - 교통사고로 인한 경제적 손실은 단순히 차량 수리비용을 넘어 의료비, 생산성 저하, 보험 처리 비용 등을 포함합니다. 
  - 이러한 간접 비용은 국가 경제에 막대한 부담을 주며, 특히 개발도상국에서 더욱 심각한 경제적 영향을 미칩니다.

- 고객은 복잡하고 시간이 오래 걸리는 보험 청구 절차에 어려움
  - 전통적인 보험 청구 과정은 평균 2~3주가 소요되며, 고객들은 복잡한 서류 작업, 반복되는 문의, 지연된 보상 등으로 심각한 스트레스와 불편함을 겪고 있습니다.

### 19.2 **해결책 (현대 보험사의 역할)**

- 데이터와 AI 활용하여 사고 처리 시간과 스트레스 감소
  - 빅데이터 분석과 인공지능 기술을 통해 사고 처리 프로세스를 획기적으로 간소화하고 효율성 제고
  - 머신러닝 알고리즘은 과거 사고 데이터를 학습하여 더 빠르고 정확한 보험 처리를 가능

- 자동화된 보험 청구 처리 워크플로우 구축
  - 사고 직후 간단한 정보 제공으로 청구 절차 시작
    - 모바일 앱을 통해 즉시 사고 정보를 입력하고 청구 절차를 시작할 수 있어 신속한 대응이 가능
  - 사고 책임자 정보 즉시 수집 및 입력
    - GPS 및 실시간 데이터 공유 기술을 활용하여 사고 관련 정보를 신속하게 수집하고 기록
  - 스마트폰 카메라를 이용한 손상 부위 촬영 및 기록
    - AI 이미지 분석 기술을 통해 차량 손상 정도를 즉시 평가하고 수리 견적을 자동으로 생성
  - 수리 업체 즉시 선택
    - 위치 기반 서비스와 협력 네트워크를 통해 최적의 수리 업체를 신속하게 추천합니다.
  - Uber 제공으로 고객의 이동 지원
    - 사고 직후 고객의 이동 편의를 위해 대체 교통수단을 즉시 제공하여 고객 경험을 개선

### 19.3 **결론**

- 보험사는 데이터 활용 능력과 고객 경험 개선을 통해 사고로 인한 스트레스를 줄일 수 있음
  - 기술 혁신을 통해 보험 서비스의 패러다임을 근본적으로 변화시키고, 고객 중심의 신속하고 투명한 서비스를 제공할 수 있습니다.

- 하이브리드 클라우드 및 AI 플랫폼을 통해 고객에게 편리한 서비스 제공 가능
  - 클라우드 컴퓨팅과 인공지능 기술의 통합은 보험 산업에 혁신적인 솔루션을 제공하며, 고객 만족도와 운영 효율성을 동시에 높일 수 있는 잠재력을 가지고 있습니다.

## 20. 지도 학습 vs. 비지도 학습
- 출처: [Supervised vs. Unsupervised Learning](https://www.youtube.com/watch?v=W01tIRP_Rqs&list=PLOspHqNVtKAC-FUNMq8qjYVw6_semZHw0&index=20)


### 20.1 **핵심 차이**

- **지도 학습 (Supervised Learning)** 
  - 레이블링된 입력 및 출력 데이터를 사용하여 모델을 학습시킴. 
  - 각 데이터 포인트에 대해 '정답'이 이미 알려져 있어, 모델이 이를 학습하고 일반화할 수 있음.
- **비지도 학습 (Unsupervised Learning)** 
  - 레이블링되지 않은 데이터에서 숨겨진 패턴을 스스로 발견함. 
  - 데이터의 내재된 구조와 관계를 모델이 자율적으로 파악함.

### **20.2 지도 학습 (Supervised Learning)**

- **정의** 
  - 레이블링된 데이터셋으로 알고리즘을 학습시켜, 새로운 데이터에 대한 정확한 출력을 예측하도록 함. 이는 마치 교사가 학생에게 정답을 알려주며 학습을 돕는 것과 유사함.
- **특징:**
  - 알고리즘은 각 학습 데이터의 정답을 알고 있어, 예측 모델을 정교하게 조정할 수 있음.
  - 오차를 최소화하는 방향으로 지속적으로 학습하며 성능을 개선.
  - 명확한 평가 지표(정확도, 정밀도, 재현율 등)를 통해 모델의 성능을 객관적으로 측정 가능.
- **하위 유형:**
  - **분류 (Classification):** 입력 데이터를 미리 정의된 클래스나 범주로 구분. 
    -  이메일 스팸 필터링, 질병 진단, 얼굴 인식 등에 광범위하게 활용됨.
    - 대표 알고리즘: 선형 분류기, 서포트 벡터 머신(SVM), 결정 트리, 랜덤 포레스트 등.
  - **회귀 (Regression):** 연속적인 값을 예측하는 모델.
    - 주택 가격 예측, 주식 시장 트렌드 분석, 기후 변화 예측 등에 사용.
    - 대표 알고리즘: 선형 회귀, 로지스틱 회귀, 다항식 회귀 등.

### 20.3 **비지도 학습 (Unsupervised Learning)**

- **정의** 
  - 레이블링되지 않은 데이터에서 숨겨진 패턴을 발견하는 알고리즘. 
  - 데이터의 고유한 구조와 관계를 스스로 학습함.
- **특징:**
  - 사람의 개입 없이 데이터의 내재된 구조를 자율적으로 파악.
  - 데이터 탐색과 패턴 발견에 탁월.
  - 명확한 '정답'이 없어 모델 평가가 상대적으로 어려움.
- **주요 작업:**
  - **군집화 (Clustering):** 유사한 특성을 가진 데이터를 그룹화.
    - 고객 세분화, 시장 분석, 이상 탐지 등에 활용.
    - 대표 알고리즘: K-means, DBSCAN, 계층적 군집화 등.
  - **연관 분석 (Association):** 데이터 내 변수 간의 숨겨진 관계를 발견.
    - 장바구니 분석, 추천 시스템, 마케팅 전략 수립에 사용.
    - 대표 알고리즘: Apriori 알고리즘, FP-growth 등.
  - **차원 축소 (Dimensionality Reduction):** 데이터의 복잡성을 줄이면서 핵심 정보 보존.
    - 데이터 시각화, 노이즈 제거, 특징 추출에 활용.
    - 대표 알고리즘: PCA(주성분 분석), t-SNE, 오토인코더 등.

### **20.4 지도 학습 vs. 비지도 학습 비교**

| 특징          | 지도 학습                                                                | 비지도 학습                                                                 |
| ------------- | ----------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| 데이터        | 레이블링된 데이터 (명확한 입력-출력 쌍)                                     | 레이블링되지 않은 데이터 (구조만 존재)                                       |
| 학습 방식      | 주어진 정답을 기반으로 모델을 지속적으로 조정                               | 데이터 자체의 내재된 구조와 패턴을 자율적으로 발견                           |
| 사람 개입      | 필요 (데이터 레이블링, 모델 설계 및 검증)                                  | 최소화 (데이터만 제공)                                                      |
| 예측 능력      | 높은 정확도로 새로운 데이터에 대한 예측 가능                                | 데이터 그룹화 및 패턴 발견에 중점, 직접적인 예측은 제한적                    |
| 모델 신뢰성    | 일반적으로 높은 신뢰성 (명확한 평가 지표 존재)                             | 상대적으로 낮은 신뢰성 (해석이 모호할 수 있음)                               |
| 활용 예시      | 의료 진단, 금융 리스크 예측, 고객 이탈 예측                                | 소비자 행동 분석, 이미지/텍스트 군집화, 이상 탐지                            |

### **20.5 어떤 학습 방법을 선택해야 할까?**
- **지도 학습:** 
  - 장점: 높은 예측 정확도, 명확한 결과 도출
  - 단점: 대규모 레이블링된 데이터 확보에 많은 노력과 비용 필요
  - 최적의 경우: 명확한 목표와 충분한 레이블링된 데이터가 존재할 때

- **비지도 학습:** 
  - 장점: 레이블링되지 않은 대규모 데이터 활용 가능, 숨겨진 패턴 발견
  - 단점: 결과의 해석이 모호하고 정확도가 상대적으로 낮음
  - 최적의 경우: 데이터 탐색, 패턴 발견, 전처리 단계에서 유용

- **준지도 학습 (Semi-supervised Learning):** 
  - 레이블링된 데이터와 레이블링되지 않은 데이터를 결합
  - 데이터 레이블링 비용을 줄이면서 모델 성능 개선
  - 의료 영상, 자연어 처리, 음성 인식 등 복잡한 도메인에서 효과적

