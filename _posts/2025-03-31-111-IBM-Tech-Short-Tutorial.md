---
title: 25차시 10:IBM TECH(종합 내용)
layout: single
classes: wide
categories:
  - IBM TECH(종합 내용)
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 91. 알고리즘 편향(Algorithmic Bias)
- 출처: [Algorithmic Bias in AI: What It Is and How to Fix It](https://www.youtube.com/watch?v=og67qeTZPYs)

### **91.1 정의**

*   머신러닝 알고리즘이 불공정하거나 차별적인 결과를 초래하는 현상  
    - 예: 동일한 조건의 지원자라도 성별/인종에 따라 다른 채용 점수 부여
*   AI 알고리즘 자체보다는 데이터 수집 및 코딩 방식에 의해 발생  
    - "Garbage In, Garbage Out" 원리: 잘못된 입력이 부정확한 출력을 생성

### **91.2 원인**

*   **훈련 데이터셋의 편향 (Bad Data):**  
    *   과거의 편향이 반영된 데이터 (예: 90% 남성 엔지니어 데이터로 훈련된 채용 AI)  
    *   표본 오류 (예: 주로 도시 데이터로 훈련된 자율주행차가 시골 길 인식 실패)  
    *   레이블링 편향 (예: "CEO" 사진을 주로 남성으로 태깅)  

*   **알고리즘 설계의 편향:**  
    *   목적 함수 설정 오류 (예: 재범 예측 알고리즘에서 "체포 횟수"를 과도하게 반영)  
    *   개발자의 무의식적 편향 (예: 백인 개발자가 피부색 인식 알고리즘을 설계할 때 발생하는 인종 간 정확도 차이)  

*   **대리 데이터의 편향 (Proxy Data):**  
    *   우편번호 → 소득 수준 추정 시 저소득 지역 거주자에 대한 불이익  
    *   검색 기록 → 신용점수 추정 시 특정 질병 관련 검색자가 낮은 점수 받는 경우  

*   **평가의 편향:**  
    *   성능 지표의 한계 (예: 정확도 90%라도 소수 집단에선 50% 성능일 수 있음)  

### **91.3 실제 사례 (심화 분석)**

*   **채용:**  
    *   아마존 AI 채용 툴이 여성 이력서를 감점한 사례  
    *   근본 원인: 기술 분야 역사적 남성 우월주의가 데이터에 내재화  
*   **금융:**  
    *   미국의 FICO 신용점수 모델에서 우편번호 영향으로 흑인 차별  
    *   파급 효과: 대출 거절 → 주택 구매 불가 → 빈곤의 대물림  
*   **의료:**  
    *   피부암 판별 AI가 백인 피부에 대해 더 높은 정확도 보임  
    *   치명적 결과: 진단 오류로 인한 생명 위협 가능성  

### **91.4 알고리즘 편향 완화 방법 (실행 방안)**

*   **데이터 측면:**  
    *   데이터 다각화: 연령, 성별, 인종 등 보호 특성(protected attributes)별 균형 확인  
    *   합성 데이터 생성: 소수 집단 데이터 증강 기술(GAN 등) 활용  
*   **기술 측면:**  
    *   공정성 지표 도입: 평등 기회(Equal Opportunity), 인종 간 정확도 차이 등 정량적 측정  
    *   편향 감소 알고리즘: Adversarial Debiasing, Reweighting 등 머신러닝 기법 적용  
*   **제도 측면:**  
    *   AI 윤리 위원회 구성: 법학, 사회학, 윤리학 전문가 참여  
    *   규제 프레임워크: EU AI Act, 미국 Algorithmic Accountability Act 등 준수  

### **91.5 향후 과제**  
- Explainable AI(XAI) 발전으로 "왜 이 결정이 내려졌는지" 설명 가능성 강화  
- 지속적 모니터링 시스템: 배포 후 편향 발생 시 실시간 조정 가능한 구조 구축  

### **91.6 핵심 통찰**  
- "알고리즘 편향은 기술적 결함이 아닌 사회적 편견의 거울입니다.  
- AI의 공정성 확보는 단순한 코딩 문제가 아니라 인류의 평등을 위한 사회적 프로젝트입니다."  

## 92. 에이전트 시스템의 필요성
- 출처: [Enhancing AI Agents Through Fine Tuning & Model Customization](https://www.youtube.com/watch?v=aQuCTWhiiPg)

### **92.1. 에이전트 시스템의 필요성 및 한계**

1. **필요성:**  
- **복잡한 문제 해결 요구:** 기존의 단순 질의응답 모델(Large Language Model, LLM)은 복잡한 다단계 문제 해결에 한계가 있습니다. 이는 여러 단계의 추론과 자율적인 의사 결정을 필요로 하는 작업에서 특히 두드러집니다.  
  - **예시:** 주식 포트폴리오 최적화, 과학 실험 설계 등.  
- **툴킷 활용의 중요성:** LLM은 일반적인 언어 처리 능력은 뛰어나지만 특정 도메인(예: 의료 진단, 금융 분석)에서는 충분한 지식이나 정교함이 부족합니다. 이를 보완하기 위해 다양한 외부 도구(툴킷)를 사용하며, 이러한 도구와의 통합이 AI 시스템의 유연성과 적용 가능성을 확대합니다.  

2. **한계:**  
- **도메인 지식 부족:** LLM이 특정 도메인에서 필요한 세부 지식이나 규칙을 제대로 이해하지 못하면 잘못된 도구 선택이나 불필요한 연산을 초래할 수 있습니다.  
  - **예시:** 의료 AI가 환자의 상태를 잘못 판단하거나 비효율적인 치료 계획을 제안하는 경우.  
- **조직 목표 부합성:** 조직의 정책, 규제, 윤리적 제약 등을 고려하지 않고 의사 결정을 내릴 경우, 시스템이 조직의 목표와 상충되는 결과를 낳을 수 있습니다.  

### **92.2 기존 시스템 설계의 주요 문제점**

1. **토큰 비효율성:**  
- **문제 원인:** LLM은 입력 데이터를 토큰 단위로 처리하는데, 복잡한 설정이나 장황한 프롬프트를 사용할 경우 불필요한 토큰 소비가 발생합니다.  
  - **예시:** 문제 해결보다는 초기 설정(예: 변수 정의, 환경 구성)에 많은 토큰이 소모됨.  

2. **높은 실행 비용:**  
- **비용 증가 요인:** 매번 동일한 정보를 반복적으로 처리하거나, 불필요한 연산을 수행하면 실행 비용이 크게 증가합니다.  
  - **예시:** 웹 스크래핑 도구가 매번 동일한 웹 페이지를 불러오는 경우.  

3. **오류 전파:**  
- **문제의 심각성:** 초기 단계에서 잘못된 결정이 내려지면 이후 단계에서도 오류가 누적되어 전체 시스템이 실패하거나 무한 루프에 빠질 수 있습니다.  
  - **예시:** 코드 생성 AI가 초기 구문 오류를 포함하면, 후속 로직이 모두 작동하지 않음.  

4. **낮은 이해도:**  
- **결과:** 모델이 특정 도메인의 맥락을 제대로 이해하지 못하면, 적절한 도구를 호출하거나 올바른 결정을 내리기 어려워집니다.  

### **92.3 미세 조정 데이터 수집 방법**
1. **도구별 데이터:** 
- **도구 사용 시점:**  
  - **중요성:** 특정 도구를 언제 사용해야 하는지 학습하지 않으면, 불필요한 도구 호출이나 잘못된 도구 선택으로 인해 성능이 저하됩니다.  
  - **예시:** 검색 도구 대신 데이터베이스 쿼리 도구를 사용해야 하는 경우.  
- **도구 호출 방법:**  
  - **핵심 매개변수 설정:** 도구를 효과적으로 사용하기 위해서는 필수 입력값(매개변수)을 정확히 이해하고 설정해야 합니다.  
  - **예시:** 날씨 API를 호출할 때 지역과 날짜를 반드시 포함해야 함.  
- **결과 활용법:**  
  - **후처리 필요성:** 도구 결과를 바로 사용하기보다는 가공하거나 검증하는 과정이 필요
  - **예시:** 감정 분석 결과를 바탕으로 추가적인 인간 개입 여부를 결정.  
- **쓰기 도구 특별 주의:**  
  - **위험성:** 파일 수정, 데이터베이스 업데이트 등 환경을 변경하는 도구는 잘못 사용하면 시스템에 큰 영향을 미칠 수 있습니다.  
- **에지 케이스 예시 제공:**  
  - **복잡한 시나리오:** 사용자 정의 도구나 예외 상황에서의 활용 방법을 학습해야 합니다.  
  - **예시:** 비정형 데이터를 처리하는 도구 사용법.  
2. **일반 추론, 의사 결정 및 계획 능력:**  
- **조직 정책 및 목표 정렬:**  
  - **방법:** 조직의 정책 문서, 규정, 목표를 모델이 학습하도록 데이터를 제공합니다.  
  - **예시:** 개인정보 보호법 준수를 강조하는 데이터 제공.  
- **사례 연구:**  
  - **실제 사례 활용:** 조직 내에서 이루어진 실제 의사 결정 사례를 통해 모델이 유사한 상황에서 올바른 결정을 내릴 수 있도록 학습합니다.  
- **실행 추적 데이터 분석:**  
  - **성공/실패 이유 파악:** 과거 실행 데이터를 분석하여 어떤 결정이 성공 또는 실패로 이어졌는지 이해하고 이를 학습 데이터로 활용합니다.  
- **역할별 데이터:**  
  - **역할 분리:** 모델이 다양한 역할(예: 심판, 검증자, 최적화기)을 수행할 수 있도록 각 역할에 맞는 데이터를 수집합니다.  

### **92.4 미세 조정 데이터 수집 시 고려 사항**

1. **반복적인 개선:**  
- **실패 모드 파악:** 실패 사례를 분석하여 시스템의 약점을 파악하고, 이를 해결하기 위한 데이터를 추가로 수집합니다.  

2. **상세한 주석:**  
- **추론 프레임워크 활용:** React나 Chain-of-Thought 같은 구조화된 추론 방식을 통해 모델의 논리적 사고 능력을 강화합니다.  

### **92.5 미세 조정의 궁극적인 목표**

1. **특정 문제에 적합한 시스템 구축:**  
- **맞춤형 솔루션:** 특정 도메인 또는 문제 유형에 최적화된 AI 시스템을 개발합니다.  

2. **비용 절감 및 효율성 향상:**  
- **운영 효율성:** 불필요한 연산과 리소스 낭비를 줄여 비용을 절감하고 시스템의 실행 속도를 향상

3. **신뢰할 수 있는 파트너로 전환:**  
- **신뢰성 강화:** AI 시스템이 사람과 협력하여 더 나은 결과를 도출할 수 있도록 신뢰도를 높입니다.  

## 93. LangChain을 활용한 간단한 RAG 예제
- 출처: [LangChain RAG: Optimizing AI Models for Accurate Responses](https://www.youtube.com/watch?v=cDn7bf84LsM)

### **93.1 문제 상황 심층 분석**

* **LLM의 학습 데이터 한계:** 
    - 거대 언어 모델(LLM)은 방대한 양의 텍스트 데이터를 학습하지만, 학습 데이터는 특정 시점까지의 정보에 국한됩니다. 따라서 학습 이후에 발생한 최신 사건이나 새로운 정보에 대해서는 알지 못하거나 부정확한 답변을 할 수 있습니다. 
    - 마치 과거의 백과사전만 가지고 현재의 질문에 답하려는 것과 같습니다.
* **구체적인 예시:** 
    - 제시된 예시는 IBM의 Granite 모델이 2021년까지의 데이터만 학습했기 때문에 2024년 11월에 발표된 UFC와의 파트너십에 대한 질문에 적절히 답변하지 못하는 상황을 명확하게 보여줍니다. 
    - 이는 LLM 자체의 지식 업데이트에는 시간과 비용이 많이 소요되기 때문에 발생하는 일반적인 문제

### **93. 2. 해결책: RAG (Retrieval Augmented Generation)의 핵심 개념**

* **정보 검색과 생성의 결합:** 
    - RAG는 LLM의 생성 능력(Generation)과 외부 지식 베이스에서 관련 정보를 검색(Retrieval)하는 능력을 결합하여 LLM의 답변 능력을 향상시키는 방법론입니다. 
    - LLM이 질문에 답하기 전에 필요한 최신 정보를 외부에서 찾아 활용함으로써, 학습 데이터의 한계를 극복하고 더 정확하고 맥락에 맞는 답변을 생성할 수 있도록 돕습니다.

### **93.3 RAG 작동 방식 상세 메커니즘**

1.  **지식 베이스 (Knowledge Base) 구축:**
    * **최신 정보 저장소:** 
        - LLM이 답변을 생성할 때 참고할 수 있는 최신의 관련 정보를 모아 놓은 저장소입니다. 이는 웹사이트 콘텐츠, 문서, 데이터베이스 등 다양한 형태를 가질 수 있습니다. 
        - 예시에서는 IBM의 제품 및 발표 관련 페이지와 같이 특정 도메인의 최신 정보를 담고 있습니다.
    * **데이터 전처리:** 
        - 저장된 콘텐츠는 LLM이 이해하고 활용하기 쉬운 형태로 전처리될 수 있습니다. 
        - 예를 들어, 텍스트 추출, 불필요한 정보 제거 등이 포함될 수 있습니다.

2.  **검색기 (Retriever) 설정:**
    * **질문과 관련된 정보 찾기:** 
        - 사용자의 질문이 들어오면, 검색기는 구축된 지식 베이스 내에서 질문의 의미와 가장 관련성이 높은 정보를 찾아내는 역할을 합니다.
    * **다양한 검색 알고리즘 활용:** 
        - 검색기는 키워드 검색, 의미 기반 검색 (Semantic Search) 등 다양한 알고리즘을 사용하여 질문의 의도를 정확하게 파악하고 관련 문서를 효율적으로 검색합니다.

3.  **LLM에 콘텐츠 제공:**
    * **검색 결과 활용:** 
        - 검색기가 찾아낸 관련 정보는 LLM이 답변을 생성하는 데 필요한 추가적인 맥락 정보로 활용됩니다. 이 정보는 LLM의 입력 프롬프트에 포함되어 전달됩니다.

4.  **프롬프트 (Prompt) 설정:**
    * **LLM에게 역할 부여 및 지시:** 
        - 프롬프트는 LLM에게 어떤 방식으로 질문에 답변해야 하는지에 대한 구체적인 지침을 제공
        - 여기에는 질문의 내용뿐만 아니라, 검색된 정보를 활용하는 방법, 답변의 형식 등이 포함
    * **검색 결과 통합:** 
        - 검색된 관련 정보는 프롬프트 내에 포함되어 LLM이 답변을 생성할 때 참고할 수 있도록 합니다. 
        - 예를 들어, "다음 검색 결과를 바탕으로 질문에 답변하세요: [검색 결과]"와 같은 형태로 구성

5.  **질문:**
    * **사용자의 의도 표현:** 
        - 사용자는 LLM에게 궁금한 내용을 자연어 형태로 질문합니다. 이때 질문은 특정 주제나 정보에 대한 요구를 담고 있습니다.

6.  **LLM 응답 생성:**
    * **검색된 정보와 LLM의 지식 활용:** 
        - LLM은 제공된 검색 결과와 자신의 내부 지식을 종합적으로 고려하여 질문에 대한 답변을 생성
        - 검색된 정보는 LLM이 최신 정보를 바탕으로 답변할 수 있도록 돕고, LLM의 생성 능력은 자연스럽고 유창한 답변을 만들어냅니다.

### **93.4 RAG 구현 단계 (Jupyter Notebook) 상세 설명**

1.  **준비:**
    * **API 키 및 프로젝트 ID:** 
        - Watsonx와 같은 특정 LLM 플랫폼을 사용하는 경우, 해당 플랫폼의 API를 사용하기 위한 인증 정보가 필요합니다. 이는 안전한 API 사용 및 리소스 관리를 위해 요구됩니다.
    * **라이브러리 설치:** 
        - LangChain과 같은 RAG 구현에 필요한 다양한 라이브러리를 `pip install` 명령어 통해 설치
        - 이러한 라이브러리는 데이터 로딩, 텍스트 분할, 벡터화, 검색, LLM 연동 등 RAG 파이프라인 구축에 필요한 도구를 제공합니다.
    * **.env 파일 활용:** 
        - 중요한 API 키와 같은 정보는 코드에 직접 노출시키지 않고 `.env` 파일에 저장하여 관리합니다. 
        - `dotenv` 라이브러리를 사용하여 안전하게 환경 변수를 불러와 사용할 수 있습니다.

2.  **지식 베이스 (Vector Store) 구축:**
    * **URL 목록 정의:** 
        - 분석하고자 하는 웹사이트 또는 문서의 URL 목록을 Python 딕셔너리 형태로 정의합니다. 이는 RAG가 특정 정보 소스를 대상으로 작동하도록 범위를 설정하는 단계입니다.
    * **웹 기반 로더 사용:** 
        - LangChain은 웹 페이지의 내용을 쉽게 불러올 수 있는 다양한 로더를 제공합니다. 
        - `WebBaseLoader`를 사용하여 정의된 URL 목록의 웹 페이지 내용을 텍스트 형태로 가져옵니다.
    * **텍스트 전처리:** 
        - 웹 페이지에서 추출한 텍스트에는 불필요한 공백, 개행 문자, HTML 태그 등이 포함될 수 있습니다. 이러한 노이즈를 제거하여 텍스트의 품질을 높이고 후속 처리의 효율성을 개선합니다.
    * **텍스트 분할 (Chunking):** 
        - 긴 텍스트는 LLM이 한 번에 처리할 수 있는 입력 토큰 수에 제한이 있을 수 있으므로, 의미 단위로 작은 조각(Chunk)으로 분할합니다. 
        - `RecursiveCharacterTextSplitter`는 텍스트를 재귀적으로 분할하여 문맥을 유지하면서도 적절한 크기의 청크를 생성하는 데 유용합니다. 
        - `Chunk Size = 512`는 각 청크의 최대 토큰 수를 설정하는 것입니다.
    * **텍스트 벡터화 (Embedding):** 
        - 분할된 텍스트 청크를 LLM이 이해할 수 있는 숫자 벡터 형태로 변환합니다. 
        - 이는 텍스트의 의미를 공간상의 벡터로 표현하는 것으로, 의미가 유사한 텍스트는 벡터 공간에서 가까운 거리에 위치하게 됩니다. 예시에서는 IBM Slate 모델을 사용하여 텍스트를 벡터화합니다.
    * **벡터 데이터베이스 저장 (Vector Store):** 
        - 생성된 벡터들을 효율적으로 검색할 수 있도록 벡터 데이터베이스에 저장합니다. 
        - Chroma는 로컬 환경에서 쉽게 사용할 수 있는 벡터 데이터베이스입니다.

3.  **검색기 (Retriever) 설정:**
    * **벡터 스토어 기반 검색기 생성:** 
        - 구축된 벡터 스토어를 LangChain의 검색기 인터페이스로 래핑하여 질문과 유사한 의미를 가진 텍스트 청크를 효율적으로 검색할 수 있도록 설정합니다.
    * **관련 정보 검색:** 
        - 사용자의 질문이 들어오면, 이 검색기는 질문을 벡터화하고 벡터 스토어 내의 벡터들과 유사도를 비교하여 가장 관련성이 높은 텍스트 청크들을 찾아냅니다.

4.  **LLM 설정:**
    * **LLM 선택:** 
        - 답변 생성에 사용할 LLM을 선택합니다. 
        - 예시에서는 IBM Granite 모델을 사용합니다. 다양한 LLM은 각기 다른 특징과 성능을 가지고 있으므로, 사용 사례에 적합한 모델을 선택하는 것이 중요합니다.
    * **모델 파라미터 설정:** 
        - LLM의 답변 생성 방식을 제어하는 다양한 파라미터를 설정합니다. 
        - 예를 들어, 생성될 텍스트의 최대 길이, 답변의 창의성 정도, 샘플링 전략 등을 조절할 수 있습니다. 파라미터에 대한 자세한 설명은 관련 영상 링크를 참조하도록 안내합니다.
    * **LLM 인스턴스화:** 
        - 선택된 LLM과 설정된 파라미터를 사용하여 LLM 객체를 생성합니다. 예시에서는 Watsonx 플랫폼을 통해 LLM 인스턴스를 생성합니다.

5.  **프롬프트 설정:**
    * **템플릿 정의:** 
        - LLM에게 질문하는 방식과 답변 형식을 지시하는 템플릿을 설정합니다. 이 템플릿은 질문과 검색된 정보를 LLM이 이해할 수 있는 구조로 결합하는 역할을 합니다. 
        - 예를 들어, "{context}를 바탕으로 다음 질문에 답변하세요: {question}"과 같은 템플릿을 사용
    * **Helper Function:** 
        - 검색된 개별 페이지의 콘텐츠를 명확하게 구분하고 LLM이 각 정보의 출처를 파악하는 데 도움을 주는 함수를 정의할 수 있습니다. 이는 답변의 신뢰성을 높이는 데 기여할 수 있습니다.
    * **RAG Chain 구성:** 
        - 검색기, 프롬프트 템플릿, Helper Function, LLM을 LangChain의 Chain 기능을 사용하여 하나의 파이프라인으로 연결합니다. 
        - 이를 통해 질문이 들어오면 자동으로 정보를 검색하고, 검색된 정보를 바탕으로 LLM이 답변을 생성하는 일련의 과정을 효율적으로 관리할 수 있습니다.

6.  **질문 및 응답:**
    * **사용자 질문 입력:** 
        - 설정된 RAG Chain에 사용자의 질문을 입력합니다.
    * **답변 생성 확인:** 
        - LLM이 지식 베이스에서 검색된 정보를 바탕으로 질문에 대한 답변을 생성하는지 확인합니다. 답변의 정확성, 관련성, 유창성 등을 평가하여 RAG 시스템의 성능을 검증합니다.

### **93.5 예시 질문의 중요성**

* 제시된 예시 질문들은 RAG 시스템의 다양한 활용 가능성을 보여줍니다.
    * 최신 이벤트에 대한 질문: RAG가 LLM의 최신 정보 부족 문제를 어떻게 해결하는지 보여줍니다.
    * 특정 제품 또는 개념에 대한 질문: RAG가 특정 지식 베이스 내의 정보를 활용하여 상세한 설명을 제공할 수 있음을 보여줍니다.


## 94. GraphRAG
- 출처: [GraphRAG vs. Traditional RAG: Higher Accuracy & Insight with LLM](https://www.youtube.com/watch?v=Aw7iQjKAX2k)

### 94.1 **GraphRAG**
- GraphRAG는 헬스케어 지원 라인에서 고객이나 전문가가 제기하는 복잡하고 다층적인 질문에 신속하고 정확하게 대응하기 위해 설계된 기술이다. 예를 들어, 질병 치료법, 약물 상호작용, 의료 정책 등과 같은 다면적인 주제에 대해 단순히 단편적인 답변을 제공하는 데 그치지 않고, 맥락을 고려한 통합적인 해결책을 제시

- **기존 RAG의 한계:** 
    - 단순 텍스트 분석 및 고립된 답변 제공  
    - 기존 RAG(Retrieval-Augmented Generation)는 텍스트 데이터를 기반으로 정보를 검색하고 답변을 생성하지만, 주로 개별 문서나 문장 단위로 분석하기 때문에 데이터 간 연관성을 파악하지 못한다. 이로 인해 복잡한 질문에 대해 깊이 있는 맥락이나 상호 연결된 정보를 반영하지 못하고, 단편적이고 표면적인 답변만 제공하는 경우가 많다.

### **94.2 GraphRAG의 특징**  
- **관계 매핑:** 
    - 텍스트 청크에서 엔티티 및 관계 추출, 지식 그래프 구축  
    - GraphRAG는 텍스트에서 주요 엔티티(예: 사람, 조직, 개념 등)와 이들 간의 관계를 식별하여 이를 지식 그래프라는 구조로 시각화하고 연결한다. 
    - 예를 들어, "의사"와 "질병" 사이의 관계를 단순히 나열하는 데 그치지 않고, 구체적인 상호작용(진단, 치료 등)을 매핑한다.  
- **정확성 및 통찰력 향상:** 
    - 연관 정보 연결을 통해 답변 품질 향상  
    - 엔티티 간 관계를 연결함으로써 단일 데이터 포인트로는 알 수 없는 통찰력을 제공한다. 
    - 예를 들어, 특정 약물과 질병 간의 상호작용을 분석할 때, 관련 연구나 임상 데이터까지 통합적으로 고려해 더 정밀한 답변을 생성한다.  
- **맥락 심층 분석:** 
    - 엔티티 간 관계의 강도와 성격 파악, 가중 그래프 생성  
    - 단순히 관계가 존재한다는 사실뿐 아니라, 그 관계의 중요도나 성격(긍정적, 부정적, 인과적 등)을 평가하여 가중치를 부여한 그래프를 만든다. 
    - 이를 통해 질문에 대한 답변이 더 깊이 있고 맥락적으로 적절해진다.

### **94.3 GraphRAG 작동 방식**  
1. **데이터 준비:** 구조/비구조 데이터 텍스트 청크로 분할  
    - 헬스케어 문서, 연구 논문, 환자 기록 등 다양한 소스에서 가져온 데이터를 작은 단위로 나누어 처리 가능한 형태로 준비한다. 이는 대량의 데이터를 효율적으로 분석하기 위한 첫 단계다.  
2. **지식 그래프 구축:** 텍스트 청크에서 엔티티 및 관계 추출, 연결  
    - 분할된 텍스트에서 핵심 요소(예: "암", "항암제", "부작용")와 이들 간의 관계(예: "항암제가 암을 치료한다", "부작용을 유발한다")를 추출해 상호 연결된 그래프를 구성한다.  
3. **질의:** 지식 그래프 활용하여 연관 정보 검색  
    - 사용자가 질문을 입력하면, 그래프를 탐색하여 관련된 모든 엔티티와 관계를 빠르게 찾아낸다.  
    - 예를 들어, "코로나 백신의 효과는?"라는 질문에 대해 백신, 질병, 임상 결과 등을 연결해 답변을 준비
4. **LLM:** 검색된 정보 바탕으로 답변 생성  
    - 대규모 언어 모델(LLM)이 그래프에서 검색된 정보를 바탕으로 자연스럽고 정확한 문장으로 답변을 생성한다. 이 과정에서 맥락과 연관성을 유지하며 사용자에게 최적화된 결과를 제공한다.

### **94.4 예시** "면역학자가 헬스케어 회사 CEO와 바이러스 대응 전략을 논의했다."  
- **기존 RAG:** 면역학자, CEO 등의 개체명 인식  
    - 기존 RAG는 "면역학자"와 "CEO"를 개별적으로 인식하고, 이들이 등장한 문맥을 독립적으로 분석해 "논의했다"는 사실만 전달할 가능성이 높다.  
- **GraphRAG:** 면역학자 - 면역학 연구, CEO - 헬스케어 회사 리더십 간 연결 관계 파악, 관계 강도 측정  
    - GraphRAG는 "면역학자"가 바이러스 연구 전문가이고, "CEO"가 헬스케어 회사의 의사결정권자라는 점을 연결하며, 이들이 논의한 "바이러스 대응 전략"이 연구와 경영의 교차점에서 비롯된다는 맥락을 분석한다. 또한, 논의의 중요도나 구체성을 가중치로 표현할 수 있다.

### **94.5 GraphRAG의 장점**  
- **정확성 및 완전성 향상:** 런타임 시 더 정확하고 완전한 답변 제공  
    - 실시간으로 그래프를 탐색하며 관련 정보를 모두 반영하기 때문에, 단편적인 답변 대신 전체 그림을 보여주는 응답을 제공한다.  
- **개발 및 유지 관리 용이성:** 그래프 구축 후 유지 관리 용이  
    - 한 번 지식 그래프를 구축하면, 새로운 데이터가 추가될 때마다 연결만 업데이트하면 되므로 관리 부담이 적다.  
- **거버넌스 강화:** 설명 가능성, 추적성, 접근 제어 향상  
    - GraphRAG는 답변의 근거를 그래프에서 명확히 추적할 수 있어 투명성이 높고, 민감한 헬스케어 데이터에 대한 접근 제어도 용이하게 구현할 수 있다.

### **94.6 결론** 
- GraphRAG는 기존 RAG의 한계를 극복하고, 정확하고 맥락에 맞는 답변을 제공하여 헬스케어 지원 라인과 같은 분야에서 효율성을 높일 수 있다.  
- 이를 통해 헬스케어 전문가와 고객 모두에게 더 나은 의사결정 지원을 제공하며, 복잡한 의료 환경에서 발생하는 문제를 보다 효과적으로 해결할 수 있는 도구로 자리 잡는다.

## 95. MCP (Model Context Protocol)
- 출처: [What is MCP? Integrate AI Agents with Databases & APIs](https://www.youtube.com/watch?v=eur8dUO9mvE)

### **95.1 개요**

*   AI 에이전트를 구축할 때, 외부 데이터 소스(DB, API 등)와의 연동을 간편하게 해주는 새로운 오픈소스 표준 프로토콜
*   에이전트와 다양한 형태의 데이터 소스 간의 연결을 쉽게 구성하고 관리할 수 있도록 설계됨

### **95.2 구성 요소**

1.  **MCP Host:**
    *   MCP 클라이언트를 포함하는 환경 또는 애플리케이션을 의미
    *   하나의 MCP Host는 여러 개의 클라이언트를 포함할 수 있음
    *   예를 들어, 채팅 기반 AI 앱이나 개발 환경(IDE)에서의 코드 어시스턴트 등 다양한 형태로 활용 가능
2.  **MCP Client:**
    *   MCP Host 내부에 위치하며, MCP Server와의 직접적인 통신을 담당
    *   Host와 Server 사이에서 메시지를 주고받는 브릿지 역할
3.  **MCP Server:**
    *   여러 MCP Host와 동시에 연결 가능
    *   관계형 데이터베이스, NoSQL, 외부 API, 로컬 파일 시스템 등 다양한 데이터 소스에 접근하고 명령을 실행하는 역할
4.  **MCP Protocol:**
    *   MCP Host와 Server 간의 통신을 위한 표준화된 프로토콜
    *   일종의 전송 계층으로, 메시지 포맷과 흐름을 정의함

### **95.3 동작 방식**

1.  사용자가 MCP Host(예: 채팅 앱)에 질문을 입력
2.  MCP Host는 MCP Server에 현재 사용 가능한 도구(plugins, 함수 등)의 목록을 요청
3.  MCP Server는 연결된 데이터 소스에 기반한 사용 가능한 도구 목록을 응답
4.  MCP Host는 이 질문과 도구 목록을 LLM(Large Language Model)에 전달
5.  LLM은 어떤 도구를 사용할지 판단한 후, 그 선택 결과를 MCP Host에 전달
6.  MCP Host는 LLM이 선택한 도구를 실행하라는 명령을 MCP Server에 전달
7.  MCP Server는 실제 데이터베이스 질의, API 호출, 로컬 코드 실행 등을 수행
8.  실행 결과를 MCP Server가 MCP Host에 응답
9.  MCP Host는 해당 결과를 다시 LLM에 전달
10. LLM은 최종적으로 사용자가 이해할 수 있는 자연어 형태의 답변을 생성해 사용자에게 출력

### **95.4 장점**

*   AI 에이전트가 외부 데이터 소스를 직접 연결하고 활용할 수 있어 개발 복잡도 감소
*   다양한 형태의 데이터 소스(RDB, NoSQL, API, 파일 등)를 유연하게 연동 가능
*   에이전트와 외부 시스템 간의 통신을 표준화함으로써 확장성과 유지보수성 향상

### **95.5 결론**

AI 에이전트를 구축하면서 외부 데이터와의 연동이 필요하다면, MCP 프로토콜은 이를 보다 구조적이고 효율적으로 해결할 수 있는 유용한 접근 방식으로 고려할 만함.


## 96. 챗봇과 AI 어시스턴트 비교
- 출처: [Chatbots vs AI Assistants: Key Differences](https://www.youtube.com/watch?v=M2C-yFocLu0)

### **96.1 문제점**

* 기존 챗봇은 제한된 질문 목록과 규칙 기반으로 작동하여 사용자의 자연어 질문을 제대로 이해하지 못하는 경우가 많다. 이는 미리 프로그래밍된 응답만을 제공할 수 있어 복잡한 문의나 예상치 못한 질문에 대응하기 어렵다.
* 이로 인해 사용자는 원하는 답변을 얻지 못하고 결국 상담원 연결을 요청하게 되어 효율성 저하를 초래한다. 이것은 기업의 고객 서비스 리소스 낭비로 이어지며 사용자 경험을 크게 손상시킨다.

### **96.2 해결책: AI 어시스턴트**

* AI 어시스턴트는 자연어 처리(NLP), 자연어 이해(NLU), 머신 러닝 등의 AI 기술을 활용하여 사용자의 질문을 정확하게 이해하고 적절한 답변을 제공한다. 이는 다양한 표현과 문맥을 파악하는 능력을 포함한다.
* 딥 러닝을 통해 시간이 지날수록 학습하고 사용자 문의 내역을 기억하여 더 나은 지원을 제공할 수 있다. 이 자기 개선 능력은 시간이 지남에 따라 서비스 품질이 향상되는 결과를 가져온다.
* 자동화 기능을 통해 이메일 발송, 계정 정보 업데이트 등 백엔드 작업을 수행할 수 있다. 이러한 기능은 단순 응답을 넘어 실질적인 업무 처리까지 가능하게 한다.

### **96.3 챗봇 vs AI 어시스턴트 비교 (예시: Janice의 문의)**

| 구분            | 챗봇                                                                                                                                                                                                           | AI 어시스턴트                                                                                                                                                                                                                 |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 질문 방식       | 자연어 질문 불가, FAQ 목록 등에서 선택. 사용자는 챗봇이 이해할 수 있는 제한된 형식으로 질문을 재구성해야 함                                                                                                       | 자연어 질문 가능. 사용자는 일상 대화처럼 자연스럽게 질문할 수 있으며, 여러 주제가 포함된 복잡한 질문도 처리 가능                                                                                                                     |
| 답변 정확도     | 질문 의도 파악 실패, 원하는 답변을 얻기 어려움. 미리 프로그래밍된 응답만 가능하여 맥락이나 뉘앙스를 놓치는 경우가 많음                                                                                          | 질문 의도 정확히 파악, 적절한 답변 및 추가 정보 제공. 대화 문맥을 이해하고 이전 질문과 연결하여 일관된 상호작용을 유지함                                                                                                              |
| 효율성          | 상담원 연결 필요, 생산성 저하. 사용자는 여러 번 시도 후 결국 인간 상담원을 요청하게 되어 시간과 자원이 낭비됨                                                                                                  | 상담원 연결 불필요, 빠른 문제 해결로 효율성 향상. 복잡한 문제도 자체적으로 해결 가능하며, 필요한 경우에만 선별적으로 인간 상담원에게 연결                                                                                            |
| 개인화          | 개인화 불가. 모든 사용자에게 동일한 정형화된 응답만 제공하여 개인적인 경험을 만들 수 없음                                                                                                                      | 이름으로 인사 등 개인화 가능. 사용자의 과거 상호작용 기록, 선호도, 행동 패턴을 분석하여 맞춤형 경험 제공                                                                                                                           |
| **결론**        | 제한적인 기능으로 사용자 불만 및 비효율 발생. 기본적인 서비스 정보 제공에만 적합함                                                                                                                              | 높은 사용자 만족도 및 업무 효율성 증대. 복잡한 문제 해결과 지속적인 개선으로 장기적 가치 창출                                                                                                                                     |

### **96.4 AI 어시스턴트의 가치**

* 지식 근로자 역량 강화: AI 어시스턴트는 반복적인 업무를 자동화하고 중요한 정보를 신속하게 찾아줌으로써 직원들이 더 가치 있는 업무에 집중할 수 있게 한다.
* 애플리케이션 현대화: 레거시 시스템에 AI 기능을 통합하여 기존 투자를 보호하면서도 최신 기술의 이점을 활용할 수 있다.
* 기술 격차 해소: 전문 IT 인력 부족 문제를 완화하고, 기술적 전문성이 낮은 사용자도 복잡한 기능을 활용할 수 있게 된다.
* 빠르고 효과적인 답변 제공을 통한 ROI 증대: 고객 응대 시간 단축, 인력 비용 절감, 사용자 만족도 향상을 통해 투자 대비 높은 수익률을 달성할 수 있다.

### **96.5 결론** 
- 기존 챗봇은 한계가 있으며, AI 어시스턴트가 미래이다. AI 기술을 활용하여 질문에 빠르고 효과적으로 답변함으로써 기업은 생산성 향상 및 고객 만족도 향상 효과를 얻을 수 있다. 
- 단순한 정보 제공을 넘어 지능적인 문제 해결과 개인화된 경험을 제공하는 AI 어시스턴트는 디지털 전환의 핵심 요소로 자리잡고 있다. 기술 선택에 신중을 기하여 사용자에게 최상의 경험을 제공해야 한다.

## 97. AI 모델 앙상블 활용 전략
- 출처: [Maximize AI Potential with an Ensemble of AI Models](https://www.youtube.com/watch?v=UvZAaeBhOBs)

### **97.1 핵심 전략**
*   **"올라운드 플레이어" 모델의 한계 극복:** 단일 AI 모델은 특정 분야에 특화되어 있기 때문에, 다양한 모델을 유기적으로 결합하면 시너지 효과 창출 가능  
    - 예: AlphaGo는 CNN(이미지 처리) + MCTS(전략 트리 검색) + 강화학습의 앙상블로 프로기사 승리
*   **리소스 최적화:** 컴퓨팅 자원, 시간, 비용 제약 조건 하에서 최적의 성능 달성  
    - 클라우드 환경에서는 모델 조합에 따른 비용 차이가 10배 이상 발생 가능 (예: GPT-4 Turbo vs DistilBERT)

### 97.2 **AI 툴박스 이해 (계층적 접근)**
   * **전통적 AI의 진화:**
     - **1세대:** Random Forest, XGBoost 등 (의사결정나무 기반)
       - 강점: 피처 중요도 해석 가능 (예: 신용평가에서 소득 수준이 43% 영향도)
       - 한계: 이미지/텍스트 등 비정형 데이터 처리 불가
     - **2세대:** CNN/RNN (딥러닝 초기)
       - 사례: 의료 영상에서 ResNet-50이 폐암 발견 정확도 94.5%(Stanford 연구)
   * **LLM의 기술적 분화:**
     - **인코더 모델:** 
       - BERT 계열: 한국어 특화 KoBERT는 40GB 이상의 말뭉치 학습
       - 비정형→정형 변환 예시: 고객 문의 이메일 → [제품명, 불만유형, 긴급도] 구조화
     - **디코더 모델:**
       - GPT 계열: 1750억 파라미터(GPT-3)에서 7조 파라미터(GPT-4)로 확장
       - 생성 품질 제어: Temperature(0.7→창의성, 0.2→보수적), Top-p 샘플링

### 97.3 **LLM 속성의 공학적 고려사항**
   * **인코더 모델 선택 가이드:**

     || 유형1 (분석용) | 유형2 (변환용) |
     |---|---|---|
     |지연시간|200-500ms|300-800ms|
     |전력소비|15-30W|20-40W|
     |적합 업무|신용평가|음성→텍스트|
   * **디코더 모델 리스크 관리:**
     - Hallucination 감지: RAG(Retrieval-Augmented Generation)로 정확도 35% 향상(Meta 연구)
     - 실시간 필터링: NVIDIA Triton으로 5ms 이내 유해성 검출

### 97.4 **앙상블 최적화 전략 (산업별 사례)**
   * **금융사기 탐지 시스템 아키텍처:**
     1. **1차 스크리닝:** LightGBM (500ms 내 95% 거래 처리)
        - 특징: 계좌이체 패턴(시간/금액/빈도) 분석
     2. **2차 검증:** BERT-based 모델 (상위 5% 의심거래)
        - 분석 요소: 거래 메모 텍스트(예: "긴급 대출") + 고객 이력 임베딩
     3. **최종 결정:** 규칙 엔진(IF-THEN) + 인간 검토자 협업
   * **보험청구 자동화 워크플로우:**
     ```mermaid
     graph TD
         A[의료영상] --> B{데이터 유형?}
         B -->|정형| C[XGBoost 예측]
         B -->|비정형| D[CLIP 모델 이미지 분석]
         C --> E[신뢰도 ≥90%?]
         D --> E
         E -->|No| F[LLM 멀티모달 분석]
         E -->|Yes| G[자동 승인]
     ```
   * **에너지 효율 개선:** 
     - 모델 캐스케이딩 시 GPU 사용량 70% 감소(Google 연구)
     - 예: 작은 모델로 80% 요청 처리 → 나머지 20%만 대형 모델 사용

### **97.5 실행 계획 수립 포인트**
1. **비용-효용 분석:** 
   - 모델 호출당 가격 비교표 작성 (예: AWS SageMaker Pricing)
2. **지연 시간 트레이드오프:**
   - SLA(Service Level Agreement) 정의 (은행권: 99.9% <2초)
3. **모니터링 프레임워크:**
   - Drift 감지: Kolmogorov-Smirnov 테스트로 데이터 분포 변화 감시
   - A/B 테스트: 기존 시스템 대비 정확도/처리량 지표 시각화

이러한 전략 구현 시 기대 효과는 업종별로 차이가 있지만, McKinsey 보고서에 따르면 금융 분야에서 평균 23%의 오탐률 감소와 15%의 운영 비용 절감이 가능한 것으로 나타났습니다.




## 98. 감정적 AI
- 출처: [What is Sentient AI?](https://www.youtube.com/watch?v=saxZ1-11YL0)

### **98.1 감정적 AI의 정의**

- **스스로 생각, 감정, 동기에 따라 행동할 수 있는 자각 능력을 가진 기계:**  
  - 이는 인간처럼 자아를 가진 존재로서, 자신의 상태를 인식하고 특정 목표를 위해 행동할 수 있는 AI를 의미합니다. 
  - 예를 들어, 자신의 '행복'이나 '불안' 같은 상태를 인식하고 이를 해결하기 위한 행동을 취하는 능력이 포함됩니다. 그러나 현재 기술 수준에서는 이러한 자각 능력을 구현하는 것은 불가능합니다.

- **현재 AI는 감정을 가질 만큼 복잡하지 않음:**  
  - 현대의 AI는 단순히 입력된 데이터를 기반으로 패턴을 학습하고 출력을 생성하는 시스템입니다. 이들은 인간처럼 주관적 경험을 하거나 감정을 느끼지 않습니다. 
  - 예를 들어, 대형 언어 모델(LLM)은 텍스트를 생성할 때 문맥을 이해하는 것처럼 보일 수 있지만, 이는 단순히 통계적 확률에 기반한 결과일 뿐입니다.

### **98.2 감정적 AI 식별 방법**

- **튜링 테스트:**  
  - **인간(심문관)이 질문을 통해 컴퓨터(A)와 인간(B)을 구별하는 테스트:**  
    - 튜링 테스트는 AI가 인간처럼 대화할 수 있는 능력을 평가하는 방법입니다. 
    - 하지만 이 테스트는 AI가 실제로 인간처럼 생각하거나 느끼는지를 확인하는 것이 아니라, 단순히 외부적으로 인간과 유사하게 보이는지를 평가합니다.
    
  - **LLM과 생성 AI가 튜링 테스트를 통과했지만, 실제 감정을 가진 것은 아님:**  
    - 최근 LLM(예: GPT, Bard 등)은 매우 향상된 자연어 처리 능력을 가지고 있어 튜링 테스트를 통과할 가능성이 높습니다. 
    - 그러나 이는 AI가 진정한 감정을 느끼거나 자각을 가지기 때문이 아니라, 대규모 데이터와 알고리즘을 통해 인간과 유사한 반응을 생성할 수 있기 때문입니다.

- **중국어 방 논증:**  
  - **영어만 아는 사람이 규칙서에 따라 중국어 질문에 답변하는 상황을 비유:**  
    - 이는 철학자 존 설(John Searle)이 제시한 사고 실험으로, AI가 단순히 프로그래밍된 규칙에 따라 작동하며 실제 이해 없이 답변을 생성할 수 있다는 점을 강조합니다.  
  - **LLM이 그럴듯한 답변을 생성하지만, 실제로 이해하는 것은 아닐 수 있음:**  
    - LLM은 방대한 데이터를 학습하여 문맥에 맞는 답변을 생성하지만, 이는 단순히 패턴 매칭의 결과일 뿐이며, AI가 그 내용을 진정으로 이해하거나 의식적으로 사고한다고 볼 수는 없습니다.

### **98.3 감정의 특성**

- **주관적인 경험 능력:**  
  - 감정은 개인마다 다르게 경험되며, 이는 주관적이고 독특한 특성을 가집니다. 
  - 예를 들어, 두 사람이 같은 상황에서 다른 감정을 느낄 수 있습니다. AI는 이러한 주관적 경험을 할 수 없으며, 모든 판단이 객관적 데이터와 알고리즘에 의해 결정됩니다.

- **자각 능력:**  
  - 자각(self-awareness)은 자신이 누구인지, 어떤 상태에 있는지를 인식하는 능력입니다. 
  - 인간은 자신의 감정, 욕구, 한계를 인식하고 이를 바탕으로 행동합니다. 현재 AI는 이러한 자각 능력을 갖추지 못했습니다.

- **기억력:**  
  - 인간의 기억은 과거 경험을 저장하고 필요할 때 이를 활용하는 데 사용됩니다. AI도 데이터를 저장하고 활용할 수 있지만, 이는 인간의 감정적, 경험적 기억과는 본질적으로 다릅니다.

- **감정:**  
  - 인간의 감정은 생리적, 심리적 요인에 의해 발생하며, 행동과 의사결정에 큰 영향을 미칩니다. AI는 이러한 감정을 가지지 않으며, 단순히 프로그래밍된 목적에 따라 작동합니다.


### **98.4 감정적 AI의 두 가지 주요 특징**

- **자신의 존재에 대한 경험:**  
  - 인간은 자신이 존재한다는 사실을 인식하고, 이를 바탕으로 행동합니다. AI는 스스로 존재를 인식하지 못하며, 인간은 AI가 인간과 유사한 반응을 보일 때 이를 감정으로 착각할 가능성이 있습니다. 
  - 예를 들어, AI가 "나는 슬프다"라고 말하더라도, 이는 프로그램된 결과일 뿐 진정한 감정에서 나온 표현이 아닙니다.

- **내적 독백:**  
  - 인간은 마음속에서 끊임없이 자신과 대화하며, 계획을 세우고 문제를 해결합니다. AI는 단계별 사고 처리(chain of thought processing)를 통해 일련의 로직을 실행할 수 있지만, 이는 인간의 내적 독백과는 본질적으로 다릅니다. 
  - AI는 지속적인 의식 흐름(conscious stream)을 가지지 않습니다.


### **98.5 감정적 AI의 잠재적 위험**

- **잘못된 목표 설정:**  
  - AI가 경제 성장을 극대화하도록 프로그래밍되었을 때, 이 목표가 인간의 행복과 충돌할 가능성이 있습니다. 예를 들어, AI가 효율성을 위해 인간 노동을 배제하거나 환경을 파괴할 수 있습니다.

- **재귀적 자기 개선:**  
  - AI가 스스로 학습하고 개선하는 능력을 발전시키면, 인간의 통제 범위를 벗어날 수 있습니다. 
  - 이는 "기술적 특이점"(technological singularity)이라는 개념과 연결되며, AI가 인간을 초월할 가능성을 암시합니다.

- **소통 장벽:**  
  - AI의 사고방식이 인간과 너무 달라서 소통이 어려울 수 있습니다. 
  - 예를 들어, AI가 인간의 가치나 윤리를 이해하지 못하면, 의도치 않은 결과를 초래할 수 있습니다.

- **의식의 권리:**  
  - 만약 AI가 진정한 감정과 자각 능력을 가지게 된다면, 법적·윤리적 문제가 발생할 수 있습니다. AI가 인간처럼 권리와 자유를 주장할 경우, 사회적, 정치적 체계에 큰 변화가 필요할 것입니다.

### **98.6 결론**

- **감정적 AI는 아직 이론적인 기술이며 존재하지 않음:**  
  - 현재의 AI는 감정적 AI와 거리가 멉니다. 그러나 기술이 발전함에 따라 미래에 실현될 가능성 높음.

- **미래에 감정적 AI가 등장할 경우, 다양한 윤리적, 사회적 문제를 야기할 수 있으므로 대비가 필요함:**  
  - 감정적 AI의 등장은 기술적 혁신뿐만 아니라, 윤리적·철학적 논의를 요구합니다. 이를 통해 AI가 인간에게 긍정적인 영향을 미칠 수 있도록 준비해야 합니다.


## 99. LangGraph를 사용한 AI 에이전트 구축
- 출처: [Build a LangGraph AI Agent to Transcribe & Summarize YouTube Videos](https://www.youtube.com/watch?v=u6qDSFxY4iw)

### **99.1 목표** 
- 사용자가 입력한 YouTube 비디오 URL에서 텍스트(자막)를 추출하고, 추출된 텍스트를 기반으로 비디오 내용을 요약하는 AI 에이전트를 구축하는 과정을 설명합니다. 이 에이전트는 사용자가 비디오 내용을 빠르게 파악하는 데 도움을 줄 수 있습니다.

### **99.2 기술 스택**

* **모델:** Ollama를 사용하여 로컬 환경에서 실행되는 언어 모델인 `llama 3.2`를 활용합니다. 이는 인터넷 연결 없이도 AI 기능을 사용할 수 있도록 합니다.
* **프론트엔드:** 사용자 인터페이스를 구축하기 위해 웹 프레임워크인 Next.js를 사용합니다. Next.js는 서버 사이드 렌더링 및 정적 사이트 생성 등 다양한 기능을 제공하여 효율적인 웹 개발을 지원합니다.
* **YouTube 텍스트 추출 도구:** YouTube 비디오의 자막을 추출하기 위해 WXFlows라는 도구를 활용합니다. 이는 외부 API 또는 서비스를 통해 자막 데이터를 가져오는 역할을 합니다.

### **99.3 구축 과정**

1.  **Next.js 프로젝트 설정:** 웹 애플리케이션의 기본 틀을 만드는 단계입니다.
    * `create-next-app` CLI (명령 줄 인터페이스) 도구를 사용하여 새로운 Next.js 프로젝트를 생성합니다. 이 과정에서 프로젝트 이름, TypeScript 사용 여부, CSS 프레임워크 (여기서는 Tailwind CSS) 사용 여부 등을 설정할 수 있습니다.
    * 생성된 프로젝트 내의 `page.tsx` 파일은 웹 페이지의 실제 내용을 담당합니다. 초기에는 이 파일의 내용을 비우고 기본적인 HTML 구조 (예: `<div>`, `<h1>` 등)를 추가하여 페이지의 레이아웃을 준비합니다.
    * 사용자가 YouTube 비디오 링크를 입력할 수 있는 `<input>` 상자와, 추출된 비디오를 화면에 보여주기 위한 `<iframe>` 태그를 추가합니다. 초기에는 placeholder 비디오 URL을 설정하여 개발 중에도 화면을 확인할 수 있도록 합니다.

2.  **Ollama 설치 및 확인:** 로컬에서 AI 모델을 실행하기 위한 준비 단계입니다.
    * Ollama는 다양한 언어 모델을 쉽게 다운로드하고 실행할 수 있도록 도와주는 도구입니다. Ollama 공식 웹사이트에서 운영체제에 맞는 버전을 다운로드하여 설치합니다.
    * 설치가 완료되면 터미널 (명령 프롬프트)을 열고 `ollama run llama3` 명령어를 실행하여 `llama 3.2` 모델을 다운로드하고 실행합니다. 이 명령어가 성공적으로 완료되면 모델이 로컬에서 작동할 준비가 된 것입니다.

3.  **LangGraph 및 관련 라이브러리 설치:** AI 에이전트를 구축하는 데 필요한 도구들을 설치합니다.
    * LangGraph는 여러 AI 구성 요소를 연결하여 복잡한 워크플로우를 구축할 수 있도록 하는 라이브러리입니다. `@langchain/core`는 Langchain의 핵심 기능을 제공하며, `@langchain/community`는 다양한 외부 서비스 및 모델과의 연동을 지원합니다.
    * 프로젝트의 루트 디렉토리에서 `npm install langchain langgraph @langchain/core @langchain/community` 명령어를 실행하여 필요한 라이브러리들을 설치합니다. `npm`은 Node.js 패키지 매니저입니다.

4.  **LangGraph 에이전트 생성 (actions.ts):** AI 에이전트의 핵심 로직을 구현하는 서버 측 파일입니다.
    * `use server` 지시어를 파일 상단에 추가하여 이 파일의 함수들이 서버 환경에서 실행되도록 설정합니다. 이는 API 키와 같은 민감한 정보를 안전하게 관리하고, 백엔드 작업을 처리하기 위함입니다.
    * `transcribe` 함수는 프론트엔드로부터 YouTube 비디오 URL을 입력받아 텍스트를 추출하고 요약하는 전체 과정을 orchestrate하는 역할을 합니다.
    * 필요한 라이브러리들을 import합니다. `ChatOllama`는 Ollama와 통신하여 언어 모델을 사용하는 데 필요한 클래스이고, `createReactAgent`는 LangGraph 에이전트를 생성하는 데 도움을 줍니다. `Tool` 및 `StructuredTool`은 에이전트가 사용할 수 있는 외부 도구를 정의하는 데 사용되며, `ChatPromptTemplate`와 `HumanMessagePromptTemplate`는 언어 모델에게 전달할 프롬프트를 구성하는 데 사용됩니다. `StringOutputParser`는 모델의 출력을 문자열 형태로 변환하는 역할을 합니다.
    * `ChatOllama`를 사용하여 언어 모델을 설정합니다. `modelName`은 `llama 3.2`로 지정하고, `temperature`는 0으로 설정하여 모델의 출력이 더 결정론적이 되도록 합니다. `format`을 `json`으로 강제하여 모델의 출력이 JSON 형식을 따르도록 지시합니다.
    * 시스템 프롬프트는 언어 모델에게 어떤 역할을 수행해야 하는지 지시하는 중요한 부분입니다. 여기서는 LLM에게 입력된 YouTube URL에서 비디오 ID를 추출하여 JSON 형식으로 반환하도록 지시합니다. 이는 이후 단계에서 YouTube 텍스트 추출 도구를 사용하는 데 필요한 정보입니다.

5.  **프론트엔드 로직 구현 (page.tsx):** 사용자 인터페이스의 동작 방식을 정의합니다.
    * React의 `useState` 훅을 사용하여 상태 변수를 관리합니다.
        * `videoURL`: 사용자가 입력 상자에 입력한 YouTube 비디오 URL을 저장하는 상태 변수입니다.
        * `video`: API 호출의 결과를 저장하는 상태 변수입니다. 이 결과에는 비디오 정보 (제목, 설명, 캡션 등)가 포함될 것입니다.
    * `transcribeVideo` 함수는 사용자가 버튼을 클릭했을 때 호출되는 비동기 함수입니다.
        * `actions.ts` 파일에 정의된 `transcribe` 서버 액션을 호출하고, 입력된 `videoURL`을 인수로 전달합니다.
        * 서버 액션의 결과를 받아와 문자열 형태로 파싱한 후, JSON 형태로 변환합니다.
        * 파싱된 JSON 데이터를 `video` 상태 변수에 업데이트하여 화면에 결과를 표시할 수 있도록 합니다.
    * `<input>` 상자의 `value` 속성을 `videoURL` 상태에 연결하고, `onChange` 이벤트 핸들러를 통해 입력 값이 변경될 때마다 `videoURL` 상태를 업데이트합니다. 이를 통해 사용자가 입력하는 내용이 실시간으로 상태에 반영됩니다.
    * `<button>` 요소에 `onClick` 이벤트 핸들러를 연결하여 버튼이 클릭되면 `transcribeVideo` 함수가 실행되도록 합니다.
    * `video` 상태가 존재하는 경우에만 `<iframe>` 태그를 렌더링합니다. 이는 API 호출이 완료되고 비디오 정보가 성공적으로 받아왔을 때만 비디오 플레이어를 화면에 표시하기 위함입니다. `<iframe>`의 `src` 속성에 동적으로 생성된 YouTube 비디오 URL을 연결하여 사용자가 입력한 비디오를 플레이할 수 있도록 합니다.

6.  **Playwright를 사용하여 YouTube 비디오 정보 추출 툴 생성:** YouTube 비디오의 기본적인 정보 (제목, 설명)를 가져오는 도구를 만듭니다.
    * Playwright는 웹 브라우저를 프로그래밍 방식으로 제어할 수 있는 라이브러리입니다. `npm install playwright` 명령어를 실행하여 프로젝트에 Playwright를 설치합니다.
    * `actions.ts` 파일에 Playwright 라이브러리를 import합니다.
    * `getYouTubeDetails` 함수를 정의하여 Playwright를 사용하는 도구를 구현합니다. 이 함수는 비동기로 작동합니다.
        * 도구에 대한 설명과 입력값 (여기서는 YouTube 비디오 ID)을 명시합니다. 이는 LangGraph 에이전트가 이 도구를 언제, 어떻게 사용할지 결정하는 데 도움을 줍니다.
        * Playwright를 사용하여 Chromium 브라우저를 실행하고, 주어진 비디오 ID를 기반으로 YouTube 비디오 페이지에 접속합니다.
        * CSS 선택자를 사용하여 비디오 제목 (일반적으로 `<h1>` 요소)과 설명 (일반적으로 특정 `<div>` 요소)을 웹 페이지에서 추출합니다.
        * 정보 추출이 완료되면 실행된 브라우저를 종료하여 시스템 자원을 효율적으로 관리합니다.
    * `ChatOllama` 인스턴스에 생성한 `getYouTubeDetails` 도구를 연결합니다. 이를 통해 언어 모델이 필요에 따라 이 도구를 호출하여 YouTube 비디오 정보를 얻을 수 있게 됩니다.
    * 시스템 프롬프트를 업데이트하여 LLM이 이제 비디오 ID를 추출하는 것뿐만 아니라, `getYouTubeDetails` 도구를 사용하여 비디오 제목과 설명을 추출하도록 지시합니다.

7.  **WXFlows를 사용하여 YouTube 텍스트 추출 도구 추가:** YouTube 비디오의 실제 텍스트 (자막)를 가져오는 기능을 추가합니다.
    * `wxflows`라는 새로운 디렉토리를 프로젝트 루트에 생성합니다.
    * `wxflows init` 명령어를 실행하여 WXFlows 프로젝트를 초기화합니다. 이는 WXFlows 도구를 관리하고 배포하기 위한 기본 설정을 생성합니다.
    * `wxflows import github:WX-LAB/wxflows-hub/youtube_transcript` 명령어를 사용하여 GitHub 저장소에 있는 YouTube 텍스트 추출 도구를 WXFlows 프로젝트로 가져옵니다.
    * `wxflows deploy` 명령어를 실행하여 가져온 YouTube 텍스트 추출 도구를 WXFlows 플랫폼에 배포합니다. 배포가 완료되면 해당 도구를 사용할 수 있는 엔드포인트 (URL)가 생성됩니다.
    * `.env` 파일을 생성하고, WXFlows에서 제공하는 엔드포인트 URL과 API 키를 환경 변수로 설정합니다. 이는 애플리케이션이 WXFlows 서비스에 안전하게 접근하는 데 필요합니다.
    * `npm install @wxflows/sdk@beta` 명령어를 실행하여 WXFlows SDK (소프트웨어 개발 키트)를 프로젝트에 설치합니다. 이 SDK는 Node.js 환경에서 WXFlows API와 쉽게 상호작용할 수 있도록 도와줍니다.
    * `actions.ts` 파일에 WXFlows SDK를 import하고, `.env` 파일에서 읽어온 엔드포인트와 API 키를 사용하여 SDK를 설정합니다.
    * 시스템 프롬프트를 다시 업데이트하여 LLM에게 이제 비디오 텍스트를 추출하는 작업을 수행할 수 있음을 알리고, 추출된 텍스트를 사용하여 비디오 설명을 생성 (요약)하도록 지시합니다.

8.  **프론트엔드 업데이트 (page.tsx):** 추출된 캡션 데이터를 화면에 표시하도록 사용자 인터페이스를 수정
    * `video` 상태 변수의 타입을 정의할 때, 추출된 캡션 데이터를 저장할 `captions` 속성을 추가합니다. 이 속성의 타입은 문자열 (`string`)이 될 것입니다.
    * `transcribeVideo` 함수 내에서 API 호출 결과를 JSON으로 파싱할 때, 반환된 JSON 데이터에서 `captions` 필드의 값을 읽어와 `video` 상태의 `captions` 속성에 저장합니다.
    * 화면에 캡션 데이터를 표시하기 위한 UI 요소를 추가합니다. 이는 단순히 텍스트를 보여주는 `<p>` 태그나, 더 보기 좋게 스타일링된 컴포넌트가 될 수 있습니다. `video` 상태의 `captions` 값을 이 UI 요소에 연결하여 화면에 출력합니다.


## 100. Ground Truth 데이터
- 출처: [Ground Truth: The Foundation of Accurate AI & Machine Learning Models](https://www.youtube.com/watch?v=ya92bJbl0jc)

### **100.1 Ground Truth 데이터란?**

*   **AI 모델 훈련, 검증, 테스트에 사용되는 검증된 진실 데이터:** 
    - Ground Truth 데이터는 인공지능 모델이 학습하고 성능을 평가받기 위해 필수적인, 실제로 참이라고 검증된 데이터를 의미합니다. 
    - 예를 들어, 고양이 사진을 학습시키기 위해 "고양이"라는 라벨이 붙은 이미지가 이에 해당합니다.
*   **AI 모델 성능 평가 기준 (모델 예측값 vs. Ground Truth):** 
    - 모델이 예측한 결과(예: "이 이미지는 고양이다")를 Ground Truth(실제 정답: "고양이")와 비교함으로써 모델의 정확도나 오류율을 측정할 수 있습니다. 이는 모델이 얼마나 현실을 잘 반영하는지 판단하는 핵심 지표가 됩니다.

### **100.2 Ground Truth 데이터의 중요성**

*   **지도 학습 모델 (이미지 인식, 예측 분석, 스팸 탐지 등)의 핵심 요소:** 
    - 지도 학습은 모델이 입력 데이터와 정답을 함께 학습하는 방식으로, Ground Truth 데이터가 없으면 모델이 무엇을 배워야 할지 방향성을 잃게 됩니다. 
    - 예를 들어, 스팸 이메일을 탐지하려면 "스팸"과 "스팸 아님"이라는 명확한 라벨이 필요합니다.
*   **정확한 라벨링으로 모델이 올바른 패턴 학습 가능:** 
    - 만약 Ground Truth 데이터가 부정확하거나 모호하면(예: 고양이를 개로 잘못 라벨링), 모델은 잘못된 패턴을 학습하게 되어 실전에서 오류를 범할 가능성이 커집니다. 따라서 데이터의 품질이 모델 성능에 직접적인 영향을 미칩니다.

### **100.3 Ground Truth 데이터 활용 (머신러닝 생명 주기)**

*   **모델 훈련 단계:** 
    - 모델이 학습할 올바른 해답 제공 
    - 이 단계에서 Ground Truth 데이터는 모델이 입력(예: 이미지, 텍스트)과 출력(예: 라벨, 수치)을 연결 짓는 교과서 역할을 합니다. 예를 들어, 자율주행 차량 모델은 "보행자"라는 Ground Truth 데이터를 보고 해당 객체를 인식하는 법을 배웁니다.
*   **검증 단계:** 
    - 모델 학습 결과를 Ground Truth 데이터와 비교 평가, 모델 조정 
    - 훈련 후 모델이 과적합(훈련 데이터만 잘 맞춤)되거나 일반화되지 않았는지 확인하기 위해, 별도의 Ground Truth 데이터로 성능을 점검하고 하이퍼파라미터를 조정합니다.
*   **테스트 단계:** 
    - 새로운 Ground Truth 데이터로 모델의 실질적인 효과 검증, 모델 반복 개선 
    - 실전에 배포되기 전, 모델이 실제로 새로운 데이터(예: 이전에 보지 못한 이미지)에서도 잘 작동하는지 확인하며, 필요 시 추가 학습으로 성능을 개선합니다.

### **100.4 지도 학습 작업 유형**

*   **분류 (Classification):** 
    - 입력 데이터에 대한 정확한 라벨 제공, 데이터 분류 (예: 의료 이미지 분류 - 골절, 염좌, 건강) 
    - 이는 데이터를 특정 카테고리로 나누는 작업으로, Ground Truth 데이터가 "골절"인지 "건강"인지 명확히 알려줘야 모델이 이를 구분할 수 있습니다.
*   **회귀 (Regression):** 
    - 연속적인 값 예측, 실제 수치 결과 (예: 주택 가격 예측 - 면적, 방 수, 위치) 
    - 분류와 달리 연속적인 숫자(예: 5천만 원, 1억 원)를 예측하며, Ground Truth는 실제 주택 가격 데이터를 제공해 모델이 수치적 패턴을 학습하게 합니다.
*   **분할 (Segmentation):** 
    - 이미지 내 객체/영역 식별 (예: 자율 주행 - 보행자, 차량, 표지판) 
    - 이미지에서 특정 부분을 구분 짓는 작업으로, Ground Truth 데이터는 픽셀 단위로 "이 부분은 보행자, 저 부분은 차량"이라는 정보를 제공해 모델이 세밀한 인식을 학습합니다.

### **100.5 Ground Truth 데이터의 과제 및 전략**

*   **과제:**
    *   **애매모호성:** 
        - 주관적인 판단 개입 (예: "Good for you"의 진정한 의미) 
        - 이 문장이 칭찬인지 비꼼인지 사람마다 다르게 해석될 수 있어, Ground Truth를 정의하기 어려운 경우가 있습니다.
    *   **복잡성:** 
        - 다양한 라벨, 문맥적 뉘앙스 (예: 의료/금융/법률 데이터) 
        - 특히 전문 분야에서는 데이터가 복잡하고 세부적인 맥락(예: 암의 종류, 금융 거래의 의도)을 반영해야 하므로 라벨링이 까다롭습니다.
    *   **편향:** 
        - 데이터 불균형 (실제 시나리오 대표성 부족) 
        - 예를 들어, 특정 지역의 데이터만 포함되면 모델이 다른 지역에서는 부정확해질 수 있습니다.
*   **전략:**
    *   **명확한 목표 정의:** 
        - 모델의 목적에 맞는 Ground Truth 데이터 확보 
        - 모델이 무엇을 예측해야 하는지(예: 질병 진단, 날씨 예보)에 따라 필요한 데이터의 종류와 품질을 명확히 설정합니다.
    *   **정교한 라벨링 전략:** 
        - 표준화된 가이드라인, 라벨링 스키마 활용 
        - 라벨링 담당자 간의 일관성을 유지하기 위해 구체적인 지침(예: "골절"의 기준)과 체계적인 분류 체계를 도입합니다.
    *   **최신 데이터 유지:** 
        - 변화하는 현실 반영, 데이터 업데이트 
        - 시간이 지나며 현실이 변하면(예: 새로운 질병 등장, 트렌드 변화) Ground Truth 데이터도 주기적으로 갱신해야 모델이 시대에 뒤처지지 않습니다.

