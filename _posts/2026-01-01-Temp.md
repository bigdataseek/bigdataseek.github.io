## 1. RAG (Retrieval Augmented Generation)

### 1.1 **목표**

*   **RAG를 활용하여 더 정확하고 신뢰할 수 있는 AI 애플리케이션 구축**  
    *   RAG는 대규모 언어 모델(LLM)의 한계를 극복하고, 외부 지식을 효과적으로 통합하여 AI의 응답 품질을 높이는 데 목적이 있습니다. 예를 들어, 최신 뉴스나 기업 내부 문서를 반영한 답변을 제공할 수 있습니다.
*   **기업 및 고객의 사용자 만족도 향상 및 시간 절약**  
    *   정확한 정보 제공으로 고객 문의 응대 시간을 단축하고, 직원들이 복잡한 데이터 검색에 소요되는 시간을 줄여 업무 효율성을 높입니다. 예: 고객 지원 챗봇이 제품 매뉴얼을 즉시 참조해 답변.
*   **LLM (Large Language Model) 결과 개선 및 활용**  
    *   LLM의 출력이 최신 데이터나 특정 도메인 지식에 기반하도록 하여, 일반적인 답변 대신 더 구체적이고 신뢰할 수 있는 결과를 제공합니다.

### 1.2 **대상**

*   **AI 도입에 참여하는 모든 직군 (개발자, 데이터 과학자, 제품 관리자, 경영진 등)**  
    *   개발자는 RAG 시스템 구현, 데이터 과학자는 데이터 처리 및 임베딩 최적화, 제품 관리자는 사용자 경험 개선, 경영진은 비즈니스 ROI 분석에 관여합니다. RAG는 팀 간 협업을 촉진하며, 각 직군이 AI 도입에서 핵심 역할을 수행할 수 있도록 지원합니다.

### 1.3 **핵심 내용**

*   **RAG란?**  
    *   **LLM을 외부 지식 소스에 연결하여 성능을 향상시키는 기술**  
        *   RAG는 LLM이 사전 학습된 데이터에만 의존하지 않고, 외부 데이터(예: 회사 문서, 웹 콘텐츠)를 검색해 답변을 생성하는 하이브리드 접근 방식입니다.
    *   **LLM이 학습된 데이터 외에 외부 정보를 검색하여 활용**  
        *   예를 들어, 최신 시장 동향이나 내부 정책 문서를 검색해 최신 정보를 반영한 답변을 제공할 수 있습니다.

*   **RAG의 필요성:**  
    *   **LLM의 지식 컷오프 (특정 시점 이후의 정보 부재) 문제 해결**  
        *   LLM은 학습 데이터의 시점에 따라 최신 정보가 누락될 수 있습니다. RAG는 실시간 데이터나 최신 문서를 검색해 이를 보완합니다. 예: 2025년 최신 법률 변경 사항 반영.
    *   **LLM이 접근할 수 없는 독점적인 또는 비공개 정보 활용 가능**  
        *   기업의 내부 데이터베이스(예: 고객 기록, 제품 사양)를 활용해 맞춤형 응답을 생성합니다.
    *   **LLM의 환각 (사실과 다른 정보 생성) 현상 감소**  
        *   LLM이 잘못된 정보를 생성하는 ‘환각’ 문제를 줄이기 위해, 검색된 사실 데이터를 기반으로 응답을 생성합니다.
    *   **LLM 응답에 대한 투명성 확보 (정보 출처 확인 가능)**  
        *   RAG는 응답의 출처를 명확히 제공하여 신뢰도를 높입니다. 예: “이 정보는 2025년 5월 회사 보고서에서 발췌”와 같은 출처 표기 가능.

*   **RAG 시스템 구성 요소:**  
    *   **지식 베이스 (Knowledge Base):** 외부 데이터 소스 (문서, 데이터베이스, API 등)  
        *   예: PDF 보고서, 회사 위키, 실시간 뉴스 API, 고객 지원 기록 등 다양한 소스를 포함할 수 있습니다.
    *   **검색기 (Retriever):** 사용자 쿼리를 기반으로 지식 베이스에서 관련 정보 검색  
        *   검색기는 쿼리와 가장 관련성 높은 데이터를 빠르게 찾아냅니다. 예: “2025년 매출 전망” 질문에 대해 최신 재무 보고서를 검색.
    *   **생성기 (Generator):** 검색된 정보와 쿼리를 결합하여 최종 응답 생성 (LLM)  
        *   LLM은 검색된 데이터를 프롬프트에 통합해 자연스럽고 정확한 답변을 생성합니다.

*   **RAG 워크플로우:**  
    1.  **데이터 준비:**  
        *   문서 또는 데이터 소스를 작은 덩어리(chunk)로 분할하고, 임베딩 모델(예: BERT, Sentence-BERT)을 사용하여 벡터 임베딩으로 변환하여 벡터 데이터베이스(예: Pinecone, FAISS)에 저장.  
        *   예: 100페이지 분량의 보고서를 1페이지 단위로 나누고, 각 페이지를 벡터로 변환해 저장.
    2.  **검색:**  
        *   사용자 쿼리 또한 동일한 임베딩 모델로 벡터화하고, 벡터 데이터베이스에서 유사한 벡터를 검색.  
        *   예: “2025년 AI 트렌드” 쿼리가 최신 AI 보고서의 관련 섹션을 검색.
    3.  **프롬프트 보강:**  
        *   검색된 텍스트와 쿼리를 결합해 LLM에 전달할 프롬프트를 생성.  
        *   예: “2025년 AI 트렌드에 대해 설명하되, 다음 문서를 참조: [검색된 보고서 내용].”
    4.  **생성:**  
        *   LLM이 검색된 컨텍스트를 기반으로 응답을 생성.  
        *   예: “2025년 AI 트렌드는 생성형 AI와 에지 컴퓨팅의 융합이 주도할 것으로 보입니다.”
    5.  **응답:**  
        *   모델은 사전 훈련된 지식뿐 아니라 검색된 최신 데이터를 기반으로 답변을 제공하여 정확성과 신뢰성을 높입니다.

*   **검색기(Retriever) 모듈 상세:**  
    *   **임베딩:** 텍스트의 의미를 수치적으로 표현하는 과정 (단어 간의 관계 파악) 
        *   예: “AI 혁신”과 “인공지능 발전”은 의미적으로 유사한 벡터로 변환됩니다.
    *   **벡터 데이터베이스:** 고차원 공간에서 유사성 검색에 최적화된 데이터베이스 (AWS Open Search, Google Alloy DB, Pine Cone 등)
        *   벡터 데이터베이스는 빠르고 효율적인 유사성 검색을 지원하며, 대규모 데이터에서도 빠르게 결과를 반환합니다.
    *   **검색 방법:**  
        *   **밀집 검색 (Dense Retrieval):** 쿼리와 문서의 벡터 간 코사인 유사도 등을 비교하여 관련성 높은 결과를 선별.  
            *   예: “AI 윤리” 쿼리에 대해 윤리 관련 논문을 우선적으로 검색.
        *   **하이브리드 검색 (Hybrid Search):** 밀집 검색과 키워드 검색(BM25 등)을 결합해 정확도와 포괄성을 높임.  
            *   예: 키워드 “AI”와 의미적 유사성을 함께 고려해 검색.
        *   **재정렬 (Reranking):** 초기 검색 결과를 LLM 또는 별도 모델로 재평가해 순위를 조정.  
            *   예: 검색된 10개 문서 중 가장 관련성 높은 3개를 상위로 재정렬.
        *   **다단계 검색 (Multistep Retrieval):** 복잡한 쿼리를 하위 쿼리로 분할하여 단계적으로 검색.  
            *   예: “AI와 의료의 결합” 쿼리를 “AI 기술”과 “의료 응용”으로 나누어 검색 후 통합.

*   **생성기(Generator) 모듈 상세:**  
    *   **프롬프트 포맷:** 시스템 지침, 검색된 컨텍스트, 사용자 쿼리, 출력 형식 지침 포함**  
        *   예: “다음 데이터를 기반으로 간결한 답변을 제공하시오: [검색된 데이터]. 쿼리: [사용자 질문].”
    *   **융합 메커니즘:** 검색된 정보를 생성 과정에 통합하는 방법**  
        *   **초기 융합 (Early Fusion):** 검색된 데이터를 프롬프트에 포함시켜 LLM이 처음부터 이를 고려.  
            *   예: 검색된 문서를 프롬프트에 추가해 바로 답변 생성.
        *   **후기 융합 (Late Fusion):** LLM이 먼저 초안을 생성한 후, 검색된 데이터를 기반으로 수정.  
            *   예: 초기 답변을 생성한 뒤, 검색된 최신 데이터를 반영해 수정.
        *   **반복 융합 (Iterative Fusion):** 검색과 생성을 반복하여 점진적으로 답변을 개선.  
            *   예: 초기 답변 후 추가 검색을 통해 더 구체적인 정보 반영.
        *   **적응형 융합 (Adaptive Fusion):** 쿼리 복잡도에 따라 검색 데이터와 LLM 지식의 비중을 조정.  
            *   예: 간단한 질문은 LLM 지식 위주, 복잡한 질문은 검색 데이터 위주로 답변.

*   **RAG 시스템의 비즈니스 가치 (ROI):**  
    *   **비용 효율성:** LLM 미세 조정(Fine-tuning) 대비 저렴한 비용**  
        *   미세 조정은 대규모 데이터와 컴퓨팅 자원이 필요하지만, RAG는 기존 LLM에 검색 기능을 추가해 비용을 절감.
    *   **환각 감소:** 사실에 기반한 응답 생성으로 정확성 향상**  
        *   예: 고객 문의에 대해 잘못된 정보를 제공할 가능성 감소.
    *   **최신 정보 유지:** 새로운 정보에 대한 즉각적인 접근**  
        *   예: 최신 제품 업데이트나 시장 동향을 즉시 반영.
    *   **설명 가능성:** 응답에 대한 출처 제공**  
        *   예: “이 답변은 2025년 5월 10일자 보고서에서 가져옴”과 같은 명확한 출처 제공.
    *   **도메인 특화:** 특정 분야의 지식 및 용어 활용 가능**  
        *   예: 의료 AI가 최신 의학 논문을 참조해 전문 용어로 답변.

*   **RAG 활용 사례:**  
    *   **고객 지원:** FAQ, 제품 문서 등을 활용하여 고객 문의에 대한 신속하고 정확한 답변 제공**  
        *   예: 고객이 “제품 A의 최신 기능은?”이라고 물으면, 최신 매뉴얼을 검색해 답변.
    *   **연구:** 연구 논문, 보고서 등을 검색하여 연구 자료 조사 및 분석 지원**  
        *   예: 학자가 “2025년 AI 윤리 동향”을 조사할 때 관련 논문을 자동 검색.
    *   **콘텐츠 제작:** 브랜드 가이드라인, 스타일 가이드에 맞춰 콘텐츠 초안 생성 및 사실 확인**  
        *   예: 마케팅 팀이 브랜드 톤에 맞는 광고 문구를 생성하며 사실 확인.
    *   **추천 시스템:** 사용자 정보와 상품 정보를 결합하여 개인화된 추천 제공**  
        *   예: 전자상거래 플랫폼에서 사용자 구매 기록과 제품 데이터를 결합해 추천.

### 1.4 **결론**

RAG는 LLM의 지식 한계와 환각 문제를 보완하며, 최신 데이터와 도메인 특화 지식을 활용해 신뢰도 높은 응답을 제공하는 강력한 기술입니다. 고객 지원, 연구, 콘텐츠 제작 등 다양한 분야에서 비즈니스 가치를 창출하며, 비용 효율성과 설명 가능성을 통해 기업의 AI 도입을 가속화합니다.



## 2. 멀티모달 라이브 에이전트 구축 with Gemini API & Agent Development Kit (ADK) 요약

**주요 내용:**

*   **두 가지 방법으로 멀티모달 라이브 에이전트 구축:**
    1.  Gemini API 사용
    2.  Google ADK (Agent Development Kit) 사용
*   **발표자:**
    *   Sita (진행)
    *   Heiko (Gen AI Black belt)
    *   Sokratis (Gen AI Black belt)

**1. Gemini API를 이용한 멀티모달 라이브 에이전트 구축 (Heiko):**

*   **아키텍처:**
    *   **Client (UI):** 브라우저
    *   **Proxy (GenAI Python SDK):**  Multimodal Live API 연결, 툴 사용 및 인증 관리. 모든 요청을 Live API로 라우팅.
    *   **Live API:** 에이전트의 핵심 두뇌 (Google 제공).
    *   **Custom Tools (예: get-weather-tool):**  Cloud Run 함수로 실행, 필요에 따라 날씨 API와 상호작용.
*   **동작 방식:**
    1.  사용자 요청 (예: "런던 날씨 알려줘")
    2.  Gemini Multimodal Live API가 요청 분석 후 날씨 관련 툴 필요 판단.
    3.  Function call을 통해 툴 핸들러에 요청 전달.
    4.  툴 핸들러가 해당 툴 (get-weather-tool) 실행.
    5.  툴이 날씨 API에서 실시간 날씨 정보 획득.
    6.  Live API로 정보 반환.
    7.  Live API가 자연스러운 언어로 응답 생성 ("런던은 14도, 구름 조금").
*   **Tool Handler:**
    *   서버 측 코드의 핵심.
    *   Live API에서 반환된 툴을 실행.
    *   Live API function call과 해당 툴을 매칭.
*   **Get-Weather-Tool:**
    *   Cloud Function으로 구현.
    *   OpenWeather API와 상호작용하여 실시간 날씨 정보 획득.

**2. Agent Development Kit (ADK)를 이용한 멀티모달 라이브 에이전트 구축 (Sokratis):**

*   **ADK의 장점:** Gemini Live Streaming API와의 상호작용 단순화 (WebSockets 직접 제어 불필요).
*   **기존 방식과의 차이점:** Proxy 제거, ADK 구현 추가
*   **필수 함수:**
    *   `handle_client_messages`:  오디오, 텍스트, 비디오 데이터를 `live_request_queue`에 푸시.
    *   `handle_agent_responses`:  ADK로부터의 이벤트 (interrupt, function call, function response, text, image, audio) 수신 및 처리.
*   **코드 예시:**
    *   WebSocket을 통해 수신된 메시지를 JSON 객체로 파싱.
    *   데이터 타입 (audio, image, text)에 따라 `live_request_queue`에 적절한 형태로 추가.
    *   ADK에서 반환된 이벤트를 기반으로 UI에 피드백 (텍스트, 오디오 등) 제공.
*   **라이브 에이전트 인스턴스화:**
    *   `voice_config` 설정 (음성 타입 설정).
    *   `run_config` 설정 (오디오 트랜스크립트 활성화 등).
    *   `runner.run_live` 호출하여 일반 에이전트를 라이브 에이전트로 변환.

**핵심 요약:** ADK를 사용하면 복잡한 프록시 서버 및 WebSocket 관리를 간소화하여 개발자가 에이전트 로직 및 기능에 집중할 수 있도록 지원합니다.


## 3. AI 코딩: 현황, 미래, 그리고 개발자의 역할 변화

**핵심 내용:**

*   **AI 코딩의 성장 가능성:**
    *   AI는 단순한 고수준 언어 추상화 도구를 넘어, 컴파일러 설계 방식에 혁신을 가져올 잠재력을 지님.
    *   소비자용 챗봇 시장 다음으로 큰 AI 시장이며, 동질적인 시장으로 볼 때 소비자용 챗봇보다 규모가 클 수도 있음.

*   **AI 코딩 시장의 특징:**
    *   기존의 스택 오버플로우(Stack Overflow)와 같은 정보 탐색 행위를 AI 모델로 대체하는 형태로, 이미 존재하는 사용자 행동과 시장을 활용.
    *   개발자들은 AI 기술을 활용해 자신의 문제를 먼저 해결하고, 생산성 향상을 추구하는 경향이 있음.
    *   AI 코딩은 입력/출력이 명확하게 검증 가능한 문제 해결에 유리하며, 다양한 문제를 코딩으로 재구성할 수 있다는 장점이 있음.

*   **AI 코딩 시장의 잠재력:**
    *   전 세계 3천만 명의 개발자가 창출하는 연간 가치는 3조 달러에 달하며, AI 코딩을 통해 개발자 생산성을 2배로 향상시킬 경우 3조 달러의 추가 가치 창출 가능.

*   **AI 코딩 시대의 개발자 역할 변화:**
    *   코딩 과정에서 모델과 함께 명세서를 작성하고 구현 방식을 논의하며, AI가 생성한 코드를 검토하는 방식으로 변화.
    *   미래에는 제품 관리자처럼 명세서를 작성하고, AI가 코드를 작성하면 디버깅을 담당하거나 QA 엔지니어처럼 코드의 적합성을 테스트하는 역할로 변화할 가능성도 있음.

*   **AI 코딩 활용 사례:**
    *   새로운 소프트웨어 개발 시, 모델과 협력하여 명세서를 작성하고, 개발 방법론에 대한 맥락을 제공하며, 모델과 함께 구현 방식을 결정.
    *   최신 문서를 검색하고 활용하거나, 선형(Linear) 티켓을 활용하여 아이디어를 구현하는 데 AI 에이전트를 활용.
    *   프론트엔드 개발과 같이 복잡하고 번거로운 작업에 AI 모델을 활용.

*   **AI 코딩의 한계 및 고려 사항:**
    *   모델이 제공하는 정보의 정확성을 검증하고, 환각(hallucination) 현상에 주의해야 함.
    *   분산 시스템과 같이 복잡하고 새로운 문제 해결에는 아직 한계가 존재하며, 더 많은 맥락과 도구 활용 능력이 필요함.
    *   모델이 알지 못하는 것을 모른다고 말하지 못하는 문제점을 개선해야 함.

*   **AI 코딩 시대의 교육 방향:**
    *   컴퓨터 과학 교육은 문제 해결 능력, 알고리즘 이해, 아키텍처 및 데이터 흐름 설명 능력과 같이 더 추상적인 개념에 집중해야 함.
    *   AI 코딩에 대한 맹신보다는, AI가 제공하는 도구를 활용하여 개발자가 더 높은 수준의 작업을 수행할 수 있도록 교육해야 함.

*   **향후 전망:**
    *   AI는 단순히 도구를 사용하는 것을 넘어, 컴퓨터 프로그래밍 방식 자체를 변화시킬 잠재력을 지니고 있음.
    *   AI 에이전트와 같은 도구를 활용하여 프롬프트를 통해 코드를 생성하는 방식이 발전할 가능성이 있음.
    *   AI를 활용하여 레거시 코드를 현대적인 언어로 마이그레이션하고, 코드 생성 의도를 기록하는 방식으로 활용할 수 있음.

**결론:**

AI 코딩은 개발자의 생산성을 향상시키고 새로운 가치를 창출할 수 있는 혁신적인 기술이지만, 한계점과 고려 사항을 충분히 이해하고 활용해야 한다. 미래에는 개발자의 역할이 변화하고, 새로운 교육 방식이 필요할 것으로 예상된다.


